2025/03/29 12:06:48 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /usr/local/cuda-12.1
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
    PyTorch: 2.1.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.1+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 0
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/03/29 12:06:49 - mmengine - INFO - Config:
crop_size = (
    512,
    512,
)
data_root = '/home/face/kaichengyang/xiaoxinghu/data'
dataset_type = 'ISPRSDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=2000,
        max_keep_ckpts=1,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
exp_name = 'DG_spatial_24_cutoff_0.3_fft_pre_6'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        adapter_config=dict(
            cutoff_ratio=0.3,
            dim=24,
            fft_layer=[
                18,
                19,
                20,
                21,
                22,
                23,
            ],
            scale=0.1,
            with_token=False),
        block_chunks=0,
        depth=24,
        embed_dim=1024,
        ffn_bias=True,
        ffn_layer='mlp',
        img_size=512,
        init_cfg=dict(
            checkpoint='checkpoints/dinov2_converted.pth', type='Pretrained'),
        init_values=1e-05,
        mlp_ratio=4,
        moe_adapter_type='earth_adapter',
        num_heads=16,
        patch_size=16,
        proj_bias=True,
        qkv_bias=True,
        type='MOE_Adpter_DinoVisionTransformer'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            1024,
            1024,
            1024,
            1024,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=6,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(crop_size=(
        512,
        512,
    ), mode='slide', stride=(
        341,
        341,
    )),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 19
optim_wrapper = dict(
    constructor='PEFTOptimWrapperConstructor',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'learnable_tokens': dict(decay_mult=0.0, lr_mult=1.0),
            'level_embed': dict(decay_mult=0.0, lr_mult=1.0),
            'norm': dict(decay_mult=0.0),
            'query_embed': dict(decay_mult=0.0, lr_mult=1.0),
            'reins.scale': dict(decay_mult=0.0, lr_mult=1.0)
        }),
        norm_decay_mult=0.0))
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=20000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='vaihingen/img_dir/val',
            seg_map_path='vaihingen/ann_dir/val'),
        data_root='/home/face/kaichengyang/xiaoxinghu/data',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                512,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        512,
        512,
    ), type='Resize'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=2000)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        data_prefix=dict(
            img_path='potsdamRGB/img_dir/train',
            seg_map_path='potsdamRGB/ann_dir/train'),
        data_root='/home/face/kaichengyang/xiaoxinghu/data',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    512,
                    512,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    512,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            512,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='vaihingen/img_dir/val',
            seg_map_path='vaihingen/ann_dir/val'),
        data_root='/home/face/kaichengyang/xiaoxinghu/data',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                512,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(type='TensorboardVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
        dict(type='TensorboardVisBackend'),
    ])
work_dir = './work_dirs/pr2vi/DG_spatial_24_cutoff_0.3_fft_pre_6/60747_seed0'

2025/03/29 12:06:59 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/03/29 12:06:59 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.scale
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.1.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.1.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.3.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.3.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.4.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.4.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.5.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.5.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.6.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.6.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.7.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.7.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.8.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.8.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.9.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.9.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.10.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.10.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.11.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.11.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.12.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.12.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.13.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.13.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.14.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.14.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.15.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.15.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.16.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.16.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.17.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.17.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.18.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.18.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.19.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.19.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.20.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.20.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.21.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.21.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.22.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.22.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.23.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.23.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.0.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.0.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.1.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.1.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.2.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.2.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.3.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.3.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.4.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.4.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.5.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.5.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.6.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.6.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.7.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.7.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.8.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.8.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.9.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.9.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.10.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.10.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.11.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.11.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.12.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.12.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.13.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.13.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.14.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.14.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.15.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.15.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.16.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.16.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.17.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.17.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.18.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.18.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.19.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.19.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.20.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.20.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.21.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.21.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.22.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.22.bias
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.23.weight
2025/03/29 12:07:00 - mmengine - INFO - set_requires_grad----refine_feat.router.23.bias
2025/03/29 12:07:00 - mmengine - INFO - Total trainable params--3737376, All params--307937056, Ratio--1.2%
2025/03/29 12:07:00 - mmengine - INFO - set_train----.refine_feat
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.scale:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.0.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.0.bias:num of params=24
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.2.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.2.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.0.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.0.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.1.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.1.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.2.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.2.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.3.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.3.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.4.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.4.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.5.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.5.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.6.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.6.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.7.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.7.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.8.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.8.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.9.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.9.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.10.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.10.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.11.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.11.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.12.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.12.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.13.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.13.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.14.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.14.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.15.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.15.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.16.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.16.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.17.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.17.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.18.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.18.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.19.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.19.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.20.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.20.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.21.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.21.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.22.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.22.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.23.weight:num of params=3072
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.23.bias:num of params=3
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.conv.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.conv.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.conv.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.conv.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.conv.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.conv.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight:num of params=49152
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias:num of params=192
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias:num of params=96
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight:num of params=49152
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias:num of params=192
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias:num of params=96
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight:num of params=49152
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias:num of params=192
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias:num of params=96
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight:num of params=49152
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias:num of params=192
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias:num of params=96
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight:num of params=49152
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias:num of params=192
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias:num of params=96
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight:num of params=49152
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias:num of params=192
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight:num of params=24576
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias:num of params=96
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias:num of params=1024
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.level_encoding.weight:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.conv.weight:num of params=262144
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.conv.weight:num of params=589824
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.mask_feature.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.mask_feature.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias:num of params=2048
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.1.weight:num of params=524288
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:num of params=25600
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:num of params=25600
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:num of params=768
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.cls_embed.weight:num of params=1792
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.cls_embed.bias:num of params=7
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.0.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.0.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.2.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.2.bias:num of params=256
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.4.weight:num of params=65536
2025/03/29 12:07:00 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.4.bias:num of params=256
2025/03/29 12:07:00 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
2025/03/29 12:07:02 - mmengine - INFO - load model from: checkpoints/dinov2_converted.pth
2025/03/29 12:07:02 - mmengine - INFO - Loads checkpoint by local backend from path: checkpoints/dinov2_converted.pth
2025/03/29 12:07:04 - mmengine - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: refine_feat.scale, refine_feat.layer_norm.0.weight, refine_feat.layer_norm.0.bias, refine_feat.layer_norm.1.weight, refine_feat.layer_norm.1.bias, refine_feat.layer_norm.2.weight, refine_feat.layer_norm.2.bias, refine_feat.layer_norm.3.weight, refine_feat.layer_norm.3.bias, refine_feat.layer_norm.4.weight, refine_feat.layer_norm.4.bias, refine_feat.layer_norm.5.weight, refine_feat.layer_norm.5.bias, refine_feat.layer_norm.6.weight, refine_feat.layer_norm.6.bias, refine_feat.layer_norm.7.weight, refine_feat.layer_norm.7.bias, refine_feat.layer_norm.8.weight, refine_feat.layer_norm.8.bias, refine_feat.layer_norm.9.weight, refine_feat.layer_norm.9.bias, refine_feat.layer_norm.10.weight, refine_feat.layer_norm.10.bias, refine_feat.layer_norm.11.weight, refine_feat.layer_norm.11.bias, refine_feat.layer_norm.12.weight, refine_feat.layer_norm.12.bias, refine_feat.layer_norm.13.weight, refine_feat.layer_norm.13.bias, refine_feat.layer_norm.14.weight, refine_feat.layer_norm.14.bias, refine_feat.layer_norm.15.weight, refine_feat.layer_norm.15.bias, refine_feat.layer_norm.16.weight, refine_feat.layer_norm.16.bias, refine_feat.layer_norm.17.weight, refine_feat.layer_norm.17.bias, refine_feat.layer_norm.18.weight, refine_feat.layer_norm.18.bias, refine_feat.layer_norm.19.weight, refine_feat.layer_norm.19.bias, refine_feat.layer_norm.20.weight, refine_feat.layer_norm.20.bias, refine_feat.layer_norm.21.weight, refine_feat.layer_norm.21.bias, refine_feat.layer_norm.22.weight, refine_feat.layer_norm.22.bias, refine_feat.layer_norm.23.weight, refine_feat.layer_norm.23.bias, refine_feat.mlp_list1.0.0.weight, refine_feat.mlp_list1.0.0.bias, refine_feat.mlp_list1.0.2.weight, refine_feat.mlp_list1.0.2.bias, refine_feat.mlp_list1.1.0.weight, refine_feat.mlp_list1.1.0.bias, refine_feat.mlp_list1.1.2.weight, refine_feat.mlp_list1.1.2.bias, refine_feat.mlp_list1.2.0.weight, refine_feat.mlp_list1.2.0.bias, refine_feat.mlp_list1.2.2.weight, refine_feat.mlp_list1.2.2.bias, refine_feat.mlp_list1.3.0.weight, refine_feat.mlp_list1.3.0.bias, refine_feat.mlp_list1.3.2.weight, refine_feat.mlp_list1.3.2.bias, refine_feat.mlp_list1.4.0.weight, refine_feat.mlp_list1.4.0.bias, refine_feat.mlp_list1.4.2.weight, refine_feat.mlp_list1.4.2.bias, refine_feat.mlp_list1.5.0.weight, refine_feat.mlp_list1.5.0.bias, refine_feat.mlp_list1.5.2.weight, refine_feat.mlp_list1.5.2.bias, refine_feat.mlp_list1.6.0.weight, refine_feat.mlp_list1.6.0.bias, refine_feat.mlp_list1.6.2.weight, refine_feat.mlp_list1.6.2.bias, refine_feat.mlp_list1.7.0.weight, refine_feat.mlp_list1.7.0.bias, refine_feat.mlp_list1.7.2.weight, refine_feat.mlp_list1.7.2.bias, refine_feat.mlp_list1.8.0.weight, refine_feat.mlp_list1.8.0.bias, refine_feat.mlp_list1.8.2.weight, refine_feat.mlp_list1.8.2.bias, refine_feat.mlp_list1.9.0.weight, refine_feat.mlp_list1.9.0.bias, refine_feat.mlp_list1.9.2.weight, refine_feat.mlp_list1.9.2.bias, refine_feat.mlp_list1.10.0.weight, refine_feat.mlp_list1.10.0.bias, refine_feat.mlp_list1.10.2.weight, refine_feat.mlp_list1.10.2.bias, refine_feat.mlp_list1.11.0.weight, refine_feat.mlp_list1.11.0.bias, refine_feat.mlp_list1.11.2.weight, refine_feat.mlp_list1.11.2.bias, refine_feat.mlp_list1.12.0.weight, refine_feat.mlp_list1.12.0.bias, refine_feat.mlp_list1.12.2.weight, refine_feat.mlp_list1.12.2.bias, refine_feat.mlp_list1.13.0.weight, refine_feat.mlp_list1.13.0.bias, refine_feat.mlp_list1.13.2.weight, refine_feat.mlp_list1.13.2.bias, refine_feat.mlp_list1.14.0.weight, refine_feat.mlp_list1.14.0.bias, refine_feat.mlp_list1.14.2.weight, refine_feat.mlp_list1.14.2.bias, refine_feat.mlp_list1.15.0.weight, refine_feat.mlp_list1.15.0.bias, refine_feat.mlp_list1.15.2.weight, refine_feat.mlp_list1.15.2.bias, refine_feat.mlp_list1.16.0.weight, refine_feat.mlp_list1.16.0.bias, refine_feat.mlp_list1.16.2.weight, refine_feat.mlp_list1.16.2.bias, refine_feat.mlp_list1.17.0.weight, refine_feat.mlp_list1.17.0.bias, refine_feat.mlp_list1.17.2.weight, refine_feat.mlp_list1.17.2.bias, refine_feat.mlp_list1.18.0.weight, refine_feat.mlp_list1.18.0.bias, refine_feat.mlp_list1.18.2.weight, refine_feat.mlp_list1.18.2.bias, refine_feat.mlp_list1.19.0.weight, refine_feat.mlp_list1.19.0.bias, refine_feat.mlp_list1.19.2.weight, refine_feat.mlp_list1.19.2.bias, refine_feat.mlp_list1.20.0.weight, refine_feat.mlp_list1.20.0.bias, refine_feat.mlp_list1.20.2.weight, refine_feat.mlp_list1.20.2.bias, refine_feat.mlp_list1.21.0.weight, refine_feat.mlp_list1.21.0.bias, refine_feat.mlp_list1.21.2.weight, refine_feat.mlp_list1.21.2.bias, refine_feat.mlp_list1.22.0.weight, refine_feat.mlp_list1.22.0.bias, refine_feat.mlp_list1.22.2.weight, refine_feat.mlp_list1.22.2.bias, refine_feat.mlp_list1.23.0.weight, refine_feat.mlp_list1.23.0.bias, refine_feat.mlp_list1.23.2.weight, refine_feat.mlp_list1.23.2.bias, refine_feat.mlp_list2.0.0.weight, refine_feat.mlp_list2.0.0.bias, refine_feat.mlp_list2.0.2.weight, refine_feat.mlp_list2.0.2.bias, refine_feat.mlp_list2.1.0.weight, refine_feat.mlp_list2.1.0.bias, refine_feat.mlp_list2.1.2.weight, refine_feat.mlp_list2.1.2.bias, refine_feat.mlp_list2.2.0.weight, refine_feat.mlp_list2.2.0.bias, refine_feat.mlp_list2.2.2.weight, refine_feat.mlp_list2.2.2.bias, refine_feat.mlp_list2.3.0.weight, refine_feat.mlp_list2.3.0.bias, refine_feat.mlp_list2.3.2.weight, refine_feat.mlp_list2.3.2.bias, refine_feat.mlp_list2.4.0.weight, refine_feat.mlp_list2.4.0.bias, refine_feat.mlp_list2.4.2.weight, refine_feat.mlp_list2.4.2.bias, refine_feat.mlp_list2.5.0.weight, refine_feat.mlp_list2.5.0.bias, refine_feat.mlp_list2.5.2.weight, refine_feat.mlp_list2.5.2.bias, refine_feat.mlp_list2.6.0.weight, refine_feat.mlp_list2.6.0.bias, refine_feat.mlp_list2.6.2.weight, refine_feat.mlp_list2.6.2.bias, refine_feat.mlp_list2.7.0.weight, refine_feat.mlp_list2.7.0.bias, refine_feat.mlp_list2.7.2.weight, refine_feat.mlp_list2.7.2.bias, refine_feat.mlp_list2.8.0.weight, refine_feat.mlp_list2.8.0.bias, refine_feat.mlp_list2.8.2.weight, refine_feat.mlp_list2.8.2.bias, refine_feat.mlp_list2.9.0.weight, refine_feat.mlp_list2.9.0.bias, refine_feat.mlp_list2.9.2.weight, refine_feat.mlp_list2.9.2.bias, refine_feat.mlp_list2.10.0.weight, refine_feat.mlp_list2.10.0.bias, refine_feat.mlp_list2.10.2.weight, refine_feat.mlp_list2.10.2.bias, refine_feat.mlp_list2.11.0.weight, refine_feat.mlp_list2.11.0.bias, refine_feat.mlp_list2.11.2.weight, refine_feat.mlp_list2.11.2.bias, refine_feat.mlp_list2.12.0.weight, refine_feat.mlp_list2.12.0.bias, refine_feat.mlp_list2.12.2.weight, refine_feat.mlp_list2.12.2.bias, refine_feat.mlp_list2.13.0.weight, refine_feat.mlp_list2.13.0.bias, refine_feat.mlp_list2.13.2.weight, refine_feat.mlp_list2.13.2.bias, refine_feat.mlp_list2.14.0.weight, refine_feat.mlp_list2.14.0.bias, refine_feat.mlp_list2.14.2.weight, refine_feat.mlp_list2.14.2.bias, refine_feat.mlp_list2.15.0.weight, refine_feat.mlp_list2.15.0.bias, refine_feat.mlp_list2.15.2.weight, refine_feat.mlp_list2.15.2.bias, refine_feat.mlp_list2.16.0.weight, refine_feat.mlp_list2.16.0.bias, refine_feat.mlp_list2.16.2.weight, refine_feat.mlp_list2.16.2.bias, refine_feat.mlp_list2.17.0.weight, refine_feat.mlp_list2.17.0.bias, refine_feat.mlp_list2.17.2.weight, refine_feat.mlp_list2.17.2.bias, refine_feat.mlp_list2.18.0.weight, refine_feat.mlp_list2.18.0.bias, refine_feat.mlp_list2.18.2.weight, refine_feat.mlp_list2.18.2.bias, refine_feat.mlp_list2.19.0.weight, refine_feat.mlp_list2.19.0.bias, refine_feat.mlp_list2.19.2.weight, refine_feat.mlp_list2.19.2.bias, refine_feat.mlp_list2.20.0.weight, refine_feat.mlp_list2.20.0.bias, refine_feat.mlp_list2.20.2.weight, refine_feat.mlp_list2.20.2.bias, refine_feat.mlp_list2.21.0.weight, refine_feat.mlp_list2.21.0.bias, refine_feat.mlp_list2.21.2.weight, refine_feat.mlp_list2.21.2.bias, refine_feat.mlp_list2.22.0.weight, refine_feat.mlp_list2.22.0.bias, refine_feat.mlp_list2.22.2.weight, refine_feat.mlp_list2.22.2.bias, refine_feat.mlp_list2.23.0.weight, refine_feat.mlp_list2.23.0.bias, refine_feat.mlp_list2.23.2.weight, refine_feat.mlp_list2.23.2.bias, refine_feat.mlp_list3.0.0.weight, refine_feat.mlp_list3.0.0.bias, refine_feat.mlp_list3.0.2.weight, refine_feat.mlp_list3.0.2.bias, refine_feat.mlp_list3.1.0.weight, refine_feat.mlp_list3.1.0.bias, refine_feat.mlp_list3.1.2.weight, refine_feat.mlp_list3.1.2.bias, refine_feat.mlp_list3.2.0.weight, refine_feat.mlp_list3.2.0.bias, refine_feat.mlp_list3.2.2.weight, refine_feat.mlp_list3.2.2.bias, refine_feat.mlp_list3.3.0.weight, refine_feat.mlp_list3.3.0.bias, refine_feat.mlp_list3.3.2.weight, refine_feat.mlp_list3.3.2.bias, refine_feat.mlp_list3.4.0.weight, refine_feat.mlp_list3.4.0.bias, refine_feat.mlp_list3.4.2.weight, refine_feat.mlp_list3.4.2.bias, refine_feat.mlp_list3.5.0.weight, refine_feat.mlp_list3.5.0.bias, refine_feat.mlp_list3.5.2.weight, refine_feat.mlp_list3.5.2.bias, refine_feat.mlp_list3.6.0.weight, refine_feat.mlp_list3.6.0.bias, refine_feat.mlp_list3.6.2.weight, refine_feat.mlp_list3.6.2.bias, refine_feat.mlp_list3.7.0.weight, refine_feat.mlp_list3.7.0.bias, refine_feat.mlp_list3.7.2.weight, refine_feat.mlp_list3.7.2.bias, refine_feat.mlp_list3.8.0.weight, refine_feat.mlp_list3.8.0.bias, refine_feat.mlp_list3.8.2.weight, refine_feat.mlp_list3.8.2.bias, refine_feat.mlp_list3.9.0.weight, refine_feat.mlp_list3.9.0.bias, refine_feat.mlp_list3.9.2.weight, refine_feat.mlp_list3.9.2.bias, refine_feat.mlp_list3.10.0.weight, refine_feat.mlp_list3.10.0.bias, refine_feat.mlp_list3.10.2.weight, refine_feat.mlp_list3.10.2.bias, refine_feat.mlp_list3.11.0.weight, refine_feat.mlp_list3.11.0.bias, refine_feat.mlp_list3.11.2.weight, refine_feat.mlp_list3.11.2.bias, refine_feat.mlp_list3.12.0.weight, refine_feat.mlp_list3.12.0.bias, refine_feat.mlp_list3.12.2.weight, refine_feat.mlp_list3.12.2.bias, refine_feat.mlp_list3.13.0.weight, refine_feat.mlp_list3.13.0.bias, refine_feat.mlp_list3.13.2.weight, refine_feat.mlp_list3.13.2.bias, refine_feat.mlp_list3.14.0.weight, refine_feat.mlp_list3.14.0.bias, refine_feat.mlp_list3.14.2.weight, refine_feat.mlp_list3.14.2.bias, refine_feat.mlp_list3.15.0.weight, refine_feat.mlp_list3.15.0.bias, refine_feat.mlp_list3.15.2.weight, refine_feat.mlp_list3.15.2.bias, refine_feat.mlp_list3.16.0.weight, refine_feat.mlp_list3.16.0.bias, refine_feat.mlp_list3.16.2.weight, refine_feat.mlp_list3.16.2.bias, refine_feat.mlp_list3.17.0.weight, refine_feat.mlp_list3.17.0.bias, refine_feat.mlp_list3.17.2.weight, refine_feat.mlp_list3.17.2.bias, refine_feat.mlp_list3.18.0.weight, refine_feat.mlp_list3.18.0.bias, refine_feat.mlp_list3.18.2.weight, refine_feat.mlp_list3.18.2.bias, refine_feat.mlp_list3.19.0.weight, refine_feat.mlp_list3.19.0.bias, refine_feat.mlp_list3.19.2.weight, refine_feat.mlp_list3.19.2.bias, refine_feat.mlp_list3.20.0.weight, refine_feat.mlp_list3.20.0.bias, refine_feat.mlp_list3.20.2.weight, refine_feat.mlp_list3.20.2.bias, refine_feat.mlp_list3.21.0.weight, refine_feat.mlp_list3.21.0.bias, refine_feat.mlp_list3.21.2.weight, refine_feat.mlp_list3.21.2.bias, refine_feat.mlp_list3.22.0.weight, refine_feat.mlp_list3.22.0.bias, refine_feat.mlp_list3.22.2.weight, refine_feat.mlp_list3.22.2.bias, refine_feat.mlp_list3.23.0.weight, refine_feat.mlp_list3.23.0.bias, refine_feat.mlp_list3.23.2.weight, refine_feat.mlp_list3.23.2.bias, refine_feat.router.0.weight, refine_feat.router.0.bias, refine_feat.router.1.weight, refine_feat.router.1.bias, refine_feat.router.2.weight, refine_feat.router.2.bias, refine_feat.router.3.weight, refine_feat.router.3.bias, refine_feat.router.4.weight, refine_feat.router.4.bias, refine_feat.router.5.weight, refine_feat.router.5.bias, refine_feat.router.6.weight, refine_feat.router.6.bias, refine_feat.router.7.weight, refine_feat.router.7.bias, refine_feat.router.8.weight, refine_feat.router.8.bias, refine_feat.router.9.weight, refine_feat.router.9.bias, refine_feat.router.10.weight, refine_feat.router.10.bias, refine_feat.router.11.weight, refine_feat.router.11.bias, refine_feat.router.12.weight, refine_feat.router.12.bias, refine_feat.router.13.weight, refine_feat.router.13.bias, refine_feat.router.14.weight, refine_feat.router.14.bias, refine_feat.router.15.weight, refine_feat.router.15.bias, refine_feat.router.16.weight, refine_feat.router.16.bias, refine_feat.router.17.weight, refine_feat.router.17.bias, refine_feat.router.18.weight, refine_feat.router.18.bias, refine_feat.router.19.weight, refine_feat.router.19.bias, refine_feat.router.20.weight, refine_feat.router.20.bias, refine_feat.router.21.weight, refine_feat.router.21.bias, refine_feat.router.22.weight, refine_feat.router.22.bias, refine_feat.router.23.weight, refine_feat.router.23.bias

Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.pos_embed - torch.Size([1, 1025, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.mask_token - torch.Size([1, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.patch_embed.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.norm.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.norm.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.refine_feat.scale - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.4.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.5.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.5.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.6.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.6.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.7.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.7.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.8.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.8.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.9.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.9.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.10.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.10.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.11.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.11.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.12.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.12.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.13.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.13.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.14.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.14.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.15.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.15.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.16.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.16.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.17.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.17.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.18.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.18.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.19.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.19.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.20.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.20.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.21.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.21.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.22.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.22.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.23.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.23.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.0.weight - torch.Size([24, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.0.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.2.weight - torch.Size([1024, 24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.0.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.1.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.2.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.2.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.3.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.3.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.4.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.4.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.5.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.5.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.6.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.6.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.7.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.7.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.8.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.8.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.9.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.9.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.10.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.10.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.11.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.11.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.12.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.12.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.13.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.13.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.14.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.14.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.15.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.15.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.16.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.16.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.17.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.17.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.18.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.18.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.19.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.19.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.20.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.20.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.21.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.21.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.22.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.22.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.23.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.23.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([7, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2025/03/29 12:07:07 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/03/29 12:07:07 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/03/29 12:07:07 - mmengine - INFO - Checkpoints will be saved to /home/face/kaichengyang/xiaoxinghu/Earth_Adapter/work_dirs/pr2vi/DG_spatial_24_cutoff_0.3_fft_pre_6/60747_seed0.
2025/03/29 12:09:44 - mmengine - INFO - Iter(train) [   50/20000]  base_lr: 9.9779e-05 lr: 9.9779e-05  eta: 17:26:52  time: 3.0031  data_time: 0.0214  memory: 15637  loss: 80.4165  decode.loss_cls: 2.3462  decode.loss_mask: 2.7655  decode.loss_dice: 3.9009  decode.d0.loss_cls: 3.8946  decode.d0.loss_mask: 2.2627  decode.d0.loss_dice: 3.3205  decode.d1.loss_cls: 1.6449  decode.d1.loss_mask: 2.1874  decode.d1.loss_dice: 3.2990  decode.d2.loss_cls: 1.6853  decode.d2.loss_mask: 2.2242  decode.d2.loss_dice: 3.3937  decode.d3.loss_cls: 1.7186  decode.d3.loss_mask: 2.2244  decode.d3.loss_dice: 3.3601  decode.d4.loss_cls: 1.7311  decode.d4.loss_mask: 2.2530  decode.d4.loss_dice: 3.4058  decode.d5.loss_cls: 1.7846  decode.d5.loss_mask: 2.2999  decode.d5.loss_dice: 3.4686  decode.d6.loss_cls: 1.9811  decode.d6.loss_mask: 2.4106  decode.d6.loss_dice: 3.5941  decode.d7.loss_cls: 2.1711  decode.d7.loss_mask: 2.5981  decode.d7.loss_dice: 3.6651  decode.d8.loss_cls: 2.2974  decode.d8.loss_mask: 2.7074  decode.d8.loss_dice: 3.8207
2025/03/29 12:12:08 - mmengine - INFO - Iter(train) [  100/20000]  base_lr: 9.9554e-05 lr: 9.9554e-05  eta: 16:37:48  time: 2.9783  data_time: 0.0225  memory: 10126  loss: 64.6336  decode.loss_cls: 1.4916  decode.loss_mask: 2.2296  decode.loss_dice: 2.8033  decode.d0.loss_cls: 3.7251  decode.d0.loss_mask: 2.1234  decode.d0.loss_dice: 2.8352  decode.d1.loss_cls: 1.2234  decode.d1.loss_mask: 2.1379  decode.d1.loss_dice: 2.6988  decode.d2.loss_cls: 1.0997  decode.d2.loss_mask: 2.2018  decode.d2.loss_dice: 2.6935  decode.d3.loss_cls: 1.0941  decode.d3.loss_mask: 2.2313  decode.d3.loss_dice: 2.6736  decode.d4.loss_cls: 1.2352  decode.d4.loss_mask: 2.2190  decode.d4.loss_dice: 2.6780  decode.d5.loss_cls: 1.2021  decode.d5.loss_mask: 2.2539  decode.d5.loss_dice: 2.7091  decode.d6.loss_cls: 1.3432  decode.d6.loss_mask: 2.2842  decode.d6.loss_dice: 2.7310  decode.d7.loss_cls: 1.2439  decode.d7.loss_mask: 2.2866  decode.d7.loss_dice: 2.7718  decode.d8.loss_cls: 1.3311  decode.d8.loss_mask: 2.3143  decode.d8.loss_dice: 2.7679
2025/03/29 12:14:38 - mmengine - INFO - Iter(train) [  150/20000]  base_lr: 9.9329e-05 lr: 9.9329e-05  eta: 16:35:08  time: 3.0210  data_time: 0.0251  memory: 10134  loss: 50.8244  decode.loss_cls: 1.0454  decode.loss_mask: 1.8141  decode.loss_dice: 2.1998  decode.d0.loss_cls: 3.6117  decode.d0.loss_mask: 1.6089  decode.d0.loss_dice: 2.3433  decode.d1.loss_cls: 0.8106  decode.d1.loss_mask: 1.7537  decode.d1.loss_dice: 2.2325  decode.d2.loss_cls: 0.6197  decode.d2.loss_mask: 1.8202  decode.d2.loss_dice: 2.2370  decode.d3.loss_cls: 0.6764  decode.d3.loss_mask: 1.7684  decode.d3.loss_dice: 2.1972  decode.d4.loss_cls: 0.7088  decode.d4.loss_mask: 1.7596  decode.d4.loss_dice: 2.2073  decode.d5.loss_cls: 0.7502  decode.d5.loss_mask: 1.8160  decode.d5.loss_dice: 2.2691  decode.d6.loss_cls: 0.7844  decode.d6.loss_mask: 1.7876  decode.d6.loss_dice: 2.1970  decode.d7.loss_cls: 0.8112  decode.d7.loss_mask: 1.8063  decode.d7.loss_dice: 2.1918  decode.d8.loss_cls: 0.9410  decode.d8.loss_mask: 1.8575  decode.d8.loss_dice: 2.1977
2025/03/29 12:17:09 - mmengine - INFO - Iter(train) [  200/20000]  base_lr: 9.9104e-05 lr: 9.9104e-05  eta: 16:33:23  time: 3.0132  data_time: 0.0231  memory: 10124  loss: 46.5714  decode.loss_cls: 0.6911  decode.loss_mask: 1.7511  decode.loss_dice: 2.1079  decode.d0.loss_cls: 3.3423  decode.d0.loss_mask: 1.5430  decode.d0.loss_dice: 2.2363  decode.d1.loss_cls: 0.5215  decode.d1.loss_mask: 1.6861  decode.d1.loss_dice: 2.0361  decode.d2.loss_cls: 0.4378  decode.d2.loss_mask: 1.7264  decode.d2.loss_dice: 2.0199  decode.d3.loss_cls: 0.4621  decode.d3.loss_mask: 1.7553  decode.d3.loss_dice: 2.0386  decode.d4.loss_cls: 0.4631  decode.d4.loss_mask: 1.7429  decode.d4.loss_dice: 2.0963  decode.d5.loss_cls: 0.4895  decode.d5.loss_mask: 1.8040  decode.d5.loss_dice: 2.1390  decode.d6.loss_cls: 0.5346  decode.d6.loss_mask: 1.8203  decode.d6.loss_dice: 2.1295  decode.d7.loss_cls: 0.5834  decode.d7.loss_mask: 1.7989  decode.d7.loss_dice: 2.1408  decode.d8.loss_cls: 0.6286  decode.d8.loss_mask: 1.7599  decode.d8.loss_dice: 2.0852
2025/03/29 12:19:39 - mmengine - INFO - Iter(train) [  250/20000]  base_lr: 9.8879e-05 lr: 9.8879e-05  eta: 16:30:51  time: 3.0156  data_time: 0.0250  memory: 10127  loss: 41.5650  decode.loss_cls: 0.3775  decode.loss_mask: 1.5189  decode.loss_dice: 2.0961  decode.d0.loss_cls: 3.0660  decode.d0.loss_mask: 1.3833  decode.d0.loss_dice: 2.2127  decode.d1.loss_cls: 0.3690  decode.d1.loss_mask: 1.4450  decode.d1.loss_dice: 2.0135  decode.d2.loss_cls: 0.3072  decode.d2.loss_mask: 1.4938  decode.d2.loss_dice: 2.0227  decode.d3.loss_cls: 0.2995  decode.d3.loss_mask: 1.5236  decode.d3.loss_dice: 2.0259  decode.d4.loss_cls: 0.3285  decode.d4.loss_mask: 1.4714  decode.d4.loss_dice: 2.0068  decode.d5.loss_cls: 0.3089  decode.d5.loss_mask: 1.4895  decode.d5.loss_dice: 2.0188  decode.d6.loss_cls: 0.2921  decode.d6.loss_mask: 1.5056  decode.d6.loss_dice: 2.0627  decode.d7.loss_cls: 0.2879  decode.d7.loss_mask: 1.5493  decode.d7.loss_dice: 2.1132  decode.d8.loss_cls: 0.3518  decode.d8.loss_mask: 1.5339  decode.d8.loss_dice: 2.0900
2025/03/29 12:22:10 - mmengine - INFO - Iter(train) [  300/20000]  base_lr: 9.8653e-05 lr: 9.8653e-05  eta: 16:28:45  time: 3.0124  data_time: 0.0224  memory: 10132  loss: 42.5301  decode.loss_cls: 0.4366  decode.loss_mask: 1.6770  decode.loss_dice: 1.9415  decode.d0.loss_cls: 3.0189  decode.d0.loss_mask: 1.4645  decode.d0.loss_dice: 2.0319  decode.d1.loss_cls: 0.4633  decode.d1.loss_mask: 1.5886  decode.d1.loss_dice: 1.9006  decode.d2.loss_cls: 0.4033  decode.d2.loss_mask: 1.5900  decode.d2.loss_dice: 1.9165  decode.d3.loss_cls: 0.3939  decode.d3.loss_mask: 1.6329  decode.d3.loss_dice: 1.9379  decode.d4.loss_cls: 0.3786  decode.d4.loss_mask: 1.6638  decode.d4.loss_dice: 1.9419  decode.d5.loss_cls: 0.3661  decode.d5.loss_mask: 1.6864  decode.d5.loss_dice: 1.9635  decode.d6.loss_cls: 0.4011  decode.d6.loss_mask: 1.6520  decode.d6.loss_dice: 1.9441  decode.d7.loss_cls: 0.3822  decode.d7.loss_mask: 1.7229  decode.d7.loss_dice: 1.9493  decode.d8.loss_cls: 0.4182  decode.d8.loss_mask: 1.7118  decode.d8.loss_dice: 1.9507
2025/03/29 12:24:41 - mmengine - INFO - Iter(train) [  350/20000]  base_lr: 9.8428e-05 lr: 9.8428e-05  eta: 16:26:25  time: 3.0052  data_time: 0.0218  memory: 10124  loss: 40.4573  decode.loss_cls: 0.3292  decode.loss_mask: 1.6934  decode.loss_dice: 1.8461  decode.d0.loss_cls: 2.8406  decode.d0.loss_mask: 1.5548  decode.d0.loss_dice: 1.9454  decode.d1.loss_cls: 0.3410  decode.d1.loss_mask: 1.6576  decode.d1.loss_dice: 1.8354  decode.d2.loss_cls: 0.3185  decode.d2.loss_mask: 1.6332  decode.d2.loss_dice: 1.8229  decode.d3.loss_cls: 0.3311  decode.d3.loss_mask: 1.6227  decode.d3.loss_dice: 1.8224  decode.d4.loss_cls: 0.3255  decode.d4.loss_mask: 1.6018  decode.d4.loss_dice: 1.8216  decode.d5.loss_cls: 0.3110  decode.d5.loss_mask: 1.6351  decode.d5.loss_dice: 1.8210  decode.d6.loss_cls: 0.2894  decode.d6.loss_mask: 1.6613  decode.d6.loss_dice: 1.8033  decode.d7.loss_cls: 0.2924  decode.d7.loss_mask: 1.6739  decode.d7.loss_dice: 1.8112  decode.d8.loss_cls: 0.3368  decode.d8.loss_mask: 1.6719  decode.d8.loss_dice: 1.8065
2025/03/29 12:27:12 - mmengine - INFO - Iter(train) [  400/20000]  base_lr: 9.8203e-05 lr: 9.8203e-05  eta: 16:23:57  time: 3.0194  data_time: 0.0260  memory: 10125  loss: 37.7620  decode.loss_cls: 0.2905  decode.loss_mask: 1.5145  decode.loss_dice: 1.7979  decode.d0.loss_cls: 2.6523  decode.d0.loss_mask: 1.3501  decode.d0.loss_dice: 1.8323  decode.d1.loss_cls: 0.2630  decode.d1.loss_mask: 1.4511  decode.d1.loss_dice: 1.8188  decode.d2.loss_cls: 0.2540  decode.d2.loss_mask: 1.4692  decode.d2.loss_dice: 1.8346  decode.d3.loss_cls: 0.2559  decode.d3.loss_mask: 1.4528  decode.d3.loss_dice: 1.8187  decode.d4.loss_cls: 0.2444  decode.d4.loss_mask: 1.4726  decode.d4.loss_dice: 1.7635  decode.d5.loss_cls: 0.2403  decode.d5.loss_mask: 1.4802  decode.d5.loss_dice: 1.7574  decode.d6.loss_cls: 0.2878  decode.d6.loss_mask: 1.5101  decode.d6.loss_dice: 1.8023  decode.d7.loss_cls: 0.2808  decode.d7.loss_mask: 1.5121  decode.d7.loss_dice: 1.8019  decode.d8.loss_cls: 0.2728  decode.d8.loss_mask: 1.4928  decode.d8.loss_dice: 1.7873
2025/03/29 12:29:42 - mmengine - INFO - Iter(train) [  450/20000]  base_lr: 9.7977e-05 lr: 9.7977e-05  eta: 16:21:29  time: 3.0046  data_time: 0.0235  memory: 10128  loss: 40.5084  decode.loss_cls: 0.3735  decode.loss_mask: 1.5591  decode.loss_dice: 1.9386  decode.d0.loss_cls: 2.5075  decode.d0.loss_mask: 1.4494  decode.d0.loss_dice: 2.0391  decode.d1.loss_cls: 0.3323  decode.d1.loss_mask: 1.5496  decode.d1.loss_dice: 1.9950  decode.d2.loss_cls: 0.3177  decode.d2.loss_mask: 1.5593  decode.d2.loss_dice: 1.9879  decode.d3.loss_cls: 0.2748  decode.d3.loss_mask: 1.5605  decode.d3.loss_dice: 1.9726  decode.d4.loss_cls: 0.2931  decode.d4.loss_mask: 1.5533  decode.d4.loss_dice: 1.9556  decode.d5.loss_cls: 0.3137  decode.d5.loss_mask: 1.5627  decode.d5.loss_dice: 1.9421  decode.d6.loss_cls: 0.3063  decode.d6.loss_mask: 1.5584  decode.d6.loss_dice: 1.9512  decode.d7.loss_cls: 0.3363  decode.d7.loss_mask: 1.5496  decode.d7.loss_dice: 1.9229  decode.d8.loss_cls: 0.3728  decode.d8.loss_mask: 1.5371  decode.d8.loss_dice: 1.9364
2025/03/29 12:32:13 - mmengine - INFO - Iter(train) [  500/20000]  base_lr: 9.7752e-05 lr: 9.7752e-05  eta: 16:19:01  time: 3.0157  data_time: 0.0246  memory: 10130  loss: 38.9749  decode.loss_cls: 0.4277  decode.loss_mask: 1.3736  decode.loss_dice: 1.9321  decode.d0.loss_cls: 2.4679  decode.d0.loss_mask: 1.3544  decode.d0.loss_dice: 1.9987  decode.d1.loss_cls: 0.3484  decode.d1.loss_mask: 1.3783  decode.d1.loss_dice: 1.9718  decode.d2.loss_cls: 0.3054  decode.d2.loss_mask: 1.3777  decode.d2.loss_dice: 1.9461  decode.d3.loss_cls: 0.3238  decode.d3.loss_mask: 1.3943  decode.d3.loss_dice: 1.9432  decode.d4.loss_cls: 0.3327  decode.d4.loss_mask: 1.3915  decode.d4.loss_dice: 1.9447  decode.d5.loss_cls: 0.3537  decode.d5.loss_mask: 1.3794  decode.d5.loss_dice: 1.9562  decode.d6.loss_cls: 0.3619  decode.d6.loss_mask: 1.3610  decode.d6.loss_dice: 1.9297  decode.d7.loss_cls: 0.3321  decode.d7.loss_mask: 1.4071  decode.d7.loss_dice: 1.9462  decode.d8.loss_cls: 0.4145  decode.d8.loss_mask: 1.4045  decode.d8.loss_dice: 1.9161
2025/03/29 12:34:44 - mmengine - INFO - Iter(train) [  550/20000]  base_lr: 9.7526e-05 lr: 9.7526e-05  eta: 16:16:38  time: 2.9955  data_time: 0.0214  memory: 10126  loss: 39.2973  decode.loss_cls: 0.3597  decode.loss_mask: 1.5772  decode.loss_dice: 1.8288  decode.d0.loss_cls: 2.3255  decode.d0.loss_mask: 1.5044  decode.d0.loss_dice: 1.8821  decode.d1.loss_cls: 0.3106  decode.d1.loss_mask: 1.5811  decode.d1.loss_dice: 1.8358  decode.d2.loss_cls: 0.3307  decode.d2.loss_mask: 1.5665  decode.d2.loss_dice: 1.7897  decode.d3.loss_cls: 0.3588  decode.d3.loss_mask: 1.5519  decode.d3.loss_dice: 1.7764  decode.d4.loss_cls: 0.3922  decode.d4.loss_mask: 1.5496  decode.d4.loss_dice: 1.7745  decode.d5.loss_cls: 0.4122  decode.d5.loss_mask: 1.5672  decode.d5.loss_dice: 1.7844  decode.d6.loss_cls: 0.3652  decode.d6.loss_mask: 1.5727  decode.d6.loss_dice: 1.7983  decode.d7.loss_cls: 0.3755  decode.d7.loss_mask: 1.5550  decode.d7.loss_dice: 1.8029  decode.d8.loss_cls: 0.4016  decode.d8.loss_mask: 1.5742  decode.d8.loss_dice: 1.7927
2025/03/29 12:37:02 - mmengine - INFO - Iter(train) [  600/20000]  base_lr: 9.7300e-05 lr: 9.7300e-05  eta: 16:07:19  time: 3.0110  data_time: 0.0257  memory: 10121  loss: 36.0420  decode.loss_cls: 0.3336  decode.loss_mask: 1.4110  decode.loss_dice: 1.7001  decode.d0.loss_cls: 2.2927  decode.d0.loss_mask: 1.3203  decode.d0.loss_dice: 1.6907  decode.d1.loss_cls: 0.3918  decode.d1.loss_mask: 1.3896  decode.d1.loss_dice: 1.6503  decode.d2.loss_cls: 0.3536  decode.d2.loss_mask: 1.3752  decode.d2.loss_dice: 1.6376  decode.d3.loss_cls: 0.3399  decode.d3.loss_mask: 1.3769  decode.d3.loss_dice: 1.6245  decode.d4.loss_cls: 0.3721  decode.d4.loss_mask: 1.3726  decode.d4.loss_dice: 1.6593  decode.d5.loss_cls: 0.3856  decode.d5.loss_mask: 1.3804  decode.d5.loss_dice: 1.6463  decode.d6.loss_cls: 0.4093  decode.d6.loss_mask: 1.3812  decode.d6.loss_dice: 1.6196  decode.d7.loss_cls: 0.3730  decode.d7.loss_mask: 1.4033  decode.d7.loss_dice: 1.6827  decode.d8.loss_cls: 0.3760  decode.d8.loss_mask: 1.4065  decode.d8.loss_dice: 1.6862
2025/03/29 12:39:32 - mmengine - INFO - Iter(train) [  650/20000]  base_lr: 9.7075e-05 lr: 9.7075e-05  eta: 16:05:11  time: 3.0310  data_time: 0.0271  memory: 10132  loss: 36.1368  decode.loss_cls: 0.3114  decode.loss_mask: 1.4077  decode.loss_dice: 1.7119  decode.d0.loss_cls: 2.1071  decode.d0.loss_mask: 1.3815  decode.d0.loss_dice: 1.8122  decode.d1.loss_cls: 0.3034  decode.d1.loss_mask: 1.3843  decode.d1.loss_dice: 1.7230  decode.d2.loss_cls: 0.3266  decode.d2.loss_mask: 1.3836  decode.d2.loss_dice: 1.7069  decode.d3.loss_cls: 0.3174  decode.d3.loss_mask: 1.4099  decode.d3.loss_dice: 1.7101  decode.d4.loss_cls: 0.2923  decode.d4.loss_mask: 1.3880  decode.d4.loss_dice: 1.7129  decode.d5.loss_cls: 0.3022  decode.d5.loss_mask: 1.4185  decode.d5.loss_dice: 1.6989  decode.d6.loss_cls: 0.3524  decode.d6.loss_mask: 1.4084  decode.d6.loss_dice: 1.6706  decode.d7.loss_cls: 0.3333  decode.d7.loss_mask: 1.4107  decode.d7.loss_dice: 1.7184  decode.d8.loss_cls: 0.3285  decode.d8.loss_mask: 1.3993  decode.d8.loss_dice: 1.7055
2025/03/29 12:42:02 - mmengine - INFO - Iter(train) [  700/20000]  base_lr: 9.6849e-05 lr: 9.6849e-05  eta: 16:02:42  time: 2.9913  data_time: 0.0243  memory: 10132  loss: 34.6751  decode.loss_cls: 0.2810  decode.loss_mask: 1.3426  decode.loss_dice: 1.6855  decode.d0.loss_cls: 2.0279  decode.d0.loss_mask: 1.2972  decode.d0.loss_dice: 1.7283  decode.d1.loss_cls: 0.2823  decode.d1.loss_mask: 1.3455  decode.d1.loss_dice: 1.6854  decode.d2.loss_cls: 0.2466  decode.d2.loss_mask: 1.3204  decode.d2.loss_dice: 1.6898  decode.d3.loss_cls: 0.2631  decode.d3.loss_mask: 1.3328  decode.d3.loss_dice: 1.6873  decode.d4.loss_cls: 0.2597  decode.d4.loss_mask: 1.3595  decode.d4.loss_dice: 1.6990  decode.d5.loss_cls: 0.2634  decode.d5.loss_mask: 1.3218  decode.d5.loss_dice: 1.6791  decode.d6.loss_cls: 0.2799  decode.d6.loss_mask: 1.3429  decode.d6.loss_dice: 1.6845  decode.d7.loss_cls: 0.2648  decode.d7.loss_mask: 1.3422  decode.d7.loss_dice: 1.6673  decode.d8.loss_cls: 0.2579  decode.d8.loss_mask: 1.3649  decode.d8.loss_dice: 1.6727
2025/03/29 12:44:31 - mmengine - INFO - Iter(train) [  750/20000]  base_lr: 9.6623e-05 lr: 9.6623e-05  eta: 16:00:09  time: 2.9956  data_time: 0.0211  memory: 10129  loss: 36.1762  decode.loss_cls: 0.2928  decode.loss_mask: 1.4316  decode.loss_dice: 1.7691  decode.d0.loss_cls: 1.8586  decode.d0.loss_mask: 1.3199  decode.d0.loss_dice: 1.7896  decode.d1.loss_cls: 0.3067  decode.d1.loss_mask: 1.3988  decode.d1.loss_dice: 1.7650  decode.d2.loss_cls: 0.3528  decode.d2.loss_mask: 1.3785  decode.d2.loss_dice: 1.7467  decode.d3.loss_cls: 0.2558  decode.d3.loss_mask: 1.4309  decode.d3.loss_dice: 1.7392  decode.d4.loss_cls: 0.2459  decode.d4.loss_mask: 1.4600  decode.d4.loss_dice: 1.7325  decode.d5.loss_cls: 0.3697  decode.d5.loss_mask: 1.4037  decode.d5.loss_dice: 1.7062  decode.d6.loss_cls: 0.2848  decode.d6.loss_mask: 1.4500  decode.d6.loss_dice: 1.7027  decode.d7.loss_cls: 0.2870  decode.d7.loss_mask: 1.4449  decode.d7.loss_dice: 1.7508  decode.d8.loss_cls: 0.2785  decode.d8.loss_mask: 1.4513  decode.d8.loss_dice: 1.7723
2025/03/29 12:47:01 - mmengine - INFO - Iter(train) [  800/20000]  base_lr: 9.6397e-05 lr: 9.6397e-05  eta: 15:57:44  time: 2.9961  data_time: 0.0231  memory: 10130  loss: 34.8603  decode.loss_cls: 0.2949  decode.loss_mask: 1.4122  decode.loss_dice: 1.6866  decode.d0.loss_cls: 1.7904  decode.d0.loss_mask: 1.3219  decode.d0.loss_dice: 1.7205  decode.d1.loss_cls: 0.3354  decode.d1.loss_mask: 1.3632  decode.d1.loss_dice: 1.6787  decode.d2.loss_cls: 0.3068  decode.d2.loss_mask: 1.3508  decode.d2.loss_dice: 1.6510  decode.d3.loss_cls: 0.2925  decode.d3.loss_mask: 1.3453  decode.d3.loss_dice: 1.6212  decode.d4.loss_cls: 0.3268  decode.d4.loss_mask: 1.3626  decode.d4.loss_dice: 1.6484  decode.d5.loss_cls: 0.3278  decode.d5.loss_mask: 1.3964  decode.d5.loss_dice: 1.6108  decode.d6.loss_cls: 0.3293  decode.d6.loss_mask: 1.3802  decode.d6.loss_dice: 1.6281  decode.d7.loss_cls: 0.3201  decode.d7.loss_mask: 1.3717  decode.d7.loss_dice: 1.6351  decode.d8.loss_cls: 0.3198  decode.d8.loss_mask: 1.3748  decode.d8.loss_dice: 1.6572
2025/03/29 12:49:31 - mmengine - INFO - Iter(train) [  850/20000]  base_lr: 9.6171e-05 lr: 9.6171e-05  eta: 15:55:18  time: 2.9745  data_time: 0.0228  memory: 10124  loss: 37.2194  decode.loss_cls: 0.4026  decode.loss_mask: 1.5852  decode.loss_dice: 1.6496  decode.d0.loss_cls: 1.7069  decode.d0.loss_mask: 1.5117  decode.d0.loss_dice: 1.7091  decode.d1.loss_cls: 0.3656  decode.d1.loss_mask: 1.5545  decode.d1.loss_dice: 1.6578  decode.d2.loss_cls: 0.3831  decode.d2.loss_mask: 1.5460  decode.d2.loss_dice: 1.6257  decode.d3.loss_cls: 0.4058  decode.d3.loss_mask: 1.5291  decode.d3.loss_dice: 1.6097  decode.d4.loss_cls: 0.3471  decode.d4.loss_mask: 1.5532  decode.d4.loss_dice: 1.6397  decode.d5.loss_cls: 0.4109  decode.d5.loss_mask: 1.5758  decode.d5.loss_dice: 1.6440  decode.d6.loss_cls: 0.4019  decode.d6.loss_mask: 1.5761  decode.d6.loss_dice: 1.6531  decode.d7.loss_cls: 0.3866  decode.d7.loss_mask: 1.5534  decode.d7.loss_dice: 1.6432  decode.d8.loss_cls: 0.3779  decode.d8.loss_mask: 1.5617  decode.d8.loss_dice: 1.6522
2025/03/29 12:50:13 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 12:52:01 - mmengine - INFO - Iter(train) [  900/20000]  base_lr: 9.5945e-05 lr: 9.5945e-05  eta: 15:52:58  time: 2.9902  data_time: 0.0237  memory: 10132  loss: 32.4068  decode.loss_cls: 0.2971  decode.loss_mask: 1.2661  decode.loss_dice: 1.5343  decode.d0.loss_cls: 1.5564  decode.d0.loss_mask: 1.2389  decode.d0.loss_dice: 1.6179  decode.d1.loss_cls: 0.2584  decode.d1.loss_mask: 1.2739  decode.d1.loss_dice: 1.5896  decode.d2.loss_cls: 0.2739  decode.d2.loss_mask: 1.2489  decode.d2.loss_dice: 1.5817  decode.d3.loss_cls: 0.2742  decode.d3.loss_mask: 1.2768  decode.d3.loss_dice: 1.5377  decode.d4.loss_cls: 0.2669  decode.d4.loss_mask: 1.2690  decode.d4.loss_dice: 1.5542  decode.d5.loss_cls: 0.2826  decode.d5.loss_mask: 1.2730  decode.d5.loss_dice: 1.5658  decode.d6.loss_cls: 0.2513  decode.d6.loss_mask: 1.2871  decode.d6.loss_dice: 1.5683  decode.d7.loss_cls: 0.2821  decode.d7.loss_mask: 1.2854  decode.d7.loss_dice: 1.5761  decode.d8.loss_cls: 0.2758  decode.d8.loss_mask: 1.2843  decode.d8.loss_dice: 1.5592
2025/03/29 12:54:31 - mmengine - INFO - Iter(train) [  950/20000]  base_lr: 9.5719e-05 lr: 9.5719e-05  eta: 15:50:29  time: 2.9904  data_time: 0.0235  memory: 10130  loss: 34.3806  decode.loss_cls: 0.3582  decode.loss_mask: 1.3087  decode.loss_dice: 1.6784  decode.d0.loss_cls: 1.5100  decode.d0.loss_mask: 1.2812  decode.d0.loss_dice: 1.7233  decode.d1.loss_cls: 0.2920  decode.d1.loss_mask: 1.3001  decode.d1.loss_dice: 1.7066  decode.d2.loss_cls: 0.3119  decode.d2.loss_mask: 1.2844  decode.d2.loss_dice: 1.6644  decode.d3.loss_cls: 0.3116  decode.d3.loss_mask: 1.2775  decode.d3.loss_dice: 1.6906  decode.d4.loss_cls: 0.3071  decode.d4.loss_mask: 1.3169  decode.d4.loss_dice: 1.6765  decode.d5.loss_cls: 0.3217  decode.d5.loss_mask: 1.3157  decode.d5.loss_dice: 1.7042  decode.d6.loss_cls: 0.3383  decode.d6.loss_mask: 1.3094  decode.d6.loss_dice: 1.6955  decode.d7.loss_cls: 0.3181  decode.d7.loss_mask: 1.3247  decode.d7.loss_dice: 1.6827  decode.d8.loss_cls: 0.3477  decode.d8.loss_mask: 1.3294  decode.d8.loss_dice: 1.6937
2025/03/29 12:57:01 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 12:57:01 - mmengine - INFO - Iter(train) [ 1000/20000]  base_lr: 9.5493e-05 lr: 9.5493e-05  eta: 15:48:04  time: 2.9905  data_time: 0.0252  memory: 10125  loss: 31.7446  decode.loss_cls: 0.2745  decode.loss_mask: 1.2722  decode.loss_dice: 1.5025  decode.d0.loss_cls: 1.3783  decode.d0.loss_mask: 1.2815  decode.d0.loss_dice: 1.5461  decode.d1.loss_cls: 0.3116  decode.d1.loss_mask: 1.2813  decode.d1.loss_dice: 1.5385  decode.d2.loss_cls: 0.3131  decode.d2.loss_mask: 1.2693  decode.d2.loss_dice: 1.4951  decode.d3.loss_cls: 0.3612  decode.d3.loss_mask: 1.2293  decode.d3.loss_dice: 1.4524  decode.d4.loss_cls: 0.3093  decode.d4.loss_mask: 1.2603  decode.d4.loss_dice: 1.4683  decode.d5.loss_cls: 0.3109  decode.d5.loss_mask: 1.2611  decode.d5.loss_dice: 1.4674  decode.d6.loss_cls: 0.3070  decode.d6.loss_mask: 1.2615  decode.d6.loss_dice: 1.4760  decode.d7.loss_cls: 0.2966  decode.d7.loss_mask: 1.2814  decode.d7.loss_dice: 1.4949  decode.d8.loss_cls: 0.2702  decode.d8.loss_mask: 1.2764  decode.d8.loss_dice: 1.4966
2025/03/29 12:59:31 - mmengine - INFO - Iter(train) [ 1050/20000]  base_lr: 9.5267e-05 lr: 9.5267e-05  eta: 15:45:39  time: 3.0049  data_time: 0.0250  memory: 10136  loss: 30.3396  decode.loss_cls: 0.2239  decode.loss_mask: 1.2173  decode.loss_dice: 1.4863  decode.d0.loss_cls: 1.3166  decode.d0.loss_mask: 1.2440  decode.d0.loss_dice: 1.5477  decode.d1.loss_cls: 0.2010  decode.d1.loss_mask: 1.2369  decode.d1.loss_dice: 1.4728  decode.d2.loss_cls: 0.2153  decode.d2.loss_mask: 1.2165  decode.d2.loss_dice: 1.4508  decode.d3.loss_cls: 0.2238  decode.d3.loss_mask: 1.2108  decode.d3.loss_dice: 1.4551  decode.d4.loss_cls: 0.2147  decode.d4.loss_mask: 1.2187  decode.d4.loss_dice: 1.4695  decode.d5.loss_cls: 0.2408  decode.d5.loss_mask: 1.2124  decode.d5.loss_dice: 1.4787  decode.d6.loss_cls: 0.2387  decode.d6.loss_mask: 1.2305  decode.d6.loss_dice: 1.4514  decode.d7.loss_cls: 0.2290  decode.d7.loss_mask: 1.2368  decode.d7.loss_dice: 1.4703  decode.d8.loss_cls: 0.2407  decode.d8.loss_mask: 1.2102  decode.d8.loss_dice: 1.4782
2025/03/29 13:01:49 - mmengine - INFO - Iter(train) [ 1100/20000]  base_lr: 9.5040e-05 lr: 9.5040e-05  eta: 15:39:56  time: 2.9878  data_time: 0.0271  memory: 10124  loss: 32.9234  decode.loss_cls: 0.3260  decode.loss_mask: 1.2948  decode.loss_dice: 1.5785  decode.d0.loss_cls: 1.2323  decode.d0.loss_mask: 1.3283  decode.d0.loss_dice: 1.6718  decode.d1.loss_cls: 0.2410  decode.d1.loss_mask: 1.3016  decode.d1.loss_dice: 1.5833  decode.d2.loss_cls: 0.2335  decode.d2.loss_mask: 1.3353  decode.d2.loss_dice: 1.5524  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 1.3007  decode.d3.loss_dice: 1.5558  decode.d4.loss_cls: 0.2927  decode.d4.loss_mask: 1.3205  decode.d4.loss_dice: 1.5617  decode.d5.loss_cls: 0.3077  decode.d5.loss_mask: 1.3290  decode.d5.loss_dice: 1.5827  decode.d6.loss_cls: 0.3264  decode.d6.loss_mask: 1.3337  decode.d6.loss_dice: 1.5500  decode.d7.loss_cls: 0.3352  decode.d7.loss_mask: 1.3539  decode.d7.loss_dice: 1.5718  decode.d8.loss_cls: 0.3333  decode.d8.loss_mask: 1.3418  decode.d8.loss_dice: 1.5610
2025/03/29 13:04:19 - mmengine - INFO - Iter(train) [ 1150/20000]  base_lr: 9.4814e-05 lr: 9.4814e-05  eta: 15:37:38  time: 2.9873  data_time: 0.0243  memory: 10126  loss: 30.6711  decode.loss_cls: 0.2697  decode.loss_mask: 1.2968  decode.loss_dice: 1.4302  decode.d0.loss_cls: 1.1733  decode.d0.loss_mask: 1.2777  decode.d0.loss_dice: 1.4247  decode.d1.loss_cls: 0.2847  decode.d1.loss_mask: 1.2731  decode.d1.loss_dice: 1.4124  decode.d2.loss_cls: 0.3220  decode.d2.loss_mask: 1.2676  decode.d2.loss_dice: 1.3740  decode.d3.loss_cls: 0.3162  decode.d3.loss_mask: 1.2697  decode.d3.loss_dice: 1.3874  decode.d4.loss_cls: 0.3031  decode.d4.loss_mask: 1.2754  decode.d4.loss_dice: 1.3810  decode.d5.loss_cls: 0.2873  decode.d5.loss_mask: 1.3003  decode.d5.loss_dice: 1.4025  decode.d6.loss_cls: 0.2834  decode.d6.loss_mask: 1.3076  decode.d6.loss_dice: 1.3957  decode.d7.loss_cls: 0.2752  decode.d7.loss_mask: 1.3017  decode.d7.loss_dice: 1.4215  decode.d8.loss_cls: 0.2631  decode.d8.loss_mask: 1.2835  decode.d8.loss_dice: 1.4104
2025/03/29 13:06:48 - mmengine - INFO - Iter(train) [ 1200/20000]  base_lr: 9.4588e-05 lr: 9.4588e-05  eta: 15:35:09  time: 2.9829  data_time: 0.0217  memory: 10130  loss: 33.5478  decode.loss_cls: 0.2131  decode.loss_mask: 1.3342  decode.loss_dice: 1.6911  decode.d0.loss_cls: 1.1020  decode.d0.loss_mask: 1.3160  decode.d0.loss_dice: 1.7462  decode.d1.loss_cls: 0.2841  decode.d1.loss_mask: 1.3264  decode.d1.loss_dice: 1.7127  decode.d2.loss_cls: 0.2695  decode.d2.loss_mask: 1.3179  decode.d2.loss_dice: 1.6906  decode.d3.loss_cls: 0.3071  decode.d3.loss_mask: 1.3055  decode.d3.loss_dice: 1.6788  decode.d4.loss_cls: 0.2742  decode.d4.loss_mask: 1.3030  decode.d4.loss_dice: 1.6881  decode.d5.loss_cls: 0.2559  decode.d5.loss_mask: 1.2911  decode.d5.loss_dice: 1.7039  decode.d6.loss_cls: 0.2235  decode.d6.loss_mask: 1.3308  decode.d6.loss_dice: 1.7002  decode.d7.loss_cls: 0.2038  decode.d7.loss_mask: 1.3438  decode.d7.loss_dice: 1.7122  decode.d8.loss_cls: 0.2177  decode.d8.loss_mask: 1.3077  decode.d8.loss_dice: 1.6966
2025/03/29 13:09:19 - mmengine - INFO - Iter(train) [ 1250/20000]  base_lr: 9.4361e-05 lr: 9.4361e-05  eta: 15:32:57  time: 2.9888  data_time: 0.0220  memory: 10123  loss: 32.4399  decode.loss_cls: 0.4190  decode.loss_mask: 1.2857  decode.loss_dice: 1.5171  decode.d0.loss_cls: 1.1265  decode.d0.loss_mask: 1.2800  decode.d0.loss_dice: 1.5724  decode.d1.loss_cls: 0.3983  decode.d1.loss_mask: 1.2630  decode.d1.loss_dice: 1.4772  decode.d2.loss_cls: 0.3867  decode.d2.loss_mask: 1.2513  decode.d2.loss_dice: 1.4857  decode.d3.loss_cls: 0.3862  decode.d3.loss_mask: 1.2713  decode.d3.loss_dice: 1.5057  decode.d4.loss_cls: 0.3702  decode.d4.loss_mask: 1.2718  decode.d4.loss_dice: 1.5336  decode.d5.loss_cls: 0.3889  decode.d5.loss_mask: 1.2540  decode.d5.loss_dice: 1.5011  decode.d6.loss_cls: 0.3939  decode.d6.loss_mask: 1.2466  decode.d6.loss_dice: 1.4759  decode.d7.loss_cls: 0.4077  decode.d7.loss_mask: 1.2638  decode.d7.loss_dice: 1.5087  decode.d8.loss_cls: 0.4377  decode.d8.loss_mask: 1.2624  decode.d8.loss_dice: 1.4974
2025/03/29 13:11:49 - mmengine - INFO - Iter(train) [ 1300/20000]  base_lr: 9.4135e-05 lr: 9.4135e-05  eta: 15:30:39  time: 3.0118  data_time: 0.0234  memory: 10131  loss: 31.0077  decode.loss_cls: 0.2900  decode.loss_mask: 1.2475  decode.loss_dice: 1.5159  decode.d0.loss_cls: 1.0098  decode.d0.loss_mask: 1.2206  decode.d0.loss_dice: 1.5936  decode.d1.loss_cls: 0.2621  decode.d1.loss_mask: 1.2463  decode.d1.loss_dice: 1.5328  decode.d2.loss_cls: 0.2306  decode.d2.loss_mask: 1.2249  decode.d2.loss_dice: 1.5222  decode.d3.loss_cls: 0.2564  decode.d3.loss_mask: 1.2383  decode.d3.loss_dice: 1.4794  decode.d4.loss_cls: 0.2296  decode.d4.loss_mask: 1.2442  decode.d4.loss_dice: 1.5262  decode.d5.loss_cls: 0.2284  decode.d5.loss_mask: 1.2584  decode.d5.loss_dice: 1.5208  decode.d6.loss_cls: 0.2782  decode.d6.loss_mask: 1.2356  decode.d6.loss_dice: 1.5084  decode.d7.loss_cls: 0.2552  decode.d7.loss_mask: 1.2750  decode.d7.loss_dice: 1.5198  decode.d8.loss_cls: 0.2847  decode.d8.loss_mask: 1.2371  decode.d8.loss_dice: 1.5356
2025/03/29 13:14:19 - mmengine - INFO - Iter(train) [ 1350/20000]  base_lr: 9.3908e-05 lr: 9.3908e-05  eta: 15:28:22  time: 2.9832  data_time: 0.0213  memory: 10132  loss: 31.9310  decode.loss_cls: 0.2750  decode.loss_mask: 1.3364  decode.loss_dice: 1.5024  decode.d0.loss_cls: 0.9936  decode.d0.loss_mask: 1.2755  decode.d0.loss_dice: 1.5285  decode.d1.loss_cls: 0.3677  decode.d1.loss_mask: 1.2994  decode.d1.loss_dice: 1.5143  decode.d2.loss_cls: 0.2897  decode.d2.loss_mask: 1.3004  decode.d2.loss_dice: 1.5456  decode.d3.loss_cls: 0.3091  decode.d3.loss_mask: 1.3071  decode.d3.loss_dice: 1.5424  decode.d4.loss_cls: 0.2852  decode.d4.loss_mask: 1.2932  decode.d4.loss_dice: 1.5088  decode.d5.loss_cls: 0.3235  decode.d5.loss_mask: 1.2938  decode.d5.loss_dice: 1.5071  decode.d6.loss_cls: 0.3146  decode.d6.loss_mask: 1.2986  decode.d6.loss_dice: 1.4983  decode.d7.loss_cls: 0.2779  decode.d7.loss_mask: 1.3004  decode.d7.loss_dice: 1.5063  decode.d8.loss_cls: 0.3296  decode.d8.loss_mask: 1.3057  decode.d8.loss_dice: 1.5007
2025/03/29 13:16:49 - mmengine - INFO - Iter(train) [ 1400/20000]  base_lr: 9.3682e-05 lr: 9.3682e-05  eta: 15:25:58  time: 3.0033  data_time: 0.0238  memory: 10124  loss: 28.2541  decode.loss_cls: 0.2200  decode.loss_mask: 1.1573  decode.loss_dice: 1.4107  decode.d0.loss_cls: 0.8224  decode.d0.loss_mask: 1.1572  decode.d0.loss_dice: 1.4784  decode.d1.loss_cls: 0.1660  decode.d1.loss_mask: 1.1609  decode.d1.loss_dice: 1.4253  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 1.1504  decode.d2.loss_dice: 1.4130  decode.d3.loss_cls: 0.1856  decode.d3.loss_mask: 1.1510  decode.d3.loss_dice: 1.4022  decode.d4.loss_cls: 0.1988  decode.d4.loss_mask: 1.1421  decode.d4.loss_dice: 1.4070  decode.d5.loss_cls: 0.2361  decode.d5.loss_mask: 1.1374  decode.d5.loss_dice: 1.3953  decode.d6.loss_cls: 0.2177  decode.d6.loss_mask: 1.1331  decode.d6.loss_dice: 1.3944  decode.d7.loss_cls: 0.2123  decode.d7.loss_mask: 1.1378  decode.d7.loss_dice: 1.4169  decode.d8.loss_cls: 0.2130  decode.d8.loss_mask: 1.1360  decode.d8.loss_dice: 1.4071
2025/03/29 13:19:19 - mmengine - INFO - Iter(train) [ 1450/20000]  base_lr: 9.3455e-05 lr: 9.3455e-05  eta: 15:23:35  time: 2.9967  data_time: 0.0247  memory: 10130  loss: 27.8453  decode.loss_cls: 0.2498  decode.loss_mask: 1.1000  decode.loss_dice: 1.3515  decode.d0.loss_cls: 0.8470  decode.d0.loss_mask: 1.1369  decode.d0.loss_dice: 1.3787  decode.d1.loss_cls: 0.2368  decode.d1.loss_mask: 1.1180  decode.d1.loss_dice: 1.3656  decode.d2.loss_cls: 0.2473  decode.d2.loss_mask: 1.1292  decode.d2.loss_dice: 1.3470  decode.d3.loss_cls: 0.2903  decode.d3.loss_mask: 1.1280  decode.d3.loss_dice: 1.3201  decode.d4.loss_cls: 0.2284  decode.d4.loss_mask: 1.1474  decode.d4.loss_dice: 1.3543  decode.d5.loss_cls: 0.2550  decode.d5.loss_mask: 1.1322  decode.d5.loss_dice: 1.3417  decode.d6.loss_cls: 0.2395  decode.d6.loss_mask: 1.1218  decode.d6.loss_dice: 1.3503  decode.d7.loss_cls: 0.2166  decode.d7.loss_mask: 1.1024  decode.d7.loss_dice: 1.3714  decode.d8.loss_cls: 0.2531  decode.d8.loss_mask: 1.1119  decode.d8.loss_dice: 1.3734
2025/03/29 13:21:48 - mmengine - INFO - Iter(train) [ 1500/20000]  base_lr: 9.3228e-05 lr: 9.3228e-05  eta: 15:21:11  time: 2.9986  data_time: 0.0235  memory: 10121  loss: 32.5653  decode.loss_cls: 0.3858  decode.loss_mask: 1.3066  decode.loss_dice: 1.5549  decode.d0.loss_cls: 0.8274  decode.d0.loss_mask: 1.3066  decode.d0.loss_dice: 1.6387  decode.d1.loss_cls: 0.3285  decode.d1.loss_mask: 1.2854  decode.d1.loss_dice: 1.5568  decode.d2.loss_cls: 0.3507  decode.d2.loss_mask: 1.2822  decode.d2.loss_dice: 1.5787  decode.d3.loss_cls: 0.3241  decode.d3.loss_mask: 1.2852  decode.d3.loss_dice: 1.5632  decode.d4.loss_cls: 0.3294  decode.d4.loss_mask: 1.2856  decode.d4.loss_dice: 1.5470  decode.d5.loss_cls: 0.3684  decode.d5.loss_mask: 1.2918  decode.d5.loss_dice: 1.5644  decode.d6.loss_cls: 0.3220  decode.d6.loss_mask: 1.2948  decode.d6.loss_dice: 1.5575  decode.d7.loss_cls: 0.3413  decode.d7.loss_mask: 1.3057  decode.d7.loss_dice: 1.5629  decode.d8.loss_cls: 0.4043  decode.d8.loss_mask: 1.2848  decode.d8.loss_dice: 1.5305
2025/03/29 13:24:19 - mmengine - INFO - Iter(train) [ 1550/20000]  base_lr: 9.3001e-05 lr: 9.3001e-05  eta: 15:18:54  time: 3.0154  data_time: 0.0258  memory: 10124  loss: 31.6062  decode.loss_cls: 0.1961  decode.loss_mask: 1.3766  decode.loss_dice: 1.5282  decode.d0.loss_cls: 0.6986  decode.d0.loss_mask: 1.3739  decode.d0.loss_dice: 1.5531  decode.d1.loss_cls: 0.1643  decode.d1.loss_mask: 1.3946  decode.d1.loss_dice: 1.5526  decode.d2.loss_cls: 0.1599  decode.d2.loss_mask: 1.3773  decode.d2.loss_dice: 1.5124  decode.d3.loss_cls: 0.1822  decode.d3.loss_mask: 1.3905  decode.d3.loss_dice: 1.5337  decode.d4.loss_cls: 0.2118  decode.d4.loss_mask: 1.3673  decode.d4.loss_dice: 1.5291  decode.d5.loss_cls: 0.2188  decode.d5.loss_mask: 1.3932  decode.d5.loss_dice: 1.5568  decode.d6.loss_cls: 0.1871  decode.d6.loss_mask: 1.3849  decode.d6.loss_dice: 1.5554  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.3831  decode.d7.loss_dice: 1.5449  decode.d8.loss_cls: 0.1873  decode.d8.loss_mask: 1.3847  decode.d8.loss_dice: 1.5324
2025/03/29 13:26:36 - mmengine - INFO - Iter(train) [ 1600/20000]  base_lr: 9.2774e-05 lr: 9.2774e-05  eta: 15:14:03  time: 2.9966  data_time: 0.0232  memory: 10124  loss: 32.5297  decode.loss_cls: 0.2507  decode.loss_mask: 1.3764  decode.loss_dice: 1.5781  decode.d0.loss_cls: 0.7188  decode.d0.loss_mask: 1.4135  decode.d0.loss_dice: 1.5766  decode.d1.loss_cls: 0.2761  decode.d1.loss_mask: 1.4177  decode.d1.loss_dice: 1.5282  decode.d2.loss_cls: 0.2506  decode.d2.loss_mask: 1.4024  decode.d2.loss_dice: 1.5156  decode.d3.loss_cls: 0.2544  decode.d3.loss_mask: 1.4080  decode.d3.loss_dice: 1.5456  decode.d4.loss_cls: 0.2357  decode.d4.loss_mask: 1.3955  decode.d4.loss_dice: 1.5506  decode.d5.loss_cls: 0.2468  decode.d5.loss_mask: 1.4046  decode.d5.loss_dice: 1.5667  decode.d6.loss_cls: 0.2059  decode.d6.loss_mask: 1.4283  decode.d6.loss_dice: 1.5897  decode.d7.loss_cls: 0.1993  decode.d7.loss_mask: 1.4166  decode.d7.loss_dice: 1.5815  decode.d8.loss_cls: 0.2205  decode.d8.loss_mask: 1.4001  decode.d8.loss_dice: 1.5751
2025/03/29 13:29:06 - mmengine - INFO - Iter(train) [ 1650/20000]  base_lr: 9.2548e-05 lr: 9.2548e-05  eta: 15:11:41  time: 2.9897  data_time: 0.0230  memory: 10132  loss: 30.4867  decode.loss_cls: 0.2501  decode.loss_mask: 1.2611  decode.loss_dice: 1.4826  decode.d0.loss_cls: 0.6361  decode.d0.loss_mask: 1.3278  decode.d0.loss_dice: 1.6004  decode.d1.loss_cls: 0.2494  decode.d1.loss_mask: 1.2709  decode.d1.loss_dice: 1.4906  decode.d2.loss_cls: 0.2556  decode.d2.loss_mask: 1.2511  decode.d2.loss_dice: 1.4925  decode.d3.loss_cls: 0.2601  decode.d3.loss_mask: 1.2309  decode.d3.loss_dice: 1.4809  decode.d4.loss_cls: 0.2797  decode.d4.loss_mask: 1.2474  decode.d4.loss_dice: 1.4861  decode.d5.loss_cls: 0.2374  decode.d5.loss_mask: 1.2430  decode.d5.loss_dice: 1.4768  decode.d6.loss_cls: 0.3317  decode.d6.loss_mask: 1.2439  decode.d6.loss_dice: 1.4546  decode.d7.loss_cls: 0.2151  decode.d7.loss_mask: 1.2530  decode.d7.loss_dice: 1.4903  decode.d8.loss_cls: 0.2168  decode.d8.loss_mask: 1.2614  decode.d8.loss_dice: 1.5094
2025/03/29 13:31:36 - mmengine - INFO - Iter(train) [ 1700/20000]  base_lr: 9.2321e-05 lr: 9.2321e-05  eta: 15:09:23  time: 2.9975  data_time: 0.0238  memory: 10128  loss: 27.2368  decode.loss_cls: 0.1431  decode.loss_mask: 1.2421  decode.loss_dice: 1.2733  decode.d0.loss_cls: 0.5614  decode.d0.loss_mask: 1.2469  decode.d0.loss_dice: 1.3518  decode.d1.loss_cls: 0.1355  decode.d1.loss_mask: 1.2387  decode.d1.loss_dice: 1.3061  decode.d2.loss_cls: 0.1467  decode.d2.loss_mask: 1.2373  decode.d2.loss_dice: 1.2945  decode.d3.loss_cls: 0.1340  decode.d3.loss_mask: 1.2386  decode.d3.loss_dice: 1.2917  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 1.2282  decode.d4.loss_dice: 1.2852  decode.d5.loss_cls: 0.1847  decode.d5.loss_mask: 1.2310  decode.d5.loss_dice: 1.2933  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 1.2289  decode.d6.loss_dice: 1.2541  decode.d7.loss_cls: 0.1626  decode.d7.loss_mask: 1.2347  decode.d7.loss_dice: 1.2742  decode.d8.loss_cls: 0.1289  decode.d8.loss_mask: 1.2403  decode.d8.loss_dice: 1.2943
2025/03/29 13:34:06 - mmengine - INFO - Iter(train) [ 1750/20000]  base_lr: 9.2094e-05 lr: 9.2094e-05  eta: 15:07:02  time: 2.9882  data_time: 0.0225  memory: 10134  loss: 30.7361  decode.loss_cls: 0.1256  decode.loss_mask: 1.2279  decode.loss_dice: 1.6928  decode.d0.loss_cls: 0.5388  decode.d0.loss_mask: 1.2145  decode.d0.loss_dice: 1.6921  decode.d1.loss_cls: 0.1684  decode.d1.loss_mask: 1.2140  decode.d1.loss_dice: 1.6187  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 1.2144  decode.d2.loss_dice: 1.6171  decode.d3.loss_cls: 0.2128  decode.d3.loss_mask: 1.1726  decode.d3.loss_dice: 1.6206  decode.d4.loss_cls: 0.1595  decode.d4.loss_mask: 1.2111  decode.d4.loss_dice: 1.6489  decode.d5.loss_cls: 0.1505  decode.d5.loss_mask: 1.1977  decode.d5.loss_dice: 1.6561  decode.d6.loss_cls: 0.1594  decode.d6.loss_mask: 1.2253  decode.d6.loss_dice: 1.6794  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 1.2342  decode.d7.loss_dice: 1.6893  decode.d8.loss_cls: 0.1757  decode.d8.loss_mask: 1.2477  decode.d8.loss_dice: 1.6775
2025/03/29 13:36:35 - mmengine - INFO - Iter(train) [ 1800/20000]  base_lr: 9.1866e-05 lr: 9.1866e-05  eta: 15:04:37  time: 2.9784  data_time: 0.0205  memory: 10134  loss: 30.3304  decode.loss_cls: 0.2907  decode.loss_mask: 1.2393  decode.loss_dice: 1.4855  decode.d0.loss_cls: 0.5796  decode.d0.loss_mask: 1.2477  decode.d0.loss_dice: 1.5046  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 1.2342  decode.d1.loss_dice: 1.4523  decode.d2.loss_cls: 0.2724  decode.d2.loss_mask: 1.2414  decode.d2.loss_dice: 1.4510  decode.d3.loss_cls: 0.3125  decode.d3.loss_mask: 1.2046  decode.d3.loss_dice: 1.4582  decode.d4.loss_cls: 0.3269  decode.d4.loss_mask: 1.2086  decode.d4.loss_dice: 1.4830  decode.d5.loss_cls: 0.2875  decode.d5.loss_mask: 1.2440  decode.d5.loss_dice: 1.4876  decode.d6.loss_cls: 0.2888  decode.d6.loss_mask: 1.2458  decode.d6.loss_dice: 1.4937  decode.d7.loss_cls: 0.2828  decode.d7.loss_mask: 1.2461  decode.d7.loss_dice: 1.4757  decode.d8.loss_cls: 0.2875  decode.d8.loss_mask: 1.2276  decode.d8.loss_dice: 1.4826
2025/03/29 13:39:05 - mmengine - INFO - Iter(train) [ 1850/20000]  base_lr: 9.1639e-05 lr: 9.1639e-05  eta: 15:02:12  time: 2.9893  data_time: 0.0218  memory: 10125  loss: 28.5320  decode.loss_cls: 0.2058  decode.loss_mask: 1.2861  decode.loss_dice: 1.3373  decode.d0.loss_cls: 0.5607  decode.d0.loss_mask: 1.2978  decode.d0.loss_dice: 1.4229  decode.d1.loss_cls: 0.1985  decode.d1.loss_mask: 1.2608  decode.d1.loss_dice: 1.3593  decode.d2.loss_cls: 0.1565  decode.d2.loss_mask: 1.2678  decode.d2.loss_dice: 1.3606  decode.d3.loss_cls: 0.1700  decode.d3.loss_mask: 1.2821  decode.d3.loss_dice: 1.3505  decode.d4.loss_cls: 0.1896  decode.d4.loss_mask: 1.2552  decode.d4.loss_dice: 1.3389  decode.d5.loss_cls: 0.2633  decode.d5.loss_mask: 1.2489  decode.d5.loss_dice: 1.2958  decode.d6.loss_cls: 0.2333  decode.d6.loss_mask: 1.2486  decode.d6.loss_dice: 1.3311  decode.d7.loss_cls: 0.2283  decode.d7.loss_mask: 1.2305  decode.d7.loss_dice: 1.3316  decode.d8.loss_cls: 0.2464  decode.d8.loss_mask: 1.2442  decode.d8.loss_dice: 1.3296
2025/03/29 13:41:34 - mmengine - INFO - Iter(train) [ 1900/20000]  base_lr: 9.1412e-05 lr: 9.1412e-05  eta: 14:59:48  time: 2.9762  data_time: 0.0218  memory: 10126  loss: 29.9858  decode.loss_cls: 0.2652  decode.loss_mask: 1.3361  decode.loss_dice: 1.3655  decode.d0.loss_cls: 0.5753  decode.d0.loss_mask: 1.3488  decode.d0.loss_dice: 1.3702  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 1.3348  decode.d1.loss_dice: 1.3420  decode.d2.loss_cls: 0.2746  decode.d2.loss_mask: 1.3094  decode.d2.loss_dice: 1.3621  decode.d3.loss_cls: 0.2825  decode.d3.loss_mask: 1.3467  decode.d3.loss_dice: 1.3451  decode.d4.loss_cls: 0.2735  decode.d4.loss_mask: 1.3081  decode.d4.loss_dice: 1.3436  decode.d5.loss_cls: 0.3095  decode.d5.loss_mask: 1.3244  decode.d5.loss_dice: 1.3452  decode.d6.loss_cls: 0.2444  decode.d6.loss_mask: 1.3680  decode.d6.loss_dice: 1.3661  decode.d7.loss_cls: 0.2495  decode.d7.loss_mask: 1.3623  decode.d7.loss_dice: 1.3722  decode.d8.loss_cls: 0.2631  decode.d8.loss_mask: 1.3424  decode.d8.loss_dice: 1.3670
2025/03/29 13:44:04 - mmengine - INFO - Iter(train) [ 1950/20000]  base_lr: 9.1185e-05 lr: 9.1185e-05  eta: 14:57:21  time: 3.0004  data_time: 0.0225  memory: 10121  loss: 32.8079  decode.loss_cls: 0.2453  decode.loss_mask: 1.4670  decode.loss_dice: 1.5264  decode.d0.loss_cls: 0.4920  decode.d0.loss_mask: 1.4561  decode.d0.loss_dice: 1.6385  decode.d1.loss_cls: 0.2377  decode.d1.loss_mask: 1.4776  decode.d1.loss_dice: 1.5779  decode.d2.loss_cls: 0.2401  decode.d2.loss_mask: 1.4695  decode.d2.loss_dice: 1.5605  decode.d3.loss_cls: 0.2184  decode.d3.loss_mask: 1.4714  decode.d3.loss_dice: 1.5876  decode.d4.loss_cls: 0.2698  decode.d4.loss_mask: 1.4336  decode.d4.loss_dice: 1.5571  decode.d5.loss_cls: 0.2450  decode.d5.loss_mask: 1.4395  decode.d5.loss_dice: 1.5351  decode.d6.loss_cls: 0.2464  decode.d6.loss_mask: 1.4367  decode.d6.loss_dice: 1.5312  decode.d7.loss_cls: 0.2347  decode.d7.loss_mask: 1.4584  decode.d7.loss_dice: 1.5326  decode.d8.loss_cls: 0.2552  decode.d8.loss_mask: 1.4466  decode.d8.loss_dice: 1.5199
2025/03/29 13:46:33 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 13:46:33 - mmengine - INFO - Iter(train) [ 2000/20000]  base_lr: 9.0957e-05 lr: 9.0957e-05  eta: 14:54:57  time: 3.0029  data_time: 0.0225  memory: 10131  loss: 28.0895  decode.loss_cls: 0.2444  decode.loss_mask: 1.2209  decode.loss_dice: 1.3176  decode.d0.loss_cls: 0.5224  decode.d0.loss_mask: 1.1804  decode.d0.loss_dice: 1.3820  decode.d1.loss_cls: 0.2718  decode.d1.loss_mask: 1.1818  decode.d1.loss_dice: 1.3204  decode.d2.loss_cls: 0.2641  decode.d2.loss_mask: 1.2003  decode.d2.loss_dice: 1.3169  decode.d3.loss_cls: 0.2757  decode.d3.loss_mask: 1.1987  decode.d3.loss_dice: 1.2891  decode.d4.loss_cls: 0.2448  decode.d4.loss_mask: 1.2058  decode.d4.loss_dice: 1.2852  decode.d5.loss_cls: 0.2957  decode.d5.loss_mask: 1.1904  decode.d5.loss_dice: 1.2924  decode.d6.loss_cls: 0.3014  decode.d6.loss_mask: 1.2095  decode.d6.loss_dice: 1.2984  decode.d7.loss_cls: 0.2580  decode.d7.loss_mask: 1.2232  decode.d7.loss_dice: 1.3113  decode.d8.loss_cls: 0.2295  decode.d8.loss_mask: 1.2328  decode.d8.loss_dice: 1.3245
2025/03/29 13:46:33 - mmengine - INFO - Saving checkpoint at 2000 iterations
2025/03/29 13:46:50 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:01:39  time: 0.2569  data_time: 0.0024  memory: 10029  
2025/03/29 13:47:03 - mmengine - INFO - Iter(val) [100/398]    eta: 0:01:20  time: 0.2552  data_time: 0.0020  memory: 1808  
2025/03/29 13:47:15 - mmengine - INFO - Iter(val) [150/398]    eta: 0:01:05  time: 0.2559  data_time: 0.0020  memory: 1808  
2025/03/29 13:47:28 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:52  time: 0.2546  data_time: 0.0019  memory: 1808  
2025/03/29 13:47:41 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:38  time: 0.2532  data_time: 0.0020  memory: 1808  
2025/03/29 13:47:54 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:25  time: 0.2556  data_time: 0.0020  memory: 1808  
2025/03/29 13:48:07 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:12  time: 0.2547  data_time: 0.0020  memory: 1808  
2025/03/29 13:48:19 - mmengine - INFO - per class results:
2025/03/29 13:48:19 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 68.14 | 70.36 |
|      building      | 79.19 | 86.02 |
|   low_vegetation   | 30.34 | 34.82 |
|        tree        | 67.25 | 76.19 |
|        car         | 52.49 |  65.2 |
|      clutter       |  3.93 | 97.46 |
+--------------------+-------+-------+
2025/03/29 13:48:19 - mmengine - INFO - Iter(val) [398/398]    aAcc: 67.9700  mIoU: 50.2200  mAcc: 71.6800  data_time: 0.0031  time: 0.2591
2025/03/29 13:48:20 - mmengine - INFO - The best checkpoint with 50.2200 mIoU at 2000 iter is saved to best_mIoU_iter_2000.pth.
2025/03/29 13:50:42 - mmengine - INFO - Iter(train) [ 2050/20000]  base_lr: 9.0730e-05 lr: 9.0730e-05  eta: 14:51:31  time: 1.9458  data_time: 0.0269  memory: 10118  loss: 33.2571  decode.loss_cls: 0.2469  decode.loss_mask: 1.4603  decode.loss_dice: 1.5658  decode.d0.loss_cls: 0.5074  decode.d0.loss_mask: 1.4554  decode.d0.loss_dice: 1.6150  decode.d1.loss_cls: 0.2851  decode.d1.loss_mask: 1.4544  decode.d1.loss_dice: 1.5987  decode.d2.loss_cls: 0.2135  decode.d2.loss_mask: 1.4391  decode.d2.loss_dice: 1.5771  decode.d3.loss_cls: 0.3169  decode.d3.loss_mask: 1.4303  decode.d3.loss_dice: 1.5585  decode.d4.loss_cls: 0.2821  decode.d4.loss_mask: 1.4294  decode.d4.loss_dice: 1.5652  decode.d5.loss_cls: 0.2873  decode.d5.loss_mask: 1.4408  decode.d5.loss_dice: 1.5410  decode.d6.loss_cls: 0.3284  decode.d6.loss_mask: 1.4492  decode.d6.loss_dice: 1.5526  decode.d7.loss_cls: 0.3127  decode.d7.loss_mask: 1.4502  decode.d7.loss_dice: 1.5921  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 1.4639  decode.d8.loss_dice: 1.5783
2025/03/29 13:51:40 - mmengine - INFO - Iter(train) [ 2100/20000]  base_lr: 9.0502e-05 lr: 9.0502e-05  eta: 14:36:08  time: 1.1797  data_time: 0.0252  memory: 10125  loss: 28.0184  decode.loss_cls: 0.1476  decode.loss_mask: 1.1692  decode.loss_dice: 1.4712  decode.d0.loss_cls: 0.4422  decode.d0.loss_mask: 1.1856  decode.d0.loss_dice: 1.4833  decode.d1.loss_cls: 0.1879  decode.d1.loss_mask: 1.1618  decode.d1.loss_dice: 1.4196  decode.d2.loss_cls: 0.1776  decode.d2.loss_mask: 1.1700  decode.d2.loss_dice: 1.4261  decode.d3.loss_cls: 0.1596  decode.d3.loss_mask: 1.1670  decode.d3.loss_dice: 1.4268  decode.d4.loss_cls: 0.1690  decode.d4.loss_mask: 1.1730  decode.d4.loss_dice: 1.4410  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 1.1716  decode.d5.loss_dice: 1.4430  decode.d6.loss_cls: 0.1421  decode.d6.loss_mask: 1.1792  decode.d6.loss_dice: 1.4372  decode.d7.loss_cls: 0.1548  decode.d7.loss_mask: 1.1696  decode.d7.loss_dice: 1.4382  decode.d8.loss_cls: 0.1437  decode.d8.loss_mask: 1.1740  decode.d8.loss_dice: 1.4297
2025/03/29 13:52:36 - mmengine - INFO - Iter(train) [ 2150/20000]  base_lr: 9.0275e-05 lr: 9.0275e-05  eta: 14:21:05  time: 1.1120  data_time: 0.0208  memory: 10133  loss: 29.1686  decode.loss_cls: 0.2835  decode.loss_mask: 1.1248  decode.loss_dice: 1.4658  decode.d0.loss_cls: 0.4199  decode.d0.loss_mask: 1.1644  decode.d0.loss_dice: 1.5793  decode.d1.loss_cls: 0.2048  decode.d1.loss_mask: 1.1352  decode.d1.loss_dice: 1.5131  decode.d2.loss_cls: 0.2606  decode.d2.loss_mask: 1.1294  decode.d2.loss_dice: 1.4968  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 1.1518  decode.d3.loss_dice: 1.5039  decode.d4.loss_cls: 0.2629  decode.d4.loss_mask: 1.1542  decode.d4.loss_dice: 1.4956  decode.d5.loss_cls: 0.2747  decode.d5.loss_mask: 1.1405  decode.d5.loss_dice: 1.4841  decode.d6.loss_cls: 0.2747  decode.d6.loss_mask: 1.1413  decode.d6.loss_dice: 1.4741  decode.d7.loss_cls: 0.3203  decode.d7.loss_mask: 1.1304  decode.d7.loss_dice: 1.4585  decode.d8.loss_cls: 0.2869  decode.d8.loss_mask: 1.1177  decode.d8.loss_dice: 1.4742
2025/03/29 13:53:32 - mmengine - INFO - Iter(train) [ 2200/20000]  base_lr: 9.0047e-05 lr: 9.0047e-05  eta: 14:06:43  time: 1.1185  data_time: 0.0215  memory: 10129  loss: 27.9165  decode.loss_cls: 0.2572  decode.loss_mask: 1.1884  decode.loss_dice: 1.3043  decode.d0.loss_cls: 0.4316  decode.d0.loss_mask: 1.2117  decode.d0.loss_dice: 1.3775  decode.d1.loss_cls: 0.2253  decode.d1.loss_mask: 1.2023  decode.d1.loss_dice: 1.3527  decode.d2.loss_cls: 0.2593  decode.d2.loss_mask: 1.1792  decode.d2.loss_dice: 1.3192  decode.d3.loss_cls: 0.2384  decode.d3.loss_mask: 1.2091  decode.d3.loss_dice: 1.3122  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 1.2033  decode.d4.loss_dice: 1.3370  decode.d5.loss_cls: 0.2393  decode.d5.loss_mask: 1.1967  decode.d5.loss_dice: 1.3243  decode.d6.loss_cls: 0.2399  decode.d6.loss_mask: 1.1987  decode.d6.loss_dice: 1.3521  decode.d7.loss_cls: 0.2428  decode.d7.loss_mask: 1.2060  decode.d7.loss_dice: 1.3194  decode.d8.loss_cls: 0.2502  decode.d8.loss_mask: 1.1808  decode.d8.loss_dice: 1.3215
2025/03/29 13:54:27 - mmengine - INFO - Iter(train) [ 2250/20000]  base_lr: 8.9820e-05 lr: 8.9820e-05  eta: 13:52:55  time: 1.1160  data_time: 0.0213  memory: 10130  loss: 29.3520  decode.loss_cls: 0.2287  decode.loss_mask: 1.3776  decode.loss_dice: 1.3287  decode.d0.loss_cls: 0.4186  decode.d0.loss_mask: 1.3136  decode.d0.loss_dice: 1.3893  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 1.3508  decode.d1.loss_dice: 1.3428  decode.d2.loss_cls: 0.2197  decode.d2.loss_mask: 1.3318  decode.d2.loss_dice: 1.3157  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 1.3534  decode.d3.loss_dice: 1.3307  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 1.3781  decode.d4.loss_dice: 1.3396  decode.d5.loss_cls: 0.2510  decode.d5.loss_mask: 1.3693  decode.d5.loss_dice: 1.3339  decode.d6.loss_cls: 0.2659  decode.d6.loss_mask: 1.3620  decode.d6.loss_dice: 1.3211  decode.d7.loss_cls: 0.2077  decode.d7.loss_mask: 1.3654  decode.d7.loss_dice: 1.3176  decode.d8.loss_cls: 0.2710  decode.d8.loss_mask: 1.3600  decode.d8.loss_dice: 1.3050
2025/03/29 13:55:23 - mmengine - INFO - Iter(train) [ 2300/20000]  base_lr: 8.9592e-05 lr: 8.9592e-05  eta: 13:39:41  time: 1.1105  data_time: 0.0203  memory: 10133  loss: 32.6182  decode.loss_cls: 0.2762  decode.loss_mask: 1.3673  decode.loss_dice: 1.6084  decode.d0.loss_cls: 0.3921  decode.d0.loss_mask: 1.4039  decode.d0.loss_dice: 1.6317  decode.d1.loss_cls: 0.2159  decode.d1.loss_mask: 1.4112  decode.d1.loss_dice: 1.6084  decode.d2.loss_cls: 0.2472  decode.d2.loss_mask: 1.3906  decode.d2.loss_dice: 1.6131  decode.d3.loss_cls: 0.2510  decode.d3.loss_mask: 1.3785  decode.d3.loss_dice: 1.5850  decode.d4.loss_cls: 0.2591  decode.d4.loss_mask: 1.3843  decode.d4.loss_dice: 1.5736  decode.d5.loss_cls: 0.2578  decode.d5.loss_mask: 1.3876  decode.d5.loss_dice: 1.6199  decode.d6.loss_cls: 0.2520  decode.d6.loss_mask: 1.3890  decode.d6.loss_dice: 1.6154  decode.d7.loss_cls: 0.2558  decode.d7.loss_mask: 1.3924  decode.d7.loss_dice: 1.5923  decode.d8.loss_cls: 0.2578  decode.d8.loss_mask: 1.3786  decode.d8.loss_dice: 1.6220
2025/03/29 13:56:19 - mmengine - INFO - Iter(train) [ 2350/20000]  base_lr: 8.9364e-05 lr: 8.9364e-05  eta: 13:26:57  time: 1.1133  data_time: 0.0209  memory: 10128  loss: 30.6536  decode.loss_cls: 0.1746  decode.loss_mask: 1.3178  decode.loss_dice: 1.5492  decode.d0.loss_cls: 0.3795  decode.d0.loss_mask: 1.3383  decode.d0.loss_dice: 1.5929  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 1.2929  decode.d1.loss_dice: 1.5341  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 1.2846  decode.d2.loss_dice: 1.5181  decode.d3.loss_cls: 0.2086  decode.d3.loss_mask: 1.2864  decode.d3.loss_dice: 1.5107  decode.d4.loss_cls: 0.2065  decode.d4.loss_mask: 1.3047  decode.d4.loss_dice: 1.5286  decode.d5.loss_cls: 0.2043  decode.d5.loss_mask: 1.3027  decode.d5.loss_dice: 1.5170  decode.d6.loss_cls: 0.1836  decode.d6.loss_mask: 1.3195  decode.d6.loss_dice: 1.5196  decode.d7.loss_cls: 0.2372  decode.d7.loss_mask: 1.3007  decode.d7.loss_dice: 1.5244  decode.d8.loss_cls: 0.2414  decode.d8.loss_mask: 1.3149  decode.d8.loss_dice: 1.5310
2025/03/29 13:57:15 - mmengine - INFO - Iter(train) [ 2400/20000]  base_lr: 8.9136e-05 lr: 8.9136e-05  eta: 13:14:45  time: 1.1111  data_time: 0.0202  memory: 10124  loss: 29.7188  decode.loss_cls: 0.2625  decode.loss_mask: 1.2227  decode.loss_dice: 1.4681  decode.d0.loss_cls: 0.4118  decode.d0.loss_mask: 1.2280  decode.d0.loss_dice: 1.5672  decode.d1.loss_cls: 0.2572  decode.d1.loss_mask: 1.2242  decode.d1.loss_dice: 1.5048  decode.d2.loss_cls: 0.2682  decode.d2.loss_mask: 1.1880  decode.d2.loss_dice: 1.4771  decode.d3.loss_cls: 0.2568  decode.d3.loss_mask: 1.1838  decode.d3.loss_dice: 1.4550  decode.d4.loss_cls: 0.2581  decode.d4.loss_mask: 1.1854  decode.d4.loss_dice: 1.4746  decode.d5.loss_cls: 0.2956  decode.d5.loss_mask: 1.1796  decode.d5.loss_dice: 1.4848  decode.d6.loss_cls: 0.2629  decode.d6.loss_mask: 1.1977  decode.d6.loss_dice: 1.4737  decode.d7.loss_cls: 0.2777  decode.d7.loss_mask: 1.1935  decode.d7.loss_dice: 1.4996  decode.d8.loss_cls: 0.2948  decode.d8.loss_mask: 1.1936  decode.d8.loss_dice: 1.4720
2025/03/29 13:58:11 - mmengine - INFO - Iter(train) [ 2450/20000]  base_lr: 8.8908e-05 lr: 8.8908e-05  eta: 13:03:00  time: 1.1139  data_time: 0.0205  memory: 10124  loss: 30.7065  decode.loss_cls: 0.2464  decode.loss_mask: 1.3308  decode.loss_dice: 1.4961  decode.d0.loss_cls: 0.4046  decode.d0.loss_mask: 1.3370  decode.d0.loss_dice: 1.5818  decode.d1.loss_cls: 0.2478  decode.d1.loss_mask: 1.3224  decode.d1.loss_dice: 1.5047  decode.d2.loss_cls: 0.1837  decode.d2.loss_mask: 1.3463  decode.d2.loss_dice: 1.4950  decode.d3.loss_cls: 0.1841  decode.d3.loss_mask: 1.3017  decode.d3.loss_dice: 1.4852  decode.d4.loss_cls: 0.1852  decode.d4.loss_mask: 1.3227  decode.d4.loss_dice: 1.5108  decode.d5.loss_cls: 0.2105  decode.d5.loss_mask: 1.3133  decode.d5.loss_dice: 1.4988  decode.d6.loss_cls: 0.2242  decode.d6.loss_mask: 1.3193  decode.d6.loss_dice: 1.5215  decode.d7.loss_cls: 0.2523  decode.d7.loss_mask: 1.3127  decode.d7.loss_dice: 1.4990  decode.d8.loss_cls: 0.2330  decode.d8.loss_mask: 1.3313  decode.d8.loss_dice: 1.5043
2025/03/29 13:59:07 - mmengine - INFO - Iter(train) [ 2500/20000]  base_lr: 8.8680e-05 lr: 8.8680e-05  eta: 12:51:40  time: 1.1137  data_time: 0.0207  memory: 10127  loss: 29.4721  decode.loss_cls: 0.1917  decode.loss_mask: 1.2023  decode.loss_dice: 1.5402  decode.d0.loss_cls: 0.3803  decode.d0.loss_mask: 1.2103  decode.d0.loss_dice: 1.5579  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 1.1999  decode.d1.loss_dice: 1.5074  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 1.2075  decode.d2.loss_dice: 1.5095  decode.d3.loss_cls: 0.2251  decode.d3.loss_mask: 1.1806  decode.d3.loss_dice: 1.4974  decode.d4.loss_cls: 0.2557  decode.d4.loss_mask: 1.1887  decode.d4.loss_dice: 1.4848  decode.d5.loss_cls: 0.2321  decode.d5.loss_mask: 1.1981  decode.d5.loss_dice: 1.4953  decode.d6.loss_cls: 0.2176  decode.d6.loss_mask: 1.2134  decode.d6.loss_dice: 1.4984  decode.d7.loss_cls: 0.1946  decode.d7.loss_mask: 1.2080  decode.d7.loss_dice: 1.5275  decode.d8.loss_cls: 0.1738  decode.d8.loss_mask: 1.2103  decode.d8.loss_dice: 1.5497
2025/03/29 14:00:03 - mmengine - INFO - Iter(train) [ 2550/20000]  base_lr: 8.8452e-05 lr: 8.8452e-05  eta: 12:40:46  time: 1.1106  data_time: 0.0201  memory: 10129  loss: 30.0863  decode.loss_cls: 0.2892  decode.loss_mask: 1.2749  decode.loss_dice: 1.4415  decode.d0.loss_cls: 0.4598  decode.d0.loss_mask: 1.2926  decode.d0.loss_dice: 1.4450  decode.d1.loss_cls: 0.3039  decode.d1.loss_mask: 1.2609  decode.d1.loss_dice: 1.4112  decode.d2.loss_cls: 0.3479  decode.d2.loss_mask: 1.2290  decode.d2.loss_dice: 1.3844  decode.d3.loss_cls: 0.3170  decode.d3.loss_mask: 1.2394  decode.d3.loss_dice: 1.3982  decode.d4.loss_cls: 0.3672  decode.d4.loss_mask: 1.2463  decode.d4.loss_dice: 1.3728  decode.d5.loss_cls: 0.3541  decode.d5.loss_mask: 1.2444  decode.d5.loss_dice: 1.3870  decode.d6.loss_cls: 0.3123  decode.d6.loss_mask: 1.2781  decode.d6.loss_dice: 1.3998  decode.d7.loss_cls: 0.3382  decode.d7.loss_mask: 1.2530  decode.d7.loss_dice: 1.4023  decode.d8.loss_cls: 0.3509  decode.d8.loss_mask: 1.2572  decode.d8.loss_dice: 1.4277
2025/03/29 14:00:59 - mmengine - INFO - Iter(train) [ 2600/20000]  base_lr: 8.8224e-05 lr: 8.8224e-05  eta: 12:30:14  time: 1.1123  data_time: 0.0205  memory: 10130  loss: 29.1114  decode.loss_cls: 0.1893  decode.loss_mask: 1.2410  decode.loss_dice: 1.4849  decode.d0.loss_cls: 0.3897  decode.d0.loss_mask: 1.2199  decode.d0.loss_dice: 1.5072  decode.d1.loss_cls: 0.2307  decode.d1.loss_mask: 1.2109  decode.d1.loss_dice: 1.4548  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 1.2130  decode.d2.loss_dice: 1.4508  decode.d3.loss_cls: 0.1856  decode.d3.loss_mask: 1.2309  decode.d3.loss_dice: 1.4437  decode.d4.loss_cls: 0.2613  decode.d4.loss_mask: 1.2055  decode.d4.loss_dice: 1.4258  decode.d5.loss_cls: 0.2148  decode.d5.loss_mask: 1.2142  decode.d5.loss_dice: 1.4437  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 1.2034  decode.d6.loss_dice: 1.4417  decode.d7.loss_cls: 0.2074  decode.d7.loss_mask: 1.2130  decode.d7.loss_dice: 1.4794  decode.d8.loss_cls: 0.1719  decode.d8.loss_mask: 1.2338  decode.d8.loss_dice: 1.4778
2025/03/29 14:01:55 - mmengine - INFO - Iter(train) [ 2650/20000]  base_lr: 8.7996e-05 lr: 8.7996e-05  eta: 12:20:08  time: 1.1887  data_time: 0.0254  memory: 10125  loss: 29.1521  decode.loss_cls: 0.2697  decode.loss_mask: 1.2215  decode.loss_dice: 1.4400  decode.d0.loss_cls: 0.4184  decode.d0.loss_mask: 1.2570  decode.d0.loss_dice: 1.4726  decode.d1.loss_cls: 0.2844  decode.d1.loss_mask: 1.1929  decode.d1.loss_dice: 1.4055  decode.d2.loss_cls: 0.2592  decode.d2.loss_mask: 1.1856  decode.d2.loss_dice: 1.4065  decode.d3.loss_cls: 0.2411  decode.d3.loss_mask: 1.1831  decode.d3.loss_dice: 1.4240  decode.d4.loss_cls: 0.2391  decode.d4.loss_mask: 1.1862  decode.d4.loss_dice: 1.4296  decode.d5.loss_cls: 0.2049  decode.d5.loss_mask: 1.2174  decode.d5.loss_dice: 1.4531  decode.d6.loss_cls: 0.2644  decode.d6.loss_mask: 1.2090  decode.d6.loss_dice: 1.4334  decode.d7.loss_cls: 0.2757  decode.d7.loss_mask: 1.2119  decode.d7.loss_dice: 1.4293  decode.d8.loss_cls: 0.2837  decode.d8.loss_mask: 1.2238  decode.d8.loss_dice: 1.4292
2025/03/29 14:02:52 - mmengine - INFO - Iter(train) [ 2700/20000]  base_lr: 8.7768e-05 lr: 8.7768e-05  eta: 12:10:20  time: 1.1093  data_time: 0.0198  memory: 10124  loss: 29.4329  decode.loss_cls: 0.2700  decode.loss_mask: 1.1974  decode.loss_dice: 1.4764  decode.d0.loss_cls: 0.3892  decode.d0.loss_mask: 1.2188  decode.d0.loss_dice: 1.4944  decode.d1.loss_cls: 0.2514  decode.d1.loss_mask: 1.2010  decode.d1.loss_dice: 1.4503  decode.d2.loss_cls: 0.2571  decode.d2.loss_mask: 1.1811  decode.d2.loss_dice: 1.4352  decode.d3.loss_cls: 0.2449  decode.d3.loss_mask: 1.2119  decode.d3.loss_dice: 1.4529  decode.d4.loss_cls: 0.2839  decode.d4.loss_mask: 1.1923  decode.d4.loss_dice: 1.4570  decode.d5.loss_cls: 0.3002  decode.d5.loss_mask: 1.1914  decode.d5.loss_dice: 1.4584  decode.d6.loss_cls: 0.2763  decode.d6.loss_mask: 1.2033  decode.d6.loss_dice: 1.4529  decode.d7.loss_cls: 0.2889  decode.d7.loss_mask: 1.1923  decode.d7.loss_dice: 1.4587  decode.d8.loss_cls: 0.2406  decode.d8.loss_mask: 1.1966  decode.d8.loss_dice: 1.5080
2025/03/29 14:03:47 - mmengine - INFO - Iter(train) [ 2750/20000]  base_lr: 8.7539e-05 lr: 8.7539e-05  eta: 12:00:49  time: 1.1163  data_time: 0.0205  memory: 10126  loss: 30.2312  decode.loss_cls: 0.2015  decode.loss_mask: 1.2640  decode.loss_dice: 1.5734  decode.d0.loss_cls: 0.3867  decode.d0.loss_mask: 1.2702  decode.d0.loss_dice: 1.6189  decode.d1.loss_cls: 0.1839  decode.d1.loss_mask: 1.2506  decode.d1.loss_dice: 1.5497  decode.d2.loss_cls: 0.2112  decode.d2.loss_mask: 1.2312  decode.d2.loss_dice: 1.5402  decode.d3.loss_cls: 0.2367  decode.d3.loss_mask: 1.2271  decode.d3.loss_dice: 1.5241  decode.d4.loss_cls: 0.2326  decode.d4.loss_mask: 1.2218  decode.d4.loss_dice: 1.5358  decode.d5.loss_cls: 0.2473  decode.d5.loss_mask: 1.2250  decode.d5.loss_dice: 1.5219  decode.d6.loss_cls: 0.2509  decode.d6.loss_mask: 1.2217  decode.d6.loss_dice: 1.5405  decode.d7.loss_cls: 0.2365  decode.d7.loss_mask: 1.2240  decode.d7.loss_dice: 1.5337  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 1.2367  decode.d8.loss_dice: 1.5401
2025/03/29 14:04:43 - mmengine - INFO - Iter(train) [ 2800/20000]  base_lr: 8.7311e-05 lr: 8.7311e-05  eta: 11:51:38  time: 1.1153  data_time: 0.0208  memory: 10118  loss: 28.0375  decode.loss_cls: 0.2371  decode.loss_mask: 1.1813  decode.loss_dice: 1.3963  decode.d0.loss_cls: 0.3600  decode.d0.loss_mask: 1.1521  decode.d0.loss_dice: 1.4299  decode.d1.loss_cls: 0.3229  decode.d1.loss_mask: 1.1468  decode.d1.loss_dice: 1.3543  decode.d2.loss_cls: 0.3148  decode.d2.loss_mask: 1.1200  decode.d2.loss_dice: 1.3067  decode.d3.loss_cls: 0.2740  decode.d3.loss_mask: 1.1265  decode.d3.loss_dice: 1.3345  decode.d4.loss_cls: 0.3230  decode.d4.loss_mask: 1.1318  decode.d4.loss_dice: 1.3289  decode.d5.loss_cls: 0.2951  decode.d5.loss_mask: 1.1339  decode.d5.loss_dice: 1.3196  decode.d6.loss_cls: 0.3042  decode.d6.loss_mask: 1.1696  decode.d6.loss_dice: 1.3480  decode.d7.loss_cls: 0.2976  decode.d7.loss_mask: 1.1565  decode.d7.loss_dice: 1.3521  decode.d8.loss_cls: 0.2808  decode.d8.loss_mask: 1.1758  decode.d8.loss_dice: 1.3631
2025/03/29 14:05:39 - mmengine - INFO - Iter(train) [ 2850/20000]  base_lr: 8.7082e-05 lr: 8.7082e-05  eta: 11:42:43  time: 1.1202  data_time: 0.0205  memory: 10129  loss: 27.8741  decode.loss_cls: 0.1623  decode.loss_mask: 1.1425  decode.loss_dice: 1.4926  decode.d0.loss_cls: 0.2756  decode.d0.loss_mask: 1.1479  decode.d0.loss_dice: 1.5415  decode.d1.loss_cls: 0.1874  decode.d1.loss_mask: 1.1197  decode.d1.loss_dice: 1.4799  decode.d2.loss_cls: 0.1999  decode.d2.loss_mask: 1.1283  decode.d2.loss_dice: 1.4445  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 1.1269  decode.d3.loss_dice: 1.4346  decode.d4.loss_cls: 0.1844  decode.d4.loss_mask: 1.1120  decode.d4.loss_dice: 1.4456  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 1.1029  decode.d5.loss_dice: 1.4462  decode.d6.loss_cls: 0.1939  decode.d6.loss_mask: 1.1191  decode.d6.loss_dice: 1.4494  decode.d7.loss_cls: 0.1660  decode.d7.loss_mask: 1.1430  decode.d7.loss_dice: 1.4547  decode.d8.loss_cls: 0.2055  decode.d8.loss_mask: 1.1335  decode.d8.loss_dice: 1.4634
2025/03/29 14:06:35 - mmengine - INFO - Iter(train) [ 2900/20000]  base_lr: 8.6854e-05 lr: 8.6854e-05  eta: 11:34:04  time: 1.1148  data_time: 0.0202  memory: 10129  loss: 27.6349  decode.loss_cls: 0.1579  decode.loss_mask: 1.1848  decode.loss_dice: 1.3887  decode.d0.loss_cls: 0.3317  decode.d0.loss_mask: 1.1287  decode.d0.loss_dice: 1.4131  decode.d1.loss_cls: 0.2172  decode.d1.loss_mask: 1.1548  decode.d1.loss_dice: 1.3583  decode.d2.loss_cls: 0.2193  decode.d2.loss_mask: 1.1577  decode.d2.loss_dice: 1.3602  decode.d3.loss_cls: 0.2382  decode.d3.loss_mask: 1.1868  decode.d3.loss_dice: 1.3594  decode.d4.loss_cls: 0.2218  decode.d4.loss_mask: 1.1804  decode.d4.loss_dice: 1.3783  decode.d5.loss_cls: 0.2016  decode.d5.loss_mask: 1.1595  decode.d5.loss_dice: 1.3689  decode.d6.loss_cls: 0.2452  decode.d6.loss_mask: 1.1763  decode.d6.loss_dice: 1.3520  decode.d7.loss_cls: 0.2257  decode.d7.loss_mask: 1.1847  decode.d7.loss_dice: 1.3459  decode.d8.loss_cls: 0.1716  decode.d8.loss_mask: 1.1868  decode.d8.loss_dice: 1.3794
2025/03/29 14:07:31 - mmengine - INFO - Iter(train) [ 2950/20000]  base_lr: 8.6625e-05 lr: 8.6625e-05  eta: 11:25:44  time: 1.1354  data_time: 0.0218  memory: 10122  loss: 29.2340  decode.loss_cls: 0.3214  decode.loss_mask: 1.2261  decode.loss_dice: 1.3500  decode.d0.loss_cls: 0.3964  decode.d0.loss_mask: 1.2239  decode.d0.loss_dice: 1.4401  decode.d1.loss_cls: 0.3122  decode.d1.loss_mask: 1.2256  decode.d1.loss_dice: 1.3704  decode.d2.loss_cls: 0.2818  decode.d2.loss_mask: 1.2019  decode.d2.loss_dice: 1.3312  decode.d3.loss_cls: 0.2936  decode.d3.loss_mask: 1.2287  decode.d3.loss_dice: 1.3558  decode.d4.loss_cls: 0.3320  decode.d4.loss_mask: 1.2234  decode.d4.loss_dice: 1.3857  decode.d5.loss_cls: 0.3758  decode.d5.loss_mask: 1.2171  decode.d5.loss_dice: 1.3977  decode.d6.loss_cls: 0.3511  decode.d6.loss_mask: 1.2331  decode.d6.loss_dice: 1.3500  decode.d7.loss_cls: 0.3090  decode.d7.loss_mask: 1.2240  decode.d7.loss_dice: 1.3735  decode.d8.loss_cls: 0.3336  decode.d8.loss_mask: 1.2121  decode.d8.loss_dice: 1.3564
2025/03/29 14:08:27 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 14:08:27 - mmengine - INFO - Iter(train) [ 3000/20000]  base_lr: 8.6397e-05 lr: 8.6397e-05  eta: 11:17:36  time: 1.1156  data_time: 0.0205  memory: 10118  loss: 28.7654  decode.loss_cls: 0.2424  decode.loss_mask: 1.2495  decode.loss_dice: 1.3658  decode.d0.loss_cls: 0.3377  decode.d0.loss_mask: 1.2387  decode.d0.loss_dice: 1.4686  decode.d1.loss_cls: 0.3024  decode.d1.loss_mask: 1.2356  decode.d1.loss_dice: 1.3602  decode.d2.loss_cls: 0.2826  decode.d2.loss_mask: 1.2434  decode.d2.loss_dice: 1.3210  decode.d3.loss_cls: 0.2490  decode.d3.loss_mask: 1.2367  decode.d3.loss_dice: 1.3324  decode.d4.loss_cls: 0.2593  decode.d4.loss_mask: 1.2218  decode.d4.loss_dice: 1.3270  decode.d5.loss_cls: 0.2437  decode.d5.loss_mask: 1.2342  decode.d5.loss_dice: 1.3336  decode.d6.loss_cls: 0.2470  decode.d6.loss_mask: 1.2301  decode.d6.loss_dice: 1.3615  decode.d7.loss_cls: 0.2395  decode.d7.loss_mask: 1.2586  decode.d7.loss_dice: 1.4209  decode.d8.loss_cls: 0.2415  decode.d8.loss_mask: 1.2949  decode.d8.loss_dice: 1.3857
2025/03/29 14:09:23 - mmengine - INFO - Iter(train) [ 3050/20000]  base_lr: 8.6168e-05 lr: 8.6168e-05  eta: 11:09:44  time: 1.1241  data_time: 0.0215  memory: 10136  loss: 30.7424  decode.loss_cls: 0.2958  decode.loss_mask: 1.2489  decode.loss_dice: 1.5766  decode.d0.loss_cls: 0.3330  decode.d0.loss_mask: 1.2340  decode.d0.loss_dice: 1.5898  decode.d1.loss_cls: 0.2851  decode.d1.loss_mask: 1.2231  decode.d1.loss_dice: 1.5127  decode.d2.loss_cls: 0.3442  decode.d2.loss_mask: 1.2198  decode.d2.loss_dice: 1.4603  decode.d3.loss_cls: 0.3370  decode.d3.loss_mask: 1.2213  decode.d3.loss_dice: 1.4863  decode.d4.loss_cls: 0.3741  decode.d4.loss_mask: 1.1994  decode.d4.loss_dice: 1.4643  decode.d5.loss_cls: 0.3391  decode.d5.loss_mask: 1.2229  decode.d5.loss_dice: 1.4826  decode.d6.loss_cls: 0.3377  decode.d6.loss_mask: 1.2348  decode.d6.loss_dice: 1.5238  decode.d7.loss_cls: 0.2959  decode.d7.loss_mask: 1.2460  decode.d7.loss_dice: 1.5511  decode.d8.loss_cls: 0.3469  decode.d8.loss_mask: 1.2320  decode.d8.loss_dice: 1.5237
2025/03/29 14:10:19 - mmengine - INFO - Iter(train) [ 3100/20000]  base_lr: 8.5939e-05 lr: 8.5939e-05  eta: 11:02:05  time: 1.1135  data_time: 0.0207  memory: 10126  loss: 25.3359  decode.loss_cls: 0.1618  decode.loss_mask: 1.0719  decode.loss_dice: 1.2581  decode.d0.loss_cls: 0.3040  decode.d0.loss_mask: 1.1120  decode.d0.loss_dice: 1.3397  decode.d1.loss_cls: 0.1502  decode.d1.loss_mask: 1.0826  decode.d1.loss_dice: 1.2569  decode.d2.loss_cls: 0.1673  decode.d2.loss_mask: 1.0769  decode.d2.loss_dice: 1.2440  decode.d3.loss_cls: 0.1702  decode.d3.loss_mask: 1.0846  decode.d3.loss_dice: 1.2440  decode.d4.loss_cls: 0.1700  decode.d4.loss_mask: 1.0755  decode.d4.loss_dice: 1.2745  decode.d5.loss_cls: 0.1805  decode.d5.loss_mask: 1.0672  decode.d5.loss_dice: 1.2804  decode.d6.loss_cls: 0.1853  decode.d6.loss_mask: 1.0651  decode.d6.loss_dice: 1.2815  decode.d7.loss_cls: 0.1761  decode.d7.loss_mask: 1.0645  decode.d7.loss_dice: 1.2857  decode.d8.loss_cls: 0.1656  decode.d8.loss_mask: 1.0703  decode.d8.loss_dice: 1.2695
2025/03/29 14:11:16 - mmengine - INFO - Iter(train) [ 3150/20000]  base_lr: 8.5710e-05 lr: 8.5710e-05  eta: 10:54:41  time: 1.1333  data_time: 0.0226  memory: 10119  loss: 27.7878  decode.loss_cls: 0.2053  decode.loss_mask: 1.1599  decode.loss_dice: 1.3590  decode.d0.loss_cls: 0.3210  decode.d0.loss_mask: 1.1814  decode.d0.loss_dice: 1.4155  decode.d1.loss_cls: 0.3187  decode.d1.loss_mask: 1.1408  decode.d1.loss_dice: 1.3411  decode.d2.loss_cls: 0.2699  decode.d2.loss_mask: 1.1525  decode.d2.loss_dice: 1.3507  decode.d3.loss_cls: 0.2368  decode.d3.loss_mask: 1.1462  decode.d3.loss_dice: 1.3526  decode.d4.loss_cls: 0.2589  decode.d4.loss_mask: 1.1377  decode.d4.loss_dice: 1.3449  decode.d5.loss_cls: 0.2629  decode.d5.loss_mask: 1.1494  decode.d5.loss_dice: 1.3500  decode.d6.loss_cls: 0.2774  decode.d6.loss_mask: 1.1476  decode.d6.loss_dice: 1.3500  decode.d7.loss_cls: 0.2543  decode.d7.loss_mask: 1.1745  decode.d7.loss_dice: 1.3412  decode.d8.loss_cls: 0.2410  decode.d8.loss_mask: 1.1769  decode.d8.loss_dice: 1.3698
2025/03/29 14:12:12 - mmengine - INFO - Iter(train) [ 3200/20000]  base_lr: 8.5481e-05 lr: 8.5481e-05  eta: 10:47:28  time: 1.1223  data_time: 0.0210  memory: 10072  loss: 32.4455  decode.loss_cls: 0.2279  decode.loss_mask: 1.4200  decode.loss_dice: 1.5764  decode.d0.loss_cls: 0.3569  decode.d0.loss_mask: 1.4331  decode.d0.loss_dice: 1.6061  decode.d1.loss_cls: 0.2301  decode.d1.loss_mask: 1.4278  decode.d1.loss_dice: 1.5865  decode.d2.loss_cls: 0.2545  decode.d2.loss_mask: 1.4120  decode.d2.loss_dice: 1.5627  decode.d3.loss_cls: 0.3090  decode.d3.loss_mask: 1.4020  decode.d3.loss_dice: 1.5275  decode.d4.loss_cls: 0.3246  decode.d4.loss_mask: 1.3926  decode.d4.loss_dice: 1.5186  decode.d5.loss_cls: 0.2950  decode.d5.loss_mask: 1.4219  decode.d5.loss_dice: 1.5520  decode.d6.loss_cls: 0.2899  decode.d6.loss_mask: 1.3922  decode.d6.loss_dice: 1.5348  decode.d7.loss_cls: 0.2496  decode.d7.loss_mask: 1.4123  decode.d7.loss_dice: 1.5391  decode.d8.loss_cls: 0.2188  decode.d8.loss_mask: 1.4110  decode.d8.loss_dice: 1.5605
2025/03/29 14:13:08 - mmengine - INFO - Iter(train) [ 3250/20000]  base_lr: 8.5252e-05 lr: 8.5252e-05  eta: 10:40:26  time: 1.1144  data_time: 0.0203  memory: 10122  loss: 27.4210  decode.loss_cls: 0.1373  decode.loss_mask: 1.2101  decode.loss_dice: 1.3562  decode.d0.loss_cls: 0.2857  decode.d0.loss_mask: 1.1964  decode.d0.loss_dice: 1.4323  decode.d1.loss_cls: 0.1776  decode.d1.loss_mask: 1.1955  decode.d1.loss_dice: 1.3592  decode.d2.loss_cls: 0.2005  decode.d2.loss_mask: 1.1833  decode.d2.loss_dice: 1.3310  decode.d3.loss_cls: 0.1575  decode.d3.loss_mask: 1.2121  decode.d3.loss_dice: 1.3394  decode.d4.loss_cls: 0.1875  decode.d4.loss_mask: 1.1908  decode.d4.loss_dice: 1.3308  decode.d5.loss_cls: 0.1424  decode.d5.loss_mask: 1.2166  decode.d5.loss_dice: 1.3535  decode.d6.loss_cls: 0.1815  decode.d6.loss_mask: 1.2061  decode.d6.loss_dice: 1.3527  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 1.1739  decode.d7.loss_dice: 1.3791  decode.d8.loss_cls: 0.1681  decode.d8.loss_mask: 1.1809  decode.d8.loss_dice: 1.3857
2025/03/29 14:14:06 - mmengine - INFO - Iter(train) [ 3300/20000]  base_lr: 8.5023e-05 lr: 8.5023e-05  eta: 10:33:43  time: 1.1082  data_time: 0.0203  memory: 10125  loss: 30.5276  decode.loss_cls: 0.3110  decode.loss_mask: 1.3491  decode.loss_dice: 1.4259  decode.d0.loss_cls: 0.3326  decode.d0.loss_mask: 1.3379  decode.d0.loss_dice: 1.5057  decode.d1.loss_cls: 0.2793  decode.d1.loss_mask: 1.3228  decode.d1.loss_dice: 1.4060  decode.d2.loss_cls: 0.2742  decode.d2.loss_mask: 1.3392  decode.d2.loss_dice: 1.4146  decode.d3.loss_cls: 0.2954  decode.d3.loss_mask: 1.3285  decode.d3.loss_dice: 1.4132  decode.d4.loss_cls: 0.2671  decode.d4.loss_mask: 1.3401  decode.d4.loss_dice: 1.4131  decode.d5.loss_cls: 0.2769  decode.d5.loss_mask: 1.3617  decode.d5.loss_dice: 1.4115  decode.d6.loss_cls: 0.2802  decode.d6.loss_mask: 1.3460  decode.d6.loss_dice: 1.4129  decode.d7.loss_cls: 0.2780  decode.d7.loss_mask: 1.3483  decode.d7.loss_dice: 1.4248  decode.d8.loss_cls: 0.2880  decode.d8.loss_mask: 1.3366  decode.d8.loss_dice: 1.4069
2025/03/29 14:15:02 - mmengine - INFO - Iter(train) [ 3350/20000]  base_lr: 8.4794e-05 lr: 8.4794e-05  eta: 10:27:02  time: 1.1192  data_time: 0.0240  memory: 10129  loss: 25.5110  decode.loss_cls: 0.1078  decode.loss_mask: 1.1228  decode.loss_dice: 1.3219  decode.d0.loss_cls: 0.1945  decode.d0.loss_mask: 1.1396  decode.d0.loss_dice: 1.3787  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 1.1372  decode.d1.loss_dice: 1.3043  decode.d2.loss_cls: 0.0931  decode.d2.loss_mask: 1.1110  decode.d2.loss_dice: 1.3198  decode.d3.loss_cls: 0.1385  decode.d3.loss_mask: 1.0769  decode.d3.loss_dice: 1.2965  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 1.0914  decode.d4.loss_dice: 1.3197  decode.d5.loss_cls: 0.1506  decode.d5.loss_mask: 1.0883  decode.d5.loss_dice: 1.2988  decode.d6.loss_cls: 0.1060  decode.d6.loss_mask: 1.0990  decode.d6.loss_dice: 1.3229  decode.d7.loss_cls: 0.1226  decode.d7.loss_mask: 1.0972  decode.d7.loss_dice: 1.3037  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 1.1115  decode.d8.loss_dice: 1.3220
2025/03/29 14:15:58 - mmengine - INFO - Iter(train) [ 3400/20000]  base_lr: 8.4565e-05 lr: 8.4565e-05  eta: 10:20:31  time: 1.1112  data_time: 0.0202  memory: 10118  loss: 29.8181  decode.loss_cls: 0.2872  decode.loss_mask: 1.2566  decode.loss_dice: 1.4358  decode.d0.loss_cls: 0.3437  decode.d0.loss_mask: 1.3138  decode.d0.loss_dice: 1.5628  decode.d1.loss_cls: 0.2873  decode.d1.loss_mask: 1.2448  decode.d1.loss_dice: 1.4649  decode.d2.loss_cls: 0.2743  decode.d2.loss_mask: 1.2674  decode.d2.loss_dice: 1.4507  decode.d3.loss_cls: 0.2755  decode.d3.loss_mask: 1.2256  decode.d3.loss_dice: 1.4325  decode.d4.loss_cls: 0.2695  decode.d4.loss_mask: 1.2390  decode.d4.loss_dice: 1.4264  decode.d5.loss_cls: 0.2399  decode.d5.loss_mask: 1.2465  decode.d5.loss_dice: 1.4224  decode.d6.loss_cls: 0.2590  decode.d6.loss_mask: 1.2475  decode.d6.loss_dice: 1.4213  decode.d7.loss_cls: 0.2778  decode.d7.loss_mask: 1.2499  decode.d7.loss_dice: 1.4141  decode.d8.loss_cls: 0.3026  decode.d8.loss_mask: 1.2514  decode.d8.loss_dice: 1.4279
2025/03/29 14:16:54 - mmengine - INFO - Iter(train) [ 3450/20000]  base_lr: 8.4336e-05 lr: 8.4336e-05  eta: 10:14:09  time: 1.1121  data_time: 0.0200  memory: 10123  loss: 28.7079  decode.loss_cls: 0.2269  decode.loss_mask: 1.2159  decode.loss_dice: 1.3978  decode.d0.loss_cls: 0.3704  decode.d0.loss_mask: 1.2437  decode.d0.loss_dice: 1.4415  decode.d1.loss_cls: 0.2315  decode.d1.loss_mask: 1.2313  decode.d1.loss_dice: 1.4179  decode.d2.loss_cls: 0.2448  decode.d2.loss_mask: 1.2292  decode.d2.loss_dice: 1.3941  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 1.2182  decode.d3.loss_dice: 1.3838  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 1.2255  decode.d4.loss_dice: 1.3995  decode.d5.loss_cls: 0.2563  decode.d5.loss_mask: 1.2132  decode.d5.loss_dice: 1.3754  decode.d6.loss_cls: 0.2112  decode.d6.loss_mask: 1.2265  decode.d6.loss_dice: 1.3992  decode.d7.loss_cls: 0.2061  decode.d7.loss_mask: 1.2212  decode.d7.loss_dice: 1.4097  decode.d8.loss_cls: 0.2680  decode.d8.loss_mask: 1.2222  decode.d8.loss_dice: 1.3889
2025/03/29 14:17:50 - mmengine - INFO - Iter(train) [ 3500/20000]  base_lr: 8.4106e-05 lr: 8.4106e-05  eta: 10:07:55  time: 1.1098  data_time: 0.0195  memory: 10119  loss: 28.9281  decode.loss_cls: 0.2766  decode.loss_mask: 1.2445  decode.loss_dice: 1.3654  decode.d0.loss_cls: 0.2849  decode.d0.loss_mask: 1.2975  decode.d0.loss_dice: 1.4770  decode.d1.loss_cls: 0.2087  decode.d1.loss_mask: 1.2611  decode.d1.loss_dice: 1.3877  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 1.2715  decode.d2.loss_dice: 1.3823  decode.d3.loss_cls: 0.2749  decode.d3.loss_mask: 1.2374  decode.d3.loss_dice: 1.3393  decode.d4.loss_cls: 0.2626  decode.d4.loss_mask: 1.2417  decode.d4.loss_dice: 1.3445  decode.d5.loss_cls: 0.2886  decode.d5.loss_mask: 1.2474  decode.d5.loss_dice: 1.3724  decode.d6.loss_cls: 0.2602  decode.d6.loss_mask: 1.2614  decode.d6.loss_dice: 1.3675  decode.d7.loss_cls: 0.2778  decode.d7.loss_mask: 1.2349  decode.d7.loss_dice: 1.3411  decode.d8.loss_cls: 0.2496  decode.d8.loss_mask: 1.2635  decode.d8.loss_dice: 1.3751
2025/03/29 14:18:45 - mmengine - INFO - Iter(train) [ 3550/20000]  base_lr: 8.3877e-05 lr: 8.3877e-05  eta: 10:01:50  time: 1.1114  data_time: 0.0199  memory: 10131  loss: 28.3130  decode.loss_cls: 0.2221  decode.loss_mask: 1.2305  decode.loss_dice: 1.3607  decode.d0.loss_cls: 0.3012  decode.d0.loss_mask: 1.2310  decode.d0.loss_dice: 1.3832  decode.d1.loss_cls: 0.2519  decode.d1.loss_mask: 1.2111  decode.d1.loss_dice: 1.3448  decode.d2.loss_cls: 0.1976  decode.d2.loss_mask: 1.2518  decode.d2.loss_dice: 1.3580  decode.d3.loss_cls: 0.2336  decode.d3.loss_mask: 1.2190  decode.d3.loss_dice: 1.3265  decode.d4.loss_cls: 0.2498  decode.d4.loss_mask: 1.2201  decode.d4.loss_dice: 1.3480  decode.d5.loss_cls: 0.2681  decode.d5.loss_mask: 1.2114  decode.d5.loss_dice: 1.3469  decode.d6.loss_cls: 0.2793  decode.d6.loss_mask: 1.2095  decode.d6.loss_dice: 1.3493  decode.d7.loss_cls: 0.2757  decode.d7.loss_mask: 1.2223  decode.d7.loss_dice: 1.3658  decode.d8.loss_cls: 0.2386  decode.d8.loss_mask: 1.2377  decode.d8.loss_dice: 1.3674
2025/03/29 14:19:41 - mmengine - INFO - Iter(train) [ 3600/20000]  base_lr: 8.3647e-05 lr: 8.3647e-05  eta: 9:55:54  time: 1.1108  data_time: 0.0199  memory: 10136  loss: 27.6439  decode.loss_cls: 0.1647  decode.loss_mask: 1.1983  decode.loss_dice: 1.3791  decode.d0.loss_cls: 0.2088  decode.d0.loss_mask: 1.2109  decode.d0.loss_dice: 1.4288  decode.d1.loss_cls: 0.2020  decode.d1.loss_mask: 1.1810  decode.d1.loss_dice: 1.3639  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 1.1820  decode.d2.loss_dice: 1.3897  decode.d3.loss_cls: 0.1699  decode.d3.loss_mask: 1.1908  decode.d3.loss_dice: 1.3959  decode.d4.loss_cls: 0.1778  decode.d4.loss_mask: 1.1838  decode.d4.loss_dice: 1.4012  decode.d5.loss_cls: 0.1891  decode.d5.loss_mask: 1.1824  decode.d5.loss_dice: 1.3878  decode.d6.loss_cls: 0.2057  decode.d6.loss_mask: 1.1849  decode.d6.loss_dice: 1.3932  decode.d7.loss_cls: 0.1974  decode.d7.loss_mask: 1.1759  decode.d7.loss_dice: 1.3804  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 1.1740  decode.d8.loss_dice: 1.3780
2025/03/29 14:20:37 - mmengine - INFO - Iter(train) [ 3650/20000]  base_lr: 8.3418e-05 lr: 8.3418e-05  eta: 9:50:07  time: 1.1103  data_time: 0.0199  memory: 10119  loss: 32.8719  decode.loss_cls: 0.2806  decode.loss_mask: 1.5981  decode.loss_dice: 1.4434  decode.d0.loss_cls: 0.4335  decode.d0.loss_mask: 1.6162  decode.d0.loss_dice: 1.4836  decode.d1.loss_cls: 0.3242  decode.d1.loss_mask: 1.5240  decode.d1.loss_dice: 1.4149  decode.d2.loss_cls: 0.2877  decode.d2.loss_mask: 1.5093  decode.d2.loss_dice: 1.4355  decode.d3.loss_cls: 0.3147  decode.d3.loss_mask: 1.4993  decode.d3.loss_dice: 1.4186  decode.d4.loss_cls: 0.3111  decode.d4.loss_mask: 1.5220  decode.d4.loss_dice: 1.4148  decode.d5.loss_cls: 0.3119  decode.d5.loss_mask: 1.5323  decode.d5.loss_dice: 1.4092  decode.d6.loss_cls: 0.3117  decode.d6.loss_mask: 1.5606  decode.d6.loss_dice: 1.4309  decode.d7.loss_cls: 0.3135  decode.d7.loss_mask: 1.5560  decode.d7.loss_dice: 1.4121  decode.d8.loss_cls: 0.2858  decode.d8.loss_mask: 1.4888  decode.d8.loss_dice: 1.4275
2025/03/29 14:21:33 - mmengine - INFO - Iter(train) [ 3700/20000]  base_lr: 8.3188e-05 lr: 8.3188e-05  eta: 9:44:27  time: 1.1150  data_time: 0.0203  memory: 10130  loss: 28.9658  decode.loss_cls: 0.1722  decode.loss_mask: 1.2127  decode.loss_dice: 1.4717  decode.d0.loss_cls: 0.2320  decode.d0.loss_mask: 1.2470  decode.d0.loss_dice: 1.5792  decode.d1.loss_cls: 0.1626  decode.d1.loss_mask: 1.2084  decode.d1.loss_dice: 1.5144  decode.d2.loss_cls: 0.1845  decode.d2.loss_mask: 1.1695  decode.d2.loss_dice: 1.5037  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 1.1635  decode.d3.loss_dice: 1.4973  decode.d4.loss_cls: 0.1758  decode.d4.loss_mask: 1.2011  decode.d4.loss_dice: 1.4955  decode.d5.loss_cls: 0.2052  decode.d5.loss_mask: 1.1931  decode.d5.loss_dice: 1.4771  decode.d6.loss_cls: 0.2485  decode.d6.loss_mask: 1.1823  decode.d6.loss_dice: 1.4891  decode.d7.loss_cls: 0.1920  decode.d7.loss_mask: 1.2008  decode.d7.loss_dice: 1.4910  decode.d8.loss_cls: 0.2078  decode.d8.loss_mask: 1.2071  decode.d8.loss_dice: 1.4768
2025/03/29 14:22:28 - mmengine - INFO - Iter(train) [ 3750/20000]  base_lr: 8.2958e-05 lr: 8.2958e-05  eta: 9:38:55  time: 1.1146  data_time: 0.0206  memory: 10122  loss: 27.8280  decode.loss_cls: 0.2810  decode.loss_mask: 1.2039  decode.loss_dice: 1.3269  decode.d0.loss_cls: 0.2971  decode.d0.loss_mask: 1.1916  decode.d0.loss_dice: 1.4121  decode.d1.loss_cls: 0.2459  decode.d1.loss_mask: 1.1735  decode.d1.loss_dice: 1.2878  decode.d2.loss_cls: 0.3135  decode.d2.loss_mask: 1.1666  decode.d2.loss_dice: 1.2894  decode.d3.loss_cls: 0.2958  decode.d3.loss_mask: 1.1798  decode.d3.loss_dice: 1.2794  decode.d4.loss_cls: 0.3248  decode.d4.loss_mask: 1.2033  decode.d4.loss_dice: 1.2344  decode.d5.loss_cls: 0.2953  decode.d5.loss_mask: 1.2128  decode.d5.loss_dice: 1.2755  decode.d6.loss_cls: 0.3027  decode.d6.loss_mask: 1.1942  decode.d6.loss_dice: 1.2724  decode.d7.loss_cls: 0.2806  decode.d7.loss_mask: 1.2222  decode.d7.loss_dice: 1.2941  decode.d8.loss_cls: 0.2771  decode.d8.loss_mask: 1.2002  decode.d8.loss_dice: 1.2942
2025/03/29 14:23:24 - mmengine - INFO - Iter(train) [ 3800/20000]  base_lr: 8.2729e-05 lr: 8.2729e-05  eta: 9:33:30  time: 1.1065  data_time: 0.0196  memory: 10134  loss: 27.1736  decode.loss_cls: 0.2249  decode.loss_mask: 1.1612  decode.loss_dice: 1.3156  decode.d0.loss_cls: 0.2700  decode.d0.loss_mask: 1.1883  decode.d0.loss_dice: 1.3707  decode.d1.loss_cls: 0.2075  decode.d1.loss_mask: 1.1779  decode.d1.loss_dice: 1.3086  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 1.1837  decode.d2.loss_dice: 1.2907  decode.d3.loss_cls: 0.2662  decode.d3.loss_mask: 1.1784  decode.d3.loss_dice: 1.2569  decode.d4.loss_cls: 0.2691  decode.d4.loss_mask: 1.1544  decode.d4.loss_dice: 1.2740  decode.d5.loss_cls: 0.2918  decode.d5.loss_mask: 1.1566  decode.d5.loss_dice: 1.2931  decode.d6.loss_cls: 0.2789  decode.d6.loss_mask: 1.1647  decode.d6.loss_dice: 1.2779  decode.d7.loss_cls: 0.2403  decode.d7.loss_mask: 1.1665  decode.d7.loss_dice: 1.2833  decode.d8.loss_cls: 0.2222  decode.d8.loss_mask: 1.1765  decode.d8.loss_dice: 1.2881
2025/03/29 14:24:20 - mmengine - INFO - Iter(train) [ 3850/20000]  base_lr: 8.2499e-05 lr: 8.2499e-05  eta: 9:28:12  time: 1.1162  data_time: 0.0206  memory: 10122  loss: 22.8506  decode.loss_cls: 0.1856  decode.loss_mask: 0.9360  decode.loss_dice: 1.1443  decode.d0.loss_cls: 0.2640  decode.d0.loss_mask: 0.9868  decode.d0.loss_dice: 1.1901  decode.d1.loss_cls: 0.1704  decode.d1.loss_mask: 0.9738  decode.d1.loss_dice: 1.1224  decode.d2.loss_cls: 0.2100  decode.d2.loss_mask: 0.9559  decode.d2.loss_dice: 1.1029  decode.d3.loss_cls: 0.1968  decode.d3.loss_mask: 0.9587  decode.d3.loss_dice: 1.1145  decode.d4.loss_cls: 0.1909  decode.d4.loss_mask: 0.9464  decode.d4.loss_dice: 1.1299  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.9404  decode.d5.loss_dice: 1.1256  decode.d6.loss_cls: 0.1963  decode.d6.loss_mask: 0.9606  decode.d6.loss_dice: 1.1279  decode.d7.loss_cls: 0.1868  decode.d7.loss_mask: 0.9400  decode.d7.loss_dice: 1.1253  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 0.9509  decode.d8.loss_dice: 1.1488
2025/03/29 14:25:16 - mmengine - INFO - Iter(train) [ 3900/20000]  base_lr: 8.2269e-05 lr: 8.2269e-05  eta: 9:23:02  time: 1.1154  data_time: 0.0201  memory: 10124  loss: 27.3049  decode.loss_cls: 0.2354  decode.loss_mask: 1.1214  decode.loss_dice: 1.3649  decode.d0.loss_cls: 0.3322  decode.d0.loss_mask: 1.1025  decode.d0.loss_dice: 1.4133  decode.d1.loss_cls: 0.2682  decode.d1.loss_mask: 1.1050  decode.d1.loss_dice: 1.3677  decode.d2.loss_cls: 0.2695  decode.d2.loss_mask: 1.0948  decode.d2.loss_dice: 1.3381  decode.d3.loss_cls: 0.2647  decode.d3.loss_mask: 1.0937  decode.d3.loss_dice: 1.3377  decode.d4.loss_cls: 0.2665  decode.d4.loss_mask: 1.0971  decode.d4.loss_dice: 1.3553  decode.d5.loss_cls: 0.2967  decode.d5.loss_mask: 1.1036  decode.d5.loss_dice: 1.3260  decode.d6.loss_cls: 0.2955  decode.d6.loss_mask: 1.1072  decode.d6.loss_dice: 1.3421  decode.d7.loss_cls: 0.2772  decode.d7.loss_mask: 1.1051  decode.d7.loss_dice: 1.3389  decode.d8.loss_cls: 0.2502  decode.d8.loss_mask: 1.1094  decode.d8.loss_dice: 1.3250
2025/03/29 14:26:12 - mmengine - INFO - Iter(train) [ 3950/20000]  base_lr: 8.2039e-05 lr: 8.2039e-05  eta: 9:17:58  time: 1.1085  data_time: 0.0200  memory: 10131  loss: 27.9119  decode.loss_cls: 0.1522  decode.loss_mask: 1.2177  decode.loss_dice: 1.4010  decode.d0.loss_cls: 0.3046  decode.d0.loss_mask: 1.1568  decode.d0.loss_dice: 1.4088  decode.d1.loss_cls: 0.2575  decode.d1.loss_mask: 1.1584  decode.d1.loss_dice: 1.3838  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.1626  decode.d2.loss_dice: 1.3879  decode.d3.loss_cls: 0.2210  decode.d3.loss_mask: 1.1612  decode.d3.loss_dice: 1.3912  decode.d4.loss_cls: 0.2186  decode.d4.loss_mask: 1.1797  decode.d4.loss_dice: 1.4201  decode.d5.loss_cls: 0.1771  decode.d5.loss_mask: 1.1901  decode.d5.loss_dice: 1.4195  decode.d6.loss_cls: 0.1823  decode.d6.loss_mask: 1.2129  decode.d6.loss_dice: 1.4264  decode.d7.loss_cls: 0.1527  decode.d7.loss_mask: 1.2043  decode.d7.loss_dice: 1.4200  decode.d8.loss_cls: 0.1740  decode.d8.loss_mask: 1.1691  decode.d8.loss_dice: 1.3891
2025/03/29 14:27:08 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 14:27:08 - mmengine - INFO - Iter(train) [ 4000/20000]  base_lr: 8.1809e-05 lr: 8.1809e-05  eta: 9:13:00  time: 1.1220  data_time: 0.0210  memory: 10133  loss: 26.7350  decode.loss_cls: 0.1823  decode.loss_mask: 1.0971  decode.loss_dice: 1.3989  decode.d0.loss_cls: 0.2006  decode.d0.loss_mask: 1.1258  decode.d0.loss_dice: 1.4729  decode.d1.loss_cls: 0.1503  decode.d1.loss_mask: 1.1099  decode.d1.loss_dice: 1.4026  decode.d2.loss_cls: 0.1682  decode.d2.loss_mask: 1.1028  decode.d2.loss_dice: 1.3924  decode.d3.loss_cls: 0.1348  decode.d3.loss_mask: 1.1052  decode.d3.loss_dice: 1.4060  decode.d4.loss_cls: 0.1513  decode.d4.loss_mask: 1.1022  decode.d4.loss_dice: 1.3921  decode.d5.loss_cls: 0.1941  decode.d5.loss_mask: 1.0889  decode.d5.loss_dice: 1.3973  decode.d6.loss_cls: 0.1633  decode.d6.loss_mask: 1.0880  decode.d6.loss_dice: 1.3937  decode.d7.loss_cls: 0.1626  decode.d7.loss_mask: 1.0924  decode.d7.loss_dice: 1.4029  decode.d8.loss_cls: 0.1581  decode.d8.loss_mask: 1.0976  decode.d8.loss_dice: 1.4010
2025/03/29 14:27:08 - mmengine - INFO - Saving checkpoint at 4000 iterations
2025/03/29 14:27:16 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:43  time: 0.1258  data_time: 0.0020  memory: 1808  
2025/03/29 14:27:22 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:37  time: 0.1244  data_time: 0.0019  memory: 1808  
2025/03/29 14:27:28 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:30  time: 0.1221  data_time: 0.0018  memory: 1808  
2025/03/29 14:27:35 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1220  data_time: 0.0018  memory: 1808  
2025/03/29 14:27:41 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1249  data_time: 0.0024  memory: 1808  
2025/03/29 14:27:47 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1263  data_time: 0.0035  memory: 1808  
2025/03/29 14:27:53 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1228  data_time: 0.0019  memory: 1808  
2025/03/29 14:27:59 - mmengine - INFO - per class results:
2025/03/29 14:27:59 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 74.97 | 85.59 |
|      building      | 86.25 | 94.91 |
|   low_vegetation   | 56.12 | 71.07 |
|        tree        | 71.58 | 79.61 |
|        car         | 56.45 | 68.63 |
|      clutter       | 34.18 | 91.42 |
+--------------------+-------+-------+
2025/03/29 14:27:59 - mmengine - INFO - Iter(val) [398/398]    aAcc: 83.2500  mIoU: 63.2600  mAcc: 81.8700  data_time: 0.0021  time: 0.1244
2025/03/29 14:27:59 - mmengine - INFO - The previous best checkpoint /home/face/kaichengyang/xiaoxinghu/Earth_Adapter/work_dirs/pr2vi/DG_spatial_24_cutoff_0.3_fft_pre_6/60747_seed0/best_mIoU_iter_2000.pth is removed
2025/03/29 14:28:00 - mmengine - INFO - The best checkpoint with 63.2600 mIoU at 4000 iter is saved to best_mIoU_iter_4000.pth.
2025/03/29 14:28:58 - mmengine - INFO - Iter(train) [ 4050/20000]  base_lr: 8.1579e-05 lr: 8.1579e-05  eta: 9:08:20  time: 1.1133  data_time: 0.0198  memory: 10119  loss: 26.9270  decode.loss_cls: 0.2679  decode.loss_mask: 1.1282  decode.loss_dice: 1.2984  decode.d0.loss_cls: 0.2750  decode.d0.loss_mask: 1.1805  decode.d0.loss_dice: 1.3806  decode.d1.loss_cls: 0.2553  decode.d1.loss_mask: 1.1089  decode.d1.loss_dice: 1.3135  decode.d2.loss_cls: 0.2533  decode.d2.loss_mask: 1.1032  decode.d2.loss_dice: 1.2779  decode.d3.loss_cls: 0.2174  decode.d3.loss_mask: 1.1101  decode.d3.loss_dice: 1.3052  decode.d4.loss_cls: 0.2789  decode.d4.loss_mask: 1.1148  decode.d4.loss_dice: 1.3098  decode.d5.loss_cls: 0.2711  decode.d5.loss_mask: 1.1185  decode.d5.loss_dice: 1.2999  decode.d6.loss_cls: 0.2222  decode.d6.loss_mask: 1.1333  decode.d6.loss_dice: 1.3144  decode.d7.loss_cls: 0.2592  decode.d7.loss_mask: 1.1098  decode.d7.loss_dice: 1.3241  decode.d8.loss_cls: 0.2730  decode.d8.loss_mask: 1.1047  decode.d8.loss_dice: 1.3180
2025/03/29 14:29:54 - mmengine - INFO - Iter(train) [ 4100/20000]  base_lr: 8.1349e-05 lr: 8.1349e-05  eta: 9:03:33  time: 1.1099  data_time: 0.0201  memory: 10129  loss: 27.5966  decode.loss_cls: 0.2762  decode.loss_mask: 1.2031  decode.loss_dice: 1.2873  decode.d0.loss_cls: 0.3662  decode.d0.loss_mask: 1.1972  decode.d0.loss_dice: 1.3375  decode.d1.loss_cls: 0.2945  decode.d1.loss_mask: 1.1506  decode.d1.loss_dice: 1.2734  decode.d2.loss_cls: 0.3123  decode.d2.loss_mask: 1.1433  decode.d2.loss_dice: 1.2689  decode.d3.loss_cls: 0.2793  decode.d3.loss_mask: 1.1455  decode.d3.loss_dice: 1.2549  decode.d4.loss_cls: 0.2970  decode.d4.loss_mask: 1.1595  decode.d4.loss_dice: 1.2810  decode.d5.loss_cls: 0.3169  decode.d5.loss_mask: 1.1720  decode.d5.loss_dice: 1.2507  decode.d6.loss_cls: 0.3308  decode.d6.loss_mask: 1.1737  decode.d6.loss_dice: 1.2540  decode.d7.loss_cls: 0.3140  decode.d7.loss_mask: 1.1896  decode.d7.loss_dice: 1.2697  decode.d8.loss_cls: 0.3121  decode.d8.loss_mask: 1.1970  decode.d8.loss_dice: 1.2885
2025/03/29 14:30:49 - mmengine - INFO - Iter(train) [ 4150/20000]  base_lr: 8.1118e-05 lr: 8.1118e-05  eta: 8:58:51  time: 1.1131  data_time: 0.0199  memory: 10133  loss: 23.8329  decode.loss_cls: 0.1141  decode.loss_mask: 1.0736  decode.loss_dice: 1.1622  decode.d0.loss_cls: 0.1812  decode.d0.loss_mask: 1.1154  decode.d0.loss_dice: 1.2676  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 1.0929  decode.d1.loss_dice: 1.1901  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 1.0831  decode.d2.loss_dice: 1.1851  decode.d3.loss_cls: 0.1291  decode.d3.loss_mask: 1.0539  decode.d3.loss_dice: 1.1562  decode.d4.loss_cls: 0.1473  decode.d4.loss_mask: 1.0641  decode.d4.loss_dice: 1.1582  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 1.0713  decode.d5.loss_dice: 1.1532  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 1.0786  decode.d6.loss_dice: 1.1427  decode.d7.loss_cls: 0.1270  decode.d7.loss_mask: 1.0883  decode.d7.loss_dice: 1.1527  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 1.0774  decode.d8.loss_dice: 1.1505
2025/03/29 14:31:45 - mmengine - INFO - Iter(train) [ 4200/20000]  base_lr: 8.0888e-05 lr: 8.0888e-05  eta: 8:54:15  time: 1.1087  data_time: 0.0197  memory: 10129  loss: 31.4311  decode.loss_cls: 0.2546  decode.loss_mask: 1.3986  decode.loss_dice: 1.4939  decode.d0.loss_cls: 0.2921  decode.d0.loss_mask: 1.3780  decode.d0.loss_dice: 1.5382  decode.d1.loss_cls: 0.2570  decode.d1.loss_mask: 1.3912  decode.d1.loss_dice: 1.4794  decode.d2.loss_cls: 0.2709  decode.d2.loss_mask: 1.3722  decode.d2.loss_dice: 1.4543  decode.d3.loss_cls: 0.2765  decode.d3.loss_mask: 1.3811  decode.d3.loss_dice: 1.4878  decode.d4.loss_cls: 0.2722  decode.d4.loss_mask: 1.3656  decode.d4.loss_dice: 1.4918  decode.d5.loss_cls: 0.2697  decode.d5.loss_mask: 1.3802  decode.d5.loss_dice: 1.4885  decode.d6.loss_cls: 0.2409  decode.d6.loss_mask: 1.3839  decode.d6.loss_dice: 1.4981  decode.d7.loss_cls: 0.2394  decode.d7.loss_mask: 1.3940  decode.d7.loss_dice: 1.4870  decode.d8.loss_cls: 0.2778  decode.d8.loss_mask: 1.4261  decode.d8.loss_dice: 1.4898
2025/03/29 14:32:41 - mmengine - INFO - Iter(train) [ 4250/20000]  base_lr: 8.0658e-05 lr: 8.0658e-05  eta: 8:49:44  time: 1.1099  data_time: 0.0198  memory: 10119  loss: 25.8463  decode.loss_cls: 0.0911  decode.loss_mask: 1.1130  decode.loss_dice: 1.3578  decode.d0.loss_cls: 0.2265  decode.d0.loss_mask: 1.0909  decode.d0.loss_dice: 1.3997  decode.d1.loss_cls: 0.1582  decode.d1.loss_mask: 1.0709  decode.d1.loss_dice: 1.3440  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 1.0911  decode.d2.loss_dice: 1.3307  decode.d3.loss_cls: 0.1464  decode.d3.loss_mask: 1.0975  decode.d3.loss_dice: 1.3092  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 1.0960  decode.d4.loss_dice: 1.2968  decode.d5.loss_cls: 0.1571  decode.d5.loss_mask: 1.1149  decode.d5.loss_dice: 1.3078  decode.d6.loss_cls: 0.1563  decode.d6.loss_mask: 1.1129  decode.d6.loss_dice: 1.3237  decode.d7.loss_cls: 0.1624  decode.d7.loss_mask: 1.1059  decode.d7.loss_dice: 1.3217  decode.d8.loss_cls: 0.1569  decode.d8.loss_mask: 1.0895  decode.d8.loss_dice: 1.3162
2025/03/29 14:33:36 - mmengine - INFO - Iter(train) [ 4300/20000]  base_lr: 8.0427e-05 lr: 8.0427e-05  eta: 8:45:18  time: 1.1092  data_time: 0.0203  memory: 10136  loss: 27.7668  decode.loss_cls: 0.2169  decode.loss_mask: 1.2251  decode.loss_dice: 1.3177  decode.d0.loss_cls: 0.2994  decode.d0.loss_mask: 1.2074  decode.d0.loss_dice: 1.3554  decode.d1.loss_cls: 0.2177  decode.d1.loss_mask: 1.1906  decode.d1.loss_dice: 1.3345  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 1.1792  decode.d2.loss_dice: 1.2977  decode.d3.loss_cls: 0.2741  decode.d3.loss_mask: 1.1748  decode.d3.loss_dice: 1.3034  decode.d4.loss_cls: 0.2680  decode.d4.loss_mask: 1.2024  decode.d4.loss_dice: 1.3267  decode.d5.loss_cls: 0.2667  decode.d5.loss_mask: 1.2150  decode.d5.loss_dice: 1.2869  decode.d6.loss_cls: 0.2767  decode.d6.loss_mask: 1.2280  decode.d6.loss_dice: 1.2953  decode.d7.loss_cls: 0.1891  decode.d7.loss_mask: 1.2451  decode.d7.loss_dice: 1.3485  decode.d8.loss_cls: 0.2619  decode.d8.loss_mask: 1.2220  decode.d8.loss_dice: 1.2995
2025/03/29 14:34:32 - mmengine - INFO - Iter(train) [ 4350/20000]  base_lr: 8.0197e-05 lr: 8.0197e-05  eta: 8:40:58  time: 1.1084  data_time: 0.0197  memory: 10126  loss: 28.0326  decode.loss_cls: 0.2222  decode.loss_mask: 1.1690  decode.loss_dice: 1.3911  decode.d0.loss_cls: 0.2603  decode.d0.loss_mask: 1.1995  decode.d0.loss_dice: 1.4224  decode.d1.loss_cls: 0.2268  decode.d1.loss_mask: 1.1602  decode.d1.loss_dice: 1.3857  decode.d2.loss_cls: 0.2034  decode.d2.loss_mask: 1.1784  decode.d2.loss_dice: 1.3841  decode.d3.loss_cls: 0.2372  decode.d3.loss_mask: 1.1931  decode.d3.loss_dice: 1.3918  decode.d4.loss_cls: 0.2094  decode.d4.loss_mask: 1.1881  decode.d4.loss_dice: 1.3961  decode.d5.loss_cls: 0.2208  decode.d5.loss_mask: 1.1859  decode.d5.loss_dice: 1.4021  decode.d6.loss_cls: 0.2174  decode.d6.loss_mask: 1.1906  decode.d6.loss_dice: 1.4006  decode.d7.loss_cls: 0.2255  decode.d7.loss_mask: 1.1836  decode.d7.loss_dice: 1.3904  decode.d8.loss_cls: 0.2175  decode.d8.loss_mask: 1.1861  decode.d8.loss_dice: 1.3935
2025/03/29 14:35:28 - mmengine - INFO - Iter(train) [ 4400/20000]  base_lr: 7.9966e-05 lr: 7.9966e-05  eta: 8:36:41  time: 1.1109  data_time: 0.0194  memory: 10133  loss: 24.9935  decode.loss_cls: 0.1407  decode.loss_mask: 1.1452  decode.loss_dice: 1.2132  decode.d0.loss_cls: 0.1889  decode.d0.loss_mask: 1.1082  decode.d0.loss_dice: 1.3031  decode.d1.loss_cls: 0.1441  decode.d1.loss_mask: 1.1281  decode.d1.loss_dice: 1.2264  decode.d2.loss_cls: 0.1281  decode.d2.loss_mask: 1.1462  decode.d2.loss_dice: 1.2037  decode.d3.loss_cls: 0.1867  decode.d3.loss_mask: 1.1225  decode.d3.loss_dice: 1.2239  decode.d4.loss_cls: 0.1880  decode.d4.loss_mask: 1.1224  decode.d4.loss_dice: 1.2044  decode.d5.loss_cls: 0.1903  decode.d5.loss_mask: 1.1238  decode.d5.loss_dice: 1.1871  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 1.1157  decode.d6.loss_dice: 1.1798  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 1.1158  decode.d7.loss_dice: 1.2101  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 1.0995  decode.d8.loss_dice: 1.1913
2025/03/29 14:36:24 - mmengine - INFO - Iter(train) [ 4450/20000]  base_lr: 7.9735e-05 lr: 7.9735e-05  eta: 8:32:29  time: 1.1155  data_time: 0.0220  memory: 10126  loss: 26.0961  decode.loss_cls: 0.1839  decode.loss_mask: 1.2206  decode.loss_dice: 1.1810  decode.d0.loss_cls: 0.2295  decode.d0.loss_mask: 1.2454  decode.d0.loss_dice: 1.2494  decode.d1.loss_cls: 0.1681  decode.d1.loss_mask: 1.2290  decode.d1.loss_dice: 1.2197  decode.d2.loss_cls: 0.1777  decode.d2.loss_mask: 1.2245  decode.d2.loss_dice: 1.1907  decode.d3.loss_cls: 0.1819  decode.d3.loss_mask: 1.2160  decode.d3.loss_dice: 1.1982  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 1.2284  decode.d4.loss_dice: 1.1960  decode.d5.loss_cls: 0.1925  decode.d5.loss_mask: 1.2140  decode.d5.loss_dice: 1.1906  decode.d6.loss_cls: 0.1744  decode.d6.loss_mask: 1.2215  decode.d6.loss_dice: 1.1879  decode.d7.loss_cls: 0.1721  decode.d7.loss_mask: 1.2306  decode.d7.loss_dice: 1.2003  decode.d8.loss_cls: 0.1838  decode.d8.loss_mask: 1.2224  decode.d8.loss_dice: 1.1988
2025/03/29 14:37:19 - mmengine - INFO - Iter(train) [ 4500/20000]  base_lr: 7.9504e-05 lr: 7.9504e-05  eta: 8:28:22  time: 1.1110  data_time: 0.0208  memory: 10119  loss: 28.2015  decode.loss_cls: 0.2201  decode.loss_mask: 1.2714  decode.loss_dice: 1.3179  decode.d0.loss_cls: 0.2980  decode.d0.loss_mask: 1.2683  decode.d0.loss_dice: 1.4225  decode.d1.loss_cls: 0.1951  decode.d1.loss_mask: 1.2522  decode.d1.loss_dice: 1.3833  decode.d2.loss_cls: 0.1973  decode.d2.loss_mask: 1.2502  decode.d2.loss_dice: 1.3491  decode.d3.loss_cls: 0.2046  decode.d3.loss_mask: 1.2682  decode.d3.loss_dice: 1.3436  decode.d4.loss_cls: 0.2175  decode.d4.loss_mask: 1.2668  decode.d4.loss_dice: 1.3257  decode.d5.loss_cls: 0.2391  decode.d5.loss_mask: 1.2880  decode.d5.loss_dice: 1.3283  decode.d6.loss_cls: 0.2009  decode.d6.loss_mask: 1.2634  decode.d6.loss_dice: 1.3215  decode.d7.loss_cls: 0.1918  decode.d7.loss_mask: 1.2568  decode.d7.loss_dice: 1.3105  decode.d8.loss_cls: 0.1813  decode.d8.loss_mask: 1.2589  decode.d8.loss_dice: 1.3093
2025/03/29 14:38:15 - mmengine - INFO - Iter(train) [ 4550/20000]  base_lr: 7.9274e-05 lr: 7.9274e-05  eta: 8:24:19  time: 1.1198  data_time: 0.0209  memory: 10122  loss: 26.9332  decode.loss_cls: 0.2230  decode.loss_mask: 1.1829  decode.loss_dice: 1.3099  decode.d0.loss_cls: 0.3050  decode.d0.loss_mask: 1.1429  decode.d0.loss_dice: 1.3160  decode.d1.loss_cls: 0.2473  decode.d1.loss_mask: 1.1846  decode.d1.loss_dice: 1.2772  decode.d2.loss_cls: 0.2729  decode.d2.loss_mask: 1.1484  decode.d2.loss_dice: 1.2453  decode.d3.loss_cls: 0.3146  decode.d3.loss_mask: 1.1328  decode.d3.loss_dice: 1.2369  decode.d4.loss_cls: 0.2618  decode.d4.loss_mask: 1.1424  decode.d4.loss_dice: 1.2735  decode.d5.loss_cls: 0.3242  decode.d5.loss_mask: 1.1039  decode.d5.loss_dice: 1.2580  decode.d6.loss_cls: 0.2641  decode.d6.loss_mask: 1.1736  decode.d6.loss_dice: 1.2636  decode.d7.loss_cls: 0.2346  decode.d7.loss_mask: 1.1538  decode.d7.loss_dice: 1.2666  decode.d8.loss_cls: 0.2330  decode.d8.loss_mask: 1.1601  decode.d8.loss_dice: 1.2801
2025/03/29 14:39:12 - mmengine - INFO - Iter(train) [ 4600/20000]  base_lr: 7.9043e-05 lr: 7.9043e-05  eta: 8:20:23  time: 1.1402  data_time: 0.0230  memory: 10126  loss: 28.9871  decode.loss_cls: 0.2640  decode.loss_mask: 1.2098  decode.loss_dice: 1.4420  decode.d0.loss_cls: 0.2713  decode.d0.loss_mask: 1.2246  decode.d0.loss_dice: 1.4682  decode.d1.loss_cls: 0.2488  decode.d1.loss_mask: 1.1733  decode.d1.loss_dice: 1.4579  decode.d2.loss_cls: 0.2961  decode.d2.loss_mask: 1.1690  decode.d2.loss_dice: 1.3685  decode.d3.loss_cls: 0.2871  decode.d3.loss_mask: 1.1781  decode.d3.loss_dice: 1.4101  decode.d4.loss_cls: 0.2745  decode.d4.loss_mask: 1.1910  decode.d4.loss_dice: 1.4090  decode.d5.loss_cls: 0.2282  decode.d5.loss_mask: 1.2320  decode.d5.loss_dice: 1.4310  decode.d6.loss_cls: 0.2485  decode.d6.loss_mask: 1.2399  decode.d6.loss_dice: 1.4283  decode.d7.loss_cls: 0.2666  decode.d7.loss_mask: 1.2267  decode.d7.loss_dice: 1.4296  decode.d8.loss_cls: 0.2461  decode.d8.loss_mask: 1.2277  decode.d8.loss_dice: 1.4392
2025/03/29 14:40:08 - mmengine - INFO - Iter(train) [ 4650/20000]  base_lr: 7.8812e-05 lr: 7.8812e-05  eta: 8:16:28  time: 1.1160  data_time: 0.0206  memory: 10121  loss: 27.3610  decode.loss_cls: 0.1311  decode.loss_mask: 1.2036  decode.loss_dice: 1.3366  decode.d0.loss_cls: 0.2088  decode.d0.loss_mask: 1.2434  decode.d0.loss_dice: 1.4256  decode.d1.loss_cls: 0.1351  decode.d1.loss_mask: 1.2250  decode.d1.loss_dice: 1.3751  decode.d2.loss_cls: 0.1940  decode.d2.loss_mask: 1.2128  decode.d2.loss_dice: 1.3482  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 1.2065  decode.d3.loss_dice: 1.3465  decode.d4.loss_cls: 0.2007  decode.d4.loss_mask: 1.2097  decode.d4.loss_dice: 1.3222  decode.d5.loss_cls: 0.2369  decode.d5.loss_mask: 1.1900  decode.d5.loss_dice: 1.3077  decode.d6.loss_cls: 0.1615  decode.d6.loss_mask: 1.2051  decode.d6.loss_dice: 1.3381  decode.d7.loss_cls: 0.1615  decode.d7.loss_mask: 1.2166  decode.d7.loss_dice: 1.3617  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 1.2165  decode.d8.loss_dice: 1.3551
2025/03/29 14:41:04 - mmengine - INFO - Iter(train) [ 4700/20000]  base_lr: 7.8581e-05 lr: 7.8581e-05  eta: 8:12:37  time: 1.1217  data_time: 0.0209  memory: 10126  loss: 24.6677  decode.loss_cls: 0.2201  decode.loss_mask: 1.0976  decode.loss_dice: 1.1916  decode.d0.loss_cls: 0.2596  decode.d0.loss_mask: 1.0805  decode.d0.loss_dice: 1.2332  decode.d1.loss_cls: 0.1913  decode.d1.loss_mask: 1.0525  decode.d1.loss_dice: 1.1704  decode.d2.loss_cls: 0.2119  decode.d2.loss_mask: 1.0548  decode.d2.loss_dice: 1.1718  decode.d3.loss_cls: 0.2234  decode.d3.loss_mask: 1.0484  decode.d3.loss_dice: 1.1644  decode.d4.loss_cls: 0.2248  decode.d4.loss_mask: 1.0385  decode.d4.loss_dice: 1.1582  decode.d5.loss_cls: 0.2279  decode.d5.loss_mask: 1.0388  decode.d5.loss_dice: 1.1509  decode.d6.loss_cls: 0.2150  decode.d6.loss_mask: 1.0630  decode.d6.loss_dice: 1.1845  decode.d7.loss_cls: 0.2228  decode.d7.loss_mask: 1.0774  decode.d7.loss_dice: 1.1940  decode.d8.loss_cls: 0.2439  decode.d8.loss_mask: 1.0813  decode.d8.loss_dice: 1.1751
2025/03/29 14:41:59 - mmengine - INFO - Iter(train) [ 4750/20000]  base_lr: 7.8349e-05 lr: 7.8349e-05  eta: 8:08:49  time: 1.1059  data_time: 0.0195  memory: 10130  loss: 28.0746  decode.loss_cls: 0.3531  decode.loss_mask: 1.1095  decode.loss_dice: 1.3650  decode.d0.loss_cls: 0.2952  decode.d0.loss_mask: 1.1275  decode.d0.loss_dice: 1.4450  decode.d1.loss_cls: 0.3082  decode.d1.loss_mask: 1.1076  decode.d1.loss_dice: 1.3637  decode.d2.loss_cls: 0.3673  decode.d2.loss_mask: 1.0853  decode.d2.loss_dice: 1.3431  decode.d3.loss_cls: 0.3545  decode.d3.loss_mask: 1.0707  decode.d3.loss_dice: 1.3350  decode.d4.loss_cls: 0.3888  decode.d4.loss_mask: 1.0865  decode.d4.loss_dice: 1.3560  decode.d5.loss_cls: 0.3451  decode.d5.loss_mask: 1.0713  decode.d5.loss_dice: 1.3759  decode.d6.loss_cls: 0.2726  decode.d6.loss_mask: 1.1034  decode.d6.loss_dice: 1.4336  decode.d7.loss_cls: 0.3031  decode.d7.loss_mask: 1.0870  decode.d7.loss_dice: 1.4018  decode.d8.loss_cls: 0.3257  decode.d8.loss_mask: 1.1068  decode.d8.loss_dice: 1.3861
2025/03/29 14:42:55 - mmengine - INFO - Iter(train) [ 4800/20000]  base_lr: 7.8118e-05 lr: 7.8118e-05  eta: 8:05:05  time: 1.1176  data_time: 0.0200  memory: 10126  loss: 25.2798  decode.loss_cls: 0.1792  decode.loss_mask: 1.0773  decode.loss_dice: 1.2378  decode.d0.loss_cls: 0.2563  decode.d0.loss_mask: 1.1156  decode.d0.loss_dice: 1.2920  decode.d1.loss_cls: 0.1857  decode.d1.loss_mask: 1.1057  decode.d1.loss_dice: 1.2757  decode.d2.loss_cls: 0.2294  decode.d2.loss_mask: 1.0681  decode.d2.loss_dice: 1.2171  decode.d3.loss_cls: 0.2139  decode.d3.loss_mask: 1.0557  decode.d3.loss_dice: 1.2048  decode.d4.loss_cls: 0.2220  decode.d4.loss_mask: 1.0658  decode.d4.loss_dice: 1.2329  decode.d5.loss_cls: 0.2519  decode.d5.loss_mask: 1.0745  decode.d5.loss_dice: 1.2092  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 1.0840  decode.d6.loss_dice: 1.2184  decode.d7.loss_cls: 0.1803  decode.d7.loss_mask: 1.0887  decode.d7.loss_dice: 1.2475  decode.d8.loss_cls: 0.1988  decode.d8.loss_mask: 1.0809  decode.d8.loss_dice: 1.2367
2025/03/29 14:43:51 - mmengine - INFO - Iter(train) [ 4850/20000]  base_lr: 7.7887e-05 lr: 7.7887e-05  eta: 8:01:24  time: 1.1118  data_time: 0.0199  memory: 10119  loss: 26.4923  decode.loss_cls: 0.2117  decode.loss_mask: 1.1075  decode.loss_dice: 1.2809  decode.d0.loss_cls: 0.2812  decode.d0.loss_mask: 1.1346  decode.d0.loss_dice: 1.3505  decode.d1.loss_cls: 0.2317  decode.d1.loss_mask: 1.1160  decode.d1.loss_dice: 1.3232  decode.d2.loss_cls: 0.2851  decode.d2.loss_mask: 1.1046  decode.d2.loss_dice: 1.2746  decode.d3.loss_cls: 0.2861  decode.d3.loss_mask: 1.0988  decode.d3.loss_dice: 1.2514  decode.d4.loss_cls: 0.2665  decode.d4.loss_mask: 1.1037  decode.d4.loss_dice: 1.2902  decode.d5.loss_cls: 0.2692  decode.d5.loss_mask: 1.0859  decode.d5.loss_dice: 1.2674  decode.d6.loss_cls: 0.2567  decode.d6.loss_mask: 1.0895  decode.d6.loss_dice: 1.2829  decode.d7.loss_cls: 0.2377  decode.d7.loss_mask: 1.1062  decode.d7.loss_dice: 1.2780  decode.d8.loss_cls: 0.2566  decode.d8.loss_mask: 1.0855  decode.d8.loss_dice: 1.2784
2025/03/29 14:44:47 - mmengine - INFO - Iter(train) [ 4900/20000]  base_lr: 7.7655e-05 lr: 7.7655e-05  eta: 7:57:47  time: 1.1171  data_time: 0.0211  memory: 10121  loss: 27.1419  decode.loss_cls: 0.1930  decode.loss_mask: 1.2543  decode.loss_dice: 1.2623  decode.d0.loss_cls: 0.2330  decode.d0.loss_mask: 1.2303  decode.d0.loss_dice: 1.3237  decode.d1.loss_cls: 0.1726  decode.d1.loss_mask: 1.2638  decode.d1.loss_dice: 1.3046  decode.d2.loss_cls: 0.2088  decode.d2.loss_mask: 1.2497  decode.d2.loss_dice: 1.2691  decode.d3.loss_cls: 0.1690  decode.d3.loss_mask: 1.2298  decode.d3.loss_dice: 1.2593  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 1.2354  decode.d4.loss_dice: 1.2559  decode.d5.loss_cls: 0.2110  decode.d5.loss_mask: 1.2416  decode.d5.loss_dice: 1.2510  decode.d6.loss_cls: 0.1878  decode.d6.loss_mask: 1.2585  decode.d6.loss_dice: 1.2551  decode.d7.loss_cls: 0.2088  decode.d7.loss_mask: 1.2391  decode.d7.loss_dice: 1.2638  decode.d8.loss_cls: 0.1779  decode.d8.loss_mask: 1.2420  decode.d8.loss_dice: 1.2844
2025/03/29 14:45:42 - mmengine - INFO - Iter(train) [ 4950/20000]  base_lr: 7.7424e-05 lr: 7.7424e-05  eta: 7:54:13  time: 1.1132  data_time: 0.0205  memory: 10133  loss: 27.9296  decode.loss_cls: 0.2873  decode.loss_mask: 1.1777  decode.loss_dice: 1.3217  decode.d0.loss_cls: 0.3111  decode.d0.loss_mask: 1.1757  decode.d0.loss_dice: 1.3869  decode.d1.loss_cls: 0.3323  decode.d1.loss_mask: 1.1322  decode.d1.loss_dice: 1.3348  decode.d2.loss_cls: 0.2998  decode.d2.loss_mask: 1.1839  decode.d2.loss_dice: 1.3105  decode.d3.loss_cls: 0.2585  decode.d3.loss_mask: 1.1846  decode.d3.loss_dice: 1.2945  decode.d4.loss_cls: 0.2710  decode.d4.loss_mask: 1.1930  decode.d4.loss_dice: 1.3198  decode.d5.loss_cls: 0.2913  decode.d5.loss_mask: 1.1716  decode.d5.loss_dice: 1.3056  decode.d6.loss_cls: 0.3059  decode.d6.loss_mask: 1.1871  decode.d6.loss_dice: 1.3057  decode.d7.loss_cls: 0.2614  decode.d7.loss_mask: 1.2131  decode.d7.loss_dice: 1.3360  decode.d8.loss_cls: 0.2795  decode.d8.loss_mask: 1.1792  decode.d8.loss_dice: 1.3179
2025/03/29 14:46:38 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 14:46:38 - mmengine - INFO - Iter(train) [ 5000/20000]  base_lr: 7.7192e-05 lr: 7.7192e-05  eta: 7:50:42  time: 1.1121  data_time: 0.0208  memory: 10129  loss: 28.8327  decode.loss_cls: 0.2452  decode.loss_mask: 1.2894  decode.loss_dice: 1.3275  decode.d0.loss_cls: 0.2904  decode.d0.loss_mask: 1.3089  decode.d0.loss_dice: 1.3917  decode.d1.loss_cls: 0.2817  decode.d1.loss_mask: 1.2775  decode.d1.loss_dice: 1.3307  decode.d2.loss_cls: 0.2683  decode.d2.loss_mask: 1.2794  decode.d2.loss_dice: 1.3258  decode.d3.loss_cls: 0.2716  decode.d3.loss_mask: 1.2908  decode.d3.loss_dice: 1.3011  decode.d4.loss_cls: 0.2334  decode.d4.loss_mask: 1.3130  decode.d4.loss_dice: 1.3290  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 1.3257  decode.d5.loss_dice: 1.3260  decode.d6.loss_cls: 0.2434  decode.d6.loss_mask: 1.3355  decode.d6.loss_dice: 1.3401  decode.d7.loss_cls: 0.2244  decode.d7.loss_mask: 1.3098  decode.d7.loss_dice: 1.3242  decode.d8.loss_cls: 0.2083  decode.d8.loss_mask: 1.2896  decode.d8.loss_dice: 1.3115
2025/03/29 14:47:34 - mmengine - INFO - Iter(train) [ 5050/20000]  base_lr: 7.6961e-05 lr: 7.6961e-05  eta: 7:47:16  time: 1.1359  data_time: 0.0207  memory: 10124  loss: 28.0563  decode.loss_cls: 0.2372  decode.loss_mask: 1.1699  decode.loss_dice: 1.3578  decode.d0.loss_cls: 0.3136  decode.d0.loss_mask: 1.1788  decode.d0.loss_dice: 1.4614  decode.d1.loss_cls: 0.3126  decode.d1.loss_mask: 1.1518  decode.d1.loss_dice: 1.3479  decode.d2.loss_cls: 0.3348  decode.d2.loss_mask: 1.1250  decode.d2.loss_dice: 1.3352  decode.d3.loss_cls: 0.3139  decode.d3.loss_mask: 1.1287  decode.d3.loss_dice: 1.3328  decode.d4.loss_cls: 0.2480  decode.d4.loss_mask: 1.1839  decode.d4.loss_dice: 1.3532  decode.d5.loss_cls: 0.2262  decode.d5.loss_mask: 1.1915  decode.d5.loss_dice: 1.3853  decode.d6.loss_cls: 0.2857  decode.d6.loss_mask: 1.1469  decode.d6.loss_dice: 1.3511  decode.d7.loss_cls: 0.2476  decode.d7.loss_mask: 1.1828  decode.d7.loss_dice: 1.3703  decode.d8.loss_cls: 0.2365  decode.d8.loss_mask: 1.1783  decode.d8.loss_dice: 1.3676
2025/03/29 14:48:31 - mmengine - INFO - Iter(train) [ 5100/20000]  base_lr: 7.6729e-05 lr: 7.6729e-05  eta: 7:43:55  time: 1.1758  data_time: 0.0274  memory: 10129  loss: 28.8958  decode.loss_cls: 0.2971  decode.loss_mask: 1.2320  decode.loss_dice: 1.3664  decode.d0.loss_cls: 0.2767  decode.d0.loss_mask: 1.2813  decode.d0.loss_dice: 1.4119  decode.d1.loss_cls: 0.2949  decode.d1.loss_mask: 1.2190  decode.d1.loss_dice: 1.3636  decode.d2.loss_cls: 0.3361  decode.d2.loss_mask: 1.1979  decode.d2.loss_dice: 1.3337  decode.d3.loss_cls: 0.3163  decode.d3.loss_mask: 1.2146  decode.d3.loss_dice: 1.3417  decode.d4.loss_cls: 0.2420  decode.d4.loss_mask: 1.2609  decode.d4.loss_dice: 1.3620  decode.d5.loss_cls: 0.2471  decode.d5.loss_mask: 1.2719  decode.d5.loss_dice: 1.3830  decode.d6.loss_cls: 0.2558  decode.d6.loss_mask: 1.2545  decode.d6.loss_dice: 1.3887  decode.d7.loss_cls: 0.2974  decode.d7.loss_mask: 1.2301  decode.d7.loss_dice: 1.3359  decode.d8.loss_cls: 0.2329  decode.d8.loss_mask: 1.2575  decode.d8.loss_dice: 1.3928
2025/03/29 14:49:28 - mmengine - INFO - Iter(train) [ 5150/20000]  base_lr: 7.6497e-05 lr: 7.6497e-05  eta: 7:40:34  time: 1.1352  data_time: 0.0200  memory: 10126  loss: 29.6320  decode.loss_cls: 0.3153  decode.loss_mask: 1.2518  decode.loss_dice: 1.4006  decode.d0.loss_cls: 0.3235  decode.d0.loss_mask: 1.2739  decode.d0.loss_dice: 1.4701  decode.d1.loss_cls: 0.3543  decode.d1.loss_mask: 1.2225  decode.d1.loss_dice: 1.3729  decode.d2.loss_cls: 0.4098  decode.d2.loss_mask: 1.2112  decode.d2.loss_dice: 1.3569  decode.d3.loss_cls: 0.3180  decode.d3.loss_mask: 1.2082  decode.d3.loss_dice: 1.3676  decode.d4.loss_cls: 0.3614  decode.d4.loss_mask: 1.1931  decode.d4.loss_dice: 1.3990  decode.d5.loss_cls: 0.3295  decode.d5.loss_mask: 1.2307  decode.d5.loss_dice: 1.4130  decode.d6.loss_cls: 0.3462  decode.d6.loss_mask: 1.2291  decode.d6.loss_dice: 1.4194  decode.d7.loss_cls: 0.3128  decode.d7.loss_mask: 1.2175  decode.d7.loss_dice: 1.3964  decode.d8.loss_cls: 0.3096  decode.d8.loss_mask: 1.2277  decode.d8.loss_dice: 1.3898
2025/03/29 14:50:24 - mmengine - INFO - Iter(train) [ 5200/20000]  base_lr: 7.6265e-05 lr: 7.6265e-05  eta: 7:37:18  time: 1.1311  data_time: 0.0204  memory: 10126  loss: 29.0474  decode.loss_cls: 0.2442  decode.loss_mask: 1.3327  decode.loss_dice: 1.3302  decode.d0.loss_cls: 0.3427  decode.d0.loss_mask: 1.3434  decode.d0.loss_dice: 1.3702  decode.d1.loss_cls: 0.3277  decode.d1.loss_mask: 1.2674  decode.d1.loss_dice: 1.3131  decode.d2.loss_cls: 0.3192  decode.d2.loss_mask: 1.2889  decode.d2.loss_dice: 1.2992  decode.d3.loss_cls: 0.2593  decode.d3.loss_mask: 1.3263  decode.d3.loss_dice: 1.3003  decode.d4.loss_cls: 0.2875  decode.d4.loss_mask: 1.3265  decode.d4.loss_dice: 1.2869  decode.d5.loss_cls: 0.2853  decode.d5.loss_mask: 1.2978  decode.d5.loss_dice: 1.2804  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 1.2929  decode.d6.loss_dice: 1.2679  decode.d7.loss_cls: 0.2489  decode.d7.loss_mask: 1.3569  decode.d7.loss_dice: 1.2937  decode.d8.loss_cls: 0.2076  decode.d8.loss_mask: 1.3475  decode.d8.loss_dice: 1.3252
2025/03/29 14:51:21 - mmengine - INFO - Iter(train) [ 5250/20000]  base_lr: 7.6034e-05 lr: 7.6034e-05  eta: 7:34:03  time: 1.1222  data_time: 0.0202  memory: 10126  loss: 27.6033  decode.loss_cls: 0.1702  decode.loss_mask: 1.2049  decode.loss_dice: 1.3574  decode.d0.loss_cls: 0.2119  decode.d0.loss_mask: 1.2222  decode.d0.loss_dice: 1.4058  decode.d1.loss_cls: 0.2010  decode.d1.loss_mask: 1.2196  decode.d1.loss_dice: 1.3553  decode.d2.loss_cls: 0.1794  decode.d2.loss_mask: 1.2340  decode.d2.loss_dice: 1.3682  decode.d3.loss_cls: 0.2261  decode.d3.loss_mask: 1.1996  decode.d3.loss_dice: 1.3177  decode.d4.loss_cls: 0.1902  decode.d4.loss_mask: 1.2030  decode.d4.loss_dice: 1.3423  decode.d5.loss_cls: 0.2114  decode.d5.loss_mask: 1.1948  decode.d5.loss_dice: 1.3501  decode.d6.loss_cls: 0.2250  decode.d6.loss_mask: 1.1958  decode.d6.loss_dice: 1.3430  decode.d7.loss_cls: 0.2172  decode.d7.loss_mask: 1.1774  decode.d7.loss_dice: 1.3413  decode.d8.loss_cls: 0.1976  decode.d8.loss_mask: 1.1917  decode.d8.loss_dice: 1.3495
2025/03/29 14:52:17 - mmengine - INFO - Iter(train) [ 5300/20000]  base_lr: 7.5802e-05 lr: 7.5802e-05  eta: 7:30:50  time: 1.1155  data_time: 0.0204  memory: 10123  loss: 25.1016  decode.loss_cls: 0.2317  decode.loss_mask: 1.0613  decode.loss_dice: 1.2494  decode.d0.loss_cls: 0.2499  decode.d0.loss_mask: 1.0422  decode.d0.loss_dice: 1.3437  decode.d1.loss_cls: 0.1845  decode.d1.loss_mask: 1.0475  decode.d1.loss_dice: 1.2561  decode.d2.loss_cls: 0.2443  decode.d2.loss_mask: 1.0225  decode.d2.loss_dice: 1.2046  decode.d3.loss_cls: 0.2147  decode.d3.loss_mask: 1.0326  decode.d3.loss_dice: 1.2132  decode.d4.loss_cls: 0.1771  decode.d4.loss_mask: 1.0323  decode.d4.loss_dice: 1.2295  decode.d5.loss_cls: 0.2033  decode.d5.loss_mask: 1.0401  decode.d5.loss_dice: 1.2402  decode.d6.loss_cls: 0.2124  decode.d6.loss_mask: 1.0977  decode.d6.loss_dice: 1.2863  decode.d7.loss_cls: 0.2077  decode.d7.loss_mask: 1.0346  decode.d7.loss_dice: 1.2423  decode.d8.loss_cls: 0.2182  decode.d8.loss_mask: 1.0335  decode.d8.loss_dice: 1.2484
2025/03/29 14:53:13 - mmengine - INFO - Iter(train) [ 5350/20000]  base_lr: 7.5569e-05 lr: 7.5569e-05  eta: 7:27:39  time: 1.1082  data_time: 0.0197  memory: 10127  loss: 29.8099  decode.loss_cls: 0.3047  decode.loss_mask: 1.2073  decode.loss_dice: 1.4621  decode.d0.loss_cls: 0.3411  decode.d0.loss_mask: 1.2431  decode.d0.loss_dice: 1.5402  decode.d1.loss_cls: 0.3096  decode.d1.loss_mask: 1.2087  decode.d1.loss_dice: 1.4653  decode.d2.loss_cls: 0.3005  decode.d2.loss_mask: 1.2301  decode.d2.loss_dice: 1.4785  decode.d3.loss_cls: 0.3336  decode.d3.loss_mask: 1.2081  decode.d3.loss_dice: 1.4390  decode.d4.loss_cls: 0.3069  decode.d4.loss_mask: 1.2087  decode.d4.loss_dice: 1.4364  decode.d5.loss_cls: 0.2553  decode.d5.loss_mask: 1.2454  decode.d5.loss_dice: 1.4405  decode.d6.loss_cls: 0.2393  decode.d6.loss_mask: 1.2360  decode.d6.loss_dice: 1.4536  decode.d7.loss_cls: 0.2786  decode.d7.loss_mask: 1.2113  decode.d7.loss_dice: 1.4530  decode.d8.loss_cls: 0.2580  decode.d8.loss_mask: 1.2371  decode.d8.loss_dice: 1.4780
2025/03/29 14:54:09 - mmengine - INFO - Iter(train) [ 5400/20000]  base_lr: 7.5337e-05 lr: 7.5337e-05  eta: 7:24:30  time: 1.1138  data_time: 0.0200  memory: 10120  loss: 30.4339  decode.loss_cls: 0.1980  decode.loss_mask: 1.3905  decode.loss_dice: 1.4710  decode.d0.loss_cls: 0.2179  decode.d0.loss_mask: 1.3632  decode.d0.loss_dice: 1.5357  decode.d1.loss_cls: 0.2357  decode.d1.loss_mask: 1.3477  decode.d1.loss_dice: 1.4579  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 1.3451  decode.d2.loss_dice: 1.4427  decode.d3.loss_cls: 0.2119  decode.d3.loss_mask: 1.3502  decode.d3.loss_dice: 1.4368  decode.d4.loss_cls: 0.1919  decode.d4.loss_mask: 1.3514  decode.d4.loss_dice: 1.4486  decode.d5.loss_cls: 0.1972  decode.d5.loss_mask: 1.3596  decode.d5.loss_dice: 1.4603  decode.d6.loss_cls: 0.2168  decode.d6.loss_mask: 1.3797  decode.d6.loss_dice: 1.4350  decode.d7.loss_cls: 0.2388  decode.d7.loss_mask: 1.3726  decode.d7.loss_dice: 1.4670  decode.d8.loss_cls: 0.2476  decode.d8.loss_mask: 1.3604  decode.d8.loss_dice: 1.4615
2025/03/29 14:55:04 - mmengine - INFO - Iter(train) [ 5450/20000]  base_lr: 7.5105e-05 lr: 7.5105e-05  eta: 7:21:24  time: 1.1128  data_time: 0.0197  memory: 10129  loss: 25.2413  decode.loss_cls: 0.2993  decode.loss_mask: 1.0132  decode.loss_dice: 1.1625  decode.d0.loss_cls: 0.2825  decode.d0.loss_mask: 1.0356  decode.d0.loss_dice: 1.3412  decode.d1.loss_cls: 0.3289  decode.d1.loss_mask: 1.0224  decode.d1.loss_dice: 1.2313  decode.d2.loss_cls: 0.3298  decode.d2.loss_mask: 0.9842  decode.d2.loss_dice: 1.1786  decode.d3.loss_cls: 0.2906  decode.d3.loss_mask: 1.0555  decode.d3.loss_dice: 1.1884  decode.d4.loss_cls: 0.2839  decode.d4.loss_mask: 1.0327  decode.d4.loss_dice: 1.1833  decode.d5.loss_cls: 0.3163  decode.d5.loss_mask: 1.0280  decode.d5.loss_dice: 1.1652  decode.d6.loss_cls: 0.3268  decode.d6.loss_mask: 1.0173  decode.d6.loss_dice: 1.1372  decode.d7.loss_cls: 0.2958  decode.d7.loss_mask: 1.0335  decode.d7.loss_dice: 1.1851  decode.d8.loss_cls: 0.2806  decode.d8.loss_mask: 1.0405  decode.d8.loss_dice: 1.1711
2025/03/29 14:56:00 - mmengine - INFO - Iter(train) [ 5500/20000]  base_lr: 7.4873e-05 lr: 7.4873e-05  eta: 7:18:20  time: 1.1179  data_time: 0.0205  memory: 10128  loss: 23.7303  decode.loss_cls: 0.1926  decode.loss_mask: 1.0485  decode.loss_dice: 1.1321  decode.d0.loss_cls: 0.2005  decode.d0.loss_mask: 1.0469  decode.d0.loss_dice: 1.2179  decode.d1.loss_cls: 0.1968  decode.d1.loss_mask: 1.0332  decode.d1.loss_dice: 1.1553  decode.d2.loss_cls: 0.2312  decode.d2.loss_mask: 1.0269  decode.d2.loss_dice: 1.1338  decode.d3.loss_cls: 0.1954  decode.d3.loss_mask: 1.0416  decode.d3.loss_dice: 1.1200  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 1.0307  decode.d4.loss_dice: 1.1226  decode.d5.loss_cls: 0.1801  decode.d5.loss_mask: 1.0277  decode.d5.loss_dice: 1.1460  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 1.0368  decode.d6.loss_dice: 1.1268  decode.d7.loss_cls: 0.1529  decode.d7.loss_mask: 1.0431  decode.d7.loss_dice: 1.1442  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 1.0558  decode.d8.loss_dice: 1.1568
2025/03/29 14:56:56 - mmengine - INFO - Iter(train) [ 5550/20000]  base_lr: 7.4640e-05 lr: 7.4640e-05  eta: 7:15:19  time: 1.1089  data_time: 0.0198  memory: 10122  loss: 25.5362  decode.loss_cls: 0.2006  decode.loss_mask: 1.0849  decode.loss_dice: 1.2646  decode.d0.loss_cls: 0.2672  decode.d0.loss_mask: 1.0701  decode.d0.loss_dice: 1.3430  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 1.0567  decode.d1.loss_dice: 1.3037  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 1.0644  decode.d2.loss_dice: 1.3218  decode.d3.loss_cls: 0.2023  decode.d3.loss_mask: 1.0535  decode.d3.loss_dice: 1.2835  decode.d4.loss_cls: 0.1651  decode.d4.loss_mask: 1.0606  decode.d4.loss_dice: 1.2879  decode.d5.loss_cls: 0.1946  decode.d5.loss_mask: 1.0455  decode.d5.loss_dice: 1.2862  decode.d6.loss_cls: 0.1857  decode.d6.loss_mask: 1.0535  decode.d6.loss_dice: 1.2964  decode.d7.loss_cls: 0.1997  decode.d7.loss_mask: 1.0490  decode.d7.loss_dice: 1.2902  decode.d8.loss_cls: 0.2049  decode.d8.loss_mask: 1.0729  decode.d8.loss_dice: 1.2592
2025/03/29 14:57:52 - mmengine - INFO - Iter(train) [ 5600/20000]  base_lr: 7.4408e-05 lr: 7.4408e-05  eta: 7:12:19  time: 1.1115  data_time: 0.0200  memory: 10126  loss: 27.4098  decode.loss_cls: 0.3377  decode.loss_mask: 1.1923  decode.loss_dice: 1.2543  decode.d0.loss_cls: 0.2445  decode.d0.loss_mask: 1.2004  decode.d0.loss_dice: 1.3891  decode.d1.loss_cls: 0.2591  decode.d1.loss_mask: 1.1478  decode.d1.loss_dice: 1.2667  decode.d2.loss_cls: 0.2714  decode.d2.loss_mask: 1.1678  decode.d2.loss_dice: 1.2671  decode.d3.loss_cls: 0.2905  decode.d3.loss_mask: 1.1687  decode.d3.loss_dice: 1.2581  decode.d4.loss_cls: 0.3467  decode.d4.loss_mask: 1.1426  decode.d4.loss_dice: 1.2419  decode.d5.loss_cls: 0.3003  decode.d5.loss_mask: 1.1741  decode.d5.loss_dice: 1.2682  decode.d6.loss_cls: 0.2535  decode.d6.loss_mask: 1.1708  decode.d6.loss_dice: 1.2783  decode.d7.loss_cls: 0.2845  decode.d7.loss_mask: 1.1649  decode.d7.loss_dice: 1.3031  decode.d8.loss_cls: 0.3359  decode.d8.loss_mask: 1.1618  decode.d8.loss_dice: 1.2677
2025/03/29 14:58:47 - mmengine - INFO - Iter(train) [ 5650/20000]  base_lr: 7.4175e-05 lr: 7.4175e-05  eta: 7:09:22  time: 1.1105  data_time: 0.0200  memory: 10125  loss: 26.6251  decode.loss_cls: 0.1532  decode.loss_mask: 1.1624  decode.loss_dice: 1.3513  decode.d0.loss_cls: 0.2282  decode.d0.loss_mask: 1.1358  decode.d0.loss_dice: 1.3843  decode.d1.loss_cls: 0.2060  decode.d1.loss_mask: 1.1085  decode.d1.loss_dice: 1.3434  decode.d2.loss_cls: 0.2394  decode.d2.loss_mask: 1.1091  decode.d2.loss_dice: 1.3135  decode.d3.loss_cls: 0.1752  decode.d3.loss_mask: 1.1214  decode.d3.loss_dice: 1.3151  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 1.1037  decode.d4.loss_dice: 1.3019  decode.d5.loss_cls: 0.1953  decode.d5.loss_mask: 1.1356  decode.d5.loss_dice: 1.2991  decode.d6.loss_cls: 0.2302  decode.d6.loss_mask: 1.1287  decode.d6.loss_dice: 1.3354  decode.d7.loss_cls: 0.2140  decode.d7.loss_mask: 1.1121  decode.d7.loss_dice: 1.3325  decode.d8.loss_cls: 0.1889  decode.d8.loss_mask: 1.1304  decode.d8.loss_dice: 1.3646
2025/03/29 14:59:43 - mmengine - INFO - Iter(train) [ 5700/20000]  base_lr: 7.3943e-05 lr: 7.3943e-05  eta: 7:06:26  time: 1.1110  data_time: 0.0201  memory: 10126  loss: 26.9095  decode.loss_cls: 0.1921  decode.loss_mask: 1.1999  decode.loss_dice: 1.2959  decode.d0.loss_cls: 0.2143  decode.d0.loss_mask: 1.2096  decode.d0.loss_dice: 1.3837  decode.d1.loss_cls: 0.2353  decode.d1.loss_mask: 1.1520  decode.d1.loss_dice: 1.2885  decode.d2.loss_cls: 0.2307  decode.d2.loss_mask: 1.1878  decode.d2.loss_dice: 1.2958  decode.d3.loss_cls: 0.1843  decode.d3.loss_mask: 1.1946  decode.d3.loss_dice: 1.3003  decode.d4.loss_cls: 0.1758  decode.d4.loss_mask: 1.1899  decode.d4.loss_dice: 1.2794  decode.d5.loss_cls: 0.1929  decode.d5.loss_mask: 1.1758  decode.d5.loss_dice: 1.2723  decode.d6.loss_cls: 0.2336  decode.d6.loss_mask: 1.1677  decode.d6.loss_dice: 1.2754  decode.d7.loss_cls: 0.2170  decode.d7.loss_mask: 1.2115  decode.d7.loss_dice: 1.2834  decode.d8.loss_cls: 0.1975  decode.d8.loss_mask: 1.2064  decode.d8.loss_dice: 1.2661
2025/03/29 15:00:38 - mmengine - INFO - Iter(train) [ 5750/20000]  base_lr: 7.3710e-05 lr: 7.3710e-05  eta: 7:03:33  time: 1.1154  data_time: 0.0204  memory: 10121  loss: 26.3974  decode.loss_cls: 0.3023  decode.loss_mask: 1.1569  decode.loss_dice: 1.2279  decode.d0.loss_cls: 0.2735  decode.d0.loss_mask: 1.1561  decode.d0.loss_dice: 1.3211  decode.d1.loss_cls: 0.2362  decode.d1.loss_mask: 1.1565  decode.d1.loss_dice: 1.1859  decode.d2.loss_cls: 0.2730  decode.d2.loss_mask: 1.1410  decode.d2.loss_dice: 1.1862  decode.d3.loss_cls: 0.2695  decode.d3.loss_mask: 1.1502  decode.d3.loss_dice: 1.2020  decode.d4.loss_cls: 0.2662  decode.d4.loss_mask: 1.1551  decode.d4.loss_dice: 1.2251  decode.d5.loss_cls: 0.2645  decode.d5.loss_mask: 1.1739  decode.d5.loss_dice: 1.2241  decode.d6.loss_cls: 0.2647  decode.d6.loss_mask: 1.1637  decode.d6.loss_dice: 1.2229  decode.d7.loss_cls: 0.2506  decode.d7.loss_mask: 1.1429  decode.d7.loss_dice: 1.1976  decode.d8.loss_cls: 0.2436  decode.d8.loss_mask: 1.1529  decode.d8.loss_dice: 1.2110
2025/03/29 15:01:34 - mmengine - INFO - Iter(train) [ 5800/20000]  base_lr: 7.3477e-05 lr: 7.3477e-05  eta: 7:00:42  time: 1.1185  data_time: 0.0202  memory: 10136  loss: 24.8796  decode.loss_cls: 0.2755  decode.loss_mask: 1.0205  decode.loss_dice: 1.1927  decode.d0.loss_cls: 0.2567  decode.d0.loss_mask: 1.0771  decode.d0.loss_dice: 1.2734  decode.d1.loss_cls: 0.2231  decode.d1.loss_mask: 1.0489  decode.d1.loss_dice: 1.1874  decode.d2.loss_cls: 0.2639  decode.d2.loss_mask: 0.9980  decode.d2.loss_dice: 1.1879  decode.d3.loss_cls: 0.2742  decode.d3.loss_mask: 1.0031  decode.d3.loss_dice: 1.2037  decode.d4.loss_cls: 0.3010  decode.d4.loss_mask: 0.9928  decode.d4.loss_dice: 1.1966  decode.d5.loss_cls: 0.2667  decode.d5.loss_mask: 1.0168  decode.d5.loss_dice: 1.1914  decode.d6.loss_cls: 0.2927  decode.d6.loss_mask: 0.9967  decode.d6.loss_dice: 1.1900  decode.d7.loss_cls: 0.2739  decode.d7.loss_mask: 1.0094  decode.d7.loss_dice: 1.2000  decode.d8.loss_cls: 0.2744  decode.d8.loss_mask: 0.9992  decode.d8.loss_dice: 1.1920
2025/03/29 15:02:31 - mmengine - INFO - Iter(train) [ 5850/20000]  base_lr: 7.3244e-05 lr: 7.3244e-05  eta: 6:57:54  time: 1.1169  data_time: 0.0201  memory: 10129  loss: 24.0751  decode.loss_cls: 0.1625  decode.loss_mask: 1.0129  decode.loss_dice: 1.2142  decode.d0.loss_cls: 0.2068  decode.d0.loss_mask: 1.0268  decode.d0.loss_dice: 1.2778  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 1.0215  decode.d1.loss_dice: 1.1969  decode.d2.loss_cls: 0.1614  decode.d2.loss_mask: 1.0180  decode.d2.loss_dice: 1.1917  decode.d3.loss_cls: 0.1334  decode.d3.loss_mask: 1.0273  decode.d3.loss_dice: 1.2353  decode.d4.loss_cls: 0.1680  decode.d4.loss_mask: 1.0245  decode.d4.loss_dice: 1.2192  decode.d5.loss_cls: 0.1786  decode.d5.loss_mask: 1.0041  decode.d5.loss_dice: 1.2249  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 1.0190  decode.d6.loss_dice: 1.2345  decode.d7.loss_cls: 0.1804  decode.d7.loss_mask: 1.0096  decode.d7.loss_dice: 1.2046  decode.d8.loss_cls: 0.1972  decode.d8.loss_mask: 1.0088  decode.d8.loss_dice: 1.1964
2025/03/29 15:03:27 - mmengine - INFO - Iter(train) [ 5900/20000]  base_lr: 7.3011e-05 lr: 7.3011e-05  eta: 6:55:08  time: 1.1160  data_time: 0.0202  memory: 10122  loss: 27.2917  decode.loss_cls: 0.1376  decode.loss_mask: 1.1481  decode.loss_dice: 1.3732  decode.d0.loss_cls: 0.2659  decode.d0.loss_mask: 1.1564  decode.d0.loss_dice: 1.4158  decode.d1.loss_cls: 0.2281  decode.d1.loss_mask: 1.1280  decode.d1.loss_dice: 1.3973  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 1.1446  decode.d2.loss_dice: 1.3936  decode.d3.loss_cls: 0.2044  decode.d3.loss_mask: 1.1346  decode.d3.loss_dice: 1.3878  decode.d4.loss_cls: 0.2347  decode.d4.loss_mask: 1.1319  decode.d4.loss_dice: 1.3758  decode.d5.loss_cls: 0.2060  decode.d5.loss_mask: 1.1612  decode.d5.loss_dice: 1.3566  decode.d6.loss_cls: 0.1670  decode.d6.loss_mask: 1.1516  decode.d6.loss_dice: 1.3732  decode.d7.loss_cls: 0.2140  decode.d7.loss_mask: 1.1326  decode.d7.loss_dice: 1.3620  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 1.1529  decode.d8.loss_dice: 1.3804
2025/03/29 15:04:22 - mmengine - INFO - Iter(train) [ 5950/20000]  base_lr: 7.2778e-05 lr: 7.2778e-05  eta: 6:52:23  time: 1.1097  data_time: 0.0197  memory: 10124  loss: 27.7947  decode.loss_cls: 0.2931  decode.loss_mask: 1.1785  decode.loss_dice: 1.3635  decode.d0.loss_cls: 0.3109  decode.d0.loss_mask: 1.1335  decode.d0.loss_dice: 1.3819  decode.d1.loss_cls: 0.2496  decode.d1.loss_mask: 1.1025  decode.d1.loss_dice: 1.3686  decode.d2.loss_cls: 0.3013  decode.d2.loss_mask: 1.1101  decode.d2.loss_dice: 1.3642  decode.d3.loss_cls: 0.3262  decode.d3.loss_mask: 1.1012  decode.d3.loss_dice: 1.3392  decode.d4.loss_cls: 0.3249  decode.d4.loss_mask: 1.0974  decode.d4.loss_dice: 1.3547  decode.d5.loss_cls: 0.2690  decode.d5.loss_mask: 1.1311  decode.d5.loss_dice: 1.3348  decode.d6.loss_cls: 0.2975  decode.d6.loss_mask: 1.1356  decode.d6.loss_dice: 1.3274  decode.d7.loss_cls: 0.2917  decode.d7.loss_mask: 1.1763  decode.d7.loss_dice: 1.3359  decode.d8.loss_cls: 0.2452  decode.d8.loss_mask: 1.1770  decode.d8.loss_dice: 1.3720
2025/03/29 15:05:18 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 15:05:18 - mmengine - INFO - Iter(train) [ 6000/20000]  base_lr: 7.2545e-05 lr: 7.2545e-05  eta: 6:49:39  time: 1.1088  data_time: 0.0198  memory: 10125  loss: 26.4822  decode.loss_cls: 0.2700  decode.loss_mask: 1.0995  decode.loss_dice: 1.3286  decode.d0.loss_cls: 0.2779  decode.d0.loss_mask: 1.0854  decode.d0.loss_dice: 1.3331  decode.d1.loss_cls: 0.2695  decode.d1.loss_mask: 1.0856  decode.d1.loss_dice: 1.2972  decode.d2.loss_cls: 0.2854  decode.d2.loss_mask: 1.0686  decode.d2.loss_dice: 1.2878  decode.d3.loss_cls: 0.2061  decode.d3.loss_mask: 1.0989  decode.d3.loss_dice: 1.3138  decode.d4.loss_cls: 0.2081  decode.d4.loss_mask: 1.0933  decode.d4.loss_dice: 1.3205  decode.d5.loss_cls: 0.2278  decode.d5.loss_mask: 1.0932  decode.d5.loss_dice: 1.3263  decode.d6.loss_cls: 0.2392  decode.d6.loss_mask: 1.0744  decode.d6.loss_dice: 1.2898  decode.d7.loss_cls: 0.2361  decode.d7.loss_mask: 1.1050  decode.d7.loss_dice: 1.2915  decode.d8.loss_cls: 0.2964  decode.d8.loss_mask: 1.0823  decode.d8.loss_dice: 1.2909
2025/03/29 15:05:18 - mmengine - INFO - Saving checkpoint at 6000 iterations
2025/03/29 15:05:26 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:42  time: 0.1229  data_time: 0.0019  memory: 1808  
2025/03/29 15:05:32 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:36  time: 0.1229  data_time: 0.0020  memory: 1808  
2025/03/29 15:05:38 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:30  time: 0.1223  data_time: 0.0020  memory: 1808  
2025/03/29 15:05:45 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1238  data_time: 0.0019  memory: 1808  
2025/03/29 15:05:51 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1236  data_time: 0.0020  memory: 1808  
2025/03/29 15:05:57 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1221  data_time: 0.0019  memory: 1808  
2025/03/29 15:06:03 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1231  data_time: 0.0019  memory: 1808  
2025/03/29 15:06:09 - mmengine - INFO - per class results:
2025/03/29 15:06:09 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 76.34 | 85.28 |
|      building      |  85.4 | 96.69 |
|   low_vegetation   | 58.98 | 70.39 |
|        tree        | 74.07 | 84.57 |
|        car         | 54.19 | 64.25 |
|      clutter       | 40.59 | 90.87 |
+--------------------+-------+-------+
2025/03/29 15:06:09 - mmengine - INFO - Iter(val) [398/398]    aAcc: 84.5200  mIoU: 64.9300  mAcc: 82.0100  data_time: 0.0020  time: 0.1234
2025/03/29 15:06:09 - mmengine - INFO - The previous best checkpoint /home/face/kaichengyang/xiaoxinghu/Earth_Adapter/work_dirs/pr2vi/DG_spatial_24_cutoff_0.3_fft_pre_6/60747_seed0/best_mIoU_iter_4000.pth is removed
2025/03/29 15:06:10 - mmengine - INFO - The best checkpoint with 64.9300 mIoU at 6000 iter is saved to best_mIoU_iter_6000.pth.
2025/03/29 15:07:08 - mmengine - INFO - Iter(train) [ 6050/20000]  base_lr: 7.2312e-05 lr: 7.2312e-05  eta: 6:47:04  time: 1.1108  data_time: 0.0199  memory: 10122  loss: 26.4825  decode.loss_cls: 0.0894  decode.loss_mask: 1.2565  decode.loss_dice: 1.3024  decode.d0.loss_cls: 0.1766  decode.d0.loss_mask: 1.2313  decode.d0.loss_dice: 1.2700  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 1.2471  decode.d1.loss_dice: 1.2848  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 1.2525  decode.d2.loss_dice: 1.2889  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 1.2495  decode.d3.loss_dice: 1.2849  decode.d4.loss_cls: 0.1152  decode.d4.loss_mask: 1.2370  decode.d4.loss_dice: 1.2979  decode.d5.loss_cls: 0.1057  decode.d5.loss_mask: 1.2273  decode.d5.loss_dice: 1.3000  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 1.2135  decode.d6.loss_dice: 1.2786  decode.d7.loss_cls: 0.1209  decode.d7.loss_mask: 1.2268  decode.d7.loss_dice: 1.2979  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 1.2496  decode.d8.loss_dice: 1.3002
2025/03/29 15:08:04 - mmengine - INFO - Iter(train) [ 6100/20000]  base_lr: 7.2079e-05 lr: 7.2079e-05  eta: 6:44:24  time: 1.1131  data_time: 0.0203  memory: 10122  loss: 24.5317  decode.loss_cls: 0.1937  decode.loss_mask: 1.1011  decode.loss_dice: 1.1701  decode.d0.loss_cls: 0.2053  decode.d0.loss_mask: 1.0875  decode.d0.loss_dice: 1.2742  decode.d1.loss_cls: 0.1747  decode.d1.loss_mask: 1.0689  decode.d1.loss_dice: 1.2266  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 1.0895  decode.d2.loss_dice: 1.1809  decode.d3.loss_cls: 0.1703  decode.d3.loss_mask: 1.0899  decode.d3.loss_dice: 1.1829  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 1.0929  decode.d4.loss_dice: 1.1982  decode.d5.loss_cls: 0.1618  decode.d5.loss_mask: 1.0861  decode.d5.loss_dice: 1.1921  decode.d6.loss_cls: 0.1565  decode.d6.loss_mask: 1.0955  decode.d6.loss_dice: 1.1753  decode.d7.loss_cls: 0.1932  decode.d7.loss_mask: 1.0802  decode.d7.loss_dice: 1.1530  decode.d8.loss_cls: 0.1769  decode.d8.loss_mask: 1.0739  decode.d8.loss_dice: 1.1591
2025/03/29 15:09:00 - mmengine - INFO - Iter(train) [ 6150/20000]  base_lr: 7.1845e-05 lr: 7.1845e-05  eta: 6:41:46  time: 1.1162  data_time: 0.0200  memory: 10128  loss: 26.2323  decode.loss_cls: 0.1668  decode.loss_mask: 1.1208  decode.loss_dice: 1.3044  decode.d0.loss_cls: 0.1757  decode.d0.loss_mask: 1.1431  decode.d0.loss_dice: 1.4043  decode.d1.loss_cls: 0.1914  decode.d1.loss_mask: 1.1155  decode.d1.loss_dice: 1.3030  decode.d2.loss_cls: 0.1818  decode.d2.loss_mask: 1.1282  decode.d2.loss_dice: 1.2916  decode.d3.loss_cls: 0.1849  decode.d3.loss_mask: 1.1238  decode.d3.loss_dice: 1.2995  decode.d4.loss_cls: 0.1923  decode.d4.loss_mask: 1.1218  decode.d4.loss_dice: 1.2986  decode.d5.loss_cls: 0.1618  decode.d5.loss_mask: 1.1354  decode.d5.loss_dice: 1.3152  decode.d6.loss_cls: 0.1510  decode.d6.loss_mask: 1.1554  decode.d6.loss_dice: 1.3008  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 1.1441  decode.d7.loss_dice: 1.3239  decode.d8.loss_cls: 0.2280  decode.d8.loss_mask: 1.1255  decode.d8.loss_dice: 1.2846
2025/03/29 15:09:56 - mmengine - INFO - Iter(train) [ 6200/20000]  base_lr: 7.1612e-05 lr: 7.1612e-05  eta: 6:39:10  time: 1.1093  data_time: 0.0200  memory: 10127  loss: 26.0623  decode.loss_cls: 0.1373  decode.loss_mask: 1.2218  decode.loss_dice: 1.2307  decode.d0.loss_cls: 0.2085  decode.d0.loss_mask: 1.2333  decode.d0.loss_dice: 1.2918  decode.d1.loss_cls: 0.1874  decode.d1.loss_mask: 1.2070  decode.d1.loss_dice: 1.2333  decode.d2.loss_cls: 0.1332  decode.d2.loss_mask: 1.2118  decode.d2.loss_dice: 1.2323  decode.d3.loss_cls: 0.1516  decode.d3.loss_mask: 1.2182  decode.d3.loss_dice: 1.2235  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 1.2289  decode.d4.loss_dice: 1.2340  decode.d5.loss_cls: 0.1271  decode.d5.loss_mask: 1.2176  decode.d5.loss_dice: 1.2318  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 1.2072  decode.d6.loss_dice: 1.2329  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 1.2120  decode.d7.loss_dice: 1.2320  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 1.2172  decode.d8.loss_dice: 1.2472
2025/03/29 15:10:51 - mmengine - INFO - Iter(train) [ 6250/20000]  base_lr: 7.1378e-05 lr: 7.1378e-05  eta: 6:36:35  time: 1.1118  data_time: 0.0201  memory: 10126  loss: 28.4771  decode.loss_cls: 0.2518  decode.loss_mask: 1.1822  decode.loss_dice: 1.3910  decode.d0.loss_cls: 0.2451  decode.d0.loss_mask: 1.2015  decode.d0.loss_dice: 1.4782  decode.d1.loss_cls: 0.2605  decode.d1.loss_mask: 1.1852  decode.d1.loss_dice: 1.4257  decode.d2.loss_cls: 0.2800  decode.d2.loss_mask: 1.1752  decode.d2.loss_dice: 1.4253  decode.d3.loss_cls: 0.2947  decode.d3.loss_mask: 1.1593  decode.d3.loss_dice: 1.3384  decode.d4.loss_cls: 0.2679  decode.d4.loss_mask: 1.1673  decode.d4.loss_dice: 1.3845  decode.d5.loss_cls: 0.3267  decode.d5.loss_mask: 1.1871  decode.d5.loss_dice: 1.4014  decode.d6.loss_cls: 0.2808  decode.d6.loss_mask: 1.1733  decode.d6.loss_dice: 1.3764  decode.d7.loss_cls: 0.2495  decode.d7.loss_mask: 1.1566  decode.d7.loss_dice: 1.3887  decode.d8.loss_cls: 0.2739  decode.d8.loss_mask: 1.1618  decode.d8.loss_dice: 1.3869
2025/03/29 15:11:47 - mmengine - INFO - Iter(train) [ 6300/20000]  base_lr: 7.1144e-05 lr: 7.1144e-05  eta: 6:34:01  time: 1.1078  data_time: 0.0204  memory: 10119  loss: 24.3334  decode.loss_cls: 0.2808  decode.loss_mask: 0.9638  decode.loss_dice: 1.1892  decode.d0.loss_cls: 0.3110  decode.d0.loss_mask: 0.9576  decode.d0.loss_dice: 1.2403  decode.d1.loss_cls: 0.2977  decode.d1.loss_mask: 0.9375  decode.d1.loss_dice: 1.2257  decode.d2.loss_cls: 0.3045  decode.d2.loss_mask: 0.9292  decode.d2.loss_dice: 1.1773  decode.d3.loss_cls: 0.3099  decode.d3.loss_mask: 0.9382  decode.d3.loss_dice: 1.1716  decode.d4.loss_cls: 0.2907  decode.d4.loss_mask: 0.9547  decode.d4.loss_dice: 1.1723  decode.d5.loss_cls: 0.2718  decode.d5.loss_mask: 0.9656  decode.d5.loss_dice: 1.1716  decode.d6.loss_cls: 0.3002  decode.d6.loss_mask: 0.9655  decode.d6.loss_dice: 1.1185  decode.d7.loss_cls: 0.3043  decode.d7.loss_mask: 0.9513  decode.d7.loss_dice: 1.1795  decode.d8.loss_cls: 0.3149  decode.d8.loss_mask: 0.9621  decode.d8.loss_dice: 1.1761
2025/03/29 15:12:44 - mmengine - INFO - Iter(train) [ 6350/20000]  base_lr: 7.0911e-05 lr: 7.0911e-05  eta: 6:31:32  time: 1.1102  data_time: 0.0202  memory: 10120  loss: 26.9299  decode.loss_cls: 0.2040  decode.loss_mask: 1.1833  decode.loss_dice: 1.3005  decode.d0.loss_cls: 0.3062  decode.d0.loss_mask: 1.1953  decode.d0.loss_dice: 1.2753  decode.d1.loss_cls: 0.2563  decode.d1.loss_mask: 1.1731  decode.d1.loss_dice: 1.2250  decode.d2.loss_cls: 0.2562  decode.d2.loss_mask: 1.1667  decode.d2.loss_dice: 1.2425  decode.d3.loss_cls: 0.1788  decode.d3.loss_mask: 1.2279  decode.d3.loss_dice: 1.2740  decode.d4.loss_cls: 0.1850  decode.d4.loss_mask: 1.2075  decode.d4.loss_dice: 1.2663  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 1.2082  decode.d5.loss_dice: 1.2572  decode.d6.loss_cls: 0.2004  decode.d6.loss_mask: 1.2300  decode.d6.loss_dice: 1.2827  decode.d7.loss_cls: 0.1943  decode.d7.loss_mask: 1.2106  decode.d7.loss_dice: 1.2750  decode.d8.loss_cls: 0.2347  decode.d8.loss_mask: 1.1981  decode.d8.loss_dice: 1.2967
2025/03/29 15:13:40 - mmengine - INFO - Iter(train) [ 6400/20000]  base_lr: 7.0677e-05 lr: 7.0677e-05  eta: 6:29:01  time: 1.1114  data_time: 0.0200  memory: 10124  loss: 23.9312  decode.loss_cls: 0.1851  decode.loss_mask: 0.9639  decode.loss_dice: 1.2531  decode.d0.loss_cls: 0.2265  decode.d0.loss_mask: 0.9804  decode.d0.loss_dice: 1.2628  decode.d1.loss_cls: 0.2368  decode.d1.loss_mask: 0.9251  decode.d1.loss_dice: 1.2125  decode.d2.loss_cls: 0.2294  decode.d2.loss_mask: 0.9413  decode.d2.loss_dice: 1.2293  decode.d3.loss_cls: 0.2329  decode.d3.loss_mask: 0.9130  decode.d3.loss_dice: 1.2001  decode.d4.loss_cls: 0.2109  decode.d4.loss_mask: 0.9395  decode.d4.loss_dice: 1.2460  decode.d5.loss_cls: 0.2126  decode.d5.loss_mask: 0.9425  decode.d5.loss_dice: 1.2122  decode.d6.loss_cls: 0.1963  decode.d6.loss_mask: 0.9445  decode.d6.loss_dice: 1.2260  decode.d7.loss_cls: 0.2308  decode.d7.loss_mask: 0.9473  decode.d7.loss_dice: 1.2379  decode.d8.loss_cls: 0.1963  decode.d8.loss_mask: 0.9509  decode.d8.loss_dice: 1.2453
2025/03/29 15:14:38 - mmengine - INFO - Iter(train) [ 6450/20000]  base_lr: 7.0443e-05 lr: 7.0443e-05  eta: 6:26:37  time: 1.1374  data_time: 0.0219  memory: 10129  loss: 25.4890  decode.loss_cls: 0.2627  decode.loss_mask: 1.0806  decode.loss_dice: 1.1956  decode.d0.loss_cls: 0.2711  decode.d0.loss_mask: 1.0762  decode.d0.loss_dice: 1.2577  decode.d1.loss_cls: 0.2517  decode.d1.loss_mask: 1.0307  decode.d1.loss_dice: 1.1996  decode.d2.loss_cls: 0.2983  decode.d2.loss_mask: 1.0407  decode.d2.loss_dice: 1.1825  decode.d3.loss_cls: 0.3008  decode.d3.loss_mask: 1.0684  decode.d3.loss_dice: 1.1883  decode.d4.loss_cls: 0.2906  decode.d4.loss_mask: 1.0815  decode.d4.loss_dice: 1.2077  decode.d5.loss_cls: 0.2688  decode.d5.loss_mask: 1.0849  decode.d5.loss_dice: 1.1951  decode.d6.loss_cls: 0.2658  decode.d6.loss_mask: 1.0889  decode.d6.loss_dice: 1.1982  decode.d7.loss_cls: 0.2560  decode.d7.loss_mask: 1.1019  decode.d7.loss_dice: 1.1964  decode.d8.loss_cls: 0.2342  decode.d8.loss_mask: 1.0920  decode.d8.loss_dice: 1.2220
2025/03/29 15:15:33 - mmengine - INFO - Iter(train) [ 6500/20000]  base_lr: 7.0209e-05 lr: 7.0209e-05  eta: 6:24:09  time: 1.1099  data_time: 0.0199  memory: 10126  loss: 27.9551  decode.loss_cls: 0.2432  decode.loss_mask: 1.2304  decode.loss_dice: 1.3408  decode.d0.loss_cls: 0.2639  decode.d0.loss_mask: 1.2241  decode.d0.loss_dice: 1.3540  decode.d1.loss_cls: 0.2405  decode.d1.loss_mask: 1.2102  decode.d1.loss_dice: 1.2850  decode.d2.loss_cls: 0.2787  decode.d2.loss_mask: 1.2186  decode.d2.loss_dice: 1.3040  decode.d3.loss_cls: 0.2934  decode.d3.loss_mask: 1.2079  decode.d3.loss_dice: 1.3504  decode.d4.loss_cls: 0.2779  decode.d4.loss_mask: 1.2165  decode.d4.loss_dice: 1.2820  decode.d5.loss_cls: 0.2742  decode.d5.loss_mask: 1.2271  decode.d5.loss_dice: 1.2799  decode.d6.loss_cls: 0.2594  decode.d6.loss_mask: 1.2441  decode.d6.loss_dice: 1.3197  decode.d7.loss_cls: 0.2520  decode.d7.loss_mask: 1.2053  decode.d7.loss_dice: 1.2913  decode.d8.loss_cls: 0.2785  decode.d8.loss_mask: 1.1970  decode.d8.loss_dice: 1.3050
2025/03/29 15:16:29 - mmengine - INFO - Iter(train) [ 6550/20000]  base_lr: 6.9975e-05 lr: 6.9975e-05  eta: 6:21:43  time: 1.1120  data_time: 0.0198  memory: 10124  loss: 27.0963  decode.loss_cls: 0.1945  decode.loss_mask: 1.1664  decode.loss_dice: 1.3510  decode.d0.loss_cls: 0.1873  decode.d0.loss_mask: 1.1766  decode.d0.loss_dice: 1.4115  decode.d1.loss_cls: 0.1726  decode.d1.loss_mask: 1.1738  decode.d1.loss_dice: 1.3683  decode.d2.loss_cls: 0.2054  decode.d2.loss_mask: 1.1768  decode.d2.loss_dice: 1.3244  decode.d3.loss_cls: 0.2480  decode.d3.loss_mask: 1.1484  decode.d3.loss_dice: 1.3214  decode.d4.loss_cls: 0.1689  decode.d4.loss_mask: 1.1785  decode.d4.loss_dice: 1.3602  decode.d5.loss_cls: 0.2192  decode.d5.loss_mask: 1.1524  decode.d5.loss_dice: 1.3132  decode.d6.loss_cls: 0.2236  decode.d6.loss_mask: 1.1682  decode.d6.loss_dice: 1.3153  decode.d7.loss_cls: 0.2181  decode.d7.loss_mask: 1.1581  decode.d7.loss_dice: 1.2969  decode.d8.loss_cls: 0.1783  decode.d8.loss_mask: 1.1783  decode.d8.loss_dice: 1.3407
2025/03/29 15:17:25 - mmengine - INFO - Iter(train) [ 6600/20000]  base_lr: 6.9741e-05 lr: 6.9741e-05  eta: 6:19:18  time: 1.1086  data_time: 0.0198  memory: 10126  loss: 26.2051  decode.loss_cls: 0.1374  decode.loss_mask: 1.1416  decode.loss_dice: 1.3377  decode.d0.loss_cls: 0.1888  decode.d0.loss_mask: 1.1260  decode.d0.loss_dice: 1.3839  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 1.1071  decode.d1.loss_dice: 1.3348  decode.d2.loss_cls: 0.1540  decode.d2.loss_mask: 1.1156  decode.d2.loss_dice: 1.3090  decode.d3.loss_cls: 0.1344  decode.d3.loss_mask: 1.1210  decode.d3.loss_dice: 1.3283  decode.d4.loss_cls: 0.1699  decode.d4.loss_mask: 1.1242  decode.d4.loss_dice: 1.3366  decode.d5.loss_cls: 0.1572  decode.d5.loss_mask: 1.1230  decode.d5.loss_dice: 1.3225  decode.d6.loss_cls: 0.1683  decode.d6.loss_mask: 1.1173  decode.d6.loss_dice: 1.3253  decode.d7.loss_cls: 0.1565  decode.d7.loss_mask: 1.1161  decode.d7.loss_dice: 1.3282  decode.d8.loss_cls: 0.1632  decode.d8.loss_mask: 1.1489  decode.d8.loss_dice: 1.3420
2025/03/29 15:18:21 - mmengine - INFO - Iter(train) [ 6650/20000]  base_lr: 6.9507e-05 lr: 6.9507e-05  eta: 6:16:55  time: 1.1310  data_time: 0.0202  memory: 10121  loss: 23.5161  decode.loss_cls: 0.2257  decode.loss_mask: 0.9366  decode.loss_dice: 1.2005  decode.d0.loss_cls: 0.2376  decode.d0.loss_mask: 0.9879  decode.d0.loss_dice: 1.2735  decode.d1.loss_cls: 0.1671  decode.d1.loss_mask: 0.9818  decode.d1.loss_dice: 1.2209  decode.d2.loss_cls: 0.1885  decode.d2.loss_mask: 0.9702  decode.d2.loss_dice: 1.1843  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 0.9301  decode.d3.loss_dice: 1.1942  decode.d4.loss_cls: 0.1884  decode.d4.loss_mask: 0.9235  decode.d4.loss_dice: 1.1835  decode.d5.loss_cls: 0.1772  decode.d5.loss_mask: 0.9348  decode.d5.loss_dice: 1.2091  decode.d6.loss_cls: 0.2043  decode.d6.loss_mask: 0.9446  decode.d6.loss_dice: 1.2075  decode.d7.loss_cls: 0.1860  decode.d7.loss_mask: 0.9449  decode.d7.loss_dice: 1.1984  decode.d8.loss_cls: 0.1960  decode.d8.loss_mask: 0.9313  decode.d8.loss_dice: 1.1926
2025/03/29 15:19:16 - mmengine - INFO - Iter(train) [ 6700/20000]  base_lr: 6.9272e-05 lr: 6.9272e-05  eta: 6:14:33  time: 1.1092  data_time: 0.0201  memory: 10115  loss: 27.9888  decode.loss_cls: 0.3051  decode.loss_mask: 1.1240  decode.loss_dice: 1.3706  decode.d0.loss_cls: 0.3212  decode.d0.loss_mask: 1.1506  decode.d0.loss_dice: 1.4908  decode.d1.loss_cls: 0.3777  decode.d1.loss_mask: 1.0819  decode.d1.loss_dice: 1.3611  decode.d2.loss_cls: 0.3769  decode.d2.loss_mask: 1.0772  decode.d2.loss_dice: 1.3247  decode.d3.loss_cls: 0.3510  decode.d3.loss_mask: 1.0717  decode.d3.loss_dice: 1.3339  decode.d4.loss_cls: 0.3432  decode.d4.loss_mask: 1.0742  decode.d4.loss_dice: 1.3328  decode.d5.loss_cls: 0.3092  decode.d5.loss_mask: 1.0841  decode.d5.loss_dice: 1.3616  decode.d6.loss_cls: 0.3705  decode.d6.loss_mask: 1.0650  decode.d6.loss_dice: 1.3624  decode.d7.loss_cls: 0.3584  decode.d7.loss_mask: 1.0650  decode.d7.loss_dice: 1.3504  decode.d8.loss_cls: 0.3950  decode.d8.loss_mask: 1.0692  decode.d8.loss_dice: 1.3295
2025/03/29 15:20:12 - mmengine - INFO - Iter(train) [ 6750/20000]  base_lr: 6.9038e-05 lr: 6.9038e-05  eta: 6:12:11  time: 1.1092  data_time: 0.0198  memory: 10122  loss: 26.8536  decode.loss_cls: 0.2649  decode.loss_mask: 1.1840  decode.loss_dice: 1.2449  decode.d0.loss_cls: 0.2848  decode.d0.loss_mask: 1.1616  decode.d0.loss_dice: 1.3282  decode.d1.loss_cls: 0.2476  decode.d1.loss_mask: 1.1634  decode.d1.loss_dice: 1.2635  decode.d2.loss_cls: 0.3144  decode.d2.loss_mask: 1.1441  decode.d2.loss_dice: 1.2166  decode.d3.loss_cls: 0.2510  decode.d3.loss_mask: 1.1878  decode.d3.loss_dice: 1.2530  decode.d4.loss_cls: 0.1878  decode.d4.loss_mask: 1.1980  decode.d4.loss_dice: 1.2619  decode.d5.loss_cls: 0.2181  decode.d5.loss_mask: 1.1853  decode.d5.loss_dice: 1.2758  decode.d6.loss_cls: 0.2307  decode.d6.loss_mask: 1.1709  decode.d6.loss_dice: 1.2453  decode.d7.loss_cls: 0.2333  decode.d7.loss_mask: 1.1811  decode.d7.loss_dice: 1.2769  decode.d8.loss_cls: 0.2482  decode.d8.loss_mask: 1.1810  decode.d8.loss_dice: 1.2497
2025/03/29 15:21:08 - mmengine - INFO - Iter(train) [ 6800/20000]  base_lr: 6.8803e-05 lr: 6.8803e-05  eta: 6:09:51  time: 1.1088  data_time: 0.0196  memory: 10121  loss: 27.4898  decode.loss_cls: 0.2847  decode.loss_mask: 1.1620  decode.loss_dice: 1.3001  decode.d0.loss_cls: 0.2789  decode.d0.loss_mask: 1.2430  decode.d0.loss_dice: 1.3658  decode.d1.loss_cls: 0.2393  decode.d1.loss_mask: 1.1641  decode.d1.loss_dice: 1.3181  decode.d2.loss_cls: 0.2280  decode.d2.loss_mask: 1.1824  decode.d2.loss_dice: 1.3171  decode.d3.loss_cls: 0.2104  decode.d3.loss_mask: 1.1729  decode.d3.loss_dice: 1.3291  decode.d4.loss_cls: 0.2797  decode.d4.loss_mask: 1.1823  decode.d4.loss_dice: 1.2758  decode.d5.loss_cls: 0.2889  decode.d5.loss_mask: 1.1757  decode.d5.loss_dice: 1.2787  decode.d6.loss_cls: 0.2659  decode.d6.loss_mask: 1.1805  decode.d6.loss_dice: 1.2935  decode.d7.loss_cls: 0.2770  decode.d7.loss_mask: 1.1610  decode.d7.loss_dice: 1.2603  decode.d8.loss_cls: 0.2964  decode.d8.loss_mask: 1.1674  decode.d8.loss_dice: 1.3109
2025/03/29 15:22:03 - mmengine - INFO - Iter(train) [ 6850/20000]  base_lr: 6.8569e-05 lr: 6.8569e-05  eta: 6:07:33  time: 1.1148  data_time: 0.0203  memory: 10124  loss: 28.6641  decode.loss_cls: 0.3651  decode.loss_mask: 1.2007  decode.loss_dice: 1.3036  decode.d0.loss_cls: 0.3826  decode.d0.loss_mask: 1.2192  decode.d0.loss_dice: 1.3527  decode.d1.loss_cls: 0.3782  decode.d1.loss_mask: 1.2208  decode.d1.loss_dice: 1.2835  decode.d2.loss_cls: 0.3623  decode.d2.loss_mask: 1.2040  decode.d2.loss_dice: 1.2444  decode.d3.loss_cls: 0.3334  decode.d3.loss_mask: 1.1987  decode.d3.loss_dice: 1.2840  decode.d4.loss_cls: 0.3188  decode.d4.loss_mask: 1.2239  decode.d4.loss_dice: 1.3138  decode.d5.loss_cls: 0.3112  decode.d5.loss_mask: 1.2144  decode.d5.loss_dice: 1.2903  decode.d6.loss_cls: 0.3717  decode.d6.loss_mask: 1.2089  decode.d6.loss_dice: 1.2988  decode.d7.loss_cls: 0.3323  decode.d7.loss_mask: 1.2207  decode.d7.loss_dice: 1.3364  decode.d8.loss_cls: 0.3231  decode.d8.loss_mask: 1.2430  decode.d8.loss_dice: 1.3237
2025/03/29 15:22:59 - mmengine - INFO - Iter(train) [ 6900/20000]  base_lr: 6.8334e-05 lr: 6.8334e-05  eta: 6:05:16  time: 1.1117  data_time: 0.0201  memory: 10124  loss: 24.4959  decode.loss_cls: 0.1502  decode.loss_mask: 1.0720  decode.loss_dice: 1.2104  decode.d0.loss_cls: 0.2274  decode.d0.loss_mask: 1.0934  decode.d0.loss_dice: 1.2312  decode.d1.loss_cls: 0.1823  decode.d1.loss_mask: 1.0794  decode.d1.loss_dice: 1.1830  decode.d2.loss_cls: 0.1714  decode.d2.loss_mask: 1.0607  decode.d2.loss_dice: 1.2003  decode.d3.loss_cls: 0.1503  decode.d3.loss_mask: 1.0878  decode.d3.loss_dice: 1.2367  decode.d4.loss_cls: 0.2058  decode.d4.loss_mask: 1.0453  decode.d4.loss_dice: 1.2061  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 1.0846  decode.d5.loss_dice: 1.2168  decode.d6.loss_cls: 0.1532  decode.d6.loss_mask: 1.0751  decode.d6.loss_dice: 1.2024  decode.d7.loss_cls: 0.1299  decode.d7.loss_mask: 1.0662  decode.d7.loss_dice: 1.1994  decode.d8.loss_cls: 0.1479  decode.d8.loss_mask: 1.0782  decode.d8.loss_dice: 1.2025
2025/03/29 15:23:55 - mmengine - INFO - Iter(train) [ 6950/20000]  base_lr: 6.8099e-05 lr: 6.8099e-05  eta: 6:03:00  time: 1.1183  data_time: 0.0217  memory: 10121  loss: 28.9753  decode.loss_cls: 0.3821  decode.loss_mask: 1.2319  decode.loss_dice: 1.3280  decode.d0.loss_cls: 0.3531  decode.d0.loss_mask: 1.2188  decode.d0.loss_dice: 1.4193  decode.d1.loss_cls: 0.4558  decode.d1.loss_mask: 1.1705  decode.d1.loss_dice: 1.2970  decode.d2.loss_cls: 0.3959  decode.d2.loss_mask: 1.1731  decode.d2.loss_dice: 1.2612  decode.d3.loss_cls: 0.3488  decode.d3.loss_mask: 1.1805  decode.d3.loss_dice: 1.2888  decode.d4.loss_cls: 0.4011  decode.d4.loss_mask: 1.1836  decode.d4.loss_dice: 1.2740  decode.d5.loss_cls: 0.3734  decode.d5.loss_mask: 1.2445  decode.d5.loss_dice: 1.2949  decode.d6.loss_cls: 0.4002  decode.d6.loss_mask: 1.2032  decode.d6.loss_dice: 1.2815  decode.d7.loss_cls: 0.3836  decode.d7.loss_mask: 1.2236  decode.d7.loss_dice: 1.3111  decode.d8.loss_cls: 0.3474  decode.d8.loss_mask: 1.2098  decode.d8.loss_dice: 1.3385
2025/03/29 15:24:51 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 15:24:51 - mmengine - INFO - Iter(train) [ 7000/20000]  base_lr: 6.7864e-05 lr: 6.7864e-05  eta: 6:00:45  time: 1.1164  data_time: 0.0209  memory: 10129  loss: 27.1265  decode.loss_cls: 0.2274  decode.loss_mask: 1.2556  decode.loss_dice: 1.2605  decode.d0.loss_cls: 0.3038  decode.d0.loss_mask: 1.2348  decode.d0.loss_dice: 1.2517  decode.d1.loss_cls: 0.2203  decode.d1.loss_mask: 1.2185  decode.d1.loss_dice: 1.2217  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 1.2558  decode.d2.loss_dice: 1.2449  decode.d3.loss_cls: 0.2708  decode.d3.loss_mask: 1.2278  decode.d3.loss_dice: 1.2105  decode.d4.loss_cls: 0.2451  decode.d4.loss_mask: 1.2312  decode.d4.loss_dice: 1.2182  decode.d5.loss_cls: 0.2739  decode.d5.loss_mask: 1.2093  decode.d5.loss_dice: 1.2163  decode.d6.loss_cls: 0.2045  decode.d6.loss_mask: 1.2568  decode.d6.loss_dice: 1.2563  decode.d7.loss_cls: 0.3009  decode.d7.loss_mask: 1.1863  decode.d7.loss_dice: 1.2112  decode.d8.loss_cls: 0.2125  decode.d8.loss_mask: 1.2518  decode.d8.loss_dice: 1.2487
2025/03/29 15:25:46 - mmengine - INFO - Iter(train) [ 7050/20000]  base_lr: 6.7629e-05 lr: 6.7629e-05  eta: 5:58:31  time: 1.1205  data_time: 0.0204  memory: 10126  loss: 26.1409  decode.loss_cls: 0.2682  decode.loss_mask: 1.1177  decode.loss_dice: 1.2572  decode.d0.loss_cls: 0.2183  decode.d0.loss_mask: 1.1310  decode.d0.loss_dice: 1.4223  decode.d1.loss_cls: 0.3353  decode.d1.loss_mask: 1.0688  decode.d1.loss_dice: 1.2203  decode.d2.loss_cls: 0.3131  decode.d2.loss_mask: 1.0894  decode.d2.loss_dice: 1.2169  decode.d3.loss_cls: 0.3031  decode.d3.loss_mask: 1.0690  decode.d3.loss_dice: 1.2026  decode.d4.loss_cls: 0.2813  decode.d4.loss_mask: 1.0830  decode.d4.loss_dice: 1.2133  decode.d5.loss_cls: 0.2646  decode.d5.loss_mask: 1.0868  decode.d5.loss_dice: 1.2111  decode.d6.loss_cls: 0.2753  decode.d6.loss_mask: 1.0802  decode.d6.loss_dice: 1.2354  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 1.0828  decode.d7.loss_dice: 1.2607  decode.d8.loss_cls: 0.2421  decode.d8.loss_mask: 1.1013  decode.d8.loss_dice: 1.2502
2025/03/29 15:26:42 - mmengine - INFO - Iter(train) [ 7100/20000]  base_lr: 6.7394e-05 lr: 6.7394e-05  eta: 5:56:19  time: 1.1142  data_time: 0.0202  memory: 10125  loss: 24.9282  decode.loss_cls: 0.2676  decode.loss_mask: 1.0392  decode.loss_dice: 1.2140  decode.d0.loss_cls: 0.2477  decode.d0.loss_mask: 1.0567  decode.d0.loss_dice: 1.2609  decode.d1.loss_cls: 0.2094  decode.d1.loss_mask: 1.0419  decode.d1.loss_dice: 1.2043  decode.d2.loss_cls: 0.2593  decode.d2.loss_mask: 1.0383  decode.d2.loss_dice: 1.1674  decode.d3.loss_cls: 0.2263  decode.d3.loss_mask: 1.0407  decode.d3.loss_dice: 1.2172  decode.d4.loss_cls: 0.2562  decode.d4.loss_mask: 1.0399  decode.d4.loss_dice: 1.1902  decode.d5.loss_cls: 0.2438  decode.d5.loss_mask: 1.0400  decode.d5.loss_dice: 1.2073  decode.d6.loss_cls: 0.2397  decode.d6.loss_mask: 1.0493  decode.d6.loss_dice: 1.1955  decode.d7.loss_cls: 0.2688  decode.d7.loss_mask: 1.0331  decode.d7.loss_dice: 1.1858  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 1.0353  decode.d8.loss_dice: 1.1931
2025/03/29 15:27:39 - mmengine - INFO - Iter(train) [ 7150/20000]  base_lr: 6.7159e-05 lr: 6.7159e-05  eta: 5:54:08  time: 1.1112  data_time: 0.0195  memory: 10119  loss: 26.1655  decode.loss_cls: 0.3137  decode.loss_mask: 1.0253  decode.loss_dice: 1.2786  decode.d0.loss_cls: 0.3272  decode.d0.loss_mask: 1.0351  decode.d0.loss_dice: 1.3490  decode.d1.loss_cls: 0.3126  decode.d1.loss_mask: 0.9995  decode.d1.loss_dice: 1.2753  decode.d2.loss_cls: 0.3460  decode.d2.loss_mask: 0.9997  decode.d2.loss_dice: 1.2753  decode.d3.loss_cls: 0.3366  decode.d3.loss_mask: 1.0082  decode.d3.loss_dice: 1.2711  decode.d4.loss_cls: 0.3448  decode.d4.loss_mask: 0.9875  decode.d4.loss_dice: 1.2268  decode.d5.loss_cls: 0.3584  decode.d5.loss_mask: 1.0082  decode.d5.loss_dice: 1.2685  decode.d6.loss_cls: 0.3015  decode.d6.loss_mask: 1.0179  decode.d6.loss_dice: 1.2731  decode.d7.loss_cls: 0.2988  decode.d7.loss_mask: 1.0304  decode.d7.loss_dice: 1.3018  decode.d8.loss_cls: 0.2958  decode.d8.loss_mask: 1.0145  decode.d8.loss_dice: 1.2845
2025/03/29 15:28:35 - mmengine - INFO - Iter(train) [ 7200/20000]  base_lr: 6.6924e-05 lr: 6.6924e-05  eta: 5:51:58  time: 1.1278  data_time: 0.0213  memory: 10119  loss: 22.8400  decode.loss_cls: 0.2350  decode.loss_mask: 0.9362  decode.loss_dice: 1.1149  decode.d0.loss_cls: 0.2128  decode.d0.loss_mask: 0.9659  decode.d0.loss_dice: 1.2051  decode.d1.loss_cls: 0.1646  decode.d1.loss_mask: 0.9705  decode.d1.loss_dice: 1.1791  decode.d2.loss_cls: 0.1810  decode.d2.loss_mask: 0.9415  decode.d2.loss_dice: 1.1282  decode.d3.loss_cls: 0.2069  decode.d3.loss_mask: 0.9453  decode.d3.loss_dice: 1.1062  decode.d4.loss_cls: 0.2238  decode.d4.loss_mask: 0.9440  decode.d4.loss_dice: 1.1039  decode.d5.loss_cls: 0.1952  decode.d5.loss_mask: 0.9399  decode.d5.loss_dice: 1.1352  decode.d6.loss_cls: 0.2005  decode.d6.loss_mask: 0.9418  decode.d6.loss_dice: 1.1310  decode.d7.loss_cls: 0.2092  decode.d7.loss_mask: 0.9381  decode.d7.loss_dice: 1.1245  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.9418  decode.d8.loss_dice: 1.1284
2025/03/29 15:29:58 - mmengine - INFO - Iter(train) [ 7250/20000]  base_lr: 6.6689e-05 lr: 6.6689e-05  eta: 5:50:36  time: 1.8829  data_time: 0.1112  memory: 10121  loss: 27.7717  decode.loss_cls: 0.1675  decode.loss_mask: 1.3343  decode.loss_dice: 1.2895  decode.d0.loss_cls: 0.2887  decode.d0.loss_mask: 1.3007  decode.d0.loss_dice: 1.2701  decode.d1.loss_cls: 0.1682  decode.d1.loss_mask: 1.3088  decode.d1.loss_dice: 1.2794  decode.d2.loss_cls: 0.1750  decode.d2.loss_mask: 1.3034  decode.d2.loss_dice: 1.2596  decode.d3.loss_cls: 0.2110  decode.d3.loss_mask: 1.2666  decode.d3.loss_dice: 1.2343  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 1.3175  decode.d4.loss_dice: 1.2667  decode.d5.loss_cls: 0.1795  decode.d5.loss_mask: 1.3346  decode.d5.loss_dice: 1.2691  decode.d6.loss_cls: 0.1403  decode.d6.loss_mask: 1.3520  decode.d6.loss_dice: 1.2839  decode.d7.loss_cls: 0.1759  decode.d7.loss_mask: 1.3290  decode.d7.loss_dice: 1.2895  decode.d8.loss_cls: 0.1486  decode.d8.loss_mask: 1.3432  decode.d8.loss_dice: 1.2964
2025/03/29 15:31:16 - mmengine - INFO - Iter(train) [ 7300/20000]  base_lr: 6.6453e-05 lr: 6.6453e-05  eta: 5:49:07  time: 1.6202  data_time: 0.0638  memory: 10136  loss: 23.2709  decode.loss_cls: 0.2983  decode.loss_mask: 0.9109  decode.loss_dice: 1.1264  decode.d0.loss_cls: 0.2772  decode.d0.loss_mask: 0.9283  decode.d0.loss_dice: 1.2165  decode.d1.loss_cls: 0.2422  decode.d1.loss_mask: 0.9126  decode.d1.loss_dice: 1.1589  decode.d2.loss_cls: 0.2653  decode.d2.loss_mask: 0.9180  decode.d2.loss_dice: 1.1370  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 0.9210  decode.d3.loss_dice: 1.1413  decode.d4.loss_cls: 0.2372  decode.d4.loss_mask: 0.9464  decode.d4.loss_dice: 1.1958  decode.d5.loss_cls: 0.2414  decode.d5.loss_mask: 0.9200  decode.d5.loss_dice: 1.1547  decode.d6.loss_cls: 0.2136  decode.d6.loss_mask: 0.9210  decode.d6.loss_dice: 1.1586  decode.d7.loss_cls: 0.2294  decode.d7.loss_mask: 0.9220  decode.d7.loss_dice: 1.1416  decode.d8.loss_cls: 0.2493  decode.d8.loss_mask: 0.9225  decode.d8.loss_dice: 1.1357
2025/03/29 15:32:22 - mmengine - INFO - Iter(train) [ 7350/20000]  base_lr: 6.6218e-05 lr: 6.6218e-05  eta: 5:47:16  time: 1.2045  data_time: 0.0290  memory: 10129  loss: 27.1002  decode.loss_cls: 0.2402  decode.loss_mask: 1.2017  decode.loss_dice: 1.2828  decode.d0.loss_cls: 0.2413  decode.d0.loss_mask: 1.2291  decode.d0.loss_dice: 1.3375  decode.d1.loss_cls: 0.2874  decode.d1.loss_mask: 1.1787  decode.d1.loss_dice: 1.2405  decode.d2.loss_cls: 0.2690  decode.d2.loss_mask: 1.1928  decode.d2.loss_dice: 1.2145  decode.d3.loss_cls: 0.3007  decode.d3.loss_mask: 1.1758  decode.d3.loss_dice: 1.1971  decode.d4.loss_cls: 0.2364  decode.d4.loss_mask: 1.2125  decode.d4.loss_dice: 1.2353  decode.d5.loss_cls: 0.1851  decode.d5.loss_mask: 1.2370  decode.d5.loss_dice: 1.2700  decode.d6.loss_cls: 0.2342  decode.d6.loss_mask: 1.2380  decode.d6.loss_dice: 1.2730  decode.d7.loss_cls: 0.1883  decode.d7.loss_mask: 1.2290  decode.d7.loss_dice: 1.2865  decode.d8.loss_cls: 0.2332  decode.d8.loss_mask: 1.2069  decode.d8.loss_dice: 1.2456
2025/03/29 15:33:33 - mmengine - INFO - Iter(train) [ 7400/20000]  base_lr: 6.5982e-05 lr: 6.5982e-05  eta: 5:45:34  time: 1.8449  data_time: 0.0829  memory: 10121  loss: 25.7368  decode.loss_cls: 0.2223  decode.loss_mask: 1.0869  decode.loss_dice: 1.2478  decode.d0.loss_cls: 0.2430  decode.d0.loss_mask: 1.1075  decode.d0.loss_dice: 1.3049  decode.d1.loss_cls: 0.2020  decode.d1.loss_mask: 1.0939  decode.d1.loss_dice: 1.2702  decode.d2.loss_cls: 0.1826  decode.d2.loss_mask: 1.1052  decode.d2.loss_dice: 1.2728  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 1.0981  decode.d3.loss_dice: 1.2648  decode.d4.loss_cls: 0.1985  decode.d4.loss_mask: 1.1035  decode.d4.loss_dice: 1.2710  decode.d5.loss_cls: 0.2020  decode.d5.loss_mask: 1.1223  decode.d5.loss_dice: 1.2678  decode.d6.loss_cls: 0.2192  decode.d6.loss_mask: 1.0898  decode.d6.loss_dice: 1.2422  decode.d7.loss_cls: 0.2031  decode.d7.loss_mask: 1.0998  decode.d7.loss_dice: 1.2554  decode.d8.loss_cls: 0.2189  decode.d8.loss_mask: 1.0921  decode.d8.loss_dice: 1.2600
2025/03/29 15:34:55 - mmengine - INFO - Iter(train) [ 7450/20000]  base_lr: 6.5746e-05 lr: 6.5746e-05  eta: 5:44:11  time: 1.5498  data_time: 0.0707  memory: 10119  loss: 27.2244  decode.loss_cls: 0.2784  decode.loss_mask: 1.1328  decode.loss_dice: 1.3395  decode.d0.loss_cls: 0.2894  decode.d0.loss_mask: 1.1170  decode.d0.loss_dice: 1.3503  decode.d1.loss_cls: 0.2589  decode.d1.loss_mask: 1.1017  decode.d1.loss_dice: 1.3272  decode.d2.loss_cls: 0.2974  decode.d2.loss_mask: 1.0977  decode.d2.loss_dice: 1.3177  decode.d3.loss_cls: 0.2620  decode.d3.loss_mask: 1.1095  decode.d3.loss_dice: 1.3348  decode.d4.loss_cls: 0.2829  decode.d4.loss_mask: 1.1201  decode.d4.loss_dice: 1.3192  decode.d5.loss_cls: 0.3116  decode.d5.loss_mask: 1.0962  decode.d5.loss_dice: 1.3146  decode.d6.loss_cls: 0.2770  decode.d6.loss_mask: 1.0940  decode.d6.loss_dice: 1.3163  decode.d7.loss_cls: 0.2819  decode.d7.loss_mask: 1.1072  decode.d7.loss_dice: 1.3187  decode.d8.loss_cls: 0.3303  decode.d8.loss_mask: 1.1039  decode.d8.loss_dice: 1.3363
2025/03/29 15:36:11 - mmengine - INFO - Iter(train) [ 7500/20000]  base_lr: 6.5511e-05 lr: 6.5511e-05  eta: 5:42:39  time: 1.5403  data_time: 0.0642  memory: 10126  loss: 30.0495  decode.loss_cls: 0.2930  decode.loss_mask: 1.3671  decode.loss_dice: 1.3926  decode.d0.loss_cls: 0.3437  decode.d0.loss_mask: 1.2818  decode.d0.loss_dice: 1.3903  decode.d1.loss_cls: 0.3396  decode.d1.loss_mask: 1.2532  decode.d1.loss_dice: 1.3249  decode.d2.loss_cls: 0.3186  decode.d2.loss_mask: 1.2610  decode.d2.loss_dice: 1.3399  decode.d3.loss_cls: 0.3303  decode.d3.loss_mask: 1.2900  decode.d3.loss_dice: 1.3598  decode.d4.loss_cls: 0.3633  decode.d4.loss_mask: 1.3102  decode.d4.loss_dice: 1.3732  decode.d5.loss_cls: 0.3037  decode.d5.loss_mask: 1.3710  decode.d5.loss_dice: 1.3573  decode.d6.loss_cls: 0.3238  decode.d6.loss_mask: 1.3097  decode.d6.loss_dice: 1.3587  decode.d7.loss_cls: 0.3203  decode.d7.loss_mask: 1.3527  decode.d7.loss_dice: 1.4047  decode.d8.loss_cls: 0.2839  decode.d8.loss_mask: 1.3326  decode.d8.loss_dice: 1.3986
2025/03/29 15:37:25 - mmengine - INFO - Iter(train) [ 7550/20000]  base_lr: 6.5275e-05 lr: 6.5275e-05  eta: 5:41:03  time: 1.6245  data_time: 0.0711  memory: 10122  loss: 23.8555  decode.loss_cls: 0.1996  decode.loss_mask: 0.9887  decode.loss_dice: 1.1752  decode.d0.loss_cls: 0.2334  decode.d0.loss_mask: 1.0040  decode.d0.loss_dice: 1.2391  decode.d1.loss_cls: 0.2268  decode.d1.loss_mask: 0.9848  decode.d1.loss_dice: 1.1873  decode.d2.loss_cls: 0.2501  decode.d2.loss_mask: 0.9529  decode.d2.loss_dice: 1.1466  decode.d3.loss_cls: 0.2753  decode.d3.loss_mask: 0.9630  decode.d3.loss_dice: 1.1592  decode.d4.loss_cls: 0.2637  decode.d4.loss_mask: 0.9879  decode.d4.loss_dice: 1.1707  decode.d5.loss_cls: 0.2873  decode.d5.loss_mask: 0.9620  decode.d5.loss_dice: 1.1640  decode.d6.loss_cls: 0.2209  decode.d6.loss_mask: 0.9551  decode.d6.loss_dice: 1.1507  decode.d7.loss_cls: 0.2014  decode.d7.loss_mask: 0.9810  decode.d7.loss_dice: 1.1694  decode.d8.loss_cls: 0.1895  decode.d8.loss_mask: 0.9881  decode.d8.loss_dice: 1.1777
2025/03/29 15:38:42 - mmengine - INFO - Iter(train) [ 7600/20000]  base_lr: 6.5039e-05 lr: 6.5039e-05  eta: 5:39:33  time: 1.3687  data_time: 0.0540  memory: 10117  loss: 29.1499  decode.loss_cls: 0.2798  decode.loss_mask: 1.2853  decode.loss_dice: 1.3300  decode.d0.loss_cls: 0.3659  decode.d0.loss_mask: 1.2695  decode.d0.loss_dice: 1.3563  decode.d1.loss_cls: 0.3245  decode.d1.loss_mask: 1.2706  decode.d1.loss_dice: 1.3398  decode.d2.loss_cls: 0.2680  decode.d2.loss_mask: 1.2633  decode.d2.loss_dice: 1.3016  decode.d3.loss_cls: 0.3082  decode.d3.loss_mask: 1.2779  decode.d3.loss_dice: 1.2917  decode.d4.loss_cls: 0.3397  decode.d4.loss_mask: 1.2695  decode.d4.loss_dice: 1.2838  decode.d5.loss_cls: 0.3635  decode.d5.loss_mask: 1.2750  decode.d5.loss_dice: 1.3000  decode.d6.loss_cls: 0.2732  decode.d6.loss_mask: 1.3277  decode.d6.loss_dice: 1.3344  decode.d7.loss_cls: 0.3197  decode.d7.loss_mask: 1.3033  decode.d7.loss_dice: 1.3025  decode.d8.loss_cls: 0.2903  decode.d8.loss_mask: 1.3245  decode.d8.loss_dice: 1.3105
2025/03/29 15:39:54 - mmengine - INFO - Iter(train) [ 7650/20000]  base_lr: 6.4803e-05 lr: 6.4803e-05  eta: 5:37:53  time: 1.3572  data_time: 0.0392  memory: 10124  loss: 27.6971  decode.loss_cls: 0.2586  decode.loss_mask: 1.2493  decode.loss_dice: 1.2984  decode.d0.loss_cls: 0.3464  decode.d0.loss_mask: 1.2459  decode.d0.loss_dice: 1.3107  decode.d1.loss_cls: 0.2606  decode.d1.loss_mask: 1.2400  decode.d1.loss_dice: 1.2595  decode.d2.loss_cls: 0.2249  decode.d2.loss_mask: 1.2307  decode.d2.loss_dice: 1.2693  decode.d3.loss_cls: 0.2591  decode.d3.loss_mask: 1.2247  decode.d3.loss_dice: 1.2551  decode.d4.loss_cls: 0.2588  decode.d4.loss_mask: 1.2367  decode.d4.loss_dice: 1.2521  decode.d5.loss_cls: 0.2481  decode.d5.loss_mask: 1.2398  decode.d5.loss_dice: 1.2551  decode.d6.loss_cls: 0.2487  decode.d6.loss_mask: 1.2280  decode.d6.loss_dice: 1.2590  decode.d7.loss_cls: 0.2188  decode.d7.loss_mask: 1.2436  decode.d7.loss_dice: 1.2736  decode.d8.loss_cls: 0.2555  decode.d8.loss_mask: 1.2512  decode.d8.loss_dice: 1.2950
2025/03/29 15:41:14 - mmengine - INFO - Iter(train) [ 7700/20000]  base_lr: 6.4566e-05 lr: 6.4566e-05  eta: 5:36:28  time: 1.7072  data_time: 0.0729  memory: 10136  loss: 25.8551  decode.loss_cls: 0.2505  decode.loss_mask: 1.0546  decode.loss_dice: 1.2318  decode.d0.loss_cls: 0.2853  decode.d0.loss_mask: 1.1029  decode.d0.loss_dice: 1.2826  decode.d1.loss_cls: 0.3253  decode.d1.loss_mask: 1.0752  decode.d1.loss_dice: 1.2429  decode.d2.loss_cls: 0.3179  decode.d2.loss_mask: 1.0701  decode.d2.loss_dice: 1.2275  decode.d3.loss_cls: 0.2554  decode.d3.loss_mask: 1.0578  decode.d3.loss_dice: 1.2216  decode.d4.loss_cls: 0.2387  decode.d4.loss_mask: 1.0665  decode.d4.loss_dice: 1.2230  decode.d5.loss_cls: 0.2604  decode.d5.loss_mask: 1.0875  decode.d5.loss_dice: 1.2445  decode.d6.loss_cls: 0.2486  decode.d6.loss_mask: 1.0709  decode.d6.loss_dice: 1.2521  decode.d7.loss_cls: 0.2868  decode.d7.loss_mask: 1.0616  decode.d7.loss_dice: 1.2289  decode.d8.loss_cls: 0.2283  decode.d8.loss_mask: 1.0788  decode.d8.loss_dice: 1.2771
2025/03/29 15:42:35 - mmengine - INFO - Iter(train) [ 7750/20000]  base_lr: 6.4330e-05 lr: 6.4330e-05  eta: 5:35:05  time: 1.6494  data_time: 0.0902  memory: 10134  loss: 26.8599  decode.loss_cls: 0.1657  decode.loss_mask: 1.2600  decode.loss_dice: 1.2670  decode.d0.loss_cls: 0.2304  decode.d0.loss_mask: 1.2549  decode.d0.loss_dice: 1.3070  decode.d1.loss_cls: 0.1757  decode.d1.loss_mask: 1.2553  decode.d1.loss_dice: 1.2641  decode.d2.loss_cls: 0.1795  decode.d2.loss_mask: 1.2543  decode.d2.loss_dice: 1.2497  decode.d3.loss_cls: 0.1677  decode.d3.loss_mask: 1.2300  decode.d3.loss_dice: 1.2428  decode.d4.loss_cls: 0.1761  decode.d4.loss_mask: 1.2459  decode.d4.loss_dice: 1.2401  decode.d5.loss_cls: 0.1450  decode.d5.loss_mask: 1.2495  decode.d5.loss_dice: 1.2748  decode.d6.loss_cls: 0.1375  decode.d6.loss_mask: 1.2519  decode.d6.loss_dice: 1.2791  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 1.2476  decode.d7.loss_dice: 1.2834  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 1.2635  decode.d8.loss_dice: 1.2692
2025/03/29 15:43:55 - mmengine - INFO - Iter(train) [ 7800/20000]  base_lr: 6.4094e-05 lr: 6.4094e-05  eta: 5:33:39  time: 1.6096  data_time: 0.0705  memory: 10126  loss: 26.5411  decode.loss_cls: 0.2800  decode.loss_mask: 1.0264  decode.loss_dice: 1.3181  decode.d0.loss_cls: 0.3024  decode.d0.loss_mask: 1.0349  decode.d0.loss_dice: 1.4345  decode.d1.loss_cls: 0.3197  decode.d1.loss_mask: 1.0280  decode.d1.loss_dice: 1.3545  decode.d2.loss_cls: 0.2564  decode.d2.loss_mask: 1.0177  decode.d2.loss_dice: 1.3170  decode.d3.loss_cls: 0.2802  decode.d3.loss_mask: 1.0152  decode.d3.loss_dice: 1.3270  decode.d4.loss_cls: 0.2983  decode.d4.loss_mask: 1.0319  decode.d4.loss_dice: 1.3071  decode.d5.loss_cls: 0.3008  decode.d5.loss_mask: 1.0244  decode.d5.loss_dice: 1.3039  decode.d6.loss_cls: 0.2798  decode.d6.loss_mask: 1.0216  decode.d6.loss_dice: 1.3231  decode.d7.loss_cls: 0.2523  decode.d7.loss_mask: 1.0476  decode.d7.loss_dice: 1.3634  decode.d8.loss_cls: 0.2863  decode.d8.loss_mask: 1.0425  decode.d8.loss_dice: 1.3460
2025/03/29 15:44:52 - mmengine - INFO - Iter(train) [ 7850/20000]  base_lr: 6.3857e-05 lr: 6.3857e-05  eta: 5:31:38  time: 1.1232  data_time: 0.0204  memory: 10125  loss: 23.7559  decode.loss_cls: 0.1418  decode.loss_mask: 1.0584  decode.loss_dice: 1.1561  decode.d0.loss_cls: 0.2069  decode.d0.loss_mask: 1.0711  decode.d0.loss_dice: 1.2011  decode.d1.loss_cls: 0.2072  decode.d1.loss_mask: 1.0686  decode.d1.loss_dice: 1.1167  decode.d2.loss_cls: 0.1509  decode.d2.loss_mask: 1.0620  decode.d2.loss_dice: 1.1357  decode.d3.loss_cls: 0.1613  decode.d3.loss_mask: 1.0807  decode.d3.loss_dice: 1.1052  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 1.0778  decode.d4.loss_dice: 1.1365  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 1.0692  decode.d5.loss_dice: 1.1308  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 1.0597  decode.d6.loss_dice: 1.1012  decode.d7.loss_cls: 0.1832  decode.d7.loss_mask: 1.0663  decode.d7.loss_dice: 1.1359  decode.d8.loss_cls: 0.2031  decode.d8.loss_mask: 1.0478  decode.d8.loss_dice: 1.1102
2025/03/29 15:45:49 - mmengine - INFO - Iter(train) [ 7900/20000]  base_lr: 6.3621e-05 lr: 6.3621e-05  eta: 5:29:38  time: 1.1172  data_time: 0.0203  memory: 10130  loss: 25.8183  decode.loss_cls: 0.2055  decode.loss_mask: 1.1592  decode.loss_dice: 1.1803  decode.d0.loss_cls: 0.3016  decode.d0.loss_mask: 1.1054  decode.d0.loss_dice: 1.2781  decode.d1.loss_cls: 0.3059  decode.d1.loss_mask: 1.1287  decode.d1.loss_dice: 1.1450  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 1.1301  decode.d2.loss_dice: 1.1833  decode.d3.loss_cls: 0.2166  decode.d3.loss_mask: 1.1479  decode.d3.loss_dice: 1.1726  decode.d4.loss_cls: 0.2726  decode.d4.loss_mask: 1.1144  decode.d4.loss_dice: 1.1832  decode.d5.loss_cls: 0.2631  decode.d5.loss_mask: 1.1350  decode.d5.loss_dice: 1.1838  decode.d6.loss_cls: 0.2351  decode.d6.loss_mask: 1.1652  decode.d6.loss_dice: 1.2084  decode.d7.loss_cls: 0.2350  decode.d7.loss_mask: 1.1466  decode.d7.loss_dice: 1.1902  decode.d8.loss_cls: 0.2438  decode.d8.loss_mask: 1.1539  decode.d8.loss_dice: 1.1922
2025/03/29 15:46:45 - mmengine - INFO - Iter(train) [ 7950/20000]  base_lr: 6.3384e-05 lr: 6.3384e-05  eta: 5:27:38  time: 1.1241  data_time: 0.0231  memory: 10126  loss: 27.3257  decode.loss_cls: 0.2658  decode.loss_mask: 1.1221  decode.loss_dice: 1.3024  decode.d0.loss_cls: 0.2804  decode.d0.loss_mask: 1.1480  decode.d0.loss_dice: 1.3492  decode.d1.loss_cls: 0.3110  decode.d1.loss_mask: 1.1210  decode.d1.loss_dice: 1.3113  decode.d2.loss_cls: 0.3357  decode.d2.loss_mask: 1.1266  decode.d2.loss_dice: 1.2927  decode.d3.loss_cls: 0.3072  decode.d3.loss_mask: 1.1314  decode.d3.loss_dice: 1.2936  decode.d4.loss_cls: 0.2725  decode.d4.loss_mask: 1.1426  decode.d4.loss_dice: 1.2941  decode.d5.loss_cls: 0.2453  decode.d5.loss_mask: 1.1525  decode.d5.loss_dice: 1.3163  decode.d6.loss_cls: 0.2567  decode.d6.loss_mask: 1.1389  decode.d6.loss_dice: 1.3250  decode.d7.loss_cls: 0.2861  decode.d7.loss_mask: 1.1362  decode.d7.loss_dice: 1.3234  decode.d8.loss_cls: 0.2819  decode.d8.loss_mask: 1.1325  decode.d8.loss_dice: 1.3233
2025/03/29 15:47:42 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 15:47:42 - mmengine - INFO - Iter(train) [ 8000/20000]  base_lr: 6.3147e-05 lr: 6.3147e-05  eta: 5:25:40  time: 1.1623  data_time: 0.0263  memory: 10128  loss: 26.5952  decode.loss_cls: 0.1872  decode.loss_mask: 1.1784  decode.loss_dice: 1.3197  decode.d0.loss_cls: 0.2324  decode.d0.loss_mask: 1.1893  decode.d0.loss_dice: 1.3635  decode.d1.loss_cls: 0.2133  decode.d1.loss_mask: 1.1508  decode.d1.loss_dice: 1.2861  decode.d2.loss_cls: 0.1795  decode.d2.loss_mask: 1.1650  decode.d2.loss_dice: 1.2726  decode.d3.loss_cls: 0.1666  decode.d3.loss_mask: 1.1649  decode.d3.loss_dice: 1.2835  decode.d4.loss_cls: 0.1822  decode.d4.loss_mask: 1.1587  decode.d4.loss_dice: 1.2872  decode.d5.loss_cls: 0.2009  decode.d5.loss_mask: 1.1699  decode.d5.loss_dice: 1.2687  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 1.1678  decode.d6.loss_dice: 1.2840  decode.d7.loss_cls: 0.2049  decode.d7.loss_mask: 1.1632  decode.d7.loss_dice: 1.2957  decode.d8.loss_cls: 0.1904  decode.d8.loss_mask: 1.1706  decode.d8.loss_dice: 1.3073
2025/03/29 15:47:42 - mmengine - INFO - Saving checkpoint at 8000 iterations
2025/03/29 15:47:52 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:44  time: 0.1259  data_time: 0.0022  memory: 1808  
2025/03/29 15:47:58 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:37  time: 0.1234  data_time: 0.0021  memory: 1808  
2025/03/29 15:48:04 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:31  time: 0.1251  data_time: 0.0019  memory: 1808  
2025/03/29 15:48:10 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1248  data_time: 0.0019  memory: 1808  
2025/03/29 15:48:16 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1223  data_time: 0.0019  memory: 1808  
2025/03/29 15:48:22 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1227  data_time: 0.0019  memory: 1808  
2025/03/29 15:48:29 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1232  data_time: 0.0019  memory: 1808  
2025/03/29 15:48:35 - mmengine - INFO - per class results:
2025/03/29 15:48:35 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 74.18 | 85.01 |
|      building      | 85.68 | 95.58 |
|   low_vegetation   | 49.07 | 57.86 |
|        tree        | 74.27 | 84.82 |
|        car         | 55.41 | 64.44 |
|      clutter       | 16.24 | 89.28 |
+--------------------+-------+-------+
2025/03/29 15:48:35 - mmengine - INFO - Iter(val) [398/398]    aAcc: 81.4300  mIoU: 59.1400  mAcc: 79.5000  data_time: 0.0022  time: 0.1242
2025/03/29 15:49:31 - mmengine - INFO - Iter(train) [ 8050/20000]  base_lr: 6.2911e-05 lr: 6.2911e-05  eta: 5:23:41  time: 1.1151  data_time: 0.0204  memory: 10123  loss: 25.2734  decode.loss_cls: 0.2435  decode.loss_mask: 1.0421  decode.loss_dice: 1.1857  decode.d0.loss_cls: 0.3658  decode.d0.loss_mask: 1.0154  decode.d0.loss_dice: 1.2817  decode.d1.loss_cls: 0.3924  decode.d1.loss_mask: 1.0117  decode.d1.loss_dice: 1.1658  decode.d2.loss_cls: 0.3570  decode.d2.loss_mask: 1.0505  decode.d2.loss_dice: 1.1617  decode.d3.loss_cls: 0.3105  decode.d3.loss_mask: 1.0428  decode.d3.loss_dice: 1.1294  decode.d4.loss_cls: 0.3343  decode.d4.loss_mask: 1.0338  decode.d4.loss_dice: 1.1564  decode.d5.loss_cls: 0.3265  decode.d5.loss_mask: 1.0365  decode.d5.loss_dice: 1.1603  decode.d6.loss_cls: 0.2980  decode.d6.loss_mask: 1.0440  decode.d6.loss_dice: 1.1530  decode.d7.loss_cls: 0.2987  decode.d7.loss_mask: 1.0338  decode.d7.loss_dice: 1.1622  decode.d8.loss_cls: 0.2661  decode.d8.loss_mask: 1.0317  decode.d8.loss_dice: 1.1821
2025/03/29 15:50:26 - mmengine - INFO - Iter(train) [ 8100/20000]  base_lr: 6.2674e-05 lr: 6.2674e-05  eta: 5:21:42  time: 1.1117  data_time: 0.0198  memory: 10123  loss: 25.6767  decode.loss_cls: 0.2052  decode.loss_mask: 1.1646  decode.loss_dice: 1.1861  decode.d0.loss_cls: 0.3219  decode.d0.loss_mask: 1.1696  decode.d0.loss_dice: 1.1989  decode.d1.loss_cls: 0.2480  decode.d1.loss_mask: 1.1458  decode.d1.loss_dice: 1.1586  decode.d2.loss_cls: 0.2320  decode.d2.loss_mask: 1.1536  decode.d2.loss_dice: 1.1573  decode.d3.loss_cls: 0.2235  decode.d3.loss_mask: 1.1645  decode.d3.loss_dice: 1.1704  decode.d4.loss_cls: 0.2485  decode.d4.loss_mask: 1.1446  decode.d4.loss_dice: 1.1643  decode.d5.loss_cls: 0.2580  decode.d5.loss_mask: 1.1371  decode.d5.loss_dice: 1.1520  decode.d6.loss_cls: 0.2368  decode.d6.loss_mask: 1.1468  decode.d6.loss_dice: 1.1807  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 1.1539  decode.d7.loss_dice: 1.1639  decode.d8.loss_cls: 0.2540  decode.d8.loss_mask: 1.1490  decode.d8.loss_dice: 1.1521
2025/03/29 15:51:23 - mmengine - INFO - Iter(train) [ 8150/20000]  base_lr: 6.2437e-05 lr: 6.2437e-05  eta: 5:19:45  time: 1.1306  data_time: 0.0226  memory: 10127  loss: 25.6073  decode.loss_cls: 0.2355  decode.loss_mask: 1.1854  decode.loss_dice: 1.1554  decode.d0.loss_cls: 0.3352  decode.d0.loss_mask: 1.1605  decode.d0.loss_dice: 1.1773  decode.d1.loss_cls: 0.2528  decode.d1.loss_mask: 1.1383  decode.d1.loss_dice: 1.1628  decode.d2.loss_cls: 0.3021  decode.d2.loss_mask: 1.1262  decode.d2.loss_dice: 1.1256  decode.d3.loss_cls: 0.2622  decode.d3.loss_mask: 1.1373  decode.d3.loss_dice: 1.1684  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 1.1646  decode.d4.loss_dice: 1.1366  decode.d5.loss_cls: 0.2486  decode.d5.loss_mask: 1.1551  decode.d5.loss_dice: 1.1519  decode.d6.loss_cls: 0.2508  decode.d6.loss_mask: 1.1636  decode.d6.loss_dice: 1.1395  decode.d7.loss_cls: 0.2634  decode.d7.loss_mask: 1.1271  decode.d7.loss_dice: 1.1342  decode.d8.loss_cls: 0.2619  decode.d8.loss_mask: 1.1391  decode.d8.loss_dice: 1.1228
2025/03/29 15:52:22 - mmengine - INFO - Iter(train) [ 8200/20000]  base_lr: 6.2199e-05 lr: 6.2199e-05  eta: 5:17:53  time: 1.1305  data_time: 0.0223  memory: 10119  loss: 23.2451  decode.loss_cls: 0.2252  decode.loss_mask: 0.9612  decode.loss_dice: 1.1200  decode.d0.loss_cls: 0.2803  decode.d0.loss_mask: 0.9731  decode.d0.loss_dice: 1.1921  decode.d1.loss_cls: 0.2624  decode.d1.loss_mask: 0.9746  decode.d1.loss_dice: 1.0916  decode.d2.loss_cls: 0.2354  decode.d2.loss_mask: 0.9619  decode.d2.loss_dice: 1.1082  decode.d3.loss_cls: 0.2380  decode.d3.loss_mask: 0.9527  decode.d3.loss_dice: 1.0874  decode.d4.loss_cls: 0.2272  decode.d4.loss_mask: 0.9534  decode.d4.loss_dice: 1.1192  decode.d5.loss_cls: 0.2425  decode.d5.loss_mask: 0.9548  decode.d5.loss_dice: 1.1017  decode.d6.loss_cls: 0.2598  decode.d6.loss_mask: 0.9462  decode.d6.loss_dice: 1.1339  decode.d7.loss_cls: 0.2514  decode.d7.loss_mask: 0.9604  decode.d7.loss_dice: 1.1141  decode.d8.loss_cls: 0.2376  decode.d8.loss_mask: 0.9629  decode.d8.loss_dice: 1.1159
2025/03/29 15:53:29 - mmengine - INFO - Iter(train) [ 8250/20000]  base_lr: 6.1962e-05 lr: 6.1962e-05  eta: 5:16:13  time: 1.1351  data_time: 0.0226  memory: 10126  loss: 24.0778  decode.loss_cls: 0.2422  decode.loss_mask: 1.0144  decode.loss_dice: 1.1809  decode.d0.loss_cls: 0.2640  decode.d0.loss_mask: 1.0075  decode.d0.loss_dice: 1.2578  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.9621  decode.d1.loss_dice: 1.1633  decode.d2.loss_cls: 0.2355  decode.d2.loss_mask: 0.9813  decode.d2.loss_dice: 1.1914  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 0.9891  decode.d3.loss_dice: 1.1670  decode.d4.loss_cls: 0.2570  decode.d4.loss_mask: 0.9919  decode.d4.loss_dice: 1.1467  decode.d5.loss_cls: 0.2350  decode.d5.loss_mask: 0.9972  decode.d5.loss_dice: 1.1697  decode.d6.loss_cls: 0.1732  decode.d6.loss_mask: 1.0088  decode.d6.loss_dice: 1.2020  decode.d7.loss_cls: 0.2508  decode.d7.loss_mask: 0.9874  decode.d7.loss_dice: 1.1632  decode.d8.loss_cls: 0.2132  decode.d8.loss_mask: 0.9886  decode.d8.loss_dice: 1.2045
2025/03/29 15:54:30 - mmengine - INFO - Iter(train) [ 8300/20000]  base_lr: 6.1725e-05 lr: 6.1725e-05  eta: 5:14:24  time: 1.1358  data_time: 0.0232  memory: 10119  loss: 21.2540  decode.loss_cls: 0.1843  decode.loss_mask: 0.8996  decode.loss_dice: 1.0518  decode.d0.loss_cls: 0.2013  decode.d0.loss_mask: 0.9034  decode.d0.loss_dice: 1.0782  decode.d1.loss_cls: 0.1534  decode.d1.loss_mask: 0.8980  decode.d1.loss_dice: 1.0738  decode.d2.loss_cls: 0.1521  decode.d2.loss_mask: 0.8927  decode.d2.loss_dice: 1.0639  decode.d3.loss_cls: 0.1450  decode.d3.loss_mask: 0.8909  decode.d3.loss_dice: 1.0533  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.8924  decode.d4.loss_dice: 1.0493  decode.d5.loss_cls: 0.1520  decode.d5.loss_mask: 0.8913  decode.d5.loss_dice: 1.0577  decode.d6.loss_cls: 0.1791  decode.d6.loss_mask: 0.8772  decode.d6.loss_dice: 1.0462  decode.d7.loss_cls: 0.1503  decode.d7.loss_mask: 0.9159  decode.d7.loss_dice: 1.0811  decode.d8.loss_cls: 0.1792  decode.d8.loss_mask: 0.9110  decode.d8.loss_dice: 1.0683
2025/03/29 15:55:31 - mmengine - INFO - Iter(train) [ 8350/20000]  base_lr: 6.1487e-05 lr: 6.1487e-05  eta: 5:12:36  time: 1.1387  data_time: 0.0239  memory: 10124  loss: 27.0854  decode.loss_cls: 0.2848  decode.loss_mask: 1.1082  decode.loss_dice: 1.3086  decode.d0.loss_cls: 0.2812  decode.d0.loss_mask: 1.1612  decode.d0.loss_dice: 1.3742  decode.d1.loss_cls: 0.2649  decode.d1.loss_mask: 1.1196  decode.d1.loss_dice: 1.3047  decode.d2.loss_cls: 0.2893  decode.d2.loss_mask: 1.0987  decode.d2.loss_dice: 1.3219  decode.d3.loss_cls: 0.2511  decode.d3.loss_mask: 1.1060  decode.d3.loss_dice: 1.2816  decode.d4.loss_cls: 0.2665  decode.d4.loss_mask: 1.1279  decode.d4.loss_dice: 1.3086  decode.d5.loss_cls: 0.2765  decode.d5.loss_mask: 1.1114  decode.d5.loss_dice: 1.3008  decode.d6.loss_cls: 0.2775  decode.d6.loss_mask: 1.1187  decode.d6.loss_dice: 1.3243  decode.d7.loss_cls: 0.3280  decode.d7.loss_mask: 1.0943  decode.d7.loss_dice: 1.2835  decode.d8.loss_cls: 0.3082  decode.d8.loss_mask: 1.1039  decode.d8.loss_dice: 1.2993
2025/03/29 15:56:32 - mmengine - INFO - Iter(train) [ 8400/20000]  base_lr: 6.1250e-05 lr: 6.1250e-05  eta: 5:10:49  time: 1.1364  data_time: 0.0235  memory: 10133  loss: 22.4203  decode.loss_cls: 0.1568  decode.loss_mask: 0.9980  decode.loss_dice: 1.0728  decode.d0.loss_cls: 0.2335  decode.d0.loss_mask: 0.9843  decode.d0.loss_dice: 1.1137  decode.d1.loss_cls: 0.1637  decode.d1.loss_mask: 0.9787  decode.d1.loss_dice: 1.0693  decode.d2.loss_cls: 0.1983  decode.d2.loss_mask: 0.9911  decode.d2.loss_dice: 1.0537  decode.d3.loss_cls: 0.1864  decode.d3.loss_mask: 0.9851  decode.d3.loss_dice: 1.0568  decode.d4.loss_cls: 0.1488  decode.d4.loss_mask: 0.9898  decode.d4.loss_dice: 1.0897  decode.d5.loss_cls: 0.1644  decode.d5.loss_mask: 0.9942  decode.d5.loss_dice: 1.0763  decode.d6.loss_cls: 0.1635  decode.d6.loss_mask: 1.0019  decode.d6.loss_dice: 1.0772  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.9902  decode.d7.loss_dice: 1.0854  decode.d8.loss_cls: 0.1787  decode.d8.loss_mask: 0.9860  decode.d8.loss_dice: 1.0678
2025/03/29 15:57:33 - mmengine - INFO - Iter(train) [ 8450/20000]  base_lr: 6.1012e-05 lr: 6.1012e-05  eta: 5:09:01  time: 1.1426  data_time: 0.0241  memory: 10133  loss: 24.1372  decode.loss_cls: 0.2321  decode.loss_mask: 1.0037  decode.loss_dice: 1.1838  decode.d0.loss_cls: 0.2654  decode.d0.loss_mask: 1.0036  decode.d0.loss_dice: 1.2494  decode.d1.loss_cls: 0.2232  decode.d1.loss_mask: 0.9954  decode.d1.loss_dice: 1.1932  decode.d2.loss_cls: 0.2384  decode.d2.loss_mask: 0.9859  decode.d2.loss_dice: 1.1787  decode.d3.loss_cls: 0.2173  decode.d3.loss_mask: 0.9946  decode.d3.loss_dice: 1.1837  decode.d4.loss_cls: 0.2593  decode.d4.loss_mask: 0.9949  decode.d4.loss_dice: 1.1730  decode.d5.loss_cls: 0.2067  decode.d5.loss_mask: 0.9953  decode.d5.loss_dice: 1.1825  decode.d6.loss_cls: 0.1863  decode.d6.loss_mask: 0.9884  decode.d6.loss_dice: 1.1843  decode.d7.loss_cls: 0.2356  decode.d7.loss_mask: 0.9892  decode.d7.loss_dice: 1.1853  decode.d8.loss_cls: 0.2375  decode.d8.loss_mask: 0.9902  decode.d8.loss_dice: 1.1805
2025/03/29 15:58:34 - mmengine - INFO - Iter(train) [ 8500/20000]  base_lr: 6.0774e-05 lr: 6.0774e-05  eta: 5:07:14  time: 1.1439  data_time: 0.0253  memory: 10124  loss: 25.4438  decode.loss_cls: 0.1743  decode.loss_mask: 1.1059  decode.loss_dice: 1.2395  decode.d0.loss_cls: 0.3132  decode.d0.loss_mask: 1.1057  decode.d0.loss_dice: 1.2372  decode.d1.loss_cls: 0.2703  decode.d1.loss_mask: 1.0538  decode.d1.loss_dice: 1.1896  decode.d2.loss_cls: 0.2647  decode.d2.loss_mask: 1.0489  decode.d2.loss_dice: 1.1934  decode.d3.loss_cls: 0.2849  decode.d3.loss_mask: 1.0462  decode.d3.loss_dice: 1.1895  decode.d4.loss_cls: 0.3165  decode.d4.loss_mask: 1.0542  decode.d4.loss_dice: 1.1707  decode.d5.loss_cls: 0.3018  decode.d5.loss_mask: 1.0645  decode.d5.loss_dice: 1.1884  decode.d6.loss_cls: 0.2407  decode.d6.loss_mask: 1.0717  decode.d6.loss_dice: 1.2055  decode.d7.loss_cls: 0.2628  decode.d7.loss_mask: 1.0809  decode.d7.loss_dice: 1.2175  decode.d8.loss_cls: 0.2201  decode.d8.loss_mask: 1.1033  decode.d8.loss_dice: 1.2282
2025/03/29 15:59:33 - mmengine - INFO - Iter(train) [ 8550/20000]  base_lr: 6.0537e-05 lr: 6.0537e-05  eta: 5:05:26  time: 1.1469  data_time: 0.0249  memory: 10129  loss: 25.9198  decode.loss_cls: 0.2466  decode.loss_mask: 1.1235  decode.loss_dice: 1.2233  decode.d0.loss_cls: 0.2119  decode.d0.loss_mask: 1.1307  decode.d0.loss_dice: 1.3218  decode.d1.loss_cls: 0.2387  decode.d1.loss_mask: 1.1335  decode.d1.loss_dice: 1.2370  decode.d2.loss_cls: 0.2560  decode.d2.loss_mask: 1.1137  decode.d2.loss_dice: 1.2051  decode.d3.loss_cls: 0.1938  decode.d3.loss_mask: 1.1245  decode.d3.loss_dice: 1.2311  decode.d4.loss_cls: 0.2488  decode.d4.loss_mask: 1.1081  decode.d4.loss_dice: 1.2147  decode.d5.loss_cls: 0.2452  decode.d5.loss_mask: 1.1064  decode.d5.loss_dice: 1.2312  decode.d6.loss_cls: 0.2475  decode.d6.loss_mask: 1.1028  decode.d6.loss_dice: 1.2264  decode.d7.loss_cls: 0.2717  decode.d7.loss_mask: 1.1030  decode.d7.loss_dice: 1.2124  decode.d8.loss_cls: 0.2519  decode.d8.loss_mask: 1.1227  decode.d8.loss_dice: 1.2357
2025/03/29 16:00:34 - mmengine - INFO - Iter(train) [ 8600/20000]  base_lr: 6.0299e-05 lr: 6.0299e-05  eta: 5:03:41  time: 1.1365  data_time: 0.0225  memory: 10121  loss: 25.4994  decode.loss_cls: 0.2269  decode.loss_mask: 1.1278  decode.loss_dice: 1.1801  decode.d0.loss_cls: 0.1843  decode.d0.loss_mask: 1.1567  decode.d0.loss_dice: 1.2880  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 1.1178  decode.d1.loss_dice: 1.2126  decode.d2.loss_cls: 0.2148  decode.d2.loss_mask: 1.1077  decode.d2.loss_dice: 1.1978  decode.d3.loss_cls: 0.2022  decode.d3.loss_mask: 1.1382  decode.d3.loss_dice: 1.2080  decode.d4.loss_cls: 0.1975  decode.d4.loss_mask: 1.1428  decode.d4.loss_dice: 1.1939  decode.d5.loss_cls: 0.1865  decode.d5.loss_mask: 1.1461  decode.d5.loss_dice: 1.1931  decode.d6.loss_cls: 0.1959  decode.d6.loss_mask: 1.1315  decode.d6.loss_dice: 1.2019  decode.d7.loss_cls: 0.1911  decode.d7.loss_mask: 1.1530  decode.d7.loss_dice: 1.1998  decode.d8.loss_cls: 0.2003  decode.d8.loss_mask: 1.1391  decode.d8.loss_dice: 1.2130
2025/03/29 16:01:34 - mmengine - INFO - Iter(train) [ 8650/20000]  base_lr: 6.0060e-05 lr: 6.0060e-05  eta: 5:01:55  time: 1.1389  data_time: 0.0233  memory: 10125  loss: 25.3358  decode.loss_cls: 0.2079  decode.loss_mask: 1.1267  decode.loss_dice: 1.1924  decode.d0.loss_cls: 0.2331  decode.d0.loss_mask: 1.1347  decode.d0.loss_dice: 1.2509  decode.d1.loss_cls: 0.2506  decode.d1.loss_mask: 1.0898  decode.d1.loss_dice: 1.1972  decode.d2.loss_cls: 0.2134  decode.d2.loss_mask: 1.1117  decode.d2.loss_dice: 1.1931  decode.d3.loss_cls: 0.2243  decode.d3.loss_mask: 1.1102  decode.d3.loss_dice: 1.1891  decode.d4.loss_cls: 0.2247  decode.d4.loss_mask: 1.1152  decode.d4.loss_dice: 1.1926  decode.d5.loss_cls: 0.2265  decode.d5.loss_mask: 1.1062  decode.d5.loss_dice: 1.1835  decode.d6.loss_cls: 0.2161  decode.d6.loss_mask: 1.1044  decode.d6.loss_dice: 1.1906  decode.d7.loss_cls: 0.1968  decode.d7.loss_mask: 1.1228  decode.d7.loss_dice: 1.2120  decode.d8.loss_cls: 0.1939  decode.d8.loss_mask: 1.1298  decode.d8.loss_dice: 1.1957
2025/03/29 16:02:35 - mmengine - INFO - Iter(train) [ 8700/20000]  base_lr: 5.9822e-05 lr: 5.9822e-05  eta: 5:00:11  time: 1.1429  data_time: 0.0226  memory: 10124  loss: 28.0129  decode.loss_cls: 0.2930  decode.loss_mask: 1.1583  decode.loss_dice: 1.3475  decode.d0.loss_cls: 0.3762  decode.d0.loss_mask: 1.1419  decode.d0.loss_dice: 1.3965  decode.d1.loss_cls: 0.3339  decode.d1.loss_mask: 1.1245  decode.d1.loss_dice: 1.3316  decode.d2.loss_cls: 0.3243  decode.d2.loss_mask: 1.1107  decode.d2.loss_dice: 1.3305  decode.d3.loss_cls: 0.2907  decode.d3.loss_mask: 1.1305  decode.d3.loss_dice: 1.3412  decode.d4.loss_cls: 0.3449  decode.d4.loss_mask: 1.1264  decode.d4.loss_dice: 1.3249  decode.d5.loss_cls: 0.3329  decode.d5.loss_mask: 1.1654  decode.d5.loss_dice: 1.3516  decode.d6.loss_cls: 0.3003  decode.d6.loss_mask: 1.1357  decode.d6.loss_dice: 1.3436  decode.d7.loss_cls: 0.3264  decode.d7.loss_mask: 1.1385  decode.d7.loss_dice: 1.3453  decode.d8.loss_cls: 0.2887  decode.d8.loss_mask: 1.1307  decode.d8.loss_dice: 1.3262
2025/03/29 16:03:35 - mmengine - INFO - Iter(train) [ 8750/20000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 4:58:26  time: 1.1420  data_time: 0.0254  memory: 10126  loss: 25.1935  decode.loss_cls: 0.2108  decode.loss_mask: 1.0959  decode.loss_dice: 1.2092  decode.d0.loss_cls: 0.1996  decode.d0.loss_mask: 1.1058  decode.d0.loss_dice: 1.2729  decode.d1.loss_cls: 0.2289  decode.d1.loss_mask: 1.0852  decode.d1.loss_dice: 1.2331  decode.d2.loss_cls: 0.2143  decode.d2.loss_mask: 1.0960  decode.d2.loss_dice: 1.2096  decode.d3.loss_cls: 0.1932  decode.d3.loss_mask: 1.1118  decode.d3.loss_dice: 1.2314  decode.d4.loss_cls: 0.1710  decode.d4.loss_mask: 1.1003  decode.d4.loss_dice: 1.2223  decode.d5.loss_cls: 0.1812  decode.d5.loss_mask: 1.1001  decode.d5.loss_dice: 1.2087  decode.d6.loss_cls: 0.1751  decode.d6.loss_mask: 1.0904  decode.d6.loss_dice: 1.2221  decode.d7.loss_cls: 0.1736  decode.d7.loss_mask: 1.1051  decode.d7.loss_dice: 1.2113  decode.d8.loss_cls: 0.2090  decode.d8.loss_mask: 1.1094  decode.d8.loss_dice: 1.2163
2025/03/29 16:04:36 - mmengine - INFO - Iter(train) [ 8800/20000]  base_lr: 5.9346e-05 lr: 5.9346e-05  eta: 4:56:43  time: 1.1392  data_time: 0.0238  memory: 10126  loss: 26.2554  decode.loss_cls: 0.2504  decode.loss_mask: 1.1537  decode.loss_dice: 1.2145  decode.d0.loss_cls: 0.3206  decode.d0.loss_mask: 1.1362  decode.d0.loss_dice: 1.3444  decode.d1.loss_cls: 0.2673  decode.d1.loss_mask: 1.1308  decode.d1.loss_dice: 1.2128  decode.d2.loss_cls: 0.2456  decode.d2.loss_mask: 1.1241  decode.d2.loss_dice: 1.2133  decode.d3.loss_cls: 0.2608  decode.d3.loss_mask: 1.1471  decode.d3.loss_dice: 1.2046  decode.d4.loss_cls: 0.2424  decode.d4.loss_mask: 1.1319  decode.d4.loss_dice: 1.2044  decode.d5.loss_cls: 0.2749  decode.d5.loss_mask: 1.1131  decode.d5.loss_dice: 1.2051  decode.d6.loss_cls: 0.2693  decode.d6.loss_mask: 1.1436  decode.d6.loss_dice: 1.2119  decode.d7.loss_cls: 0.2914  decode.d7.loss_mask: 1.1331  decode.d7.loss_dice: 1.1892  decode.d8.loss_cls: 0.3017  decode.d8.loss_mask: 1.1304  decode.d8.loss_dice: 1.1869
2025/03/29 16:05:37 - mmengine - INFO - Iter(train) [ 8850/20000]  base_lr: 5.9107e-05 lr: 5.9107e-05  eta: 4:55:00  time: 1.1380  data_time: 0.0236  memory: 10121  loss: 22.8762  decode.loss_cls: 0.2129  decode.loss_mask: 0.9164  decode.loss_dice: 1.1500  decode.d0.loss_cls: 0.2365  decode.d0.loss_mask: 0.9248  decode.d0.loss_dice: 1.2303  decode.d1.loss_cls: 0.2406  decode.d1.loss_mask: 0.8986  decode.d1.loss_dice: 1.1484  decode.d2.loss_cls: 0.2505  decode.d2.loss_mask: 0.9007  decode.d2.loss_dice: 1.1438  decode.d3.loss_cls: 0.1998  decode.d3.loss_mask: 0.9102  decode.d3.loss_dice: 1.1280  decode.d4.loss_cls: 0.2236  decode.d4.loss_mask: 0.9127  decode.d4.loss_dice: 1.1531  decode.d5.loss_cls: 0.2027  decode.d5.loss_mask: 0.9213  decode.d5.loss_dice: 1.1492  decode.d6.loss_cls: 0.2318  decode.d6.loss_mask: 0.9103  decode.d6.loss_dice: 1.1403  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 0.9149  decode.d7.loss_dice: 1.1378  decode.d8.loss_cls: 0.2077  decode.d8.loss_mask: 0.9133  decode.d8.loss_dice: 1.1403
2025/03/29 16:06:38 - mmengine - INFO - Iter(train) [ 8900/20000]  base_lr: 5.8869e-05 lr: 5.8869e-05  eta: 4:53:17  time: 1.1641  data_time: 0.0237  memory: 10125  loss: 24.2762  decode.loss_cls: 0.1621  decode.loss_mask: 1.0375  decode.loss_dice: 1.2275  decode.d0.loss_cls: 0.2313  decode.d0.loss_mask: 1.0098  decode.d0.loss_dice: 1.2290  decode.d1.loss_cls: 0.2124  decode.d1.loss_mask: 1.0194  decode.d1.loss_dice: 1.2060  decode.d2.loss_cls: 0.2317  decode.d2.loss_mask: 1.0113  decode.d2.loss_dice: 1.1718  decode.d3.loss_cls: 0.1988  decode.d3.loss_mask: 0.9983  decode.d3.loss_dice: 1.1843  decode.d4.loss_cls: 0.1734  decode.d4.loss_mask: 1.0413  decode.d4.loss_dice: 1.2308  decode.d5.loss_cls: 0.1834  decode.d5.loss_mask: 1.0357  decode.d5.loss_dice: 1.2346  decode.d6.loss_cls: 0.2126  decode.d6.loss_mask: 1.0090  decode.d6.loss_dice: 1.1750  decode.d7.loss_cls: 0.2195  decode.d7.loss_mask: 1.0148  decode.d7.loss_dice: 1.1856  decode.d8.loss_cls: 0.1654  decode.d8.loss_mask: 1.0418  decode.d8.loss_dice: 1.2224
2025/03/29 16:07:38 - mmengine - INFO - Iter(train) [ 8950/20000]  base_lr: 5.8630e-05 lr: 5.8630e-05  eta: 4:51:35  time: 1.1466  data_time: 0.0228  memory: 10123  loss: 24.5661  decode.loss_cls: 0.2486  decode.loss_mask: 1.0600  decode.loss_dice: 1.2072  decode.d0.loss_cls: 0.2340  decode.d0.loss_mask: 1.0470  decode.d0.loss_dice: 1.2182  decode.d1.loss_cls: 0.2237  decode.d1.loss_mask: 1.0256  decode.d1.loss_dice: 1.1843  decode.d2.loss_cls: 0.2392  decode.d2.loss_mask: 1.0298  decode.d2.loss_dice: 1.1714  decode.d3.loss_cls: 0.2181  decode.d3.loss_mask: 1.0373  decode.d3.loss_dice: 1.1685  decode.d4.loss_cls: 0.2580  decode.d4.loss_mask: 1.0430  decode.d4.loss_dice: 1.1704  decode.d5.loss_cls: 0.2442  decode.d5.loss_mask: 1.0329  decode.d5.loss_dice: 1.1687  decode.d6.loss_cls: 0.2371  decode.d6.loss_mask: 1.0235  decode.d6.loss_dice: 1.1857  decode.d7.loss_cls: 0.2531  decode.d7.loss_mask: 1.0264  decode.d7.loss_dice: 1.1738  decode.d8.loss_cls: 0.2335  decode.d8.loss_mask: 1.0475  decode.d8.loss_dice: 1.1553
2025/03/29 16:08:38 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 16:08:38 - mmengine - INFO - Iter(train) [ 9000/20000]  base_lr: 5.8391e-05 lr: 5.8391e-05  eta: 4:49:52  time: 1.1365  data_time: 0.0243  memory: 10125  loss: 24.0054  decode.loss_cls: 0.2885  decode.loss_mask: 0.9666  decode.loss_dice: 1.1319  decode.d0.loss_cls: 0.2901  decode.d0.loss_mask: 0.9773  decode.d0.loss_dice: 1.2675  decode.d1.loss_cls: 0.3069  decode.d1.loss_mask: 0.9323  decode.d1.loss_dice: 1.1588  decode.d2.loss_cls: 0.3428  decode.d2.loss_mask: 0.9332  decode.d2.loss_dice: 1.1314  decode.d3.loss_cls: 0.2967  decode.d3.loss_mask: 0.9382  decode.d3.loss_dice: 1.1365  decode.d4.loss_cls: 0.2927  decode.d4.loss_mask: 0.9346  decode.d4.loss_dice: 1.1269  decode.d5.loss_cls: 0.2932  decode.d5.loss_mask: 0.9477  decode.d5.loss_dice: 1.1463  decode.d6.loss_cls: 0.3168  decode.d6.loss_mask: 0.9496  decode.d6.loss_dice: 1.1274  decode.d7.loss_cls: 0.3378  decode.d7.loss_mask: 0.9433  decode.d7.loss_dice: 1.1161  decode.d8.loss_cls: 0.3301  decode.d8.loss_mask: 0.9437  decode.d8.loss_dice: 1.1004
2025/03/29 16:09:39 - mmengine - INFO - Iter(train) [ 9050/20000]  base_lr: 5.8152e-05 lr: 5.8152e-05  eta: 4:48:11  time: 1.1434  data_time: 0.0233  memory: 10121  loss: 22.2137  decode.loss_cls: 0.2353  decode.loss_mask: 0.9455  decode.loss_dice: 1.0564  decode.d0.loss_cls: 0.2483  decode.d0.loss_mask: 0.9620  decode.d0.loss_dice: 1.1379  decode.d1.loss_cls: 0.2708  decode.d1.loss_mask: 0.9226  decode.d1.loss_dice: 1.0208  decode.d2.loss_cls: 0.2178  decode.d2.loss_mask: 0.9309  decode.d2.loss_dice: 1.0295  decode.d3.loss_cls: 0.1996  decode.d3.loss_mask: 0.9313  decode.d3.loss_dice: 1.0741  decode.d4.loss_cls: 0.2714  decode.d4.loss_mask: 0.8964  decode.d4.loss_dice: 1.0152  decode.d5.loss_cls: 0.2677  decode.d5.loss_mask: 0.9102  decode.d5.loss_dice: 1.0268  decode.d6.loss_cls: 0.2772  decode.d6.loss_mask: 0.9185  decode.d6.loss_dice: 1.0036  decode.d7.loss_cls: 0.3159  decode.d7.loss_mask: 0.9061  decode.d7.loss_dice: 0.9964  decode.d8.loss_cls: 0.3147  decode.d8.loss_mask: 0.8960  decode.d8.loss_dice: 1.0149
2025/03/29 16:10:40 - mmengine - INFO - Iter(train) [ 9100/20000]  base_lr: 5.7913e-05 lr: 5.7913e-05  eta: 4:46:30  time: 1.1367  data_time: 0.0256  memory: 10126  loss: 24.6783  decode.loss_cls: 0.1876  decode.loss_mask: 1.1260  decode.loss_dice: 1.1261  decode.d0.loss_cls: 0.2718  decode.d0.loss_mask: 1.1422  decode.d0.loss_dice: 1.1525  decode.d1.loss_cls: 0.2205  decode.d1.loss_mask: 1.1315  decode.d1.loss_dice: 1.1117  decode.d2.loss_cls: 0.1859  decode.d2.loss_mask: 1.1445  decode.d2.loss_dice: 1.1148  decode.d3.loss_cls: 0.1454  decode.d3.loss_mask: 1.1528  decode.d3.loss_dice: 1.1389  decode.d4.loss_cls: 0.1553  decode.d4.loss_mask: 1.1442  decode.d4.loss_dice: 1.1361  decode.d5.loss_cls: 0.1871  decode.d5.loss_mask: 1.1256  decode.d5.loss_dice: 1.1480  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 1.1285  decode.d6.loss_dice: 1.1688  decode.d7.loss_cls: 0.1879  decode.d7.loss_mask: 1.1428  decode.d7.loss_dice: 1.1512  decode.d8.loss_cls: 0.1974  decode.d8.loss_mask: 1.1326  decode.d8.loss_dice: 1.1359
2025/03/29 16:11:41 - mmengine - INFO - Iter(train) [ 9150/20000]  base_lr: 5.7674e-05 lr: 5.7674e-05  eta: 4:44:50  time: 1.1492  data_time: 0.0229  memory: 10072  loss: 23.4428  decode.loss_cls: 0.1644  decode.loss_mask: 1.0593  decode.loss_dice: 1.0863  decode.d0.loss_cls: 0.2533  decode.d0.loss_mask: 1.0834  decode.d0.loss_dice: 1.1293  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 1.0473  decode.d1.loss_dice: 1.1294  decode.d2.loss_cls: 0.1896  decode.d2.loss_mask: 1.0595  decode.d2.loss_dice: 1.1037  decode.d3.loss_cls: 0.1678  decode.d3.loss_mask: 1.0333  decode.d3.loss_dice: 1.0957  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 1.0443  decode.d4.loss_dice: 1.1020  decode.d5.loss_cls: 0.1703  decode.d5.loss_mask: 1.0639  decode.d5.loss_dice: 1.1059  decode.d6.loss_cls: 0.1661  decode.d6.loss_mask: 1.0505  decode.d6.loss_dice: 1.1103  decode.d7.loss_cls: 0.1665  decode.d7.loss_mask: 1.0590  decode.d7.loss_dice: 1.1048  decode.d8.loss_cls: 0.1795  decode.d8.loss_mask: 1.0402  decode.d8.loss_dice: 1.1033
2025/03/29 16:12:42 - mmengine - INFO - Iter(train) [ 9200/20000]  base_lr: 5.7435e-05 lr: 5.7435e-05  eta: 4:43:11  time: 1.1646  data_time: 0.0283  memory: 10133  loss: 21.6643  decode.loss_cls: 0.1595  decode.loss_mask: 0.8763  decode.loss_dice: 1.1166  decode.d0.loss_cls: 0.2067  decode.d0.loss_mask: 0.8985  decode.d0.loss_dice: 1.1626  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 0.8632  decode.d1.loss_dice: 1.1163  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 0.8637  decode.d2.loss_dice: 1.1122  decode.d3.loss_cls: 0.1668  decode.d3.loss_mask: 0.8737  decode.d3.loss_dice: 1.1295  decode.d4.loss_cls: 0.1267  decode.d4.loss_mask: 0.8794  decode.d4.loss_dice: 1.1441  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 0.8660  decode.d5.loss_dice: 1.1148  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 0.8504  decode.d6.loss_dice: 1.1135  decode.d7.loss_cls: 0.1784  decode.d7.loss_mask: 0.8704  decode.d7.loss_dice: 1.1214  decode.d8.loss_cls: 0.1714  decode.d8.loss_mask: 0.8740  decode.d8.loss_dice: 1.1091
2025/03/29 16:13:41 - mmengine - INFO - Iter(train) [ 9250/20000]  base_lr: 5.7195e-05 lr: 5.7195e-05  eta: 4:41:29  time: 1.1463  data_time: 0.0248  memory: 10125  loss: 24.7020  decode.loss_cls: 0.1698  decode.loss_mask: 1.0531  decode.loss_dice: 1.2360  decode.d0.loss_cls: 0.2883  decode.d0.loss_mask: 1.0039  decode.d0.loss_dice: 1.2619  decode.d1.loss_cls: 0.2415  decode.d1.loss_mask: 1.0025  decode.d1.loss_dice: 1.2082  decode.d2.loss_cls: 0.2316  decode.d2.loss_mask: 1.0365  decode.d2.loss_dice: 1.1979  decode.d3.loss_cls: 0.2159  decode.d3.loss_mask: 1.0284  decode.d3.loss_dice: 1.2040  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 1.0435  decode.d4.loss_dice: 1.2121  decode.d5.loss_cls: 0.2223  decode.d5.loss_mask: 1.0354  decode.d5.loss_dice: 1.1970  decode.d6.loss_cls: 0.2363  decode.d6.loss_mask: 1.0431  decode.d6.loss_dice: 1.1979  decode.d7.loss_cls: 0.2135  decode.d7.loss_mask: 1.0331  decode.d7.loss_dice: 1.2180  decode.d8.loss_cls: 0.2003  decode.d8.loss_mask: 1.0389  decode.d8.loss_dice: 1.2144
2025/03/29 16:14:40 - mmengine - INFO - Iter(train) [ 9300/20000]  base_lr: 5.6956e-05 lr: 5.6956e-05  eta: 4:39:48  time: 1.1378  data_time: 0.0231  memory: 10129  loss: 26.3109  decode.loss_cls: 0.2320  decode.loss_mask: 1.1335  decode.loss_dice: 1.2561  decode.d0.loss_cls: 0.2392  decode.d0.loss_mask: 1.1684  decode.d0.loss_dice: 1.3251  decode.d1.loss_cls: 0.2138  decode.d1.loss_mask: 1.1219  decode.d1.loss_dice: 1.2631  decode.d2.loss_cls: 0.2119  decode.d2.loss_mask: 1.1304  decode.d2.loss_dice: 1.2516  decode.d3.loss_cls: 0.2487  decode.d3.loss_mask: 1.1191  decode.d3.loss_dice: 1.2465  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 1.1349  decode.d4.loss_dice: 1.2547  decode.d5.loss_cls: 0.2604  decode.d5.loss_mask: 1.1198  decode.d5.loss_dice: 1.2319  decode.d6.loss_cls: 0.2249  decode.d6.loss_mask: 1.1514  decode.d6.loss_dice: 1.2521  decode.d7.loss_cls: 0.2096  decode.d7.loss_mask: 1.1514  decode.d7.loss_dice: 1.2732  decode.d8.loss_cls: 0.2100  decode.d8.loss_mask: 1.1535  decode.d8.loss_dice: 1.2856
2025/03/29 16:15:39 - mmengine - INFO - Iter(train) [ 9350/20000]  base_lr: 5.6716e-05 lr: 5.6716e-05  eta: 4:38:08  time: 1.1466  data_time: 0.0243  memory: 10125  loss: 27.5439  decode.loss_cls: 0.1780  decode.loss_mask: 1.2746  decode.loss_dice: 1.3162  decode.d0.loss_cls: 0.2648  decode.d0.loss_mask: 1.2851  decode.d0.loss_dice: 1.3245  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 1.2241  decode.d1.loss_dice: 1.2822  decode.d2.loss_cls: 0.1893  decode.d2.loss_mask: 1.2508  decode.d2.loss_dice: 1.2779  decode.d3.loss_cls: 0.1821  decode.d3.loss_mask: 1.2540  decode.d3.loss_dice: 1.2901  decode.d4.loss_cls: 0.2119  decode.d4.loss_mask: 1.2333  decode.d4.loss_dice: 1.2868  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 1.2825  decode.d5.loss_dice: 1.3034  decode.d6.loss_cls: 0.1760  decode.d6.loss_mask: 1.2558  decode.d6.loss_dice: 1.3089  decode.d7.loss_cls: 0.1869  decode.d7.loss_mask: 1.3053  decode.d7.loss_dice: 1.2911  decode.d8.loss_cls: 0.1940  decode.d8.loss_mask: 1.2517  decode.d8.loss_dice: 1.2913
2025/03/29 16:16:36 - mmengine - INFO - Iter(train) [ 9400/20000]  base_lr: 5.6477e-05 lr: 5.6477e-05  eta: 4:36:26  time: 1.1514  data_time: 0.0248  memory: 10070  loss: 26.7312  decode.loss_cls: 0.2316  decode.loss_mask: 1.0780  decode.loss_dice: 1.2854  decode.d0.loss_cls: 0.3993  decode.d0.loss_mask: 1.0603  decode.d0.loss_dice: 1.3421  decode.d1.loss_cls: 0.3169  decode.d1.loss_mask: 1.1331  decode.d1.loss_dice: 1.2820  decode.d2.loss_cls: 0.3266  decode.d2.loss_mask: 1.0677  decode.d2.loss_dice: 1.2735  decode.d3.loss_cls: 0.2943  decode.d3.loss_mask: 1.0957  decode.d3.loss_dice: 1.2753  decode.d4.loss_cls: 0.3186  decode.d4.loss_mask: 1.0665  decode.d4.loss_dice: 1.2715  decode.d5.loss_cls: 0.3083  decode.d5.loss_mask: 1.0790  decode.d5.loss_dice: 1.2806  decode.d6.loss_cls: 0.3177  decode.d6.loss_mask: 1.0915  decode.d6.loss_dice: 1.2802  decode.d7.loss_cls: 0.2405  decode.d7.loss_mask: 1.0967  decode.d7.loss_dice: 1.2903  decode.d8.loss_cls: 0.2382  decode.d8.loss_mask: 1.1108  decode.d8.loss_dice: 1.2790
2025/03/29 16:17:45 - mmengine - INFO - Iter(train) [ 9450/20000]  base_lr: 5.6237e-05 lr: 5.6237e-05  eta: 4:34:57  time: 1.1361  data_time: 0.0246  memory: 10131  loss: 25.8795  decode.loss_cls: 0.1839  decode.loss_mask: 1.1420  decode.loss_dice: 1.2325  decode.d0.loss_cls: 0.2307  decode.d0.loss_mask: 1.1581  decode.d0.loss_dice: 1.2986  decode.d1.loss_cls: 0.2376  decode.d1.loss_mask: 1.1253  decode.d1.loss_dice: 1.2518  decode.d2.loss_cls: 0.2215  decode.d2.loss_mask: 1.1441  decode.d2.loss_dice: 1.2266  decode.d3.loss_cls: 0.2283  decode.d3.loss_mask: 1.1394  decode.d3.loss_dice: 1.1976  decode.d4.loss_cls: 0.2146  decode.d4.loss_mask: 1.1444  decode.d4.loss_dice: 1.2323  decode.d5.loss_cls: 0.1847  decode.d5.loss_mask: 1.1635  decode.d5.loss_dice: 1.2317  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 1.1675  decode.d6.loss_dice: 1.2046  decode.d7.loss_cls: 0.1509  decode.d7.loss_mask: 1.1664  decode.d7.loss_dice: 1.2366  decode.d8.loss_cls: 0.1831  decode.d8.loss_mask: 1.1560  decode.d8.loss_dice: 1.2338
2025/03/29 16:18:42 - mmengine - INFO - Iter(train) [ 9500/20000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 4:33:15  time: 1.1182  data_time: 0.0200  memory: 10118  loss: 26.9569  decode.loss_cls: 0.2230  decode.loss_mask: 1.1705  decode.loss_dice: 1.3040  decode.d0.loss_cls: 0.2358  decode.d0.loss_mask: 1.2081  decode.d0.loss_dice: 1.2987  decode.d1.loss_cls: 0.2676  decode.d1.loss_mask: 1.1677  decode.d1.loss_dice: 1.2961  decode.d2.loss_cls: 0.2809  decode.d2.loss_mask: 1.1538  decode.d2.loss_dice: 1.2711  decode.d3.loss_cls: 0.2479  decode.d3.loss_mask: 1.1397  decode.d3.loss_dice: 1.2860  decode.d4.loss_cls: 0.2230  decode.d4.loss_mask: 1.1563  decode.d4.loss_dice: 1.2966  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 1.1550  decode.d5.loss_dice: 1.2827  decode.d6.loss_cls: 0.2558  decode.d6.loss_mask: 1.1455  decode.d6.loss_dice: 1.2890  decode.d7.loss_cls: 0.2625  decode.d7.loss_mask: 1.1382  decode.d7.loss_dice: 1.2803  decode.d8.loss_cls: 0.2134  decode.d8.loss_mask: 1.1695  decode.d8.loss_dice: 1.3091
2025/03/29 16:19:39 - mmengine - INFO - Iter(train) [ 9550/20000]  base_lr: 5.5757e-05 lr: 5.5757e-05  eta: 4:31:34  time: 1.1155  data_time: 0.0203  memory: 10121  loss: 21.7040  decode.loss_cls: 0.1544  decode.loss_mask: 0.9557  decode.loss_dice: 1.0444  decode.d0.loss_cls: 0.2445  decode.d0.loss_mask: 0.9434  decode.d0.loss_dice: 1.1341  decode.d1.loss_cls: 0.2129  decode.d1.loss_mask: 0.9257  decode.d1.loss_dice: 1.0454  decode.d2.loss_cls: 0.1986  decode.d2.loss_mask: 0.9224  decode.d2.loss_dice: 1.0309  decode.d3.loss_cls: 0.1896  decode.d3.loss_mask: 0.9129  decode.d3.loss_dice: 1.0275  decode.d4.loss_cls: 0.1880  decode.d4.loss_mask: 0.9124  decode.d4.loss_dice: 1.0232  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 0.9095  decode.d5.loss_dice: 1.0558  decode.d6.loss_cls: 0.1828  decode.d6.loss_mask: 0.9357  decode.d6.loss_dice: 1.0338  decode.d7.loss_cls: 0.2116  decode.d7.loss_mask: 0.9197  decode.d7.loss_dice: 1.0364  decode.d8.loss_cls: 0.1912  decode.d8.loss_mask: 0.9307  decode.d8.loss_dice: 1.0455
2025/03/29 16:20:35 - mmengine - INFO - Iter(train) [ 9600/20000]  base_lr: 5.5517e-05 lr: 5.5517e-05  eta: 4:29:52  time: 1.1264  data_time: 0.0208  memory: 10133  loss: 23.4314  decode.loss_cls: 0.2207  decode.loss_mask: 1.0337  decode.loss_dice: 1.1182  decode.d0.loss_cls: 0.2379  decode.d0.loss_mask: 1.0062  decode.d0.loss_dice: 1.1814  decode.d1.loss_cls: 0.2296  decode.d1.loss_mask: 1.0139  decode.d1.loss_dice: 1.0980  decode.d2.loss_cls: 0.2328  decode.d2.loss_mask: 1.0032  decode.d2.loss_dice: 1.0638  decode.d3.loss_cls: 0.2143  decode.d3.loss_mask: 1.0153  decode.d3.loss_dice: 1.0708  decode.d4.loss_cls: 0.2263  decode.d4.loss_mask: 1.0058  decode.d4.loss_dice: 1.0826  decode.d5.loss_cls: 0.1623  decode.d5.loss_mask: 1.0437  decode.d5.loss_dice: 1.1298  decode.d6.loss_cls: 0.1762  decode.d6.loss_mask: 1.0533  decode.d6.loss_dice: 1.1165  decode.d7.loss_cls: 0.1680  decode.d7.loss_mask: 1.0428  decode.d7.loss_dice: 1.1455  decode.d8.loss_cls: 0.1860  decode.d8.loss_mask: 1.0338  decode.d8.loss_dice: 1.1189
2025/03/29 16:21:31 - mmengine - INFO - Iter(train) [ 9650/20000]  base_lr: 5.5276e-05 lr: 5.5276e-05  eta: 4:28:11  time: 1.1129  data_time: 0.0205  memory: 10124  loss: 24.9649  decode.loss_cls: 0.2040  decode.loss_mask: 1.0909  decode.loss_dice: 1.2063  decode.d0.loss_cls: 0.2441  decode.d0.loss_mask: 1.0922  decode.d0.loss_dice: 1.2636  decode.d1.loss_cls: 0.1924  decode.d1.loss_mask: 1.0737  decode.d1.loss_dice: 1.2050  decode.d2.loss_cls: 0.2234  decode.d2.loss_mask: 1.0625  decode.d2.loss_dice: 1.1800  decode.d3.loss_cls: 0.2523  decode.d3.loss_mask: 1.0679  decode.d3.loss_dice: 1.1763  decode.d4.loss_cls: 0.2160  decode.d4.loss_mask: 1.0828  decode.d4.loss_dice: 1.1823  decode.d5.loss_cls: 0.1983  decode.d5.loss_mask: 1.0850  decode.d5.loss_dice: 1.2074  decode.d6.loss_cls: 0.2017  decode.d6.loss_mask: 1.0854  decode.d6.loss_dice: 1.1791  decode.d7.loss_cls: 0.2282  decode.d7.loss_mask: 1.0746  decode.d7.loss_dice: 1.1952  decode.d8.loss_cls: 0.1865  decode.d8.loss_mask: 1.0909  decode.d8.loss_dice: 1.2171
2025/03/29 16:22:27 - mmengine - INFO - Iter(train) [ 9700/20000]  base_lr: 5.5036e-05 lr: 5.5036e-05  eta: 4:26:30  time: 1.1182  data_time: 0.0206  memory: 10131  loss: 25.8767  decode.loss_cls: 0.2188  decode.loss_mask: 1.1435  decode.loss_dice: 1.2154  decode.d0.loss_cls: 0.2982  decode.d0.loss_mask: 1.1399  decode.d0.loss_dice: 1.2790  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 1.1375  decode.d1.loss_dice: 1.2025  decode.d2.loss_cls: 0.2012  decode.d2.loss_mask: 1.1513  decode.d2.loss_dice: 1.2186  decode.d3.loss_cls: 0.2293  decode.d3.loss_mask: 1.1516  decode.d3.loss_dice: 1.2046  decode.d4.loss_cls: 0.2209  decode.d4.loss_mask: 1.1503  decode.d4.loss_dice: 1.1953  decode.d5.loss_cls: 0.2068  decode.d5.loss_mask: 1.1688  decode.d5.loss_dice: 1.2080  decode.d6.loss_cls: 0.1720  decode.d6.loss_mask: 1.1611  decode.d6.loss_dice: 1.2187  decode.d7.loss_cls: 0.1719  decode.d7.loss_mask: 1.1494  decode.d7.loss_dice: 1.2203  decode.d8.loss_cls: 0.2006  decode.d8.loss_mask: 1.1564  decode.d8.loss_dice: 1.2430
2025/03/29 16:23:23 - mmengine - INFO - Iter(train) [ 9750/20000]  base_lr: 5.4795e-05 lr: 5.4795e-05  eta: 4:24:50  time: 1.1208  data_time: 0.0209  memory: 10130  loss: 24.0449  decode.loss_cls: 0.2086  decode.loss_mask: 1.0115  decode.loss_dice: 1.1599  decode.d0.loss_cls: 0.2641  decode.d0.loss_mask: 1.0368  decode.d0.loss_dice: 1.2350  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 1.0059  decode.d1.loss_dice: 1.1968  decode.d2.loss_cls: 0.2193  decode.d2.loss_mask: 1.0103  decode.d2.loss_dice: 1.1552  decode.d3.loss_cls: 0.2114  decode.d3.loss_mask: 1.0197  decode.d3.loss_dice: 1.1764  decode.d4.loss_cls: 0.2436  decode.d4.loss_mask: 1.0183  decode.d4.loss_dice: 1.1407  decode.d5.loss_cls: 0.1953  decode.d5.loss_mask: 1.0067  decode.d5.loss_dice: 1.1622  decode.d6.loss_cls: 0.2048  decode.d6.loss_mask: 1.0237  decode.d6.loss_dice: 1.1680  decode.d7.loss_cls: 0.2268  decode.d7.loss_mask: 1.0187  decode.d7.loss_dice: 1.1487  decode.d8.loss_cls: 0.2165  decode.d8.loss_mask: 1.0054  decode.d8.loss_dice: 1.1605
2025/03/29 16:24:19 - mmengine - INFO - Iter(train) [ 9800/20000]  base_lr: 5.4555e-05 lr: 5.4555e-05  eta: 4:23:10  time: 1.1104  data_time: 0.0208  memory: 10128  loss: 25.1923  decode.loss_cls: 0.2355  decode.loss_mask: 1.1169  decode.loss_dice: 1.1742  decode.d0.loss_cls: 0.2886  decode.d0.loss_mask: 1.0800  decode.d0.loss_dice: 1.2082  decode.d1.loss_cls: 0.2959  decode.d1.loss_mask: 1.0630  decode.d1.loss_dice: 1.1515  decode.d2.loss_cls: 0.2730  decode.d2.loss_mask: 1.0958  decode.d2.loss_dice: 1.1449  decode.d3.loss_cls: 0.2574  decode.d3.loss_mask: 1.0779  decode.d3.loss_dice: 1.1553  decode.d4.loss_cls: 0.2698  decode.d4.loss_mask: 1.0549  decode.d4.loss_dice: 1.1317  decode.d5.loss_cls: 0.2804  decode.d5.loss_mask: 1.0711  decode.d5.loss_dice: 1.1451  decode.d6.loss_cls: 0.2817  decode.d6.loss_mask: 1.0899  decode.d6.loss_dice: 1.1639  decode.d7.loss_cls: 0.2605  decode.d7.loss_mask: 1.0981  decode.d7.loss_dice: 1.1668  decode.d8.loss_cls: 0.3255  decode.d8.loss_mask: 1.0787  decode.d8.loss_dice: 1.1565
2025/03/29 16:25:15 - mmengine - INFO - Iter(train) [ 9850/20000]  base_lr: 5.4314e-05 lr: 5.4314e-05  eta: 4:21:30  time: 1.1118  data_time: 0.0201  memory: 10071  loss: 23.3327  decode.loss_cls: 0.0947  decode.loss_mask: 1.0527  decode.loss_dice: 1.1648  decode.d0.loss_cls: 0.1853  decode.d0.loss_mask: 1.0482  decode.d0.loss_dice: 1.2162  decode.d1.loss_cls: 0.1077  decode.d1.loss_mask: 1.0462  decode.d1.loss_dice: 1.1883  decode.d2.loss_cls: 0.1377  decode.d2.loss_mask: 1.0515  decode.d2.loss_dice: 1.1680  decode.d3.loss_cls: 0.1149  decode.d3.loss_mask: 1.0479  decode.d3.loss_dice: 1.1651  decode.d4.loss_cls: 0.0993  decode.d4.loss_mask: 1.0433  decode.d4.loss_dice: 1.1493  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 1.0402  decode.d5.loss_dice: 1.1636  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 1.0258  decode.d6.loss_dice: 1.1576  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 1.0528  decode.d7.loss_dice: 1.1789  decode.d8.loss_cls: 0.1397  decode.d8.loss_mask: 1.0502  decode.d8.loss_dice: 1.1407
2025/03/29 16:26:11 - mmengine - INFO - Iter(train) [ 9900/20000]  base_lr: 5.4073e-05 lr: 5.4073e-05  eta: 4:19:51  time: 1.1116  data_time: 0.0206  memory: 10129  loss: 26.5475  decode.loss_cls: 0.3101  decode.loss_mask: 1.1590  decode.loss_dice: 1.2376  decode.d0.loss_cls: 0.3299  decode.d0.loss_mask: 1.1323  decode.d0.loss_dice: 1.2534  decode.d1.loss_cls: 0.2739  decode.d1.loss_mask: 1.1450  decode.d1.loss_dice: 1.2260  decode.d2.loss_cls: 0.2812  decode.d2.loss_mask: 1.1346  decode.d2.loss_dice: 1.2047  decode.d3.loss_cls: 0.2964  decode.d3.loss_mask: 1.1383  decode.d3.loss_dice: 1.2011  decode.d4.loss_cls: 0.3272  decode.d4.loss_mask: 1.1146  decode.d4.loss_dice: 1.2213  decode.d5.loss_cls: 0.2941  decode.d5.loss_mask: 1.1327  decode.d5.loss_dice: 1.2198  decode.d6.loss_cls: 0.2149  decode.d6.loss_mask: 1.1441  decode.d6.loss_dice: 1.2390  decode.d7.loss_cls: 0.2970  decode.d7.loss_mask: 1.1368  decode.d7.loss_dice: 1.2154  decode.d8.loss_cls: 0.3064  decode.d8.loss_mask: 1.1644  decode.d8.loss_dice: 1.1962
2025/03/29 16:27:06 - mmengine - INFO - Iter(train) [ 9950/20000]  base_lr: 5.3832e-05 lr: 5.3832e-05  eta: 4:18:12  time: 1.1120  data_time: 0.0196  memory: 10115  loss: 23.4431  decode.loss_cls: 0.1994  decode.loss_mask: 1.0261  decode.loss_dice: 1.1016  decode.d0.loss_cls: 0.3009  decode.d0.loss_mask: 1.0087  decode.d0.loss_dice: 1.1671  decode.d1.loss_cls: 0.2164  decode.d1.loss_mask: 1.0065  decode.d1.loss_dice: 1.1101  decode.d2.loss_cls: 0.1973  decode.d2.loss_mask: 1.0307  decode.d2.loss_dice: 1.1058  decode.d3.loss_cls: 0.1854  decode.d3.loss_mask: 1.0267  decode.d3.loss_dice: 1.1192  decode.d4.loss_cls: 0.2205  decode.d4.loss_mask: 1.0077  decode.d4.loss_dice: 1.1030  decode.d5.loss_cls: 0.2113  decode.d5.loss_mask: 1.0006  decode.d5.loss_dice: 1.0996  decode.d6.loss_cls: 0.1965  decode.d6.loss_mask: 1.0167  decode.d6.loss_dice: 1.0932  decode.d7.loss_cls: 0.2533  decode.d7.loss_mask: 1.0117  decode.d7.loss_dice: 1.0919  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 1.0265  decode.d8.loss_dice: 1.1123
2025/03/29 16:28:02 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 16:28:02 - mmengine - INFO - Iter(train) [10000/20000]  base_lr: 5.3591e-05 lr: 5.3591e-05  eta: 4:16:34  time: 1.1111  data_time: 0.0199  memory: 10126  loss: 28.7663  decode.loss_cls: 0.3335  decode.loss_mask: 1.2697  decode.loss_dice: 1.2525  decode.d0.loss_cls: 0.4089  decode.d0.loss_mask: 1.2737  decode.d0.loss_dice: 1.3914  decode.d1.loss_cls: 0.3581  decode.d1.loss_mask: 1.2391  decode.d1.loss_dice: 1.2832  decode.d2.loss_cls: 0.2748  decode.d2.loss_mask: 1.2855  decode.d2.loss_dice: 1.2931  decode.d3.loss_cls: 0.2956  decode.d3.loss_mask: 1.3047  decode.d3.loss_dice: 1.2674  decode.d4.loss_cls: 0.2779  decode.d4.loss_mask: 1.2913  decode.d4.loss_dice: 1.2819  decode.d5.loss_cls: 0.2785  decode.d5.loss_mask: 1.2850  decode.d5.loss_dice: 1.2734  decode.d6.loss_cls: 0.2411  decode.d6.loss_mask: 1.2839  decode.d6.loss_dice: 1.2871  decode.d7.loss_cls: 0.2821  decode.d7.loss_mask: 1.2989  decode.d7.loss_dice: 1.2886  decode.d8.loss_cls: 0.3247  decode.d8.loss_mask: 1.2604  decode.d8.loss_dice: 1.2801
2025/03/29 16:28:03 - mmengine - INFO - Saving checkpoint at 10000 iterations
2025/03/29 16:28:11 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:43  time: 0.1239  data_time: 0.0020  memory: 1808  
2025/03/29 16:28:17 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:36  time: 0.1237  data_time: 0.0019  memory: 1808  
2025/03/29 16:28:23 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:30  time: 0.1234  data_time: 0.0019  memory: 1808  
2025/03/29 16:28:30 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1238  data_time: 0.0019  memory: 1808  
2025/03/29 16:28:36 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1283  data_time: 0.0020  memory: 1808  
2025/03/29 16:28:42 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1217  data_time: 0.0019  memory: 1808  
2025/03/29 16:28:48 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1216  data_time: 0.0018  memory: 1808  
2025/03/29 16:28:54 - mmengine - INFO - per class results:
2025/03/29 16:28:54 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface |  74.4 | 85.14 |
|      building      | 86.28 | 95.74 |
|   low_vegetation   | 47.68 | 54.04 |
|        tree        | 73.52 |  88.4 |
|        car         | 56.57 | 64.76 |
|      clutter       | 17.24 | 91.22 |
+--------------------+-------+-------+
2025/03/29 16:28:54 - mmengine - INFO - Iter(val) [398/398]    aAcc: 81.4900  mIoU: 59.2800  mAcc: 79.8800  data_time: 0.0020  time: 0.1239
2025/03/29 16:29:50 - mmengine - INFO - Iter(train) [10050/20000]  base_lr: 5.3350e-05 lr: 5.3350e-05  eta: 4:14:56  time: 1.1111  data_time: 0.0202  memory: 10123  loss: 23.2468  decode.loss_cls: 0.1449  decode.loss_mask: 1.0184  decode.loss_dice: 1.1552  decode.d0.loss_cls: 0.2070  decode.d0.loss_mask: 1.0347  decode.d0.loss_dice: 1.1925  decode.d1.loss_cls: 0.1557  decode.d1.loss_mask: 1.0199  decode.d1.loss_dice: 1.1600  decode.d2.loss_cls: 0.1509  decode.d2.loss_mask: 1.0179  decode.d2.loss_dice: 1.1634  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 1.0165  decode.d3.loss_dice: 1.1517  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.9967  decode.d4.loss_dice: 1.1711  decode.d5.loss_cls: 0.0939  decode.d5.loss_mask: 1.0314  decode.d5.loss_dice: 1.1628  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 1.0286  decode.d6.loss_dice: 1.1440  decode.d7.loss_cls: 0.1709  decode.d7.loss_mask: 0.9899  decode.d7.loss_dice: 1.1440  decode.d8.loss_cls: 0.1377  decode.d8.loss_mask: 1.0169  decode.d8.loss_dice: 1.1614
2025/03/29 16:31:14 - mmengine - INFO - Iter(train) [10100/20000]  base_lr: 5.3109e-05 lr: 5.3109e-05  eta: 4:13:46  time: 2.9757  data_time: 0.0218  memory: 10129  loss: 21.7841  decode.loss_cls: 0.0827  decode.loss_mask: 0.9933  decode.loss_dice: 1.0860  decode.d0.loss_cls: 0.1886  decode.d0.loss_mask: 0.9946  decode.d0.loss_dice: 1.1025  decode.d1.loss_cls: 0.1596  decode.d1.loss_mask: 0.9844  decode.d1.loss_dice: 1.0771  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.9779  decode.d2.loss_dice: 1.0701  decode.d3.loss_cls: 0.1229  decode.d3.loss_mask: 0.9846  decode.d3.loss_dice: 1.0732  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.9875  decode.d4.loss_dice: 1.0786  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.9895  decode.d5.loss_dice: 1.0877  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 1.0064  decode.d6.loss_dice: 1.0882  decode.d7.loss_cls: 0.1002  decode.d7.loss_mask: 0.9860  decode.d7.loss_dice: 1.0517  decode.d8.loss_cls: 0.1260  decode.d8.loss_mask: 0.9794  decode.d8.loss_dice: 1.0710
2025/03/29 16:33:44 - mmengine - INFO - Iter(train) [10150/20000]  base_lr: 5.2867e-05 lr: 5.2867e-05  eta: 4:13:40  time: 3.0029  data_time: 0.0215  memory: 10124  loss: 28.4345  decode.loss_cls: 0.2625  decode.loss_mask: 1.1937  decode.loss_dice: 1.3709  decode.d0.loss_cls: 0.2952  decode.d0.loss_mask: 1.2131  decode.d0.loss_dice: 1.4744  decode.d1.loss_cls: 0.3177  decode.d1.loss_mask: 1.1944  decode.d1.loss_dice: 1.3229  decode.d2.loss_cls: 0.3549  decode.d2.loss_mask: 1.1890  decode.d2.loss_dice: 1.3346  decode.d3.loss_cls: 0.3652  decode.d3.loss_mask: 1.1800  decode.d3.loss_dice: 1.2881  decode.d4.loss_cls: 0.3245  decode.d4.loss_mask: 1.1747  decode.d4.loss_dice: 1.2848  decode.d5.loss_cls: 0.3253  decode.d5.loss_mask: 1.1697  decode.d5.loss_dice: 1.2968  decode.d6.loss_cls: 0.3298  decode.d6.loss_mask: 1.1851  decode.d6.loss_dice: 1.3164  decode.d7.loss_cls: 0.2839  decode.d7.loss_mask: 1.1929  decode.d7.loss_dice: 1.3466  decode.d8.loss_cls: 0.2592  decode.d8.loss_mask: 1.2142  decode.d8.loss_dice: 1.3738
2025/03/29 16:36:15 - mmengine - INFO - Iter(train) [10200/20000]  base_lr: 5.2625e-05 lr: 5.2625e-05  eta: 4:13:34  time: 3.0080  data_time: 0.0224  memory: 10119  loss: 24.6216  decode.loss_cls: 0.2339  decode.loss_mask: 1.0816  decode.loss_dice: 1.1457  decode.d0.loss_cls: 0.2964  decode.d0.loss_mask: 1.0516  decode.d0.loss_dice: 1.2065  decode.d1.loss_cls: 0.2873  decode.d1.loss_mask: 1.0592  decode.d1.loss_dice: 1.1417  decode.d2.loss_cls: 0.2492  decode.d2.loss_mask: 1.0328  decode.d2.loss_dice: 1.1710  decode.d3.loss_cls: 0.2149  decode.d3.loss_mask: 1.0360  decode.d3.loss_dice: 1.1952  decode.d4.loss_cls: 0.2444  decode.d4.loss_mask: 1.0543  decode.d4.loss_dice: 1.1546  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 1.0690  decode.d5.loss_dice: 1.1452  decode.d6.loss_cls: 0.1903  decode.d6.loss_mask: 1.0658  decode.d6.loss_dice: 1.1739  decode.d7.loss_cls: 0.2147  decode.d7.loss_mask: 1.0571  decode.d7.loss_dice: 1.1641  decode.d8.loss_cls: 0.2112  decode.d8.loss_mask: 1.0749  decode.d8.loss_dice: 1.1422
2025/03/29 16:38:45 - mmengine - INFO - Iter(train) [10250/20000]  base_lr: 5.2384e-05 lr: 5.2384e-05  eta: 4:13:25  time: 3.0019  data_time: 0.0216  memory: 10126  loss: 23.0638  decode.loss_cls: 0.1771  decode.loss_mask: 1.0261  decode.loss_dice: 1.1110  decode.d0.loss_cls: 0.2242  decode.d0.loss_mask: 1.0286  decode.d0.loss_dice: 1.1565  decode.d1.loss_cls: 0.1941  decode.d1.loss_mask: 0.9990  decode.d1.loss_dice: 1.0881  decode.d2.loss_cls: 0.1906  decode.d2.loss_mask: 1.0120  decode.d2.loss_dice: 1.0886  decode.d3.loss_cls: 0.1590  decode.d3.loss_mask: 1.0394  decode.d3.loss_dice: 1.0886  decode.d4.loss_cls: 0.1371  decode.d4.loss_mask: 1.0360  decode.d4.loss_dice: 1.0822  decode.d5.loss_cls: 0.1631  decode.d5.loss_mask: 1.0336  decode.d5.loss_dice: 1.1168  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 1.0386  decode.d6.loss_dice: 1.0965  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 1.0292  decode.d7.loss_dice: 1.1002  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 1.0198  decode.d8.loss_dice: 1.1104
2025/03/29 16:41:16 - mmengine - INFO - Iter(train) [10300/20000]  base_lr: 5.2142e-05 lr: 5.2142e-05  eta: 4:13:15  time: 3.0101  data_time: 0.0208  memory: 10121  loss: 25.5683  decode.loss_cls: 0.3164  decode.loss_mask: 1.0425  decode.loss_dice: 1.1520  decode.d0.loss_cls: 0.3796  decode.d0.loss_mask: 1.0773  decode.d0.loss_dice: 1.2772  decode.d1.loss_cls: 0.3966  decode.d1.loss_mask: 1.0180  decode.d1.loss_dice: 1.1559  decode.d2.loss_cls: 0.3327  decode.d2.loss_mask: 1.0550  decode.d2.loss_dice: 1.1695  decode.d3.loss_cls: 0.3638  decode.d3.loss_mask: 1.0251  decode.d3.loss_dice: 1.1627  decode.d4.loss_cls: 0.3647  decode.d4.loss_mask: 1.0105  decode.d4.loss_dice: 1.1382  decode.d5.loss_cls: 0.3131  decode.d5.loss_mask: 1.0388  decode.d5.loss_dice: 1.1836  decode.d6.loss_cls: 0.3274  decode.d6.loss_mask: 1.0272  decode.d6.loss_dice: 1.1584  decode.d7.loss_cls: 0.3296  decode.d7.loss_mask: 1.0467  decode.d7.loss_dice: 1.1832  decode.d8.loss_cls: 0.3477  decode.d8.loss_mask: 1.0326  decode.d8.loss_dice: 1.1425
2025/03/29 16:43:46 - mmengine - INFO - Iter(train) [10350/20000]  base_lr: 5.1900e-05 lr: 5.1900e-05  eta: 4:13:04  time: 2.9988  data_time: 0.0210  memory: 10121  loss: 24.3050  decode.loss_cls: 0.3031  decode.loss_mask: 0.9873  decode.loss_dice: 1.1156  decode.d0.loss_cls: 0.3158  decode.d0.loss_mask: 1.0119  decode.d0.loss_dice: 1.2409  decode.d1.loss_cls: 0.3457  decode.d1.loss_mask: 0.9772  decode.d1.loss_dice: 1.1181  decode.d2.loss_cls: 0.3487  decode.d2.loss_mask: 0.9767  decode.d2.loss_dice: 1.0979  decode.d3.loss_cls: 0.3039  decode.d3.loss_mask: 0.9740  decode.d3.loss_dice: 1.0981  decode.d4.loss_cls: 0.2821  decode.d4.loss_mask: 1.0002  decode.d4.loss_dice: 1.1247  decode.d5.loss_cls: 0.2689  decode.d5.loss_mask: 0.9827  decode.d5.loss_dice: 1.1420  decode.d6.loss_cls: 0.3051  decode.d6.loss_mask: 0.9868  decode.d6.loss_dice: 1.1380  decode.d7.loss_cls: 0.3440  decode.d7.loss_mask: 0.9717  decode.d7.loss_dice: 1.1059  decode.d8.loss_cls: 0.3228  decode.d8.loss_mask: 0.9827  decode.d8.loss_dice: 1.1324
2025/03/29 16:46:16 - mmengine - INFO - Iter(train) [10400/20000]  base_lr: 5.1658e-05 lr: 5.1658e-05  eta: 4:12:52  time: 3.0099  data_time: 0.0207  memory: 10127  loss: 29.1196  decode.loss_cls: 0.2844  decode.loss_mask: 1.2786  decode.loss_dice: 1.3590  decode.d0.loss_cls: 0.2537  decode.d0.loss_mask: 1.3015  decode.d0.loss_dice: 1.4634  decode.d1.loss_cls: 0.2695  decode.d1.loss_mask: 1.2866  decode.d1.loss_dice: 1.3499  decode.d2.loss_cls: 0.2645  decode.d2.loss_mask: 1.2506  decode.d2.loss_dice: 1.3374  decode.d3.loss_cls: 0.2752  decode.d3.loss_mask: 1.2492  decode.d3.loss_dice: 1.3383  decode.d4.loss_cls: 0.2543  decode.d4.loss_mask: 1.2854  decode.d4.loss_dice: 1.3762  decode.d5.loss_cls: 0.2913  decode.d5.loss_mask: 1.2703  decode.d5.loss_dice: 1.3542  decode.d6.loss_cls: 0.2807  decode.d6.loss_mask: 1.2644  decode.d6.loss_dice: 1.3801  decode.d7.loss_cls: 0.2505  decode.d7.loss_mask: 1.2832  decode.d7.loss_dice: 1.3697  decode.d8.loss_cls: 0.2716  decode.d8.loss_mask: 1.2673  decode.d8.loss_dice: 1.3584
2025/03/29 16:48:46 - mmengine - INFO - Iter(train) [10450/20000]  base_lr: 5.1416e-05 lr: 5.1416e-05  eta: 4:12:38  time: 3.0088  data_time: 0.0212  memory: 10122  loss: 22.5122  decode.loss_cls: 0.1258  decode.loss_mask: 0.9827  decode.loss_dice: 1.1206  decode.d0.loss_cls: 0.1566  decode.d0.loss_mask: 1.0076  decode.d0.loss_dice: 1.1986  decode.d1.loss_cls: 0.1570  decode.d1.loss_mask: 0.9847  decode.d1.loss_dice: 1.1230  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 0.9827  decode.d2.loss_dice: 1.1113  decode.d3.loss_cls: 0.1652  decode.d3.loss_mask: 0.9660  decode.d3.loss_dice: 1.1223  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.9791  decode.d4.loss_dice: 1.1090  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 0.9572  decode.d5.loss_dice: 1.1161  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.9813  decode.d6.loss_dice: 1.1062  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.9814  decode.d7.loss_dice: 1.1208  decode.d8.loss_cls: 0.1594  decode.d8.loss_mask: 0.9698  decode.d8.loss_dice: 1.1109
2025/03/29 16:51:17 - mmengine - INFO - Iter(train) [10500/20000]  base_lr: 5.1173e-05 lr: 5.1173e-05  eta: 4:12:23  time: 3.0109  data_time: 0.0222  memory: 10122  loss: 24.4844  decode.loss_cls: 0.2961  decode.loss_mask: 1.0002  decode.loss_dice: 1.1591  decode.d0.loss_cls: 0.3538  decode.d0.loss_mask: 0.9733  decode.d0.loss_dice: 1.2534  decode.d1.loss_cls: 0.3118  decode.d1.loss_mask: 0.9426  decode.d1.loss_dice: 1.1659  decode.d2.loss_cls: 0.2915  decode.d2.loss_mask: 0.9837  decode.d2.loss_dice: 1.1567  decode.d3.loss_cls: 0.3594  decode.d3.loss_mask: 0.9512  decode.d3.loss_dice: 1.1132  decode.d4.loss_cls: 0.3350  decode.d4.loss_mask: 0.9579  decode.d4.loss_dice: 1.1363  decode.d5.loss_cls: 0.3201  decode.d5.loss_mask: 0.9540  decode.d5.loss_dice: 1.1539  decode.d6.loss_cls: 0.3439  decode.d6.loss_mask: 0.9585  decode.d6.loss_dice: 1.1476  decode.d7.loss_cls: 0.3285  decode.d7.loss_mask: 0.9609  decode.d7.loss_dice: 1.1578  decode.d8.loss_cls: 0.3280  decode.d8.loss_mask: 0.9505  decode.d8.loss_dice: 1.1397
2025/03/29 16:53:47 - mmengine - INFO - Iter(train) [10550/20000]  base_lr: 5.0931e-05 lr: 5.0931e-05  eta: 4:12:06  time: 3.0088  data_time: 0.0202  memory: 10122  loss: 26.8550  decode.loss_cls: 0.2491  decode.loss_mask: 1.0953  decode.loss_dice: 1.3485  decode.d0.loss_cls: 0.3271  decode.d0.loss_mask: 1.0631  decode.d0.loss_dice: 1.3404  decode.d1.loss_cls: 0.2696  decode.d1.loss_mask: 1.1068  decode.d1.loss_dice: 1.3064  decode.d2.loss_cls: 0.2283  decode.d2.loss_mask: 1.0928  decode.d2.loss_dice: 1.3044  decode.d3.loss_cls: 0.2554  decode.d3.loss_mask: 1.0978  decode.d3.loss_dice: 1.3041  decode.d4.loss_cls: 0.2688  decode.d4.loss_mask: 1.0863  decode.d4.loss_dice: 1.3158  decode.d5.loss_cls: 0.2751  decode.d5.loss_mask: 1.0986  decode.d5.loss_dice: 1.3465  decode.d6.loss_cls: 0.2774  decode.d6.loss_mask: 1.0734  decode.d6.loss_dice: 1.3325  decode.d7.loss_cls: 0.2651  decode.d7.loss_mask: 1.0872  decode.d7.loss_dice: 1.3450  decode.d8.loss_cls: 0.3028  decode.d8.loss_mask: 1.0680  decode.d8.loss_dice: 1.3232
2025/03/29 16:56:06 - mmengine - INFO - Iter(train) [10600/20000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 4:11:38  time: 3.0112  data_time: 0.0253  memory: 10122  loss: 24.7828  decode.loss_cls: 0.2853  decode.loss_mask: 0.9806  decode.loss_dice: 1.2193  decode.d0.loss_cls: 0.2353  decode.d0.loss_mask: 0.9716  decode.d0.loss_dice: 1.3151  decode.d1.loss_cls: 0.3053  decode.d1.loss_mask: 0.9511  decode.d1.loss_dice: 1.2311  decode.d2.loss_cls: 0.3173  decode.d2.loss_mask: 0.9480  decode.d2.loss_dice: 1.1744  decode.d3.loss_cls: 0.2961  decode.d3.loss_mask: 0.9709  decode.d3.loss_dice: 1.2088  decode.d4.loss_cls: 0.3179  decode.d4.loss_mask: 0.9458  decode.d4.loss_dice: 1.1911  decode.d5.loss_cls: 0.3098  decode.d5.loss_mask: 0.9615  decode.d5.loss_dice: 1.2128  decode.d6.loss_cls: 0.2617  decode.d6.loss_mask: 0.9716  decode.d6.loss_dice: 1.2128  decode.d7.loss_cls: 0.3205  decode.d7.loss_mask: 0.9619  decode.d7.loss_dice: 1.2220  decode.d8.loss_cls: 0.3313  decode.d8.loss_mask: 0.9518  decode.d8.loss_dice: 1.2001
2025/03/29 16:58:38 - mmengine - INFO - Iter(train) [10650/20000]  base_lr: 5.0446e-05 lr: 5.0446e-05  eta: 4:11:21  time: 3.0286  data_time: 0.0256  memory: 10125  loss: 23.9316  decode.loss_cls: 0.1678  decode.loss_mask: 1.0372  decode.loss_dice: 1.1627  decode.d0.loss_cls: 0.2556  decode.d0.loss_mask: 1.0510  decode.d0.loss_dice: 1.2213  decode.d1.loss_cls: 0.2323  decode.d1.loss_mask: 1.0562  decode.d1.loss_dice: 1.1604  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 1.0352  decode.d2.loss_dice: 1.1444  decode.d3.loss_cls: 0.1478  decode.d3.loss_mask: 1.0354  decode.d3.loss_dice: 1.1719  decode.d4.loss_cls: 0.1735  decode.d4.loss_mask: 1.0362  decode.d4.loss_dice: 1.1776  decode.d5.loss_cls: 0.1699  decode.d5.loss_mask: 1.0352  decode.d5.loss_dice: 1.1565  decode.d6.loss_cls: 0.1657  decode.d6.loss_mask: 1.0392  decode.d6.loss_dice: 1.1542  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 1.0399  decode.d7.loss_dice: 1.1625  decode.d8.loss_cls: 0.1802  decode.d8.loss_mask: 1.0304  decode.d8.loss_dice: 1.1594
2025/03/29 17:01:08 - mmengine - INFO - Iter(train) [10700/20000]  base_lr: 5.0203e-05 lr: 5.0203e-05  eta: 4:11:01  time: 3.0060  data_time: 0.0215  memory: 10130  loss: 22.1486  decode.loss_cls: 0.1688  decode.loss_mask: 1.0358  decode.loss_dice: 1.0106  decode.d0.loss_cls: 0.2007  decode.d0.loss_mask: 1.0842  decode.d0.loss_dice: 1.0548  decode.d1.loss_cls: 0.1973  decode.d1.loss_mask: 1.0363  decode.d1.loss_dice: 0.9981  decode.d2.loss_cls: 0.1569  decode.d2.loss_mask: 1.0324  decode.d2.loss_dice: 0.9877  decode.d3.loss_cls: 0.1726  decode.d3.loss_mask: 1.0267  decode.d3.loss_dice: 0.9873  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 1.0306  decode.d4.loss_dice: 0.9719  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 1.0535  decode.d5.loss_dice: 0.9892  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 1.0560  decode.d6.loss_dice: 0.9988  decode.d7.loss_cls: 0.1477  decode.d7.loss_mask: 1.0591  decode.d7.loss_dice: 1.0131  decode.d8.loss_cls: 0.1779  decode.d8.loss_mask: 1.0557  decode.d8.loss_dice: 0.9866
2025/03/29 17:03:38 - mmengine - INFO - Iter(train) [10750/20000]  base_lr: 4.9960e-05 lr: 4.9960e-05  eta: 4:10:39  time: 2.9953  data_time: 0.0207  memory: 10122  loss: 26.0283  decode.loss_cls: 0.2039  decode.loss_mask: 1.2008  decode.loss_dice: 1.1780  decode.d0.loss_cls: 0.2393  decode.d0.loss_mask: 1.2080  decode.d0.loss_dice: 1.2589  decode.d1.loss_cls: 0.2155  decode.d1.loss_mask: 1.1904  decode.d1.loss_dice: 1.1934  decode.d2.loss_cls: 0.2133  decode.d2.loss_mask: 1.1916  decode.d2.loss_dice: 1.1725  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 1.2043  decode.d3.loss_dice: 1.1863  decode.d4.loss_cls: 0.1765  decode.d4.loss_mask: 1.2146  decode.d4.loss_dice: 1.1882  decode.d5.loss_cls: 0.1988  decode.d5.loss_mask: 1.2088  decode.d5.loss_dice: 1.1799  decode.d6.loss_cls: 0.2118  decode.d6.loss_mask: 1.2143  decode.d6.loss_dice: 1.1734  decode.d7.loss_cls: 0.1986  decode.d7.loss_mask: 1.2220  decode.d7.loss_dice: 1.1925  decode.d8.loss_cls: 0.2165  decode.d8.loss_mask: 1.2057  decode.d8.loss_dice: 1.1908
2025/03/29 17:06:09 - mmengine - INFO - Iter(train) [10800/20000]  base_lr: 4.9717e-05 lr: 4.9717e-05  eta: 4:10:17  time: 3.0002  data_time: 0.0216  memory: 10124  loss: 21.4006  decode.loss_cls: 0.1804  decode.loss_mask: 0.8157  decode.loss_dice: 1.1254  decode.d0.loss_cls: 0.1827  decode.d0.loss_mask: 0.8124  decode.d0.loss_dice: 1.1778  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.8119  decode.d1.loss_dice: 1.1766  decode.d2.loss_cls: 0.1773  decode.d2.loss_mask: 0.8100  decode.d2.loss_dice: 1.1574  decode.d3.loss_cls: 0.1772  decode.d3.loss_mask: 0.8113  decode.d3.loss_dice: 1.1039  decode.d4.loss_cls: 0.2239  decode.d4.loss_mask: 0.8098  decode.d4.loss_dice: 1.1052  decode.d5.loss_cls: 0.2030  decode.d5.loss_mask: 0.8131  decode.d5.loss_dice: 1.1387  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 0.8121  decode.d6.loss_dice: 1.1209  decode.d7.loss_cls: 0.1914  decode.d7.loss_mask: 0.8211  decode.d7.loss_dice: 1.1500  decode.d8.loss_cls: 0.1813  decode.d8.loss_mask: 0.8144  decode.d8.loss_dice: 1.1330
2025/03/29 17:08:39 - mmengine - INFO - Iter(train) [10850/20000]  base_lr: 4.9473e-05 lr: 4.9473e-05  eta: 4:09:53  time: 2.9843  data_time: 0.0216  memory: 10124  loss: 23.3351  decode.loss_cls: 0.2533  decode.loss_mask: 0.9910  decode.loss_dice: 1.1269  decode.d0.loss_cls: 0.2809  decode.d0.loss_mask: 1.0000  decode.d0.loss_dice: 1.1694  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 0.9966  decode.d1.loss_dice: 1.1538  decode.d2.loss_cls: 0.1629  decode.d2.loss_mask: 1.0124  decode.d2.loss_dice: 1.1377  decode.d3.loss_cls: 0.1794  decode.d3.loss_mask: 0.9885  decode.d3.loss_dice: 1.1158  decode.d4.loss_cls: 0.1926  decode.d4.loss_mask: 0.9803  decode.d4.loss_dice: 1.1210  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 0.9766  decode.d5.loss_dice: 1.1145  decode.d6.loss_cls: 0.2249  decode.d6.loss_mask: 0.9850  decode.d6.loss_dice: 1.1228  decode.d7.loss_cls: 0.1840  decode.d7.loss_mask: 0.9968  decode.d7.loss_dice: 1.1493  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 1.0207  decode.d8.loss_dice: 1.1880
2025/03/29 17:11:08 - mmengine - INFO - Iter(train) [10900/20000]  base_lr: 4.9230e-05 lr: 4.9230e-05  eta: 4:09:28  time: 2.9960  data_time: 0.0210  memory: 10123  loss: 20.2070  decode.loss_cls: 0.1421  decode.loss_mask: 0.8953  decode.loss_dice: 0.9764  decode.d0.loss_cls: 0.2428  decode.d0.loss_mask: 0.9108  decode.d0.loss_dice: 1.0115  decode.d1.loss_cls: 0.1350  decode.d1.loss_mask: 0.9110  decode.d1.loss_dice: 0.9760  decode.d2.loss_cls: 0.1420  decode.d2.loss_mask: 0.8873  decode.d2.loss_dice: 0.9710  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 0.8691  decode.d3.loss_dice: 0.9626  decode.d4.loss_cls: 0.1636  decode.d4.loss_mask: 0.8834  decode.d4.loss_dice: 0.9589  decode.d5.loss_cls: 0.1539  decode.d5.loss_mask: 0.8876  decode.d5.loss_dice: 0.9530  decode.d6.loss_cls: 0.1855  decode.d6.loss_mask: 0.8496  decode.d6.loss_dice: 0.9527  decode.d7.loss_cls: 0.1748  decode.d7.loss_mask: 0.8802  decode.d7.loss_dice: 0.9518  decode.d8.loss_cls: 0.1756  decode.d8.loss_mask: 0.8752  decode.d8.loss_dice: 0.9716
2025/03/29 17:13:39 - mmengine - INFO - Iter(train) [10950/20000]  base_lr: 4.8986e-05 lr: 4.8986e-05  eta: 4:09:02  time: 3.0099  data_time: 0.0217  memory: 10133  loss: 24.2367  decode.loss_cls: 0.1932  decode.loss_mask: 1.0701  decode.loss_dice: 1.1548  decode.d0.loss_cls: 0.2743  decode.d0.loss_mask: 1.0638  decode.d0.loss_dice: 1.1876  decode.d1.loss_cls: 0.2494  decode.d1.loss_mask: 1.0337  decode.d1.loss_dice: 1.1326  decode.d2.loss_cls: 0.1803  decode.d2.loss_mask: 1.0521  decode.d2.loss_dice: 1.1508  decode.d3.loss_cls: 0.2122  decode.d3.loss_mask: 1.0538  decode.d3.loss_dice: 1.1516  decode.d4.loss_cls: 0.2030  decode.d4.loss_mask: 1.0618  decode.d4.loss_dice: 1.1311  decode.d5.loss_cls: 0.2081  decode.d5.loss_mask: 1.0779  decode.d5.loss_dice: 1.1389  decode.d6.loss_cls: 0.1962  decode.d6.loss_mask: 1.0700  decode.d6.loss_dice: 1.1597  decode.d7.loss_cls: 0.2087  decode.d7.loss_mask: 1.0579  decode.d7.loss_dice: 1.1498  decode.d8.loss_cls: 0.2292  decode.d8.loss_mask: 1.0554  decode.d8.loss_dice: 1.1288
2025/03/29 17:16:09 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 17:16:09 - mmengine - INFO - Iter(train) [11000/20000]  base_lr: 4.8743e-05 lr: 4.8743e-05  eta: 4:08:34  time: 2.9955  data_time: 0.0220  memory: 10130  loss: 23.8859  decode.loss_cls: 0.2520  decode.loss_mask: 1.0587  decode.loss_dice: 1.0669  decode.d0.loss_cls: 0.2186  decode.d0.loss_mask: 1.0994  decode.d0.loss_dice: 1.1579  decode.d1.loss_cls: 0.2339  decode.d1.loss_mask: 1.0545  decode.d1.loss_dice: 1.1208  decode.d2.loss_cls: 0.2782  decode.d2.loss_mask: 1.0607  decode.d2.loss_dice: 1.0880  decode.d3.loss_cls: 0.2370  decode.d3.loss_mask: 1.0595  decode.d3.loss_dice: 1.0661  decode.d4.loss_cls: 0.2124  decode.d4.loss_mask: 1.0763  decode.d4.loss_dice: 1.0767  decode.d5.loss_cls: 0.2033  decode.d5.loss_mask: 1.0665  decode.d5.loss_dice: 1.0926  decode.d6.loss_cls: 0.2167  decode.d6.loss_mask: 1.0516  decode.d6.loss_dice: 1.0798  decode.d7.loss_cls: 0.2131  decode.d7.loss_mask: 1.0563  decode.d7.loss_dice: 1.1042  decode.d8.loss_cls: 0.2451  decode.d8.loss_mask: 1.0592  decode.d8.loss_dice: 1.0798
2025/03/29 17:18:39 - mmengine - INFO - Iter(train) [11050/20000]  base_lr: 4.8499e-05 lr: 4.8499e-05  eta: 4:08:06  time: 2.9935  data_time: 0.0206  memory: 10129  loss: 23.5787  decode.loss_cls: 0.1381  decode.loss_mask: 1.0932  decode.loss_dice: 1.1029  decode.d0.loss_cls: 0.2125  decode.d0.loss_mask: 1.0906  decode.d0.loss_dice: 1.1529  decode.d1.loss_cls: 0.1655  decode.d1.loss_mask: 1.0647  decode.d1.loss_dice: 1.1015  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 1.0841  decode.d2.loss_dice: 1.1171  decode.d3.loss_cls: 0.1206  decode.d3.loss_mask: 1.0981  decode.d3.loss_dice: 1.1250  decode.d4.loss_cls: 0.1323  decode.d4.loss_mask: 1.0894  decode.d4.loss_dice: 1.1027  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 1.0953  decode.d5.loss_dice: 1.1335  decode.d6.loss_cls: 0.1569  decode.d6.loss_mask: 1.0930  decode.d6.loss_dice: 1.1129  decode.d7.loss_cls: 0.1864  decode.d7.loss_mask: 1.0817  decode.d7.loss_dice: 1.1029  decode.d8.loss_cls: 0.1749  decode.d8.loss_mask: 1.0770  decode.d8.loss_dice: 1.1028
2025/03/29 17:20:53 - mmengine - INFO - Iter(train) [11100/20000]  base_lr: 4.8255e-05 lr: 4.8255e-05  eta: 4:07:23  time: 2.6604  data_time: 0.0213  memory: 10118  loss: 25.6581  decode.loss_cls: 0.2759  decode.loss_mask: 1.0064  decode.loss_dice: 1.2309  decode.d0.loss_cls: 0.4051  decode.d0.loss_mask: 1.0157  decode.d0.loss_dice: 1.2588  decode.d1.loss_cls: 0.3812  decode.d1.loss_mask: 1.0020  decode.d1.loss_dice: 1.2294  decode.d2.loss_cls: 0.3499  decode.d2.loss_mask: 1.0004  decode.d2.loss_dice: 1.2091  decode.d3.loss_cls: 0.3185  decode.d3.loss_mask: 0.9753  decode.d3.loss_dice: 1.2088  decode.d4.loss_cls: 0.3138  decode.d4.loss_mask: 0.9995  decode.d4.loss_dice: 1.2325  decode.d5.loss_cls: 0.2963  decode.d5.loss_mask: 1.0106  decode.d5.loss_dice: 1.2295  decode.d6.loss_cls: 0.3542  decode.d6.loss_mask: 0.9895  decode.d6.loss_dice: 1.2182  decode.d7.loss_cls: 0.3345  decode.d7.loss_mask: 1.0125  decode.d7.loss_dice: 1.2288  decode.d8.loss_cls: 0.3434  decode.d8.loss_mask: 1.0074  decode.d8.loss_dice: 1.2200
2025/03/29 17:23:23 - mmengine - INFO - Iter(train) [11150/20000]  base_lr: 4.8011e-05 lr: 4.8011e-05  eta: 4:06:53  time: 3.0058  data_time: 0.0210  memory: 10127  loss: 25.1156  decode.loss_cls: 0.1746  decode.loss_mask: 1.1420  decode.loss_dice: 1.1951  decode.d0.loss_cls: 0.2505  decode.d0.loss_mask: 1.1623  decode.d0.loss_dice: 1.2561  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 1.1393  decode.d1.loss_dice: 1.1950  decode.d2.loss_cls: 0.1762  decode.d2.loss_mask: 1.1411  decode.d2.loss_dice: 1.1936  decode.d3.loss_cls: 0.1685  decode.d3.loss_mask: 1.1265  decode.d3.loss_dice: 1.1821  decode.d4.loss_cls: 0.1676  decode.d4.loss_mask: 1.1421  decode.d4.loss_dice: 1.1866  decode.d5.loss_cls: 0.1643  decode.d5.loss_mask: 1.1377  decode.d5.loss_dice: 1.1786  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 1.1347  decode.d6.loss_dice: 1.1885  decode.d7.loss_cls: 0.1713  decode.d7.loss_mask: 1.1266  decode.d7.loss_dice: 1.1933  decode.d8.loss_cls: 0.1662  decode.d8.loss_mask: 1.1359  decode.d8.loss_dice: 1.1553
2025/03/29 17:25:53 - mmengine - INFO - Iter(train) [11200/20000]  base_lr: 4.7767e-05 lr: 4.7767e-05  eta: 4:06:22  time: 3.0033  data_time: 0.0204  memory: 10122  loss: 23.9297  decode.loss_cls: 0.1258  decode.loss_mask: 1.1146  decode.loss_dice: 1.1545  decode.d0.loss_cls: 0.2802  decode.d0.loss_mask: 1.1176  decode.d0.loss_dice: 1.1674  decode.d1.loss_cls: 0.1739  decode.d1.loss_mask: 1.0780  decode.d1.loss_dice: 1.1203  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 1.0771  decode.d2.loss_dice: 1.1134  decode.d3.loss_cls: 0.1403  decode.d3.loss_mask: 1.0801  decode.d3.loss_dice: 1.1197  decode.d4.loss_cls: 0.1282  decode.d4.loss_mask: 1.1009  decode.d4.loss_dice: 1.1349  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 1.0931  decode.d5.loss_dice: 1.1194  decode.d6.loss_cls: 0.1417  decode.d6.loss_mask: 1.1073  decode.d6.loss_dice: 1.1600  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 1.0938  decode.d7.loss_dice: 1.1431  decode.d8.loss_cls: 0.1373  decode.d8.loss_mask: 1.1071  decode.d8.loss_dice: 1.1311
2025/03/29 17:28:23 - mmengine - INFO - Iter(train) [11250/20000]  base_lr: 4.7523e-05 lr: 4.7523e-05  eta: 4:05:49  time: 3.0056  data_time: 0.0203  memory: 10121  loss: 25.2859  decode.loss_cls: 0.1167  decode.loss_mask: 1.1277  decode.loss_dice: 1.2774  decode.d0.loss_cls: 0.1819  decode.d0.loss_mask: 1.1532  decode.d0.loss_dice: 1.3373  decode.d1.loss_cls: 0.1289  decode.d1.loss_mask: 1.1180  decode.d1.loss_dice: 1.2723  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 1.1156  decode.d2.loss_dice: 1.2898  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 1.1147  decode.d3.loss_dice: 1.2659  decode.d4.loss_cls: 0.1307  decode.d4.loss_mask: 1.1161  decode.d4.loss_dice: 1.2627  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 1.1330  decode.d5.loss_dice: 1.2814  decode.d6.loss_cls: 0.1150  decode.d6.loss_mask: 1.1236  decode.d6.loss_dice: 1.2651  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 1.1141  decode.d7.loss_dice: 1.2630  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 1.1207  decode.d8.loss_dice: 1.2671
2025/03/29 17:30:53 - mmengine - INFO - Iter(train) [11300/20000]  base_lr: 4.7278e-05 lr: 4.7278e-05  eta: 4:05:15  time: 2.9854  data_time: 0.0202  memory: 10134  loss: 24.0391  decode.loss_cls: 0.2365  decode.loss_mask: 1.0486  decode.loss_dice: 1.1149  decode.d0.loss_cls: 0.2260  decode.d0.loss_mask: 1.0760  decode.d0.loss_dice: 1.2001  decode.d1.loss_cls: 0.3107  decode.d1.loss_mask: 1.0228  decode.d1.loss_dice: 1.1004  decode.d2.loss_cls: 0.2627  decode.d2.loss_mask: 1.0441  decode.d2.loss_dice: 1.0718  decode.d3.loss_cls: 0.2631  decode.d3.loss_mask: 1.0419  decode.d3.loss_dice: 1.0890  decode.d4.loss_cls: 0.2639  decode.d4.loss_mask: 1.0480  decode.d4.loss_dice: 1.0969  decode.d5.loss_cls: 0.2565  decode.d5.loss_mask: 1.0318  decode.d5.loss_dice: 1.0880  decode.d6.loss_cls: 0.2471  decode.d6.loss_mask: 1.0493  decode.d6.loss_dice: 1.0683  decode.d7.loss_cls: 0.2375  decode.d7.loss_mask: 1.0706  decode.d7.loss_dice: 1.0996  decode.d8.loss_cls: 0.2505  decode.d8.loss_mask: 1.0430  decode.d8.loss_dice: 1.0795
2025/03/29 17:33:24 - mmengine - INFO - Iter(train) [11350/20000]  base_lr: 4.7033e-05 lr: 4.7033e-05  eta: 4:04:41  time: 3.0277  data_time: 0.0229  memory: 10121  loss: 23.3542  decode.loss_cls: 0.1245  decode.loss_mask: 1.1080  decode.loss_dice: 1.1154  decode.d0.loss_cls: 0.1835  decode.d0.loss_mask: 1.1053  decode.d0.loss_dice: 1.0956  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 1.1104  decode.d1.loss_dice: 1.0850  decode.d2.loss_cls: 0.1072  decode.d2.loss_mask: 1.1174  decode.d2.loss_dice: 1.0883  decode.d3.loss_cls: 0.0977  decode.d3.loss_mask: 1.1055  decode.d3.loss_dice: 1.1017  decode.d4.loss_cls: 0.1387  decode.d4.loss_mask: 1.1083  decode.d4.loss_dice: 1.0982  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 1.0974  decode.d5.loss_dice: 1.0840  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 1.0958  decode.d6.loss_dice: 1.0910  decode.d7.loss_cls: 0.1305  decode.d7.loss_mask: 1.1054  decode.d7.loss_dice: 1.0891  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 1.1320  decode.d8.loss_dice: 1.0953
2025/03/29 17:35:55 - mmengine - INFO - Iter(train) [11400/20000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 4:04:06  time: 3.0118  data_time: 0.0240  memory: 10121  loss: 21.5297  decode.loss_cls: 0.1337  decode.loss_mask: 1.0623  decode.loss_dice: 0.9893  decode.d0.loss_cls: 0.1997  decode.d0.loss_mask: 1.0461  decode.d0.loss_dice: 1.0336  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 1.0275  decode.d1.loss_dice: 0.9993  decode.d2.loss_cls: 0.1260  decode.d2.loss_mask: 1.0258  decode.d2.loss_dice: 1.0078  decode.d3.loss_cls: 0.0988  decode.d3.loss_mask: 1.0207  decode.d3.loss_dice: 0.9957  decode.d4.loss_cls: 0.1164  decode.d4.loss_mask: 1.0175  decode.d4.loss_dice: 0.9752  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 1.0304  decode.d5.loss_dice: 0.9881  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 1.0419  decode.d6.loss_dice: 0.9979  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 1.0501  decode.d7.loss_dice: 0.9857  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 1.0533  decode.d8.loss_dice: 0.9794
2025/03/29 17:38:25 - mmengine - INFO - Iter(train) [11450/20000]  base_lr: 4.6544e-05 lr: 4.6544e-05  eta: 4:03:30  time: 3.0288  data_time: 0.0228  memory: 10121  loss: 24.2653  decode.loss_cls: 0.1650  decode.loss_mask: 1.1004  decode.loss_dice: 1.1653  decode.d0.loss_cls: 0.1954  decode.d0.loss_mask: 1.1026  decode.d0.loss_dice: 1.2328  decode.d1.loss_cls: 0.1816  decode.d1.loss_mask: 1.0911  decode.d1.loss_dice: 1.1305  decode.d2.loss_cls: 0.1934  decode.d2.loss_mask: 1.0882  decode.d2.loss_dice: 1.1215  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 1.1043  decode.d3.loss_dice: 1.1570  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 1.1003  decode.d4.loss_dice: 1.1407  decode.d5.loss_cls: 0.1892  decode.d5.loss_mask: 1.0696  decode.d5.loss_dice: 1.1407  decode.d6.loss_cls: 0.1674  decode.d6.loss_mask: 1.0984  decode.d6.loss_dice: 1.1475  decode.d7.loss_cls: 0.1992  decode.d7.loss_mask: 1.0856  decode.d7.loss_dice: 1.1526  decode.d8.loss_cls: 0.1712  decode.d8.loss_mask: 1.0852  decode.d8.loss_dice: 1.1532
2025/03/29 17:40:55 - mmengine - INFO - Iter(train) [11500/20000]  base_lr: 4.6299e-05 lr: 4.6299e-05  eta: 4:02:52  time: 2.9995  data_time: 0.0208  memory: 10136  loss: 26.1340  decode.loss_cls: 0.2396  decode.loss_mask: 1.0830  decode.loss_dice: 1.2970  decode.d0.loss_cls: 0.2471  decode.d0.loss_mask: 1.0767  decode.d0.loss_dice: 1.3640  decode.d1.loss_cls: 0.2500  decode.d1.loss_mask: 1.0779  decode.d1.loss_dice: 1.3029  decode.d2.loss_cls: 0.2336  decode.d2.loss_mask: 1.0831  decode.d2.loss_dice: 1.2802  decode.d3.loss_cls: 0.2605  decode.d3.loss_mask: 1.0833  decode.d3.loss_dice: 1.2879  decode.d4.loss_cls: 0.2449  decode.d4.loss_mask: 1.0931  decode.d4.loss_dice: 1.2621  decode.d5.loss_cls: 0.2714  decode.d5.loss_mask: 1.0821  decode.d5.loss_dice: 1.2642  decode.d6.loss_cls: 0.2373  decode.d6.loss_mask: 1.0918  decode.d6.loss_dice: 1.2480  decode.d7.loss_cls: 0.2558  decode.d7.loss_mask: 1.0871  decode.d7.loss_dice: 1.2384  decode.d8.loss_cls: 0.2736  decode.d8.loss_mask: 1.0516  decode.d8.loss_dice: 1.2658
2025/03/29 17:43:26 - mmengine - INFO - Iter(train) [11550/20000]  base_lr: 4.6054e-05 lr: 4.6054e-05  eta: 4:02:14  time: 3.0127  data_time: 0.0213  memory: 10120  loss: 26.3586  decode.loss_cls: 0.1887  decode.loss_mask: 1.2061  decode.loss_dice: 1.2418  decode.d0.loss_cls: 0.2441  decode.d0.loss_mask: 1.2256  decode.d0.loss_dice: 1.3015  decode.d1.loss_cls: 0.2178  decode.d1.loss_mask: 1.1810  decode.d1.loss_dice: 1.2505  decode.d2.loss_cls: 0.1675  decode.d2.loss_mask: 1.2057  decode.d2.loss_dice: 1.2524  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 1.2013  decode.d3.loss_dice: 1.2386  decode.d4.loss_cls: 0.1859  decode.d4.loss_mask: 1.1896  decode.d4.loss_dice: 1.2456  decode.d5.loss_cls: 0.1840  decode.d5.loss_mask: 1.2010  decode.d5.loss_dice: 1.2244  decode.d6.loss_cls: 0.1655  decode.d6.loss_mask: 1.1974  decode.d6.loss_dice: 1.2327  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 1.1847  decode.d7.loss_dice: 1.2635  decode.d8.loss_cls: 0.1666  decode.d8.loss_mask: 1.1845  decode.d8.loss_dice: 1.2486
2025/03/29 17:45:43 - mmengine - INFO - Iter(train) [11600/20000]  base_lr: 4.5808e-05 lr: 4.5808e-05  eta: 4:01:25  time: 1.9121  data_time: 0.0251  memory: 10124  loss: 23.2054  decode.loss_cls: 0.2071  decode.loss_mask: 0.9862  decode.loss_dice: 1.1229  decode.d0.loss_cls: 0.2364  decode.d0.loss_mask: 0.9986  decode.d0.loss_dice: 1.1518  decode.d1.loss_cls: 0.2300  decode.d1.loss_mask: 0.9843  decode.d1.loss_dice: 1.1166  decode.d2.loss_cls: 0.1818  decode.d2.loss_mask: 0.9869  decode.d2.loss_dice: 1.1068  decode.d3.loss_cls: 0.1886  decode.d3.loss_mask: 1.0042  decode.d3.loss_dice: 1.1206  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 1.0050  decode.d4.loss_dice: 1.1222  decode.d5.loss_cls: 0.2334  decode.d5.loss_mask: 0.9776  decode.d5.loss_dice: 1.1239  decode.d6.loss_cls: 0.2272  decode.d6.loss_mask: 0.9759  decode.d6.loss_dice: 1.1303  decode.d7.loss_cls: 0.1928  decode.d7.loss_mask: 0.9821  decode.d7.loss_dice: 1.1287  decode.d8.loss_cls: 0.1802  decode.d8.loss_mask: 0.9863  decode.d8.loss_dice: 1.1339
2025/03/29 17:48:13 - mmengine - INFO - Iter(train) [11650/20000]  base_lr: 4.5563e-05 lr: 4.5563e-05  eta: 4:00:44  time: 2.9856  data_time: 0.0221  memory: 10134  loss: 24.5907  decode.loss_cls: 0.2032  decode.loss_mask: 1.0506  decode.loss_dice: 1.1976  decode.d0.loss_cls: 0.2265  decode.d0.loss_mask: 1.0633  decode.d0.loss_dice: 1.2666  decode.d1.loss_cls: 0.2702  decode.d1.loss_mask: 1.0308  decode.d1.loss_dice: 1.1634  decode.d2.loss_cls: 0.2570  decode.d2.loss_mask: 1.0494  decode.d2.loss_dice: 1.1557  decode.d3.loss_cls: 0.2199  decode.d3.loss_mask: 1.0395  decode.d3.loss_dice: 1.1881  decode.d4.loss_cls: 0.2307  decode.d4.loss_mask: 1.0390  decode.d4.loss_dice: 1.1623  decode.d5.loss_cls: 0.2115  decode.d5.loss_mask: 1.0477  decode.d5.loss_dice: 1.1947  decode.d6.loss_cls: 0.2008  decode.d6.loss_mask: 1.0398  decode.d6.loss_dice: 1.1981  decode.d7.loss_cls: 0.2006  decode.d7.loss_mask: 1.0533  decode.d7.loss_dice: 1.1852  decode.d8.loss_cls: 0.1883  decode.d8.loss_mask: 1.0617  decode.d8.loss_dice: 1.1952
2025/03/29 17:50:43 - mmengine - INFO - Iter(train) [11700/20000]  base_lr: 4.5317e-05 lr: 4.5317e-05  eta: 4:00:03  time: 2.9972  data_time: 0.0215  memory: 10122  loss: 24.7080  decode.loss_cls: 0.2372  decode.loss_mask: 1.0325  decode.loss_dice: 1.1819  decode.d0.loss_cls: 0.3296  decode.d0.loss_mask: 1.0856  decode.d0.loss_dice: 1.2508  decode.d1.loss_cls: 0.2683  decode.d1.loss_mask: 1.0383  decode.d1.loss_dice: 1.1801  decode.d2.loss_cls: 0.2399  decode.d2.loss_mask: 1.0432  decode.d2.loss_dice: 1.1412  decode.d3.loss_cls: 0.2201  decode.d3.loss_mask: 1.0384  decode.d3.loss_dice: 1.1368  decode.d4.loss_cls: 0.2437  decode.d4.loss_mask: 1.0341  decode.d4.loss_dice: 1.1533  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 1.0702  decode.d5.loss_dice: 1.1480  decode.d6.loss_cls: 0.2261  decode.d6.loss_mask: 1.0695  decode.d6.loss_dice: 1.1733  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 1.0267  decode.d7.loss_dice: 1.1584  decode.d8.loss_cls: 0.2040  decode.d8.loss_mask: 1.1159  decode.d8.loss_dice: 1.1884
2025/03/29 17:53:14 - mmengine - INFO - Iter(train) [11750/20000]  base_lr: 4.5071e-05 lr: 4.5071e-05  eta: 3:59:21  time: 3.0049  data_time: 0.0223  memory: 10126  loss: 24.5739  decode.loss_cls: 0.1647  decode.loss_mask: 1.1318  decode.loss_dice: 1.1610  decode.d0.loss_cls: 0.2241  decode.d0.loss_mask: 1.1018  decode.d0.loss_dice: 1.2074  decode.d1.loss_cls: 0.1706  decode.d1.loss_mask: 1.1046  decode.d1.loss_dice: 1.1726  decode.d2.loss_cls: 0.1627  decode.d2.loss_mask: 1.1027  decode.d2.loss_dice: 1.1651  decode.d3.loss_cls: 0.1370  decode.d3.loss_mask: 1.1294  decode.d3.loss_dice: 1.1725  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 1.1297  decode.d4.loss_dice: 1.1739  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 1.1272  decode.d5.loss_dice: 1.1777  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 1.1463  decode.d6.loss_dice: 1.2023  decode.d7.loss_cls: 0.1238  decode.d7.loss_mask: 1.1490  decode.d7.loss_dice: 1.1892  decode.d8.loss_cls: 0.1375  decode.d8.loss_mask: 1.1368  decode.d8.loss_dice: 1.1680
2025/03/29 17:55:44 - mmengine - INFO - Iter(train) [11800/20000]  base_lr: 4.4825e-05 lr: 4.4825e-05  eta: 3:58:38  time: 3.0109  data_time: 0.0220  memory: 10129  loss: 22.7744  decode.loss_cls: 0.2012  decode.loss_mask: 0.9084  decode.loss_dice: 1.1805  decode.d0.loss_cls: 0.1914  decode.d0.loss_mask: 0.9061  decode.d0.loss_dice: 1.2348  decode.d1.loss_cls: 0.2243  decode.d1.loss_mask: 0.9182  decode.d1.loss_dice: 1.1515  decode.d2.loss_cls: 0.2078  decode.d2.loss_mask: 0.9270  decode.d2.loss_dice: 1.0850  decode.d3.loss_cls: 0.1903  decode.d3.loss_mask: 0.9177  decode.d3.loss_dice: 1.1449  decode.d4.loss_cls: 0.1989  decode.d4.loss_mask: 0.9220  decode.d4.loss_dice: 1.1473  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 0.9098  decode.d5.loss_dice: 1.1580  decode.d6.loss_cls: 0.2244  decode.d6.loss_mask: 0.9115  decode.d6.loss_dice: 1.1480  decode.d7.loss_cls: 0.2030  decode.d7.loss_mask: 0.9089  decode.d7.loss_dice: 1.1482  decode.d8.loss_cls: 0.1892  decode.d8.loss_mask: 0.9134  decode.d8.loss_dice: 1.1852
2025/03/29 17:58:14 - mmengine - INFO - Iter(train) [11850/20000]  base_lr: 4.4579e-05 lr: 4.4579e-05  eta: 3:57:54  time: 3.0010  data_time: 0.0213  memory: 10117  loss: 26.7230  decode.loss_cls: 0.2268  decode.loss_mask: 1.1778  decode.loss_dice: 1.2469  decode.d0.loss_cls: 0.2713  decode.d0.loss_mask: 1.2194  decode.d0.loss_dice: 1.3285  decode.d1.loss_cls: 0.1754  decode.d1.loss_mask: 1.1762  decode.d1.loss_dice: 1.3037  decode.d2.loss_cls: 0.1541  decode.d2.loss_mask: 1.1826  decode.d2.loss_dice: 1.3238  decode.d3.loss_cls: 0.1979  decode.d3.loss_mask: 1.1662  decode.d3.loss_dice: 1.2703  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 1.1794  decode.d4.loss_dice: 1.2729  decode.d5.loss_cls: 0.1958  decode.d5.loss_mask: 1.1809  decode.d5.loss_dice: 1.2834  decode.d6.loss_cls: 0.1938  decode.d6.loss_mask: 1.1835  decode.d6.loss_dice: 1.2676  decode.d7.loss_cls: 0.2263  decode.d7.loss_mask: 1.1972  decode.d7.loss_dice: 1.2494  decode.d8.loss_cls: 0.2180  decode.d8.loss_mask: 1.1915  decode.d8.loss_dice: 1.2698
2025/03/29 18:00:44 - mmengine - INFO - Iter(train) [11900/20000]  base_lr: 4.4333e-05 lr: 4.4333e-05  eta: 3:57:09  time: 2.9995  data_time: 0.0203  memory: 10124  loss: 24.7275  decode.loss_cls: 0.1962  decode.loss_mask: 1.0957  decode.loss_dice: 1.1881  decode.d0.loss_cls: 0.2681  decode.d0.loss_mask: 1.0993  decode.d0.loss_dice: 1.2111  decode.d1.loss_cls: 0.2142  decode.d1.loss_mask: 1.0968  decode.d1.loss_dice: 1.1694  decode.d2.loss_cls: 0.1839  decode.d2.loss_mask: 1.1182  decode.d2.loss_dice: 1.1542  decode.d3.loss_cls: 0.2033  decode.d3.loss_mask: 1.1169  decode.d3.loss_dice: 1.1729  decode.d4.loss_cls: 0.1745  decode.d4.loss_mask: 1.1017  decode.d4.loss_dice: 1.1738  decode.d5.loss_cls: 0.1765  decode.d5.loss_mask: 1.1063  decode.d5.loss_dice: 1.1643  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 1.1038  decode.d6.loss_dice: 1.1536  decode.d7.loss_cls: 0.1909  decode.d7.loss_mask: 1.1055  decode.d7.loss_dice: 1.1527  decode.d8.loss_cls: 0.1832  decode.d8.loss_mask: 1.1087  decode.d8.loss_dice: 1.1675
2025/03/29 18:03:15 - mmengine - INFO - Iter(train) [11950/20000]  base_lr: 4.4087e-05 lr: 4.4087e-05  eta: 3:56:23  time: 3.0214  data_time: 0.0242  memory: 10126  loss: 23.6433  decode.loss_cls: 0.1313  decode.loss_mask: 1.0677  decode.loss_dice: 1.1406  decode.d0.loss_cls: 0.1691  decode.d0.loss_mask: 1.0830  decode.d0.loss_dice: 1.2010  decode.d1.loss_cls: 0.1541  decode.d1.loss_mask: 1.0682  decode.d1.loss_dice: 1.1540  decode.d2.loss_cls: 0.1457  decode.d2.loss_mask: 1.0679  decode.d2.loss_dice: 1.1417  decode.d3.loss_cls: 0.1332  decode.d3.loss_mask: 1.0662  decode.d3.loss_dice: 1.1564  decode.d4.loss_cls: 0.1551  decode.d4.loss_mask: 1.0645  decode.d4.loss_dice: 1.1351  decode.d5.loss_cls: 0.1244  decode.d5.loss_mask: 1.0690  decode.d5.loss_dice: 1.1390  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 1.0762  decode.d6.loss_dice: 1.1505  decode.d7.loss_cls: 0.1235  decode.d7.loss_mask: 1.0744  decode.d7.loss_dice: 1.1552  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 1.0795  decode.d8.loss_dice: 1.1616
2025/03/29 18:05:45 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 18:05:45 - mmengine - INFO - Iter(train) [12000/20000]  base_lr: 4.3840e-05 lr: 4.3840e-05  eta: 3:55:36  time: 3.0001  data_time: 0.0207  memory: 10131  loss: 24.3091  decode.loss_cls: 0.1389  decode.loss_mask: 1.1197  decode.loss_dice: 1.1745  decode.d0.loss_cls: 0.1694  decode.d0.loss_mask: 1.1377  decode.d0.loss_dice: 1.2056  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 1.1192  decode.d1.loss_dice: 1.1520  decode.d2.loss_cls: 0.1481  decode.d2.loss_mask: 1.1176  decode.d2.loss_dice: 1.1454  decode.d3.loss_cls: 0.1621  decode.d3.loss_mask: 1.1244  decode.d3.loss_dice: 1.1372  decode.d4.loss_cls: 0.1532  decode.d4.loss_mask: 1.1282  decode.d4.loss_dice: 1.1726  decode.d5.loss_cls: 0.1384  decode.d5.loss_mask: 1.1244  decode.d5.loss_dice: 1.1437  decode.d6.loss_cls: 0.1404  decode.d6.loss_mask: 1.1267  decode.d6.loss_dice: 1.1450  decode.d7.loss_cls: 0.1304  decode.d7.loss_mask: 1.1188  decode.d7.loss_dice: 1.1560  decode.d8.loss_cls: 0.1302  decode.d8.loss_mask: 1.1173  decode.d8.loss_dice: 1.1607
2025/03/29 18:05:45 - mmengine - INFO - Saving checkpoint at 12000 iterations
2025/03/29 18:06:00 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:01:29  time: 0.2565  data_time: 0.0021  memory: 1808  
2025/03/29 18:06:13 - mmengine - INFO - Iter(val) [100/398]    eta: 0:01:16  time: 0.2557  data_time: 0.0023  memory: 1808  
2025/03/29 18:06:26 - mmengine - INFO - Iter(val) [150/398]    eta: 0:01:03  time: 0.2590  data_time: 0.0022  memory: 1808  
2025/03/29 18:06:39 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:50  time: 0.2566  data_time: 0.0020  memory: 1808  
2025/03/29 18:06:52 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:37  time: 0.2546  data_time: 0.0020  memory: 1808  
2025/03/29 18:07:04 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:25  time: 0.2551  data_time: 0.0020  memory: 1808  
2025/03/29 18:07:17 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:12  time: 0.2588  data_time: 0.0022  memory: 1808  
2025/03/29 18:07:30 - mmengine - INFO - per class results:
2025/03/29 18:07:30 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 74.46 | 84.41 |
|      building      | 87.33 | 95.61 |
|   low_vegetation   | 53.46 | 62.17 |
|        tree        | 73.74 | 88.18 |
|        car         | 55.09 | 63.97 |
|      clutter       | 24.36 | 93.19 |
+--------------------+-------+-------+
2025/03/29 18:07:30 - mmengine - INFO - Iter(val) [398/398]    aAcc: 83.0100  mIoU: 61.4100  mAcc: 81.2500  data_time: 0.0023  time: 0.2566
2025/03/29 18:10:00 - mmengine - INFO - Iter(train) [12050/20000]  base_lr: 4.3594e-05 lr: 4.3594e-05  eta: 3:54:49  time: 3.0087  data_time: 0.0211  memory: 10120  loss: 22.0599  decode.loss_cls: 0.1882  decode.loss_mask: 1.0012  decode.loss_dice: 1.0221  decode.d0.loss_cls: 0.2566  decode.d0.loss_mask: 0.9931  decode.d0.loss_dice: 1.0551  decode.d1.loss_cls: 0.2051  decode.d1.loss_mask: 0.9743  decode.d1.loss_dice: 0.9977  decode.d2.loss_cls: 0.2247  decode.d2.loss_mask: 0.9378  decode.d2.loss_dice: 0.9951  decode.d3.loss_cls: 0.2829  decode.d3.loss_mask: 0.9394  decode.d3.loss_dice: 0.9714  decode.d4.loss_cls: 0.2380  decode.d4.loss_mask: 0.9460  decode.d4.loss_dice: 1.0165  decode.d5.loss_cls: 0.2318  decode.d5.loss_mask: 0.9627  decode.d5.loss_dice: 1.0001  decode.d6.loss_cls: 0.2648  decode.d6.loss_mask: 0.9555  decode.d6.loss_dice: 1.0038  decode.d7.loss_cls: 0.2438  decode.d7.loss_mask: 0.9459  decode.d7.loss_dice: 1.0053  decode.d8.loss_cls: 0.2525  decode.d8.loss_mask: 0.9458  decode.d8.loss_dice: 1.0027
2025/03/29 18:12:16 - mmengine - INFO - Iter(train) [12100/20000]  base_lr: 4.3347e-05 lr: 4.3347e-05  eta: 3:53:51  time: 3.0001  data_time: 0.0202  memory: 10133  loss: 26.6170  decode.loss_cls: 0.1382  decode.loss_mask: 1.1522  decode.loss_dice: 1.3563  decode.d0.loss_cls: 0.1834  decode.d0.loss_mask: 1.1321  decode.d0.loss_dice: 1.4262  decode.d1.loss_cls: 0.1749  decode.d1.loss_mask: 1.1678  decode.d1.loss_dice: 1.3509  decode.d2.loss_cls: 0.1302  decode.d2.loss_mask: 1.1643  decode.d2.loss_dice: 1.3419  decode.d3.loss_cls: 0.1377  decode.d3.loss_mask: 1.1709  decode.d3.loss_dice: 1.3330  decode.d4.loss_cls: 0.1414  decode.d4.loss_mask: 1.1642  decode.d4.loss_dice: 1.3518  decode.d5.loss_cls: 0.1234  decode.d5.loss_mask: 1.1624  decode.d5.loss_dice: 1.3478  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 1.1683  decode.d6.loss_dice: 1.3666  decode.d7.loss_cls: 0.1150  decode.d7.loss_mask: 1.1587  decode.d7.loss_dice: 1.3784  decode.d8.loss_cls: 0.1389  decode.d8.loss_mask: 1.1549  decode.d8.loss_dice: 1.3708
2025/03/29 18:14:46 - mmengine - INFO - Iter(train) [12150/20000]  base_lr: 4.3100e-05 lr: 4.3100e-05  eta: 3:53:02  time: 2.9931  data_time: 0.0201  memory: 10120  loss: 24.5899  decode.loss_cls: 0.2401  decode.loss_mask: 0.9832  decode.loss_dice: 1.1925  decode.d0.loss_cls: 0.2408  decode.d0.loss_mask: 1.0246  decode.d0.loss_dice: 1.2861  decode.d1.loss_cls: 0.2713  decode.d1.loss_mask: 1.0026  decode.d1.loss_dice: 1.2061  decode.d2.loss_cls: 0.2736  decode.d2.loss_mask: 0.9820  decode.d2.loss_dice: 1.1778  decode.d3.loss_cls: 0.2532  decode.d3.loss_mask: 0.9836  decode.d3.loss_dice: 1.1945  decode.d4.loss_cls: 0.2735  decode.d4.loss_mask: 0.9784  decode.d4.loss_dice: 1.1841  decode.d5.loss_cls: 0.2957  decode.d5.loss_mask: 0.9738  decode.d5.loss_dice: 1.1803  decode.d6.loss_cls: 0.2688  decode.d6.loss_mask: 0.9943  decode.d6.loss_dice: 1.2111  decode.d7.loss_cls: 0.2790  decode.d7.loss_mask: 0.9965  decode.d7.loss_dice: 1.1893  decode.d8.loss_cls: 0.2638  decode.d8.loss_mask: 0.9904  decode.d8.loss_dice: 1.1988
2025/03/29 18:17:17 - mmengine - INFO - Iter(train) [12200/20000]  base_lr: 4.2853e-05 lr: 4.2853e-05  eta: 3:52:12  time: 2.9979  data_time: 0.0213  memory: 10119  loss: 22.2505  decode.loss_cls: 0.2121  decode.loss_mask: 0.9103  decode.loss_dice: 1.1010  decode.d0.loss_cls: 0.2416  decode.d0.loss_mask: 0.9347  decode.d0.loss_dice: 1.1250  decode.d1.loss_cls: 0.2223  decode.d1.loss_mask: 0.9038  decode.d1.loss_dice: 1.0984  decode.d2.loss_cls: 0.2252  decode.d2.loss_mask: 0.9097  decode.d2.loss_dice: 1.0883  decode.d3.loss_cls: 0.1827  decode.d3.loss_mask: 0.9079  decode.d3.loss_dice: 1.0950  decode.d4.loss_cls: 0.2157  decode.d4.loss_mask: 0.9243  decode.d4.loss_dice: 1.1065  decode.d5.loss_cls: 0.2013  decode.d5.loss_mask: 0.9189  decode.d5.loss_dice: 1.0825  decode.d6.loss_cls: 0.1600  decode.d6.loss_mask: 0.9212  decode.d6.loss_dice: 1.1142  decode.d7.loss_cls: 0.1950  decode.d7.loss_mask: 0.9175  decode.d7.loss_dice: 1.1134  decode.d8.loss_cls: 0.1930  decode.d8.loss_mask: 0.9129  decode.d8.loss_dice: 1.1161
2025/03/29 18:19:47 - mmengine - INFO - Iter(train) [12250/20000]  base_lr: 4.2605e-05 lr: 4.2605e-05  eta: 3:51:21  time: 3.0042  data_time: 0.0206  memory: 10119  loss: 22.5944  decode.loss_cls: 0.2432  decode.loss_mask: 0.8993  decode.loss_dice: 1.1124  decode.d0.loss_cls: 0.2503  decode.d0.loss_mask: 0.9276  decode.d0.loss_dice: 1.1672  decode.d1.loss_cls: 0.2475  decode.d1.loss_mask: 0.9009  decode.d1.loss_dice: 1.1023  decode.d2.loss_cls: 0.2165  decode.d2.loss_mask: 0.9051  decode.d2.loss_dice: 1.1110  decode.d3.loss_cls: 0.2588  decode.d3.loss_mask: 0.8948  decode.d3.loss_dice: 1.0666  decode.d4.loss_cls: 0.2486  decode.d4.loss_mask: 0.9013  decode.d4.loss_dice: 1.0972  decode.d5.loss_cls: 0.2421  decode.d5.loss_mask: 0.9190  decode.d5.loss_dice: 1.1120  decode.d6.loss_cls: 0.2188  decode.d6.loss_mask: 0.9194  decode.d6.loss_dice: 1.1168  decode.d7.loss_cls: 0.2175  decode.d7.loss_mask: 0.9191  decode.d7.loss_dice: 1.1049  decode.d8.loss_cls: 0.2359  decode.d8.loss_mask: 0.9124  decode.d8.loss_dice: 1.1256
2025/03/29 18:22:17 - mmengine - INFO - Iter(train) [12300/20000]  base_lr: 4.2358e-05 lr: 4.2358e-05  eta: 3:50:29  time: 3.0035  data_time: 0.0216  memory: 10128  loss: 22.2778  decode.loss_cls: 0.1103  decode.loss_mask: 1.0692  decode.loss_dice: 1.0368  decode.d0.loss_cls: 0.2385  decode.d0.loss_mask: 1.0718  decode.d0.loss_dice: 1.0474  decode.d1.loss_cls: 0.1475  decode.d1.loss_mask: 1.0700  decode.d1.loss_dice: 1.0395  decode.d2.loss_cls: 0.1250  decode.d2.loss_mask: 1.0500  decode.d2.loss_dice: 1.0259  decode.d3.loss_cls: 0.1110  decode.d3.loss_mask: 1.0419  decode.d3.loss_dice: 1.0219  decode.d4.loss_cls: 0.1171  decode.d4.loss_mask: 1.0451  decode.d4.loss_dice: 1.0590  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 1.0428  decode.d5.loss_dice: 1.0554  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 1.0651  decode.d6.loss_dice: 1.0592  decode.d7.loss_cls: 0.1081  decode.d7.loss_mask: 1.0657  decode.d7.loss_dice: 1.0400  decode.d8.loss_cls: 0.1108  decode.d8.loss_mask: 1.0642  decode.d8.loss_dice: 1.0425
2025/03/29 18:24:47 - mmengine - INFO - Iter(train) [12350/20000]  base_lr: 4.2110e-05 lr: 4.2110e-05  eta: 3:49:37  time: 3.0005  data_time: 0.0214  memory: 10121  loss: 24.6956  decode.loss_cls: 0.2582  decode.loss_mask: 1.0301  decode.loss_dice: 1.2193  decode.d0.loss_cls: 0.2992  decode.d0.loss_mask: 1.0421  decode.d0.loss_dice: 1.2620  decode.d1.loss_cls: 0.2984  decode.d1.loss_mask: 1.0250  decode.d1.loss_dice: 1.1639  decode.d2.loss_cls: 0.2687  decode.d2.loss_mask: 1.0222  decode.d2.loss_dice: 1.1684  decode.d3.loss_cls: 0.2980  decode.d3.loss_mask: 1.0245  decode.d3.loss_dice: 1.1419  decode.d4.loss_cls: 0.2748  decode.d4.loss_mask: 1.0448  decode.d4.loss_dice: 1.1483  decode.d5.loss_cls: 0.1912  decode.d5.loss_mask: 1.0579  decode.d5.loss_dice: 1.1921  decode.d6.loss_cls: 0.2206  decode.d6.loss_mask: 1.0312  decode.d6.loss_dice: 1.1603  decode.d7.loss_cls: 0.1871  decode.d7.loss_mask: 1.0437  decode.d7.loss_dice: 1.1675  decode.d8.loss_cls: 0.2578  decode.d8.loss_mask: 1.0271  decode.d8.loss_dice: 1.1693
2025/03/29 18:27:18 - mmengine - INFO - Iter(train) [12400/20000]  base_lr: 4.1862e-05 lr: 4.1862e-05  eta: 3:48:45  time: 3.0055  data_time: 0.0214  memory: 10125  loss: 25.1478  decode.loss_cls: 0.2037  decode.loss_mask: 1.0412  decode.loss_dice: 1.2789  decode.d0.loss_cls: 0.2860  decode.d0.loss_mask: 1.0073  decode.d0.loss_dice: 1.3245  decode.d1.loss_cls: 0.2779  decode.d1.loss_mask: 1.0298  decode.d1.loss_dice: 1.2634  decode.d2.loss_cls: 0.1867  decode.d2.loss_mask: 1.0332  decode.d2.loss_dice: 1.2604  decode.d3.loss_cls: 0.2025  decode.d3.loss_mask: 1.0181  decode.d3.loss_dice: 1.2342  decode.d4.loss_cls: 0.2248  decode.d4.loss_mask: 1.0104  decode.d4.loss_dice: 1.2742  decode.d5.loss_cls: 0.2308  decode.d5.loss_mask: 1.0207  decode.d5.loss_dice: 1.2444  decode.d6.loss_cls: 0.2120  decode.d6.loss_mask: 1.0268  decode.d6.loss_dice: 1.2489  decode.d7.loss_cls: 0.2184  decode.d7.loss_mask: 1.0328  decode.d7.loss_dice: 1.2455  decode.d8.loss_cls: 0.1952  decode.d8.loss_mask: 1.0538  decode.d8.loss_dice: 1.2611
2025/03/29 18:29:48 - mmengine - INFO - Iter(train) [12450/20000]  base_lr: 4.1615e-05 lr: 4.1615e-05  eta: 3:47:50  time: 2.9959  data_time: 0.0207  memory: 10126  loss: 22.2284  decode.loss_cls: 0.1465  decode.loss_mask: 1.0024  decode.loss_dice: 1.0590  decode.d0.loss_cls: 0.1824  decode.d0.loss_mask: 1.0240  decode.d0.loss_dice: 1.0940  decode.d1.loss_cls: 0.1624  decode.d1.loss_mask: 1.0085  decode.d1.loss_dice: 1.0754  decode.d2.loss_cls: 0.1137  decode.d2.loss_mask: 1.0085  decode.d2.loss_dice: 1.0825  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 0.9923  decode.d3.loss_dice: 1.0371  decode.d4.loss_cls: 0.1551  decode.d4.loss_mask: 1.0000  decode.d4.loss_dice: 1.0576  decode.d5.loss_cls: 0.1734  decode.d5.loss_mask: 1.0082  decode.d5.loss_dice: 1.0563  decode.d6.loss_cls: 0.1654  decode.d6.loss_mask: 0.9981  decode.d6.loss_dice: 1.0429  decode.d7.loss_cls: 0.1785  decode.d7.loss_mask: 0.9898  decode.d7.loss_dice: 1.0329  decode.d8.loss_cls: 0.1502  decode.d8.loss_mask: 0.9919  decode.d8.loss_dice: 1.0626
2025/03/29 18:32:18 - mmengine - INFO - Iter(train) [12500/20000]  base_lr: 4.1366e-05 lr: 4.1366e-05  eta: 3:46:56  time: 3.0011  data_time: 0.0203  memory: 10127  loss: 23.9216  decode.loss_cls: 0.2510  decode.loss_mask: 0.9492  decode.loss_dice: 1.1768  decode.d0.loss_cls: 0.2629  decode.d0.loss_mask: 0.9172  decode.d0.loss_dice: 1.2302  decode.d1.loss_cls: 0.2601  decode.d1.loss_mask: 0.9544  decode.d1.loss_dice: 1.2014  decode.d2.loss_cls: 0.2789  decode.d2.loss_mask: 0.9590  decode.d2.loss_dice: 1.1676  decode.d3.loss_cls: 0.2558  decode.d3.loss_mask: 0.9525  decode.d3.loss_dice: 1.1671  decode.d4.loss_cls: 0.2119  decode.d4.loss_mask: 0.9658  decode.d4.loss_dice: 1.1988  decode.d5.loss_cls: 0.2302  decode.d5.loss_mask: 0.9463  decode.d5.loss_dice: 1.1858  decode.d6.loss_cls: 0.2663  decode.d6.loss_mask: 0.9535  decode.d6.loss_dice: 1.1772  decode.d7.loss_cls: 0.2749  decode.d7.loss_mask: 0.9433  decode.d7.loss_dice: 1.1499  decode.d8.loss_cls: 0.2982  decode.d8.loss_mask: 0.9630  decode.d8.loss_dice: 1.1724
2025/03/29 18:34:48 - mmengine - INFO - Iter(train) [12550/20000]  base_lr: 4.1118e-05 lr: 4.1118e-05  eta: 3:46:00  time: 2.9946  data_time: 0.0244  memory: 10122  loss: 23.2174  decode.loss_cls: 0.1977  decode.loss_mask: 1.0243  decode.loss_dice: 1.0653  decode.d0.loss_cls: 0.2552  decode.d0.loss_mask: 1.0167  decode.d0.loss_dice: 1.1453  decode.d1.loss_cls: 0.2719  decode.d1.loss_mask: 1.0171  decode.d1.loss_dice: 1.0558  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 1.0219  decode.d2.loss_dice: 1.0548  decode.d3.loss_cls: 0.2046  decode.d3.loss_mask: 1.0267  decode.d3.loss_dice: 1.0775  decode.d4.loss_cls: 0.2555  decode.d4.loss_mask: 1.0032  decode.d4.loss_dice: 1.0405  decode.d5.loss_cls: 0.2134  decode.d5.loss_mask: 1.0153  decode.d5.loss_dice: 1.0706  decode.d6.loss_cls: 0.2296  decode.d6.loss_mask: 1.0191  decode.d6.loss_dice: 1.0841  decode.d7.loss_cls: 0.2295  decode.d7.loss_mask: 1.0144  decode.d7.loss_dice: 1.0593  decode.d8.loss_cls: 0.2546  decode.d8.loss_mask: 1.0246  decode.d8.loss_dice: 1.0467
2025/03/29 18:36:05 - mmengine - INFO - Iter(train) [12600/20000]  base_lr: 4.0870e-05 lr: 4.0870e-05  eta: 3:44:21  time: 1.1239  data_time: 0.0241  memory: 10126  loss: 25.2844  decode.loss_cls: 0.3468  decode.loss_mask: 1.0295  decode.loss_dice: 1.1647  decode.d0.loss_cls: 0.2295  decode.d0.loss_mask: 1.0811  decode.d0.loss_dice: 1.2661  decode.d1.loss_cls: 0.3327  decode.d1.loss_mask: 1.0294  decode.d1.loss_dice: 1.1523  decode.d2.loss_cls: 0.2852  decode.d2.loss_mask: 1.0563  decode.d2.loss_dice: 1.1537  decode.d3.loss_cls: 0.2952  decode.d3.loss_mask: 1.0560  decode.d3.loss_dice: 1.1433  decode.d4.loss_cls: 0.3088  decode.d4.loss_mask: 1.0534  decode.d4.loss_dice: 1.1463  decode.d5.loss_cls: 0.2692  decode.d5.loss_mask: 1.0611  decode.d5.loss_dice: 1.1711  decode.d6.loss_cls: 0.3112  decode.d6.loss_mask: 1.0523  decode.d6.loss_dice: 1.1636  decode.d7.loss_cls: 0.3349  decode.d7.loss_mask: 1.0687  decode.d7.loss_dice: 1.1583  decode.d8.loss_cls: 0.3306  decode.d8.loss_mask: 1.0629  decode.d8.loss_dice: 1.1704
2025/03/29 18:37:01 - mmengine - INFO - Iter(train) [12650/20000]  base_lr: 4.0621e-05 lr: 4.0621e-05  eta: 3:42:30  time: 1.1122  data_time: 0.0206  memory: 10133  loss: 24.0328  decode.loss_cls: 0.1829  decode.loss_mask: 1.0526  decode.loss_dice: 1.1857  decode.d0.loss_cls: 0.2770  decode.d0.loss_mask: 1.0009  decode.d0.loss_dice: 1.2368  decode.d1.loss_cls: 0.2853  decode.d1.loss_mask: 1.0075  decode.d1.loss_dice: 1.1543  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.0046  decode.d2.loss_dice: 1.1765  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 1.0007  decode.d3.loss_dice: 1.1383  decode.d4.loss_cls: 0.2144  decode.d4.loss_mask: 1.0043  decode.d4.loss_dice: 1.1762  decode.d5.loss_cls: 0.1911  decode.d5.loss_mask: 0.9996  decode.d5.loss_dice: 1.1609  decode.d6.loss_cls: 0.2148  decode.d6.loss_mask: 0.9880  decode.d6.loss_dice: 1.1539  decode.d7.loss_cls: 0.2328  decode.d7.loss_mask: 0.9871  decode.d7.loss_dice: 1.1765  decode.d8.loss_cls: 0.2126  decode.d8.loss_mask: 1.0427  decode.d8.loss_dice: 1.1573
2025/03/29 18:37:57 - mmengine - INFO - Iter(train) [12700/20000]  base_lr: 4.0372e-05 lr: 4.0372e-05  eta: 3:40:39  time: 1.1136  data_time: 0.0206  memory: 10137  loss: 25.1903  decode.loss_cls: 0.2049  decode.loss_mask: 1.0826  decode.loss_dice: 1.2129  decode.d0.loss_cls: 0.2432  decode.d0.loss_mask: 1.0901  decode.d0.loss_dice: 1.2839  decode.d1.loss_cls: 0.2372  decode.d1.loss_mask: 1.0806  decode.d1.loss_dice: 1.2114  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 1.0900  decode.d2.loss_dice: 1.2287  decode.d3.loss_cls: 0.1863  decode.d3.loss_mask: 1.1094  decode.d3.loss_dice: 1.2121  decode.d4.loss_cls: 0.1869  decode.d4.loss_mask: 1.0963  decode.d4.loss_dice: 1.2163  decode.d5.loss_cls: 0.2216  decode.d5.loss_mask: 1.0968  decode.d5.loss_dice: 1.2004  decode.d6.loss_cls: 0.1995  decode.d6.loss_mask: 1.0965  decode.d6.loss_dice: 1.2178  decode.d7.loss_cls: 0.2074  decode.d7.loss_mask: 1.0803  decode.d7.loss_dice: 1.2225  decode.d8.loss_cls: 0.2328  decode.d8.loss_mask: 1.0762  decode.d8.loss_dice: 1.2008
2025/03/29 18:38:53 - mmengine - INFO - Iter(train) [12750/20000]  base_lr: 4.0123e-05 lr: 4.0123e-05  eta: 3:38:48  time: 1.1150  data_time: 0.0198  memory: 10126  loss: 23.0812  decode.loss_cls: 0.1544  decode.loss_mask: 1.0365  decode.loss_dice: 1.1005  decode.d0.loss_cls: 0.2113  decode.d0.loss_mask: 1.0311  decode.d0.loss_dice: 1.1087  decode.d1.loss_cls: 0.1594  decode.d1.loss_mask: 1.0438  decode.d1.loss_dice: 1.1024  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 1.0410  decode.d2.loss_dice: 1.0916  decode.d3.loss_cls: 0.1765  decode.d3.loss_mask: 1.0305  decode.d3.loss_dice: 1.1011  decode.d4.loss_cls: 0.1842  decode.d4.loss_mask: 1.0330  decode.d4.loss_dice: 1.1066  decode.d5.loss_cls: 0.1530  decode.d5.loss_mask: 1.0444  decode.d5.loss_dice: 1.1118  decode.d6.loss_cls: 0.1643  decode.d6.loss_mask: 1.0299  decode.d6.loss_dice: 1.1154  decode.d7.loss_cls: 0.1536  decode.d7.loss_mask: 1.0427  decode.d7.loss_dice: 1.1099  decode.d8.loss_cls: 0.1723  decode.d8.loss_mask: 1.0163  decode.d8.loss_dice: 1.0928
2025/03/29 18:39:49 - mmengine - INFO - Iter(train) [12800/20000]  base_lr: 3.9874e-05 lr: 3.9874e-05  eta: 3:36:58  time: 1.1156  data_time: 0.0210  memory: 10071  loss: 24.9577  decode.loss_cls: 0.1628  decode.loss_mask: 1.1351  decode.loss_dice: 1.1853  decode.d0.loss_cls: 0.2097  decode.d0.loss_mask: 1.1712  decode.d0.loss_dice: 1.2399  decode.d1.loss_cls: 0.1956  decode.d1.loss_mask: 1.1437  decode.d1.loss_dice: 1.1880  decode.d2.loss_cls: 0.1632  decode.d2.loss_mask: 1.1214  decode.d2.loss_dice: 1.1627  decode.d3.loss_cls: 0.1707  decode.d3.loss_mask: 1.1171  decode.d3.loss_dice: 1.1731  decode.d4.loss_cls: 0.1590  decode.d4.loss_mask: 1.1355  decode.d4.loss_dice: 1.1937  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 1.1314  decode.d5.loss_dice: 1.1936  decode.d6.loss_cls: 0.1404  decode.d6.loss_mask: 1.1365  decode.d6.loss_dice: 1.1821  decode.d7.loss_cls: 0.1575  decode.d7.loss_mask: 1.1333  decode.d7.loss_dice: 1.1910  decode.d8.loss_cls: 0.1828  decode.d8.loss_mask: 1.1297  decode.d8.loss_dice: 1.1845
2025/03/29 18:40:45 - mmengine - INFO - Iter(train) [12850/20000]  base_lr: 3.9625e-05 lr: 3.9625e-05  eta: 3:35:08  time: 1.1247  data_time: 0.0214  memory: 10117  loss: 24.6419  decode.loss_cls: 0.2383  decode.loss_mask: 1.0721  decode.loss_dice: 1.1677  decode.d0.loss_cls: 0.2946  decode.d0.loss_mask: 1.1001  decode.d0.loss_dice: 1.1837  decode.d1.loss_cls: 0.2584  decode.d1.loss_mask: 1.0767  decode.d1.loss_dice: 1.1557  decode.d2.loss_cls: 0.2228  decode.d2.loss_mask: 1.0712  decode.d2.loss_dice: 1.1381  decode.d3.loss_cls: 0.2701  decode.d3.loss_mask: 1.0636  decode.d3.loss_dice: 1.1102  decode.d4.loss_cls: 0.2672  decode.d4.loss_mask: 1.0587  decode.d4.loss_dice: 1.1553  decode.d5.loss_cls: 0.2420  decode.d5.loss_mask: 1.0801  decode.d5.loss_dice: 1.1439  decode.d6.loss_cls: 0.2693  decode.d6.loss_mask: 1.0263  decode.d6.loss_dice: 1.1176  decode.d7.loss_cls: 0.2371  decode.d7.loss_mask: 1.0537  decode.d7.loss_dice: 1.1215  decode.d8.loss_cls: 0.2488  decode.d8.loss_mask: 1.0493  decode.d8.loss_dice: 1.1478
2025/03/29 18:41:41 - mmengine - INFO - Iter(train) [12900/20000]  base_lr: 3.9375e-05 lr: 3.9375e-05  eta: 3:33:19  time: 1.1164  data_time: 0.0206  memory: 10118  loss: 21.0930  decode.loss_cls: 0.1518  decode.loss_mask: 0.8585  decode.loss_dice: 1.0817  decode.d0.loss_cls: 0.2040  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 1.1610  decode.d1.loss_cls: 0.1479  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 1.0990  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.8814  decode.d2.loss_dice: 1.1003  decode.d3.loss_cls: 0.1640  decode.d3.loss_mask: 0.8639  decode.d3.loss_dice: 1.0803  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.8561  decode.d4.loss_dice: 1.0772  decode.d5.loss_cls: 0.1429  decode.d5.loss_mask: 0.8685  decode.d5.loss_dice: 1.0846  decode.d6.loss_cls: 0.0918  decode.d6.loss_mask: 0.8859  decode.d6.loss_dice: 1.1135  decode.d7.loss_cls: 0.1157  decode.d7.loss_mask: 0.8709  decode.d7.loss_dice: 1.0815  decode.d8.loss_cls: 0.1384  decode.d8.loss_mask: 0.8755  decode.d8.loss_dice: 1.0880
2025/03/29 18:42:36 - mmengine - INFO - Iter(train) [12950/20000]  base_lr: 3.9126e-05 lr: 3.9126e-05  eta: 3:31:30  time: 1.1167  data_time: 0.0206  memory: 10124  loss: 25.0625  decode.loss_cls: 0.2058  decode.loss_mask: 1.0571  decode.loss_dice: 1.2217  decode.d0.loss_cls: 0.1409  decode.d0.loss_mask: 1.0805  decode.d0.loss_dice: 1.3236  decode.d1.loss_cls: 0.2282  decode.d1.loss_mask: 1.0595  decode.d1.loss_dice: 1.2645  decode.d2.loss_cls: 0.2331  decode.d2.loss_mask: 1.0540  decode.d2.loss_dice: 1.2361  decode.d3.loss_cls: 0.1935  decode.d3.loss_mask: 1.0689  decode.d3.loss_dice: 1.2416  decode.d4.loss_cls: 0.1581  decode.d4.loss_mask: 1.0761  decode.d4.loss_dice: 1.2608  decode.d5.loss_cls: 0.2149  decode.d5.loss_mask: 1.0640  decode.d5.loss_dice: 1.2480  decode.d6.loss_cls: 0.1539  decode.d6.loss_mask: 1.0698  decode.d6.loss_dice: 1.2574  decode.d7.loss_cls: 0.1955  decode.d7.loss_mask: 1.0621  decode.d7.loss_dice: 1.2292  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 1.0628  decode.d8.loss_dice: 1.2300
2025/03/29 18:43:32 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 18:43:32 - mmengine - INFO - Iter(train) [13000/20000]  base_lr: 3.8876e-05 lr: 3.8876e-05  eta: 3:29:42  time: 1.1138  data_time: 0.0199  memory: 10124  loss: 21.8288  decode.loss_cls: 0.1681  decode.loss_mask: 0.9073  decode.loss_dice: 1.0513  decode.d0.loss_cls: 0.2216  decode.d0.loss_mask: 0.9578  decode.d0.loss_dice: 1.1340  decode.d1.loss_cls: 0.1880  decode.d1.loss_mask: 0.9374  decode.d1.loss_dice: 1.0878  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 0.9209  decode.d2.loss_dice: 1.0764  decode.d3.loss_cls: 0.1614  decode.d3.loss_mask: 0.9019  decode.d3.loss_dice: 1.0594  decode.d4.loss_cls: 0.1521  decode.d4.loss_mask: 0.9316  decode.d4.loss_dice: 1.1000  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.9227  decode.d5.loss_dice: 1.0931  decode.d6.loss_cls: 0.1736  decode.d6.loss_mask: 0.9249  decode.d6.loss_dice: 1.0756  decode.d7.loss_cls: 0.1673  decode.d7.loss_mask: 0.9180  decode.d7.loss_dice: 1.0879  decode.d8.loss_cls: 0.1446  decode.d8.loss_mask: 0.9375  decode.d8.loss_dice: 1.0725
2025/03/29 18:44:28 - mmengine - INFO - Iter(train) [13050/20000]  base_lr: 3.8626e-05 lr: 3.8626e-05  eta: 3:27:54  time: 1.1142  data_time: 0.0201  memory: 10129  loss: 22.9474  decode.loss_cls: 0.2466  decode.loss_mask: 0.9194  decode.loss_dice: 1.1067  decode.d0.loss_cls: 0.2234  decode.d0.loss_mask: 0.9601  decode.d0.loss_dice: 1.1790  decode.d1.loss_cls: 0.2382  decode.d1.loss_mask: 0.9267  decode.d1.loss_dice: 1.1576  decode.d2.loss_cls: 0.2407  decode.d2.loss_mask: 0.9302  decode.d2.loss_dice: 1.1263  decode.d3.loss_cls: 0.2168  decode.d3.loss_mask: 0.9312  decode.d3.loss_dice: 1.1198  decode.d4.loss_cls: 0.2163  decode.d4.loss_mask: 0.9185  decode.d4.loss_dice: 1.1396  decode.d5.loss_cls: 0.2417  decode.d5.loss_mask: 0.9399  decode.d5.loss_dice: 1.1296  decode.d6.loss_cls: 0.2195  decode.d6.loss_mask: 0.9261  decode.d6.loss_dice: 1.1340  decode.d7.loss_cls: 0.2218  decode.d7.loss_mask: 0.9333  decode.d7.loss_dice: 1.1298  decode.d8.loss_cls: 0.2408  decode.d8.loss_mask: 0.9207  decode.d8.loss_dice: 1.1131
2025/03/29 18:45:24 - mmengine - INFO - Iter(train) [13100/20000]  base_lr: 3.8376e-05 lr: 3.8376e-05  eta: 3:26:06  time: 1.1123  data_time: 0.0201  memory: 10134  loss: 22.9632  decode.loss_cls: 0.2282  decode.loss_mask: 0.9417  decode.loss_dice: 1.1166  decode.d0.loss_cls: 0.2246  decode.d0.loss_mask: 0.9293  decode.d0.loss_dice: 1.2037  decode.d1.loss_cls: 0.2304  decode.d1.loss_mask: 0.9320  decode.d1.loss_dice: 1.1492  decode.d2.loss_cls: 0.1984  decode.d2.loss_mask: 0.9485  decode.d2.loss_dice: 1.1712  decode.d3.loss_cls: 0.2168  decode.d3.loss_mask: 0.9358  decode.d3.loss_dice: 1.0921  decode.d4.loss_cls: 0.2109  decode.d4.loss_mask: 0.9374  decode.d4.loss_dice: 1.1160  decode.d5.loss_cls: 0.2346  decode.d5.loss_mask: 0.9388  decode.d5.loss_dice: 1.1248  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 0.9418  decode.d6.loss_dice: 1.1401  decode.d7.loss_cls: 0.2338  decode.d7.loss_mask: 0.9372  decode.d7.loss_dice: 1.1312  decode.d8.loss_cls: 0.2378  decode.d8.loss_mask: 0.9417  decode.d8.loss_dice: 1.1114
2025/03/29 18:46:20 - mmengine - INFO - Iter(train) [13150/20000]  base_lr: 3.8125e-05 lr: 3.8125e-05  eta: 3:24:19  time: 1.1152  data_time: 0.0213  memory: 10129  loss: 26.2256  decode.loss_cls: 0.1766  decode.loss_mask: 1.2422  decode.loss_dice: 1.2251  decode.d0.loss_cls: 0.2115  decode.d0.loss_mask: 1.2531  decode.d0.loss_dice: 1.2870  decode.d1.loss_cls: 0.2102  decode.d1.loss_mask: 1.2332  decode.d1.loss_dice: 1.2146  decode.d2.loss_cls: 0.2002  decode.d2.loss_mask: 1.2220  decode.d2.loss_dice: 1.1725  decode.d3.loss_cls: 0.1965  decode.d3.loss_mask: 1.2387  decode.d3.loss_dice: 1.2050  decode.d4.loss_cls: 0.1771  decode.d4.loss_mask: 1.2296  decode.d4.loss_dice: 1.1990  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 1.2187  decode.d5.loss_dice: 1.2104  decode.d6.loss_cls: 0.1594  decode.d6.loss_mask: 1.2194  decode.d6.loss_dice: 1.1919  decode.d7.loss_cls: 0.1618  decode.d7.loss_mask: 1.2202  decode.d7.loss_dice: 1.2068  decode.d8.loss_cls: 0.1563  decode.d8.loss_mask: 1.2224  decode.d8.loss_dice: 1.2027
2025/03/29 18:47:15 - mmengine - INFO - Iter(train) [13200/20000]  base_lr: 3.7875e-05 lr: 3.7875e-05  eta: 3:22:32  time: 1.1163  data_time: 0.0201  memory: 10119  loss: 26.7828  decode.loss_cls: 0.1601  decode.loss_mask: 1.1836  decode.loss_dice: 1.2930  decode.d0.loss_cls: 0.3095  decode.d0.loss_mask: 1.1577  decode.d0.loss_dice: 1.3465  decode.d1.loss_cls: 0.3004  decode.d1.loss_mask: 1.1326  decode.d1.loss_dice: 1.2580  decode.d2.loss_cls: 0.2815  decode.d2.loss_mask: 1.1506  decode.d2.loss_dice: 1.2468  decode.d3.loss_cls: 0.2472  decode.d3.loss_mask: 1.1323  decode.d3.loss_dice: 1.2588  decode.d4.loss_cls: 0.2213  decode.d4.loss_mask: 1.1687  decode.d4.loss_dice: 1.3055  decode.d5.loss_cls: 0.1882  decode.d5.loss_mask: 1.1590  decode.d5.loss_dice: 1.3024  decode.d6.loss_cls: 0.1841  decode.d6.loss_mask: 1.1609  decode.d6.loss_dice: 1.3018  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 1.1674  decode.d7.loss_dice: 1.2939  decode.d8.loss_cls: 0.1639  decode.d8.loss_mask: 1.1923  decode.d8.loss_dice: 1.3072
2025/03/29 18:48:11 - mmengine - INFO - Iter(train) [13250/20000]  base_lr: 3.7624e-05 lr: 3.7624e-05  eta: 3:20:46  time: 1.1115  data_time: 0.0199  memory: 10126  loss: 21.0642  decode.loss_cls: 0.1533  decode.loss_mask: 0.9223  decode.loss_dice: 1.0177  decode.d0.loss_cls: 0.1927  decode.d0.loss_mask: 0.9432  decode.d0.loss_dice: 1.1179  decode.d1.loss_cls: 0.1651  decode.d1.loss_mask: 0.9126  decode.d1.loss_dice: 1.0378  decode.d2.loss_cls: 0.2067  decode.d2.loss_mask: 0.9114  decode.d2.loss_dice: 1.0075  decode.d3.loss_cls: 0.2006  decode.d3.loss_mask: 0.8972  decode.d3.loss_dice: 0.9872  decode.d4.loss_cls: 0.1764  decode.d4.loss_mask: 0.9049  decode.d4.loss_dice: 0.9985  decode.d5.loss_cls: 0.2136  decode.d5.loss_mask: 0.8868  decode.d5.loss_dice: 0.9837  decode.d6.loss_cls: 0.1782  decode.d6.loss_mask: 0.8924  decode.d6.loss_dice: 1.0056  decode.d7.loss_cls: 0.1828  decode.d7.loss_mask: 0.8840  decode.d7.loss_dice: 0.9974  decode.d8.loss_cls: 0.1531  decode.d8.loss_mask: 0.9080  decode.d8.loss_dice: 1.0256
2025/03/29 18:49:07 - mmengine - INFO - Iter(train) [13300/20000]  base_lr: 3.7373e-05 lr: 3.7373e-05  eta: 3:19:00  time: 1.1191  data_time: 0.0205  memory: 10134  loss: 21.6041  decode.loss_cls: 0.1671  decode.loss_mask: 0.9329  decode.loss_dice: 1.0456  decode.d0.loss_cls: 0.2466  decode.d0.loss_mask: 0.9504  decode.d0.loss_dice: 1.0844  decode.d1.loss_cls: 0.2248  decode.d1.loss_mask: 0.9273  decode.d1.loss_dice: 1.0266  decode.d2.loss_cls: 0.1836  decode.d2.loss_mask: 0.9278  decode.d2.loss_dice: 1.0091  decode.d3.loss_cls: 0.1733  decode.d3.loss_mask: 0.9286  decode.d3.loss_dice: 1.0177  decode.d4.loss_cls: 0.1826  decode.d4.loss_mask: 0.9179  decode.d4.loss_dice: 1.0412  decode.d5.loss_cls: 0.1931  decode.d5.loss_mask: 0.9179  decode.d5.loss_dice: 1.0477  decode.d6.loss_cls: 0.1818  decode.d6.loss_mask: 0.9279  decode.d6.loss_dice: 1.0428  decode.d7.loss_cls: 0.1975  decode.d7.loss_mask: 0.9239  decode.d7.loss_dice: 1.0302  decode.d8.loss_cls: 0.2012  decode.d8.loss_mask: 0.9214  decode.d8.loss_dice: 1.0314
2025/03/29 18:50:03 - mmengine - INFO - Iter(train) [13350/20000]  base_lr: 3.7122e-05 lr: 3.7122e-05  eta: 3:17:14  time: 1.1169  data_time: 0.0203  memory: 10119  loss: 23.2192  decode.loss_cls: 0.2189  decode.loss_mask: 0.9736  decode.loss_dice: 1.1419  decode.d0.loss_cls: 0.2216  decode.d0.loss_mask: 0.9722  decode.d0.loss_dice: 1.1626  decode.d1.loss_cls: 0.2215  decode.d1.loss_mask: 0.9607  decode.d1.loss_dice: 1.1404  decode.d2.loss_cls: 0.2234  decode.d2.loss_mask: 0.9591  decode.d2.loss_dice: 1.1291  decode.d3.loss_cls: 0.2151  decode.d3.loss_mask: 0.9636  decode.d3.loss_dice: 1.1305  decode.d4.loss_cls: 0.2320  decode.d4.loss_mask: 0.9728  decode.d4.loss_dice: 1.1370  decode.d5.loss_cls: 0.2068  decode.d5.loss_mask: 0.9707  decode.d5.loss_dice: 1.1177  decode.d6.loss_cls: 0.2101  decode.d6.loss_mask: 0.9730  decode.d6.loss_dice: 1.1090  decode.d7.loss_cls: 0.2109  decode.d7.loss_mask: 0.9739  decode.d7.loss_dice: 1.1505  decode.d8.loss_cls: 0.2377  decode.d8.loss_mask: 0.9734  decode.d8.loss_dice: 1.1093
2025/03/29 18:50:59 - mmengine - INFO - Iter(train) [13400/20000]  base_lr: 3.6871e-05 lr: 3.6871e-05  eta: 3:15:29  time: 1.1103  data_time: 0.0197  memory: 10122  loss: 21.5212  decode.loss_cls: 0.1684  decode.loss_mask: 0.9359  decode.loss_dice: 1.0225  decode.d0.loss_cls: 0.2005  decode.d0.loss_mask: 0.9807  decode.d0.loss_dice: 1.1038  decode.d1.loss_cls: 0.1948  decode.d1.loss_mask: 0.9368  decode.d1.loss_dice: 1.0303  decode.d2.loss_cls: 0.1683  decode.d2.loss_mask: 0.9300  decode.d2.loss_dice: 1.0390  decode.d3.loss_cls: 0.2046  decode.d3.loss_mask: 0.9319  decode.d3.loss_dice: 1.0200  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 0.9322  decode.d4.loss_dice: 1.0442  decode.d5.loss_cls: 0.1550  decode.d5.loss_mask: 0.9388  decode.d5.loss_dice: 1.0365  decode.d6.loss_cls: 0.1687  decode.d6.loss_mask: 0.9478  decode.d6.loss_dice: 1.0160  decode.d7.loss_cls: 0.1621  decode.d7.loss_mask: 0.9237  decode.d7.loss_dice: 1.0285  decode.d8.loss_cls: 0.1461  decode.d8.loss_mask: 0.9436  decode.d8.loss_dice: 1.0569
2025/03/29 18:51:55 - mmengine - INFO - Iter(train) [13450/20000]  base_lr: 3.6619e-05 lr: 3.6619e-05  eta: 3:13:44  time: 1.1192  data_time: 0.0213  memory: 10125  loss: 23.2446  decode.loss_cls: 0.1324  decode.loss_mask: 1.0180  decode.loss_dice: 1.1613  decode.d0.loss_cls: 0.2382  decode.d0.loss_mask: 1.0123  decode.d0.loss_dice: 1.1772  decode.d1.loss_cls: 0.1673  decode.d1.loss_mask: 0.9983  decode.d1.loss_dice: 1.1647  decode.d2.loss_cls: 0.1542  decode.d2.loss_mask: 1.0079  decode.d2.loss_dice: 1.1637  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 1.0094  decode.d3.loss_dice: 1.1658  decode.d4.loss_cls: 0.1399  decode.d4.loss_mask: 1.0120  decode.d4.loss_dice: 1.1691  decode.d5.loss_cls: 0.1852  decode.d5.loss_mask: 0.9974  decode.d5.loss_dice: 1.1360  decode.d6.loss_cls: 0.1458  decode.d6.loss_mask: 1.0026  decode.d6.loss_dice: 1.1516  decode.d7.loss_cls: 0.1166  decode.d7.loss_mask: 1.0166  decode.d7.loss_dice: 1.1690  decode.d8.loss_cls: 0.1278  decode.d8.loss_mask: 1.0140  decode.d8.loss_dice: 1.1500
2025/03/29 18:52:51 - mmengine - INFO - Iter(train) [13500/20000]  base_lr: 3.6368e-05 lr: 3.6368e-05  eta: 3:11:59  time: 1.1125  data_time: 0.0201  memory: 10125  loss: 19.8545  decode.loss_cls: 0.1537  decode.loss_mask: 0.8348  decode.loss_dice: 0.9801  decode.d0.loss_cls: 0.1969  decode.d0.loss_mask: 0.8379  decode.d0.loss_dice: 1.0401  decode.d1.loss_cls: 0.1907  decode.d1.loss_mask: 0.8265  decode.d1.loss_dice: 0.9711  decode.d2.loss_cls: 0.2208  decode.d2.loss_mask: 0.8260  decode.d2.loss_dice: 0.9947  decode.d3.loss_cls: 0.1560  decode.d3.loss_mask: 0.8314  decode.d3.loss_dice: 0.9884  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.8314  decode.d4.loss_dice: 0.9850  decode.d5.loss_cls: 0.1925  decode.d5.loss_mask: 0.8313  decode.d5.loss_dice: 0.9667  decode.d6.loss_cls: 0.1269  decode.d6.loss_mask: 0.8309  decode.d6.loss_dice: 0.9791  decode.d7.loss_cls: 0.1239  decode.d7.loss_mask: 0.8378  decode.d7.loss_dice: 0.9725  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 0.8375  decode.d8.loss_dice: 1.0075
2025/03/29 18:53:46 - mmengine - INFO - Iter(train) [13550/20000]  base_lr: 3.6116e-05 lr: 3.6116e-05  eta: 3:10:15  time: 1.1098  data_time: 0.0198  memory: 10121  loss: 23.5558  decode.loss_cls: 0.1891  decode.loss_mask: 1.0840  decode.loss_dice: 1.0588  decode.d0.loss_cls: 0.2197  decode.d0.loss_mask: 1.1166  decode.d0.loss_dice: 1.1299  decode.d1.loss_cls: 0.1837  decode.d1.loss_mask: 1.0844  decode.d1.loss_dice: 1.0721  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 1.0863  decode.d2.loss_dice: 1.0843  decode.d3.loss_cls: 0.1720  decode.d3.loss_mask: 1.0878  decode.d3.loss_dice: 1.0892  decode.d4.loss_cls: 0.1918  decode.d4.loss_mask: 1.0833  decode.d4.loss_dice: 1.0750  decode.d5.loss_cls: 0.1859  decode.d5.loss_mask: 1.0922  decode.d5.loss_dice: 1.0633  decode.d6.loss_cls: 0.1624  decode.d6.loss_mask: 1.0937  decode.d6.loss_dice: 1.0698  decode.d7.loss_cls: 0.1636  decode.d7.loss_mask: 1.0804  decode.d7.loss_dice: 1.0713  decode.d8.loss_cls: 0.1910  decode.d8.loss_mask: 1.0908  decode.d8.loss_dice: 1.0770
2025/03/29 18:54:42 - mmengine - INFO - Iter(train) [13600/20000]  base_lr: 3.5864e-05 lr: 3.5864e-05  eta: 3:08:31  time: 1.1160  data_time: 0.0216  memory: 10124  loss: 23.0498  decode.loss_cls: 0.2881  decode.loss_mask: 0.9293  decode.loss_dice: 1.1002  decode.d0.loss_cls: 0.2745  decode.d0.loss_mask: 0.9431  decode.d0.loss_dice: 1.1608  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 0.9253  decode.d1.loss_dice: 1.1061  decode.d2.loss_cls: 0.2991  decode.d2.loss_mask: 0.9219  decode.d2.loss_dice: 1.0601  decode.d3.loss_cls: 0.3080  decode.d3.loss_mask: 0.9125  decode.d3.loss_dice: 1.0829  decode.d4.loss_cls: 0.3187  decode.d4.loss_mask: 0.9223  decode.d4.loss_dice: 1.0893  decode.d5.loss_cls: 0.2289  decode.d5.loss_mask: 0.9213  decode.d5.loss_dice: 1.0844  decode.d6.loss_cls: 0.3009  decode.d6.loss_mask: 0.9254  decode.d6.loss_dice: 1.1034  decode.d7.loss_cls: 0.2964  decode.d7.loss_mask: 0.9162  decode.d7.loss_dice: 1.0456  decode.d8.loss_cls: 0.2649  decode.d8.loss_mask: 0.9344  decode.d8.loss_dice: 1.0907
2025/03/29 18:55:38 - mmengine - INFO - Iter(train) [13650/20000]  base_lr: 3.5611e-05 lr: 3.5611e-05  eta: 3:06:48  time: 1.1138  data_time: 0.0200  memory: 10129  loss: 24.4041  decode.loss_cls: 0.2056  decode.loss_mask: 1.0544  decode.loss_dice: 1.1643  decode.d0.loss_cls: 0.3093  decode.d0.loss_mask: 1.0633  decode.d0.loss_dice: 1.1870  decode.d1.loss_cls: 0.2772  decode.d1.loss_mask: 1.0411  decode.d1.loss_dice: 1.1493  decode.d2.loss_cls: 0.2572  decode.d2.loss_mask: 1.0312  decode.d2.loss_dice: 1.1200  decode.d3.loss_cls: 0.2007  decode.d3.loss_mask: 1.0570  decode.d3.loss_dice: 1.1776  decode.d4.loss_cls: 0.2047  decode.d4.loss_mask: 1.0565  decode.d4.loss_dice: 1.1498  decode.d5.loss_cls: 0.2090  decode.d5.loss_mask: 1.0542  decode.d5.loss_dice: 1.1731  decode.d6.loss_cls: 0.2197  decode.d6.loss_mask: 1.0511  decode.d6.loss_dice: 1.1465  decode.d7.loss_cls: 0.2053  decode.d7.loss_mask: 1.0639  decode.d7.loss_dice: 1.1512  decode.d8.loss_cls: 0.2101  decode.d8.loss_mask: 1.0516  decode.d8.loss_dice: 1.1624
2025/03/29 18:56:34 - mmengine - INFO - Iter(train) [13700/20000]  base_lr: 3.5359e-05 lr: 3.5359e-05  eta: 3:05:05  time: 1.1094  data_time: 0.0199  memory: 10118  loss: 21.0789  decode.loss_cls: 0.0871  decode.loss_mask: 0.9702  decode.loss_dice: 1.0225  decode.d0.loss_cls: 0.1907  decode.d0.loss_mask: 0.9581  decode.d0.loss_dice: 1.0655  decode.d1.loss_cls: 0.1657  decode.d1.loss_mask: 0.9589  decode.d1.loss_dice: 1.0211  decode.d2.loss_cls: 0.1320  decode.d2.loss_mask: 0.9591  decode.d2.loss_dice: 0.9974  decode.d3.loss_cls: 0.1664  decode.d3.loss_mask: 0.9472  decode.d3.loss_dice: 0.9966  decode.d4.loss_cls: 0.1557  decode.d4.loss_mask: 0.9527  decode.d4.loss_dice: 1.0009  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.9350  decode.d5.loss_dice: 0.9744  decode.d6.loss_cls: 0.1530  decode.d6.loss_mask: 0.9408  decode.d6.loss_dice: 0.9846  decode.d7.loss_cls: 0.1360  decode.d7.loss_mask: 0.9440  decode.d7.loss_dice: 0.9951  decode.d8.loss_cls: 0.1300  decode.d8.loss_mask: 0.9527  decode.d8.loss_dice: 1.0125
2025/03/29 18:57:29 - mmengine - INFO - Iter(train) [13750/20000]  base_lr: 3.5106e-05 lr: 3.5106e-05  eta: 3:03:22  time: 1.1130  data_time: 0.0201  memory: 10126  loss: 26.2040  decode.loss_cls: 0.3196  decode.loss_mask: 1.1067  decode.loss_dice: 1.1826  decode.d0.loss_cls: 0.2797  decode.d0.loss_mask: 1.1119  decode.d0.loss_dice: 1.2879  decode.d1.loss_cls: 0.3138  decode.d1.loss_mask: 1.1101  decode.d1.loss_dice: 1.2145  decode.d2.loss_cls: 0.3102  decode.d2.loss_mask: 1.1140  decode.d2.loss_dice: 1.1974  decode.d3.loss_cls: 0.2926  decode.d3.loss_mask: 1.1012  decode.d3.loss_dice: 1.1862  decode.d4.loss_cls: 0.2832  decode.d4.loss_mask: 1.1089  decode.d4.loss_dice: 1.2092  decode.d5.loss_cls: 0.3091  decode.d5.loss_mask: 1.1315  decode.d5.loss_dice: 1.1953  decode.d6.loss_cls: 0.3440  decode.d6.loss_mask: 1.0957  decode.d6.loss_dice: 1.1847  decode.d7.loss_cls: 0.3387  decode.d7.loss_mask: 1.0905  decode.d7.loss_dice: 1.1808  decode.d8.loss_cls: 0.3199  decode.d8.loss_mask: 1.0976  decode.d8.loss_dice: 1.1863
2025/03/29 18:58:25 - mmengine - INFO - Iter(train) [13800/20000]  base_lr: 3.4853e-05 lr: 3.4853e-05  eta: 3:01:39  time: 1.1230  data_time: 0.0208  memory: 10131  loss: 21.9646  decode.loss_cls: 0.1541  decode.loss_mask: 0.9755  decode.loss_dice: 1.0444  decode.d0.loss_cls: 0.1760  decode.d0.loss_mask: 0.9665  decode.d0.loss_dice: 1.1259  decode.d1.loss_cls: 0.2057  decode.d1.loss_mask: 0.9723  decode.d1.loss_dice: 1.0443  decode.d2.loss_cls: 0.1381  decode.d2.loss_mask: 0.9845  decode.d2.loss_dice: 1.0619  decode.d3.loss_cls: 0.1544  decode.d3.loss_mask: 0.9896  decode.d3.loss_dice: 1.0625  decode.d4.loss_cls: 0.1430  decode.d4.loss_mask: 0.9793  decode.d4.loss_dice: 1.0739  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.9791  decode.d5.loss_dice: 1.0481  decode.d6.loss_cls: 0.1398  decode.d6.loss_mask: 0.9845  decode.d6.loss_dice: 1.0579  decode.d7.loss_cls: 0.1539  decode.d7.loss_mask: 0.9780  decode.d7.loss_dice: 1.0469  decode.d8.loss_cls: 0.1432  decode.d8.loss_mask: 0.9829  decode.d8.loss_dice: 1.0648
2025/03/29 18:59:21 - mmengine - INFO - Iter(train) [13850/20000]  base_lr: 3.4600e-05 lr: 3.4600e-05  eta: 2:59:57  time: 1.1125  data_time: 0.0202  memory: 10122  loss: 23.0321  decode.loss_cls: 0.2541  decode.loss_mask: 0.9800  decode.loss_dice: 1.0300  decode.d0.loss_cls: 0.3270  decode.d0.loss_mask: 0.9944  decode.d0.loss_dice: 1.1439  decode.d1.loss_cls: 0.3351  decode.d1.loss_mask: 0.9673  decode.d1.loss_dice: 1.0553  decode.d2.loss_cls: 0.2769  decode.d2.loss_mask: 0.9651  decode.d2.loss_dice: 1.0514  decode.d3.loss_cls: 0.2621  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.0553  decode.d4.loss_cls: 0.2485  decode.d4.loss_mask: 0.9519  decode.d4.loss_dice: 1.0532  decode.d5.loss_cls: 0.2718  decode.d5.loss_mask: 0.9507  decode.d5.loss_dice: 1.0257  decode.d6.loss_cls: 0.2816  decode.d6.loss_mask: 0.9767  decode.d6.loss_dice: 1.0331  decode.d7.loss_cls: 0.2909  decode.d7.loss_mask: 0.9772  decode.d7.loss_dice: 1.0415  decode.d8.loss_cls: 0.2560  decode.d8.loss_mask: 0.9729  decode.d8.loss_dice: 1.0349
2025/03/29 19:00:17 - mmengine - INFO - Iter(train) [13900/20000]  base_lr: 3.4347e-05 lr: 3.4347e-05  eta: 2:58:15  time: 1.1108  data_time: 0.0199  memory: 10124  loss: 21.6740  decode.loss_cls: 0.1983  decode.loss_mask: 0.9225  decode.loss_dice: 1.0496  decode.d0.loss_cls: 0.1579  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 1.1519  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.9373  decode.d1.loss_dice: 1.1021  decode.d2.loss_cls: 0.1775  decode.d2.loss_mask: 0.9322  decode.d2.loss_dice: 1.0570  decode.d3.loss_cls: 0.1573  decode.d3.loss_mask: 0.9326  decode.d3.loss_dice: 1.0567  decode.d4.loss_cls: 0.2000  decode.d4.loss_mask: 0.9060  decode.d4.loss_dice: 1.0500  decode.d5.loss_cls: 0.1888  decode.d5.loss_mask: 0.9201  decode.d5.loss_dice: 1.0465  decode.d6.loss_cls: 0.1579  decode.d6.loss_mask: 0.9253  decode.d6.loss_dice: 1.0648  decode.d7.loss_cls: 0.2097  decode.d7.loss_mask: 0.9249  decode.d7.loss_dice: 1.0387  decode.d8.loss_cls: 0.1814  decode.d8.loss_mask: 0.9207  decode.d8.loss_dice: 1.0461
2025/03/29 19:01:13 - mmengine - INFO - Iter(train) [13950/20000]  base_lr: 3.4094e-05 lr: 3.4094e-05  eta: 2:56:34  time: 1.1124  data_time: 0.0196  memory: 10124  loss: 23.3807  decode.loss_cls: 0.1941  decode.loss_mask: 1.0628  decode.loss_dice: 1.0660  decode.d0.loss_cls: 0.2797  decode.d0.loss_mask: 1.0677  decode.d0.loss_dice: 1.0899  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 1.0403  decode.d1.loss_dice: 1.0771  decode.d2.loss_cls: 0.2123  decode.d2.loss_mask: 1.0458  decode.d2.loss_dice: 1.0523  decode.d3.loss_cls: 0.1947  decode.d3.loss_mask: 1.0616  decode.d3.loss_dice: 1.0643  decode.d4.loss_cls: 0.1725  decode.d4.loss_mask: 1.0616  decode.d4.loss_dice: 1.0866  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 1.0745  decode.d5.loss_dice: 1.0723  decode.d6.loss_cls: 0.1796  decode.d6.loss_mask: 1.0622  decode.d6.loss_dice: 1.0750  decode.d7.loss_cls: 0.2131  decode.d7.loss_mask: 1.0636  decode.d7.loss_dice: 1.0577  decode.d8.loss_cls: 0.1953  decode.d8.loss_mask: 1.0632  decode.d8.loss_dice: 1.0667
2025/03/29 19:02:09 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 19:02:09 - mmengine - INFO - Iter(train) [14000/20000]  base_lr: 3.3840e-05 lr: 3.3840e-05  eta: 2:54:53  time: 1.1171  data_time: 0.0205  memory: 10130  loss: 21.9307  decode.loss_cls: 0.2516  decode.loss_mask: 0.8468  decode.loss_dice: 1.0726  decode.d0.loss_cls: 0.2552  decode.d0.loss_mask: 0.8619  decode.d0.loss_dice: 1.1269  decode.d1.loss_cls: 0.2564  decode.d1.loss_mask: 0.8669  decode.d1.loss_dice: 1.0736  decode.d2.loss_cls: 0.2638  decode.d2.loss_mask: 0.8693  decode.d2.loss_dice: 1.0791  decode.d3.loss_cls: 0.2121  decode.d3.loss_mask: 0.8657  decode.d3.loss_dice: 1.0806  decode.d4.loss_cls: 0.2321  decode.d4.loss_mask: 0.8652  decode.d4.loss_dice: 1.0892  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 0.8567  decode.d5.loss_dice: 1.0563  decode.d6.loss_cls: 0.2676  decode.d6.loss_mask: 0.8751  decode.d6.loss_dice: 1.0882  decode.d7.loss_cls: 0.2123  decode.d7.loss_mask: 0.8766  decode.d7.loss_dice: 1.0707  decode.d8.loss_cls: 0.2567  decode.d8.loss_mask: 0.8552  decode.d8.loss_dice: 1.0840
2025/03/29 19:02:09 - mmengine - INFO - Saving checkpoint at 14000 iterations
2025/03/29 19:02:17 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:43  time: 0.1231  data_time: 0.0019  memory: 1808  
2025/03/29 19:02:23 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:36  time: 0.1232  data_time: 0.0021  memory: 1808  
2025/03/29 19:02:30 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:30  time: 0.1227  data_time: 0.0019  memory: 1808  
2025/03/29 19:02:36 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1223  data_time: 0.0019  memory: 1808  
2025/03/29 19:02:42 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1226  data_time: 0.0019  memory: 1808  
2025/03/29 19:02:48 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1244  data_time: 0.0022  memory: 1808  
2025/03/29 19:02:54 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1259  data_time: 0.0020  memory: 1808  
2025/03/29 19:03:00 - mmengine - INFO - per class results:
2025/03/29 19:03:00 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 73.88 | 82.48 |
|      building      | 87.13 | 93.95 |
|   low_vegetation   | 47.82 |  57.4 |
|        tree        | 73.19 | 88.15 |
|        car         | 58.53 | 72.14 |
|      clutter       |  16.3 | 92.28 |
+--------------------+-------+-------+
2025/03/29 19:03:00 - mmengine - INFO - Iter(val) [398/398]    aAcc: 81.0800  mIoU: 59.4800  mAcc: 81.0700  data_time: 0.0021  time: 0.1238
2025/03/29 19:03:56 - mmengine - INFO - Iter(train) [14050/20000]  base_lr: 3.3586e-05 lr: 3.3586e-05  eta: 2:53:12  time: 1.1129  data_time: 0.0203  memory: 10119  loss: 23.6214  decode.loss_cls: 0.1521  decode.loss_mask: 1.0547  decode.loss_dice: 1.1360  decode.d0.loss_cls: 0.2456  decode.d0.loss_mask: 1.0704  decode.d0.loss_dice: 1.2019  decode.d1.loss_cls: 0.2459  decode.d1.loss_mask: 1.0361  decode.d1.loss_dice: 1.0920  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 1.0421  decode.d2.loss_dice: 1.0986  decode.d3.loss_cls: 0.2073  decode.d3.loss_mask: 1.0224  decode.d3.loss_dice: 1.1172  decode.d4.loss_cls: 0.1926  decode.d4.loss_mask: 1.0173  decode.d4.loss_dice: 1.1329  decode.d5.loss_cls: 0.1863  decode.d5.loss_mask: 1.0384  decode.d5.loss_dice: 1.0953  decode.d6.loss_cls: 0.1973  decode.d6.loss_mask: 1.0131  decode.d6.loss_dice: 1.1000  decode.d7.loss_cls: 0.2079  decode.d7.loss_mask: 1.0260  decode.d7.loss_dice: 1.1011  decode.d8.loss_cls: 0.1875  decode.d8.loss_mask: 1.0650  decode.d8.loss_dice: 1.1267
2025/03/29 19:04:52 - mmengine - INFO - Iter(train) [14100/20000]  base_lr: 3.3332e-05 lr: 3.3332e-05  eta: 2:51:31  time: 1.1103  data_time: 0.0195  memory: 10126  loss: 23.2198  decode.loss_cls: 0.1860  decode.loss_mask: 1.0176  decode.loss_dice: 1.0997  decode.d0.loss_cls: 0.2181  decode.d0.loss_mask: 1.0046  decode.d0.loss_dice: 1.1692  decode.d1.loss_cls: 0.2359  decode.d1.loss_mask: 1.0211  decode.d1.loss_dice: 1.1035  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 1.0035  decode.d2.loss_dice: 1.1137  decode.d3.loss_cls: 0.2090  decode.d3.loss_mask: 1.0064  decode.d3.loss_dice: 1.1083  decode.d4.loss_cls: 0.1954  decode.d4.loss_mask: 0.9993  decode.d4.loss_dice: 1.1011  decode.d5.loss_cls: 0.2186  decode.d5.loss_mask: 0.9953  decode.d5.loss_dice: 1.1011  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 1.0049  decode.d6.loss_dice: 1.1045  decode.d7.loss_cls: 0.1727  decode.d7.loss_mask: 1.0128  decode.d7.loss_dice: 1.1091  decode.d8.loss_cls: 0.2197  decode.d8.loss_mask: 1.0095  decode.d8.loss_dice: 1.1114
2025/03/29 19:05:47 - mmengine - INFO - Iter(train) [14150/20000]  base_lr: 3.3078e-05 lr: 3.3078e-05  eta: 2:49:51  time: 1.1168  data_time: 0.0203  memory: 10129  loss: 25.0898  decode.loss_cls: 0.2143  decode.loss_mask: 1.1731  decode.loss_dice: 1.1506  decode.d0.loss_cls: 0.3097  decode.d0.loss_mask: 1.0882  decode.d0.loss_dice: 1.1774  decode.d1.loss_cls: 0.2582  decode.d1.loss_mask: 1.1279  decode.d1.loss_dice: 1.1366  decode.d2.loss_cls: 0.2446  decode.d2.loss_mask: 1.1394  decode.d2.loss_dice: 1.1408  decode.d3.loss_cls: 0.2061  decode.d3.loss_mask: 1.1828  decode.d3.loss_dice: 1.1596  decode.d4.loss_cls: 0.2274  decode.d4.loss_mask: 1.1001  decode.d4.loss_dice: 1.1343  decode.d5.loss_cls: 0.2427  decode.d5.loss_mask: 1.0831  decode.d5.loss_dice: 1.1230  decode.d6.loss_cls: 0.2023  decode.d6.loss_mask: 1.1572  decode.d6.loss_dice: 1.1392  decode.d7.loss_cls: 0.1985  decode.d7.loss_mask: 1.1213  decode.d7.loss_dice: 1.1320  decode.d8.loss_cls: 0.2415  decode.d8.loss_mask: 1.1342  decode.d8.loss_dice: 1.1439
2025/03/29 19:06:43 - mmengine - INFO - Iter(train) [14200/20000]  base_lr: 3.2823e-05 lr: 3.2823e-05  eta: 2:48:11  time: 1.1138  data_time: 0.0206  memory: 10119  loss: 24.3746  decode.loss_cls: 0.2085  decode.loss_mask: 1.1081  decode.loss_dice: 1.1000  decode.d0.loss_cls: 0.2309  decode.d0.loss_mask: 1.1125  decode.d0.loss_dice: 1.1647  decode.d1.loss_cls: 0.1723  decode.d1.loss_mask: 1.1370  decode.d1.loss_dice: 1.1200  decode.d2.loss_cls: 0.1887  decode.d2.loss_mask: 1.1670  decode.d2.loss_dice: 1.1221  decode.d3.loss_cls: 0.1924  decode.d3.loss_mask: 1.1556  decode.d3.loss_dice: 1.1102  decode.d4.loss_cls: 0.1801  decode.d4.loss_mask: 1.1337  decode.d4.loss_dice: 1.1079  decode.d5.loss_cls: 0.1855  decode.d5.loss_mask: 1.1330  decode.d5.loss_dice: 1.1167  decode.d6.loss_cls: 0.1552  decode.d6.loss_mask: 1.1230  decode.d6.loss_dice: 1.1247  decode.d7.loss_cls: 0.1974  decode.d7.loss_mask: 1.1216  decode.d7.loss_dice: 1.0910  decode.d8.loss_cls: 0.2177  decode.d8.loss_mask: 1.1105  decode.d8.loss_dice: 1.0866
2025/03/29 19:07:39 - mmengine - INFO - Iter(train) [14250/20000]  base_lr: 3.2568e-05 lr: 3.2568e-05  eta: 2:46:31  time: 1.1164  data_time: 0.0204  memory: 10124  loss: 22.1734  decode.loss_cls: 0.2052  decode.loss_mask: 1.0132  decode.loss_dice: 0.9699  decode.d0.loss_cls: 0.2892  decode.d0.loss_mask: 1.0015  decode.d0.loss_dice: 1.0271  decode.d1.loss_cls: 0.2088  decode.d1.loss_mask: 1.0202  decode.d1.loss_dice: 1.0065  decode.d2.loss_cls: 0.2088  decode.d2.loss_mask: 1.0104  decode.d2.loss_dice: 0.9771  decode.d3.loss_cls: 0.1993  decode.d3.loss_mask: 1.0175  decode.d3.loss_dice: 0.9814  decode.d4.loss_cls: 0.2136  decode.d4.loss_mask: 1.0188  decode.d4.loss_dice: 0.9824  decode.d5.loss_cls: 0.2185  decode.d5.loss_mask: 1.0052  decode.d5.loss_dice: 0.9622  decode.d6.loss_cls: 0.2218  decode.d6.loss_mask: 1.0277  decode.d6.loss_dice: 0.9839  decode.d7.loss_cls: 0.1783  decode.d7.loss_mask: 1.0237  decode.d7.loss_dice: 0.9914  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 1.0326  decode.d8.loss_dice: 0.9855
2025/03/29 19:08:35 - mmengine - INFO - Iter(train) [14300/20000]  base_lr: 3.2313e-05 lr: 3.2313e-05  eta: 2:44:52  time: 1.1102  data_time: 0.0197  memory: 10122  loss: 25.6148  decode.loss_cls: 0.2541  decode.loss_mask: 1.1771  decode.loss_dice: 1.0762  decode.d0.loss_cls: 0.3442  decode.d0.loss_mask: 1.1647  decode.d0.loss_dice: 1.1472  decode.d1.loss_cls: 0.3465  decode.d1.loss_mask: 1.1326  decode.d1.loss_dice: 1.0814  decode.d2.loss_cls: 0.3204  decode.d2.loss_mask: 1.1614  decode.d2.loss_dice: 1.0644  decode.d3.loss_cls: 0.2680  decode.d3.loss_mask: 1.2009  decode.d3.loss_dice: 1.0894  decode.d4.loss_cls: 0.2939  decode.d4.loss_mask: 1.1507  decode.d4.loss_dice: 1.1046  decode.d5.loss_cls: 0.2709  decode.d5.loss_mask: 1.1628  decode.d5.loss_dice: 1.1023  decode.d6.loss_cls: 0.2154  decode.d6.loss_mask: 1.2067  decode.d6.loss_dice: 1.1215  decode.d7.loss_cls: 0.2831  decode.d7.loss_mask: 1.1984  decode.d7.loss_dice: 1.0979  decode.d8.loss_cls: 0.2677  decode.d8.loss_mask: 1.2164  decode.d8.loss_dice: 1.0938
2025/03/29 19:09:31 - mmengine - INFO - Iter(train) [14350/20000]  base_lr: 3.2058e-05 lr: 3.2058e-05  eta: 2:43:13  time: 1.1095  data_time: 0.0196  memory: 10124  loss: 24.9397  decode.loss_cls: 0.2581  decode.loss_mask: 1.0695  decode.loss_dice: 1.1643  decode.d0.loss_cls: 0.3105  decode.d0.loss_mask: 1.0667  decode.d0.loss_dice: 1.2284  decode.d1.loss_cls: 0.2687  decode.d1.loss_mask: 1.0396  decode.d1.loss_dice: 1.1469  decode.d2.loss_cls: 0.2582  decode.d2.loss_mask: 1.0409  decode.d2.loss_dice: 1.1527  decode.d3.loss_cls: 0.2670  decode.d3.loss_mask: 1.0404  decode.d3.loss_dice: 1.1615  decode.d4.loss_cls: 0.2336  decode.d4.loss_mask: 1.0717  decode.d4.loss_dice: 1.1927  decode.d5.loss_cls: 0.2204  decode.d5.loss_mask: 1.0655  decode.d5.loss_dice: 1.1946  decode.d6.loss_cls: 0.2530  decode.d6.loss_mask: 1.0709  decode.d6.loss_dice: 1.1821  decode.d7.loss_cls: 0.2403  decode.d7.loss_mask: 1.0661  decode.d7.loss_dice: 1.1813  decode.d8.loss_cls: 0.2461  decode.d8.loss_mask: 1.0740  decode.d8.loss_dice: 1.1739
2025/03/29 19:10:26 - mmengine - INFO - Iter(train) [14400/20000]  base_lr: 3.1803e-05 lr: 3.1803e-05  eta: 2:41:34  time: 1.1145  data_time: 0.0199  memory: 10121  loss: 22.9801  decode.loss_cls: 0.1996  decode.loss_mask: 0.9679  decode.loss_dice: 1.1245  decode.d0.loss_cls: 0.2182  decode.d0.loss_mask: 0.9770  decode.d0.loss_dice: 1.2058  decode.d1.loss_cls: 0.2353  decode.d1.loss_mask: 0.9556  decode.d1.loss_dice: 1.1344  decode.d2.loss_cls: 0.1954  decode.d2.loss_mask: 0.9514  decode.d2.loss_dice: 1.1086  decode.d3.loss_cls: 0.1836  decode.d3.loss_mask: 0.9532  decode.d3.loss_dice: 1.1162  decode.d4.loss_cls: 0.1921  decode.d4.loss_mask: 0.9465  decode.d4.loss_dice: 1.1223  decode.d5.loss_cls: 0.2158  decode.d5.loss_mask: 0.9673  decode.d5.loss_dice: 1.1091  decode.d6.loss_cls: 0.2294  decode.d6.loss_mask: 0.9567  decode.d6.loss_dice: 1.1174  decode.d7.loss_cls: 0.2239  decode.d7.loss_mask: 0.9635  decode.d7.loss_dice: 1.1036  decode.d8.loss_cls: 0.2352  decode.d8.loss_mask: 0.9599  decode.d8.loss_dice: 1.1111
2025/03/29 19:11:22 - mmengine - INFO - Iter(train) [14450/20000]  base_lr: 3.1547e-05 lr: 3.1547e-05  eta: 2:39:56  time: 1.1153  data_time: 0.0200  memory: 10118  loss: 24.3673  decode.loss_cls: 0.2393  decode.loss_mask: 1.0617  decode.loss_dice: 1.1253  decode.d0.loss_cls: 0.1443  decode.d0.loss_mask: 1.0788  decode.d0.loss_dice: 1.2737  decode.d1.loss_cls: 0.2518  decode.d1.loss_mask: 1.0579  decode.d1.loss_dice: 1.1274  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 1.0644  decode.d2.loss_dice: 1.1632  decode.d3.loss_cls: 0.2259  decode.d3.loss_mask: 1.0695  decode.d3.loss_dice: 1.1551  decode.d4.loss_cls: 0.2444  decode.d4.loss_mask: 1.0642  decode.d4.loss_dice: 1.1528  decode.d5.loss_cls: 0.2350  decode.d5.loss_mask: 1.0643  decode.d5.loss_dice: 1.1409  decode.d6.loss_cls: 0.1492  decode.d6.loss_mask: 1.0937  decode.d6.loss_dice: 1.1786  decode.d7.loss_cls: 0.2083  decode.d7.loss_mask: 1.0716  decode.d7.loss_dice: 1.1438  decode.d8.loss_cls: 0.1932  decode.d8.loss_mask: 1.0659  decode.d8.loss_dice: 1.1465
2025/03/29 19:12:18 - mmengine - INFO - Iter(train) [14500/20000]  base_lr: 3.1291e-05 lr: 3.1291e-05  eta: 2:38:18  time: 1.1098  data_time: 0.0198  memory: 10126  loss: 23.3356  decode.loss_cls: 0.1804  decode.loss_mask: 1.0532  decode.loss_dice: 1.0841  decode.d0.loss_cls: 0.2789  decode.d0.loss_mask: 1.0584  decode.d0.loss_dice: 1.1373  decode.d1.loss_cls: 0.1627  decode.d1.loss_mask: 1.0816  decode.d1.loss_dice: 1.1198  decode.d2.loss_cls: 0.1825  decode.d2.loss_mask: 1.0594  decode.d2.loss_dice: 1.0928  decode.d3.loss_cls: 0.1626  decode.d3.loss_mask: 1.0674  decode.d3.loss_dice: 1.0756  decode.d4.loss_cls: 0.1660  decode.d4.loss_mask: 1.0532  decode.d4.loss_dice: 1.0761  decode.d5.loss_cls: 0.1438  decode.d5.loss_mask: 1.0623  decode.d5.loss_dice: 1.0834  decode.d6.loss_cls: 0.1603  decode.d6.loss_mask: 1.0687  decode.d6.loss_dice: 1.0885  decode.d7.loss_cls: 0.1576  decode.d7.loss_mask: 1.0893  decode.d7.loss_dice: 1.0822  decode.d8.loss_cls: 0.1687  decode.d8.loss_mask: 1.0521  decode.d8.loss_dice: 1.0868
2025/03/29 19:13:14 - mmengine - INFO - Iter(train) [14550/20000]  base_lr: 3.1035e-05 lr: 3.1035e-05  eta: 2:36:40  time: 1.1212  data_time: 0.0206  memory: 10119  loss: 23.6808  decode.loss_cls: 0.2162  decode.loss_mask: 1.0382  decode.loss_dice: 1.0949  decode.d0.loss_cls: 0.2287  decode.d0.loss_mask: 1.0600  decode.d0.loss_dice: 1.2093  decode.d1.loss_cls: 0.2207  decode.d1.loss_mask: 1.0178  decode.d1.loss_dice: 1.1151  decode.d2.loss_cls: 0.2246  decode.d2.loss_mask: 1.0319  decode.d2.loss_dice: 1.1149  decode.d3.loss_cls: 0.2310  decode.d3.loss_mask: 1.0254  decode.d3.loss_dice: 1.0896  decode.d4.loss_cls: 0.2237  decode.d4.loss_mask: 1.0183  decode.d4.loss_dice: 1.0933  decode.d5.loss_cls: 0.2495  decode.d5.loss_mask: 1.0207  decode.d5.loss_dice: 1.0974  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 1.0250  decode.d6.loss_dice: 1.1285  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 1.0234  decode.d7.loss_dice: 1.1071  decode.d8.loss_cls: 0.2290  decode.d8.loss_mask: 1.0203  decode.d8.loss_dice: 1.0970
2025/03/29 19:14:10 - mmengine - INFO - Iter(train) [14600/20000]  base_lr: 3.0778e-05 lr: 3.0778e-05  eta: 2:35:03  time: 1.1101  data_time: 0.0197  memory: 10130  loss: 22.1412  decode.loss_cls: 0.1376  decode.loss_mask: 1.0498  decode.loss_dice: 1.0028  decode.d0.loss_cls: 0.2155  decode.d0.loss_mask: 1.0907  decode.d0.loss_dice: 1.0351  decode.d1.loss_cls: 0.1291  decode.d1.loss_mask: 1.0707  decode.d1.loss_dice: 1.0290  decode.d2.loss_cls: 0.1594  decode.d2.loss_mask: 1.0351  decode.d2.loss_dice: 0.9966  decode.d3.loss_cls: 0.1387  decode.d3.loss_mask: 1.0503  decode.d3.loss_dice: 1.0130  decode.d4.loss_cls: 0.1365  decode.d4.loss_mask: 1.0521  decode.d4.loss_dice: 1.0136  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 1.0430  decode.d5.loss_dice: 1.0108  decode.d6.loss_cls: 0.1282  decode.d6.loss_mask: 1.0585  decode.d6.loss_dice: 1.0187  decode.d7.loss_cls: 0.1394  decode.d7.loss_mask: 1.0525  decode.d7.loss_dice: 1.0214  decode.d8.loss_cls: 0.1305  decode.d8.loss_mask: 1.0498  decode.d8.loss_dice: 1.0121
2025/03/29 19:15:05 - mmengine - INFO - Iter(train) [14650/20000]  base_lr: 3.0522e-05 lr: 3.0522e-05  eta: 2:33:26  time: 1.1087  data_time: 0.0195  memory: 10122  loss: 24.1107  decode.loss_cls: 0.2279  decode.loss_mask: 0.9812  decode.loss_dice: 1.1918  decode.d0.loss_cls: 0.2274  decode.d0.loss_mask: 1.0394  decode.d0.loss_dice: 1.2225  decode.d1.loss_cls: 0.2715  decode.d1.loss_mask: 1.0009  decode.d1.loss_dice: 1.1886  decode.d2.loss_cls: 0.2550  decode.d2.loss_mask: 1.0207  decode.d2.loss_dice: 1.1533  decode.d3.loss_cls: 0.2284  decode.d3.loss_mask: 1.0062  decode.d3.loss_dice: 1.1464  decode.d4.loss_cls: 0.2093  decode.d4.loss_mask: 1.0077  decode.d4.loss_dice: 1.1790  decode.d5.loss_cls: 0.1926  decode.d5.loss_mask: 1.0053  decode.d5.loss_dice: 1.1866  decode.d6.loss_cls: 0.2244  decode.d6.loss_mask: 0.9928  decode.d6.loss_dice: 1.1649  decode.d7.loss_cls: 0.2202  decode.d7.loss_mask: 0.9995  decode.d7.loss_dice: 1.1896  decode.d8.loss_cls: 0.2219  decode.d8.loss_mask: 0.9893  decode.d8.loss_dice: 1.1667
2025/03/29 19:16:01 - mmengine - INFO - Iter(train) [14700/20000]  base_lr: 3.0265e-05 lr: 3.0265e-05  eta: 2:31:49  time: 1.1123  data_time: 0.0215  memory: 10129  loss: 23.6720  decode.loss_cls: 0.1775  decode.loss_mask: 1.0583  decode.loss_dice: 1.1037  decode.d0.loss_cls: 0.3119  decode.d0.loss_mask: 1.0852  decode.d0.loss_dice: 1.1304  decode.d1.loss_cls: 0.1978  decode.d1.loss_mask: 1.0664  decode.d1.loss_dice: 1.1018  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 1.0681  decode.d2.loss_dice: 1.1015  decode.d3.loss_cls: 0.1954  decode.d3.loss_mask: 1.0511  decode.d3.loss_dice: 1.0869  decode.d4.loss_cls: 0.2040  decode.d4.loss_mask: 1.0753  decode.d4.loss_dice: 1.1091  decode.d5.loss_cls: 0.2032  decode.d5.loss_mask: 1.0535  decode.d5.loss_dice: 1.0843  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 1.0834  decode.d6.loss_dice: 1.1089  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 1.0825  decode.d7.loss_dice: 1.1094  decode.d8.loss_cls: 0.1869  decode.d8.loss_mask: 1.0643  decode.d8.loss_dice: 1.0880
2025/03/29 19:16:59 - mmengine - INFO - Iter(train) [14750/20000]  base_lr: 3.0008e-05 lr: 3.0008e-05  eta: 2:30:13  time: 1.1215  data_time: 0.0214  memory: 10126  loss: 24.2491  decode.loss_cls: 0.2222  decode.loss_mask: 1.0542  decode.loss_dice: 1.1127  decode.d0.loss_cls: 0.3514  decode.d0.loss_mask: 1.0711  decode.d0.loss_dice: 1.1521  decode.d1.loss_cls: 0.3138  decode.d1.loss_mask: 1.0318  decode.d1.loss_dice: 1.1033  decode.d2.loss_cls: 0.2444  decode.d2.loss_mask: 1.0670  decode.d2.loss_dice: 1.1274  decode.d3.loss_cls: 0.2450  decode.d3.loss_mask: 1.0496  decode.d3.loss_dice: 1.1005  decode.d4.loss_cls: 0.2224  decode.d4.loss_mask: 1.0653  decode.d4.loss_dice: 1.1149  decode.d5.loss_cls: 0.2526  decode.d5.loss_mask: 1.0399  decode.d5.loss_dice: 1.0859  decode.d6.loss_cls: 0.2614  decode.d6.loss_mask: 1.0422  decode.d6.loss_dice: 1.1028  decode.d7.loss_cls: 0.2752  decode.d7.loss_mask: 1.0319  decode.d7.loss_dice: 1.1052  decode.d8.loss_cls: 0.2614  decode.d8.loss_mask: 1.0345  decode.d8.loss_dice: 1.1071
2025/03/29 19:17:55 - mmengine - INFO - Iter(train) [14800/20000]  base_lr: 2.9751e-05 lr: 2.9751e-05  eta: 2:28:36  time: 1.1328  data_time: 0.0215  memory: 10125  loss: 22.0119  decode.loss_cls: 0.1876  decode.loss_mask: 0.9030  decode.loss_dice: 1.1380  decode.d0.loss_cls: 0.2439  decode.d0.loss_mask: 0.9189  decode.d0.loss_dice: 1.1484  decode.d1.loss_cls: 0.2176  decode.d1.loss_mask: 0.8980  decode.d1.loss_dice: 1.1040  decode.d2.loss_cls: 0.1771  decode.d2.loss_mask: 0.8907  decode.d2.loss_dice: 1.1053  decode.d3.loss_cls: 0.1848  decode.d3.loss_mask: 0.8857  decode.d3.loss_dice: 1.1042  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.8885  decode.d4.loss_dice: 1.1159  decode.d5.loss_cls: 0.1873  decode.d5.loss_mask: 0.8875  decode.d5.loss_dice: 1.0989  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 0.8985  decode.d6.loss_dice: 1.0930  decode.d7.loss_cls: 0.1928  decode.d7.loss_mask: 0.8959  decode.d7.loss_dice: 1.1103  decode.d8.loss_cls: 0.1926  decode.d8.loss_mask: 0.9014  decode.d8.loss_dice: 1.1109
2025/03/29 19:18:51 - mmengine - INFO - Iter(train) [14850/20000]  base_lr: 2.9493e-05 lr: 2.9493e-05  eta: 2:27:00  time: 1.1172  data_time: 0.0206  memory: 10124  loss: 23.9961  decode.loss_cls: 0.2860  decode.loss_mask: 0.9410  decode.loss_dice: 1.1912  decode.d0.loss_cls: 0.3320  decode.d0.loss_mask: 0.9836  decode.d0.loss_dice: 1.2459  decode.d1.loss_cls: 0.3301  decode.d1.loss_mask: 0.9496  decode.d1.loss_dice: 1.1788  decode.d2.loss_cls: 0.2724  decode.d2.loss_mask: 0.9448  decode.d2.loss_dice: 1.1519  decode.d3.loss_cls: 0.2729  decode.d3.loss_mask: 0.9486  decode.d3.loss_dice: 1.1571  decode.d4.loss_cls: 0.2798  decode.d4.loss_mask: 0.9393  decode.d4.loss_dice: 1.1496  decode.d5.loss_cls: 0.2849  decode.d5.loss_mask: 0.9319  decode.d5.loss_dice: 1.1341  decode.d6.loss_cls: 0.2692  decode.d6.loss_mask: 0.9385  decode.d6.loss_dice: 1.1593  decode.d7.loss_cls: 0.2582  decode.d7.loss_mask: 0.9428  decode.d7.loss_dice: 1.1686  decode.d8.loss_cls: 0.2544  decode.d8.loss_mask: 0.9405  decode.d8.loss_dice: 1.1589
2025/03/29 19:19:47 - mmengine - INFO - Iter(train) [14900/20000]  base_lr: 2.9235e-05 lr: 2.9235e-05  eta: 2:25:24  time: 1.1153  data_time: 0.0202  memory: 10073  loss: 21.6361  decode.loss_cls: 0.2071  decode.loss_mask: 0.8639  decode.loss_dice: 1.1405  decode.d0.loss_cls: 0.1843  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 1.1345  decode.d1.loss_cls: 0.1907  decode.d1.loss_mask: 0.8520  decode.d1.loss_dice: 1.1006  decode.d2.loss_cls: 0.2340  decode.d2.loss_mask: 0.8424  decode.d2.loss_dice: 1.0756  decode.d3.loss_cls: 0.2255  decode.d3.loss_mask: 0.8505  decode.d3.loss_dice: 1.0906  decode.d4.loss_cls: 0.1840  decode.d4.loss_mask: 0.8570  decode.d4.loss_dice: 1.1013  decode.d5.loss_cls: 0.2663  decode.d5.loss_mask: 0.8252  decode.d5.loss_dice: 1.0670  decode.d6.loss_cls: 0.1953  decode.d6.loss_mask: 0.8618  decode.d6.loss_dice: 1.0859  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 0.8628  decode.d7.loss_dice: 1.0991  decode.d8.loss_cls: 0.2090  decode.d8.loss_mask: 0.8436  decode.d8.loss_dice: 1.1059
2025/03/29 19:20:43 - mmengine - INFO - Iter(train) [14950/20000]  base_lr: 2.8977e-05 lr: 2.8977e-05  eta: 2:23:49  time: 1.1142  data_time: 0.0198  memory: 10122  loss: 22.8124  decode.loss_cls: 0.1228  decode.loss_mask: 1.0265  decode.loss_dice: 1.0938  decode.d0.loss_cls: 0.2218  decode.d0.loss_mask: 1.0320  decode.d0.loss_dice: 1.0862  decode.d1.loss_cls: 0.1685  decode.d1.loss_mask: 1.0211  decode.d1.loss_dice: 1.0933  decode.d2.loss_cls: 0.1662  decode.d2.loss_mask: 1.0395  decode.d2.loss_dice: 1.0943  decode.d3.loss_cls: 0.1732  decode.d3.loss_mask: 1.0222  decode.d3.loss_dice: 1.0678  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 1.0327  decode.d4.loss_dice: 1.0943  decode.d5.loss_cls: 0.1648  decode.d5.loss_mask: 1.0263  decode.d5.loss_dice: 1.0737  decode.d6.loss_cls: 0.1549  decode.d6.loss_mask: 1.0284  decode.d6.loss_dice: 1.0943  decode.d7.loss_cls: 0.1165  decode.d7.loss_mask: 1.0675  decode.d7.loss_dice: 1.0915  decode.d8.loss_cls: 0.1671  decode.d8.loss_mask: 1.0287  decode.d8.loss_dice: 1.0873
2025/03/29 19:21:39 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 19:21:39 - mmengine - INFO - Iter(train) [15000/20000]  base_lr: 2.8719e-05 lr: 2.8719e-05  eta: 2:22:14  time: 1.1148  data_time: 0.0204  memory: 10121  loss: 24.4334  decode.loss_cls: 0.2111  decode.loss_mask: 1.1483  decode.loss_dice: 1.0567  decode.d0.loss_cls: 0.3230  decode.d0.loss_mask: 1.1659  decode.d0.loss_dice: 1.1390  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 1.1450  decode.d1.loss_dice: 1.0954  decode.d2.loss_cls: 0.2387  decode.d2.loss_mask: 1.1360  decode.d2.loss_dice: 1.0553  decode.d3.loss_cls: 0.2399  decode.d3.loss_mask: 1.1236  decode.d3.loss_dice: 1.0489  decode.d4.loss_cls: 0.2321  decode.d4.loss_mask: 1.1091  decode.d4.loss_dice: 1.0515  decode.d5.loss_cls: 0.2442  decode.d5.loss_mask: 1.1233  decode.d5.loss_dice: 1.0300  decode.d6.loss_cls: 0.2684  decode.d6.loss_mask: 1.1323  decode.d6.loss_dice: 1.0128  decode.d7.loss_cls: 0.2158  decode.d7.loss_mask: 1.1491  decode.d7.loss_dice: 1.0665  decode.d8.loss_cls: 0.2253  decode.d8.loss_mask: 1.1611  decode.d8.loss_dice: 1.0462
2025/03/29 19:22:34 - mmengine - INFO - Iter(train) [15050/20000]  base_lr: 2.8460e-05 lr: 2.8460e-05  eta: 2:20:39  time: 1.1182  data_time: 0.0205  memory: 10119  loss: 20.9542  decode.loss_cls: 0.1084  decode.loss_mask: 0.9298  decode.loss_dice: 1.0315  decode.d0.loss_cls: 0.1829  decode.d0.loss_mask: 0.9539  decode.d0.loss_dice: 1.0813  decode.d1.loss_cls: 0.1563  decode.d1.loss_mask: 0.9285  decode.d1.loss_dice: 1.0318  decode.d2.loss_cls: 0.1383  decode.d2.loss_mask: 0.9272  decode.d2.loss_dice: 1.0176  decode.d3.loss_cls: 0.1416  decode.d3.loss_mask: 0.9284  decode.d3.loss_dice: 1.0187  decode.d4.loss_cls: 0.1283  decode.d4.loss_mask: 0.9225  decode.d4.loss_dice: 1.0157  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.9158  decode.d5.loss_dice: 1.0141  decode.d6.loss_cls: 0.1290  decode.d6.loss_mask: 0.9218  decode.d6.loss_dice: 1.0215  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.9126  decode.d7.loss_dice: 1.0312  decode.d8.loss_cls: 0.1275  decode.d8.loss_mask: 0.9211  decode.d8.loss_dice: 1.0292
2025/03/29 19:23:30 - mmengine - INFO - Iter(train) [15100/20000]  base_lr: 2.8201e-05 lr: 2.8201e-05  eta: 2:19:04  time: 1.1154  data_time: 0.0203  memory: 10124  loss: 22.7683  decode.loss_cls: 0.1774  decode.loss_mask: 1.0490  decode.loss_dice: 1.0307  decode.d0.loss_cls: 0.2544  decode.d0.loss_mask: 1.0880  decode.d0.loss_dice: 1.0809  decode.d1.loss_cls: 0.1681  decode.d1.loss_mask: 1.0738  decode.d1.loss_dice: 1.0533  decode.d2.loss_cls: 0.1364  decode.d2.loss_mask: 1.0647  decode.d2.loss_dice: 1.0462  decode.d3.loss_cls: 0.1591  decode.d3.loss_mask: 1.0611  decode.d3.loss_dice: 1.0532  decode.d4.loss_cls: 0.1675  decode.d4.loss_mask: 1.0710  decode.d4.loss_dice: 1.0186  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 1.0458  decode.d5.loss_dice: 1.0114  decode.d6.loss_cls: 0.1454  decode.d6.loss_mask: 1.0750  decode.d6.loss_dice: 1.0460  decode.d7.loss_cls: 0.1634  decode.d7.loss_mask: 1.0583  decode.d7.loss_dice: 1.0318  decode.d8.loss_cls: 0.1648  decode.d8.loss_mask: 1.0676  decode.d8.loss_dice: 1.0396
2025/03/29 19:24:26 - mmengine - INFO - Iter(train) [15150/20000]  base_lr: 2.7942e-05 lr: 2.7942e-05  eta: 2:17:29  time: 1.1124  data_time: 0.0201  memory: 10117  loss: 23.1064  decode.loss_cls: 0.2212  decode.loss_mask: 0.9515  decode.loss_dice: 1.0738  decode.d0.loss_cls: 0.2733  decode.d0.loss_mask: 0.9829  decode.d0.loss_dice: 1.1998  decode.d1.loss_cls: 0.2755  decode.d1.loss_mask: 0.9739  decode.d1.loss_dice: 1.1349  decode.d2.loss_cls: 0.2647  decode.d2.loss_mask: 0.9695  decode.d2.loss_dice: 1.0815  decode.d3.loss_cls: 0.2459  decode.d3.loss_mask: 0.9757  decode.d3.loss_dice: 1.0847  decode.d4.loss_cls: 0.2411  decode.d4.loss_mask: 0.9469  decode.d4.loss_dice: 1.0804  decode.d5.loss_cls: 0.2611  decode.d5.loss_mask: 0.9568  decode.d5.loss_dice: 1.0818  decode.d6.loss_cls: 0.2417  decode.d6.loss_mask: 0.9534  decode.d6.loss_dice: 1.0716  decode.d7.loss_cls: 0.2594  decode.d7.loss_mask: 0.9659  decode.d7.loss_dice: 1.0888  decode.d8.loss_cls: 0.2203  decode.d8.loss_mask: 0.9556  decode.d8.loss_dice: 1.0726
2025/03/29 19:25:22 - mmengine - INFO - Iter(train) [15200/20000]  base_lr: 2.7683e-05 lr: 2.7683e-05  eta: 2:15:55  time: 1.1149  data_time: 0.0206  memory: 10129  loss: 22.8727  decode.loss_cls: 0.2137  decode.loss_mask: 0.9968  decode.loss_dice: 1.0390  decode.d0.loss_cls: 0.3321  decode.d0.loss_mask: 0.9927  decode.d0.loss_dice: 1.0807  decode.d1.loss_cls: 0.2356  decode.d1.loss_mask: 1.0481  decode.d1.loss_dice: 1.0701  decode.d2.loss_cls: 0.2249  decode.d2.loss_mask: 1.0748  decode.d2.loss_dice: 1.0508  decode.d3.loss_cls: 0.2273  decode.d3.loss_mask: 1.0125  decode.d3.loss_dice: 1.0307  decode.d4.loss_cls: 0.2293  decode.d4.loss_mask: 0.9927  decode.d4.loss_dice: 1.0195  decode.d5.loss_cls: 0.2228  decode.d5.loss_mask: 1.0086  decode.d5.loss_dice: 1.0269  decode.d6.loss_cls: 0.2244  decode.d6.loss_mask: 0.9909  decode.d6.loss_dice: 1.0292  decode.d7.loss_cls: 0.2203  decode.d7.loss_mask: 0.9984  decode.d7.loss_dice: 1.0304  decode.d8.loss_cls: 0.2119  decode.d8.loss_mask: 1.0007  decode.d8.loss_dice: 1.0372
2025/03/29 19:26:18 - mmengine - INFO - Iter(train) [15250/20000]  base_lr: 2.7423e-05 lr: 2.7423e-05  eta: 2:14:21  time: 1.1153  data_time: 0.0203  memory: 10123  loss: 21.6531  decode.loss_cls: 0.1998  decode.loss_mask: 0.8724  decode.loss_dice: 1.0512  decode.d0.loss_cls: 0.2524  decode.d0.loss_mask: 0.9057  decode.d0.loss_dice: 1.0998  decode.d1.loss_cls: 0.1888  decode.d1.loss_mask: 0.9178  decode.d1.loss_dice: 1.1019  decode.d2.loss_cls: 0.2038  decode.d2.loss_mask: 0.8980  decode.d2.loss_dice: 1.0714  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 0.8861  decode.d3.loss_dice: 1.0581  decode.d4.loss_cls: 0.2630  decode.d4.loss_mask: 0.8779  decode.d4.loss_dice: 1.0372  decode.d5.loss_cls: 0.2028  decode.d5.loss_mask: 0.8875  decode.d5.loss_dice: 1.0608  decode.d6.loss_cls: 0.2096  decode.d6.loss_mask: 0.8794  decode.d6.loss_dice: 1.0456  decode.d7.loss_cls: 0.2367  decode.d7.loss_mask: 0.8833  decode.d7.loss_dice: 1.0469  decode.d8.loss_cls: 0.2015  decode.d8.loss_mask: 0.8746  decode.d8.loss_dice: 1.0385
2025/03/29 19:27:13 - mmengine - INFO - Iter(train) [15300/20000]  base_lr: 2.7163e-05 lr: 2.7163e-05  eta: 2:12:47  time: 1.1137  data_time: 0.0202  memory: 10122  loss: 23.0132  decode.loss_cls: 0.2011  decode.loss_mask: 1.0161  decode.loss_dice: 1.0487  decode.d0.loss_cls: 0.3113  decode.d0.loss_mask: 1.0068  decode.d0.loss_dice: 1.0803  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 1.0534  decode.d1.loss_dice: 1.0439  decode.d2.loss_cls: 0.1846  decode.d2.loss_mask: 1.0226  decode.d2.loss_dice: 1.0539  decode.d3.loss_cls: 0.2080  decode.d3.loss_mask: 1.0141  decode.d3.loss_dice: 1.0492  decode.d4.loss_cls: 0.2199  decode.d4.loss_mask: 1.0070  decode.d4.loss_dice: 1.0273  decode.d5.loss_cls: 0.2307  decode.d5.loss_mask: 1.0175  decode.d5.loss_dice: 1.0469  decode.d6.loss_cls: 0.2516  decode.d6.loss_mask: 1.0242  decode.d6.loss_dice: 1.0396  decode.d7.loss_cls: 0.2380  decode.d7.loss_mask: 1.0003  decode.d7.loss_dice: 1.0582  decode.d8.loss_cls: 0.2125  decode.d8.loss_mask: 1.0313  decode.d8.loss_dice: 1.0907
2025/03/29 19:28:09 - mmengine - INFO - Iter(train) [15350/20000]  base_lr: 2.6903e-05 lr: 2.6903e-05  eta: 2:11:14  time: 1.1148  data_time: 0.0204  memory: 10131  loss: 23.3098  decode.loss_cls: 0.1290  decode.loss_mask: 1.0931  decode.loss_dice: 1.0891  decode.d0.loss_cls: 0.2154  decode.d0.loss_mask: 1.0841  decode.d0.loss_dice: 1.1497  decode.d1.loss_cls: 0.1606  decode.d1.loss_mask: 1.0858  decode.d1.loss_dice: 1.0969  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 1.0854  decode.d2.loss_dice: 1.0890  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 1.0888  decode.d3.loss_dice: 1.0827  decode.d4.loss_cls: 0.1477  decode.d4.loss_mask: 1.0942  decode.d4.loss_dice: 1.0864  decode.d5.loss_cls: 0.1718  decode.d5.loss_mask: 1.0803  decode.d5.loss_dice: 1.0582  decode.d6.loss_cls: 0.1386  decode.d6.loss_mask: 1.0904  decode.d6.loss_dice: 1.0901  decode.d7.loss_cls: 0.1468  decode.d7.loss_mask: 1.0839  decode.d7.loss_dice: 1.0912  decode.d8.loss_cls: 0.1302  decode.d8.loss_mask: 1.0878  decode.d8.loss_dice: 1.0848
2025/03/29 19:29:05 - mmengine - INFO - Iter(train) [15400/20000]  base_lr: 2.6642e-05 lr: 2.6642e-05  eta: 2:09:40  time: 1.1122  data_time: 0.0201  memory: 10133  loss: 21.8713  decode.loss_cls: 0.1332  decode.loss_mask: 0.9393  decode.loss_dice: 1.0774  decode.d0.loss_cls: 0.1647  decode.d0.loss_mask: 0.9381  decode.d0.loss_dice: 1.1264  decode.d1.loss_cls: 0.1717  decode.d1.loss_mask: 0.9564  decode.d1.loss_dice: 1.0751  decode.d2.loss_cls: 0.1508  decode.d2.loss_mask: 0.9447  decode.d2.loss_dice: 1.0702  decode.d3.loss_cls: 0.1822  decode.d3.loss_mask: 0.9373  decode.d3.loss_dice: 1.0707  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 0.9426  decode.d4.loss_dice: 1.0835  decode.d5.loss_cls: 0.1831  decode.d5.loss_mask: 0.9464  decode.d5.loss_dice: 1.0834  decode.d6.loss_cls: 0.1592  decode.d6.loss_mask: 0.9443  decode.d6.loss_dice: 1.0787  decode.d7.loss_cls: 0.1335  decode.d7.loss_mask: 0.9463  decode.d7.loss_dice: 1.0730  decode.d8.loss_cls: 0.1820  decode.d8.loss_mask: 0.9389  decode.d8.loss_dice: 1.0829
2025/03/29 19:30:01 - mmengine - INFO - Iter(train) [15450/20000]  base_lr: 2.6382e-05 lr: 2.6382e-05  eta: 2:08:07  time: 1.1138  data_time: 0.0212  memory: 10124  loss: 22.8805  decode.loss_cls: 0.2245  decode.loss_mask: 0.9562  decode.loss_dice: 1.0969  decode.d0.loss_cls: 0.2359  decode.d0.loss_mask: 1.0026  decode.d0.loss_dice: 1.1536  decode.d1.loss_cls: 0.2727  decode.d1.loss_mask: 0.9459  decode.d1.loss_dice: 1.0708  decode.d2.loss_cls: 0.2065  decode.d2.loss_mask: 0.9485  decode.d2.loss_dice: 1.1102  decode.d3.loss_cls: 0.2242  decode.d3.loss_mask: 0.9665  decode.d3.loss_dice: 1.1007  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 0.9516  decode.d4.loss_dice: 1.1034  decode.d5.loss_cls: 0.2507  decode.d5.loss_mask: 0.9469  decode.d5.loss_dice: 1.0802  decode.d6.loss_cls: 0.2087  decode.d6.loss_mask: 0.9603  decode.d6.loss_dice: 1.1089  decode.d7.loss_cls: 0.2566  decode.d7.loss_mask: 0.9464  decode.d7.loss_dice: 1.0635  decode.d8.loss_cls: 0.2375  decode.d8.loss_mask: 0.9475  decode.d8.loss_dice: 1.0860
2025/03/29 19:30:56 - mmengine - INFO - Iter(train) [15500/20000]  base_lr: 2.6121e-05 lr: 2.6121e-05  eta: 2:06:34  time: 1.1110  data_time: 0.0200  memory: 10129  loss: 21.5498  decode.loss_cls: 0.1478  decode.loss_mask: 0.9157  decode.loss_dice: 1.0826  decode.d0.loss_cls: 0.2382  decode.d0.loss_mask: 0.9302  decode.d0.loss_dice: 1.1373  decode.d1.loss_cls: 0.1722  decode.d1.loss_mask: 0.9146  decode.d1.loss_dice: 1.0954  decode.d2.loss_cls: 0.1427  decode.d2.loss_mask: 0.9110  decode.d2.loss_dice: 1.0824  decode.d3.loss_cls: 0.1643  decode.d3.loss_mask: 0.9012  decode.d3.loss_dice: 1.0557  decode.d4.loss_cls: 0.1572  decode.d4.loss_mask: 0.9096  decode.d4.loss_dice: 1.0599  decode.d5.loss_cls: 0.1376  decode.d5.loss_mask: 0.9049  decode.d5.loss_dice: 1.0823  decode.d6.loss_cls: 0.1674  decode.d6.loss_mask: 0.9092  decode.d6.loss_dice: 1.0627  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.9075  decode.d7.loss_dice: 1.0692  decode.d8.loss_cls: 0.1406  decode.d8.loss_mask: 0.9099  decode.d8.loss_dice: 1.0872
2025/03/29 19:31:53 - mmengine - INFO - Iter(train) [15550/20000]  base_lr: 2.5859e-05 lr: 2.5859e-05  eta: 2:05:02  time: 1.1181  data_time: 0.0202  memory: 10126  loss: 23.7187  decode.loss_cls: 0.2098  decode.loss_mask: 1.0114  decode.loss_dice: 1.1222  decode.d0.loss_cls: 0.2700  decode.d0.loss_mask: 1.0181  decode.d0.loss_dice: 1.1566  decode.d1.loss_cls: 0.2791  decode.d1.loss_mask: 1.0296  decode.d1.loss_dice: 1.1398  decode.d2.loss_cls: 0.2486  decode.d2.loss_mask: 1.0191  decode.d2.loss_dice: 1.0982  decode.d3.loss_cls: 0.2582  decode.d3.loss_mask: 1.0043  decode.d3.loss_dice: 1.0976  decode.d4.loss_cls: 0.2386  decode.d4.loss_mask: 0.9952  decode.d4.loss_dice: 1.0966  decode.d5.loss_cls: 0.2361  decode.d5.loss_mask: 1.0090  decode.d5.loss_dice: 1.1061  decode.d6.loss_cls: 0.2157  decode.d6.loss_mask: 1.0118  decode.d6.loss_dice: 1.1094  decode.d7.loss_cls: 0.2354  decode.d7.loss_mask: 1.0155  decode.d7.loss_dice: 1.1187  decode.d8.loss_cls: 0.2408  decode.d8.loss_mask: 1.0182  decode.d8.loss_dice: 1.1092
2025/03/29 19:32:49 - mmengine - INFO - Iter(train) [15600/20000]  base_lr: 2.5598e-05 lr: 2.5598e-05  eta: 2:03:30  time: 1.1090  data_time: 0.0195  memory: 10125  loss: 20.9921  decode.loss_cls: 0.1745  decode.loss_mask: 0.9322  decode.loss_dice: 0.9839  decode.d0.loss_cls: 0.2714  decode.d0.loss_mask: 0.9143  decode.d0.loss_dice: 1.0088  decode.d1.loss_cls: 0.2616  decode.d1.loss_mask: 0.9146  decode.d1.loss_dice: 0.9489  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.9301  decode.d2.loss_dice: 0.9498  decode.d3.loss_cls: 0.2283  decode.d3.loss_mask: 0.9238  decode.d3.loss_dice: 0.9419  decode.d4.loss_cls: 0.2033  decode.d4.loss_mask: 0.9155  decode.d4.loss_dice: 0.9586  decode.d5.loss_cls: 0.2024  decode.d5.loss_mask: 0.9179  decode.d5.loss_dice: 0.9540  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.9201  decode.d6.loss_dice: 0.9561  decode.d7.loss_cls: 0.2184  decode.d7.loss_mask: 0.9096  decode.d7.loss_dice: 0.9298  decode.d8.loss_cls: 0.2095  decode.d8.loss_mask: 0.9258  decode.d8.loss_dice: 0.9559
2025/03/29 19:33:45 - mmengine - INFO - Iter(train) [15650/20000]  base_lr: 2.5336e-05 lr: 2.5336e-05  eta: 2:01:58  time: 1.1110  data_time: 0.0197  memory: 10121  loss: 22.5847  decode.loss_cls: 0.2457  decode.loss_mask: 0.9266  decode.loss_dice: 1.1202  decode.d0.loss_cls: 0.1870  decode.d0.loss_mask: 0.9440  decode.d0.loss_dice: 1.2039  decode.d1.loss_cls: 0.2672  decode.d1.loss_mask: 0.9179  decode.d1.loss_dice: 1.0858  decode.d2.loss_cls: 0.2514  decode.d2.loss_mask: 0.9048  decode.d2.loss_dice: 1.0819  decode.d3.loss_cls: 0.2367  decode.d3.loss_mask: 0.9067  decode.d3.loss_dice: 1.0936  decode.d4.loss_cls: 0.2463  decode.d4.loss_mask: 0.8987  decode.d4.loss_dice: 1.0675  decode.d5.loss_cls: 0.2387  decode.d5.loss_mask: 0.9082  decode.d5.loss_dice: 1.0879  decode.d6.loss_cls: 0.2688  decode.d6.loss_mask: 0.8926  decode.d6.loss_dice: 1.0804  decode.d7.loss_cls: 0.2497  decode.d7.loss_mask: 0.9111  decode.d7.loss_dice: 1.1056  decode.d8.loss_cls: 0.2601  decode.d8.loss_mask: 0.9104  decode.d8.loss_dice: 1.0851
2025/03/29 19:34:40 - mmengine - INFO - Iter(train) [15700/20000]  base_lr: 2.5073e-05 lr: 2.5073e-05  eta: 2:00:26  time: 1.1120  data_time: 0.0200  memory: 10124  loss: 22.5820  decode.loss_cls: 0.1621  decode.loss_mask: 0.9921  decode.loss_dice: 1.0913  decode.d0.loss_cls: 0.1889  decode.d0.loss_mask: 0.9744  decode.d0.loss_dice: 1.1790  decode.d1.loss_cls: 0.1796  decode.d1.loss_mask: 0.9806  decode.d1.loss_dice: 1.1176  decode.d2.loss_cls: 0.1631  decode.d2.loss_mask: 0.9858  decode.d2.loss_dice: 1.0952  decode.d3.loss_cls: 0.1903  decode.d3.loss_mask: 0.9673  decode.d3.loss_dice: 1.0844  decode.d4.loss_cls: 0.1844  decode.d4.loss_mask: 0.9608  decode.d4.loss_dice: 1.0739  decode.d5.loss_cls: 0.1768  decode.d5.loss_mask: 0.9736  decode.d5.loss_dice: 1.0822  decode.d6.loss_cls: 0.1694  decode.d6.loss_mask: 0.9729  decode.d6.loss_dice: 1.1082  decode.d7.loss_cls: 0.1754  decode.d7.loss_mask: 0.9858  decode.d7.loss_dice: 1.0992  decode.d8.loss_cls: 0.1782  decode.d8.loss_mask: 0.9970  decode.d8.loss_dice: 1.0926
2025/03/29 19:35:36 - mmengine - INFO - Iter(train) [15750/20000]  base_lr: 2.4811e-05 lr: 2.4811e-05  eta: 1:58:54  time: 1.1124  data_time: 0.0209  memory: 10130  loss: 22.3339  decode.loss_cls: 0.1010  decode.loss_mask: 1.0622  decode.loss_dice: 1.0535  decode.d0.loss_cls: 0.2268  decode.d0.loss_mask: 1.0703  decode.d0.loss_dice: 1.0829  decode.d1.loss_cls: 0.1486  decode.d1.loss_mask: 1.0701  decode.d1.loss_dice: 1.0621  decode.d2.loss_cls: 0.1179  decode.d2.loss_mask: 1.0338  decode.d2.loss_dice: 1.0422  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 1.0522  decode.d3.loss_dice: 1.0349  decode.d4.loss_cls: 0.1226  decode.d4.loss_mask: 1.0507  decode.d4.loss_dice: 1.0299  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 1.0642  decode.d5.loss_dice: 1.0369  decode.d6.loss_cls: 0.1382  decode.d6.loss_mask: 1.0610  decode.d6.loss_dice: 1.0388  decode.d7.loss_cls: 0.1193  decode.d7.loss_mask: 1.0599  decode.d7.loss_dice: 1.0300  decode.d8.loss_cls: 0.1075  decode.d8.loss_mask: 1.0480  decode.d8.loss_dice: 1.0534
2025/03/29 19:36:32 - mmengine - INFO - Iter(train) [15800/20000]  base_lr: 2.4548e-05 lr: 2.4548e-05  eta: 1:57:23  time: 1.1145  data_time: 0.0200  memory: 10123  loss: 22.6160  decode.loss_cls: 0.1151  decode.loss_mask: 1.0414  decode.loss_dice: 1.0821  decode.d0.loss_cls: 0.1989  decode.d0.loss_mask: 1.0318  decode.d0.loss_dice: 1.1369  decode.d1.loss_cls: 0.1857  decode.d1.loss_mask: 1.0278  decode.d1.loss_dice: 1.0619  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 1.0410  decode.d2.loss_dice: 1.0710  decode.d3.loss_cls: 0.1690  decode.d3.loss_mask: 1.0120  decode.d3.loss_dice: 1.0507  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 1.0326  decode.d4.loss_dice: 1.0547  decode.d5.loss_cls: 0.1457  decode.d5.loss_mask: 1.0216  decode.d5.loss_dice: 1.0728  decode.d6.loss_cls: 0.1593  decode.d6.loss_mask: 1.0125  decode.d6.loss_dice: 1.0666  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 1.0392  decode.d7.loss_dice: 1.0871  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 1.0417  decode.d8.loss_dice: 1.0832
2025/03/29 19:37:28 - mmengine - INFO - Iter(train) [15850/20000]  base_lr: 2.4285e-05 lr: 2.4285e-05  eta: 1:55:51  time: 1.1117  data_time: 0.0198  memory: 10131  loss: 23.7219  decode.loss_cls: 0.1607  decode.loss_mask: 1.0579  decode.loss_dice: 1.1438  decode.d0.loss_cls: 0.1830  decode.d0.loss_mask: 1.0597  decode.d0.loss_dice: 1.2171  decode.d1.loss_cls: 0.2014  decode.d1.loss_mask: 1.0628  decode.d1.loss_dice: 1.1665  decode.d2.loss_cls: 0.1367  decode.d2.loss_mask: 1.0750  decode.d2.loss_dice: 1.1616  decode.d3.loss_cls: 0.1391  decode.d3.loss_mask: 1.0813  decode.d3.loss_dice: 1.1541  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 1.0652  decode.d4.loss_dice: 1.1527  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 1.0634  decode.d5.loss_dice: 1.1417  decode.d6.loss_cls: 0.1193  decode.d6.loss_mask: 1.0761  decode.d6.loss_dice: 1.1561  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 1.0537  decode.d7.loss_dice: 1.1392  decode.d8.loss_cls: 0.1510  decode.d8.loss_mask: 1.0482  decode.d8.loss_dice: 1.1359
2025/03/29 19:38:24 - mmengine - INFO - Iter(train) [15900/20000]  base_lr: 2.4021e-05 lr: 2.4021e-05  eta: 1:54:20  time: 1.1117  data_time: 0.0199  memory: 10125  loss: 21.9771  decode.loss_cls: 0.1577  decode.loss_mask: 0.9285  decode.loss_dice: 1.0671  decode.d0.loss_cls: 0.1865  decode.d0.loss_mask: 0.9358  decode.d0.loss_dice: 1.1388  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 0.9287  decode.d1.loss_dice: 1.0999  decode.d2.loss_cls: 0.1873  decode.d2.loss_mask: 0.9223  decode.d2.loss_dice: 1.0770  decode.d3.loss_cls: 0.1712  decode.d3.loss_mask: 0.9336  decode.d3.loss_dice: 1.0784  decode.d4.loss_cls: 0.1639  decode.d4.loss_mask: 0.9240  decode.d4.loss_dice: 1.1005  decode.d5.loss_cls: 0.1777  decode.d5.loss_mask: 0.9284  decode.d5.loss_dice: 1.0775  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 0.9484  decode.d6.loss_dice: 1.0891  decode.d7.loss_cls: 0.1811  decode.d7.loss_mask: 0.9400  decode.d7.loss_dice: 1.0950  decode.d8.loss_cls: 0.1675  decode.d8.loss_mask: 0.9245  decode.d8.loss_dice: 1.0713
2025/03/29 19:39:20 - mmengine - INFO - Iter(train) [15950/20000]  base_lr: 2.3758e-05 lr: 2.3758e-05  eta: 1:52:50  time: 1.1238  data_time: 0.0208  memory: 10121  loss: 22.4926  decode.loss_cls: 0.1153  decode.loss_mask: 1.0187  decode.loss_dice: 1.0942  decode.d0.loss_cls: 0.1965  decode.d0.loss_mask: 1.0205  decode.d0.loss_dice: 1.1253  decode.d1.loss_cls: 0.1581  decode.d1.loss_mask: 1.0107  decode.d1.loss_dice: 1.0999  decode.d2.loss_cls: 0.1362  decode.d2.loss_mask: 0.9994  decode.d2.loss_dice: 1.0964  decode.d3.loss_cls: 0.1290  decode.d3.loss_mask: 1.0056  decode.d3.loss_dice: 1.0803  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 1.0048  decode.d4.loss_dice: 1.0832  decode.d5.loss_cls: 0.1258  decode.d5.loss_mask: 1.0161  decode.d5.loss_dice: 1.0981  decode.d6.loss_cls: 0.1229  decode.d6.loss_mask: 1.0148  decode.d6.loss_dice: 1.1057  decode.d7.loss_cls: 0.1305  decode.d7.loss_mask: 1.0170  decode.d7.loss_dice: 1.1048  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 1.0180  decode.d8.loss_dice: 1.1133
2025/03/29 19:40:16 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 19:40:16 - mmengine - INFO - Iter(train) [16000/20000]  base_lr: 2.3493e-05 lr: 2.3493e-05  eta: 1:51:19  time: 1.1119  data_time: 0.0199  memory: 10124  loss: 20.6829  decode.loss_cls: 0.2072  decode.loss_mask: 0.8567  decode.loss_dice: 0.9908  decode.d0.loss_cls: 0.2360  decode.d0.loss_mask: 0.8664  decode.d0.loss_dice: 1.0827  decode.d1.loss_cls: 0.2017  decode.d1.loss_mask: 0.8490  decode.d1.loss_dice: 1.0204  decode.d2.loss_cls: 0.2162  decode.d2.loss_mask: 0.8497  decode.d2.loss_dice: 1.0010  decode.d3.loss_cls: 0.1765  decode.d3.loss_mask: 0.8572  decode.d3.loss_dice: 0.9873  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 0.8611  decode.d4.loss_dice: 0.9961  decode.d5.loss_cls: 0.1945  decode.d5.loss_mask: 0.8551  decode.d5.loss_dice: 0.9779  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.8620  decode.d6.loss_dice: 0.9971  decode.d7.loss_cls: 0.2612  decode.d7.loss_mask: 0.8554  decode.d7.loss_dice: 0.9890  decode.d8.loss_cls: 0.1894  decode.d8.loss_mask: 0.8526  decode.d8.loss_dice: 0.9911
2025/03/29 19:40:16 - mmengine - INFO - Saving checkpoint at 16000 iterations
2025/03/29 19:40:24 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:43  time: 0.1225  data_time: 0.0019  memory: 1808  
2025/03/29 19:40:30 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:37  time: 0.1251  data_time: 0.0019  memory: 1808  
2025/03/29 19:40:37 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:30  time: 0.1231  data_time: 0.0019  memory: 1808  
2025/03/29 19:40:43 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1230  data_time: 0.0020  memory: 1808  
2025/03/29 19:40:49 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1250  data_time: 0.0027  memory: 1808  
2025/03/29 19:40:55 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1240  data_time: 0.0019  memory: 1808  
2025/03/29 19:41:01 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1244  data_time: 0.0020  memory: 1808  
2025/03/29 19:41:07 - mmengine - INFO - per class results:
2025/03/29 19:41:07 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 75.27 | 84.33 |
|      building      | 84.86 | 95.07 |
|   low_vegetation   | 48.27 | 54.95 |
|        tree        | 73.84 | 87.72 |
|        car         |  59.4 | 72.86 |
|      clutter       | 15.29 | 92.95 |
+--------------------+-------+-------+
2025/03/29 19:41:07 - mmengine - INFO - Iter(val) [398/398]    aAcc: 81.2600  mIoU: 59.4900  mAcc: 81.3100  data_time: 0.0020  time: 0.1241
2025/03/29 19:42:03 - mmengine - INFO - Iter(train) [16050/20000]  base_lr: 2.3229e-05 lr: 2.3229e-05  eta: 1:49:49  time: 1.1155  data_time: 0.0208  memory: 10129  loss: 21.9193  decode.loss_cls: 0.2146  decode.loss_mask: 0.9791  decode.loss_dice: 1.0199  decode.d0.loss_cls: 0.2706  decode.d0.loss_mask: 0.9570  decode.d0.loss_dice: 1.0675  decode.d1.loss_cls: 0.2538  decode.d1.loss_mask: 0.9703  decode.d1.loss_dice: 1.0136  decode.d2.loss_cls: 0.2489  decode.d2.loss_mask: 0.9637  decode.d2.loss_dice: 0.9895  decode.d3.loss_cls: 0.2487  decode.d3.loss_mask: 0.9365  decode.d3.loss_dice: 0.9699  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 0.9518  decode.d4.loss_dice: 1.0116  decode.d5.loss_cls: 0.2031  decode.d5.loss_mask: 0.9650  decode.d5.loss_dice: 0.9855  decode.d6.loss_cls: 0.2375  decode.d6.loss_mask: 0.9723  decode.d6.loss_dice: 0.9840  decode.d7.loss_cls: 0.2231  decode.d7.loss_mask: 0.9469  decode.d7.loss_dice: 0.9715  decode.d8.loss_cls: 0.2433  decode.d8.loss_mask: 0.9466  decode.d8.loss_dice: 0.9861
2025/03/29 19:42:59 - mmengine - INFO - Iter(train) [16100/20000]  base_lr: 2.2964e-05 lr: 2.2964e-05  eta: 1:48:19  time: 1.1126  data_time: 0.0199  memory: 10126  loss: 23.1506  decode.loss_cls: 0.1686  decode.loss_mask: 1.0340  decode.loss_dice: 1.1180  decode.d0.loss_cls: 0.2533  decode.d0.loss_mask: 1.0489  decode.d0.loss_dice: 1.1592  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 1.0201  decode.d1.loss_dice: 1.1185  decode.d2.loss_cls: 0.1520  decode.d2.loss_mask: 1.0226  decode.d2.loss_dice: 1.1123  decode.d3.loss_cls: 0.1505  decode.d3.loss_mask: 1.0374  decode.d3.loss_dice: 1.1155  decode.d4.loss_cls: 0.1574  decode.d4.loss_mask: 1.0305  decode.d4.loss_dice: 1.0971  decode.d5.loss_cls: 0.1447  decode.d5.loss_mask: 1.0156  decode.d5.loss_dice: 1.1147  decode.d6.loss_cls: 0.1522  decode.d6.loss_mask: 1.0145  decode.d6.loss_dice: 1.1157  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 1.0168  decode.d7.loss_dice: 1.1227  decode.d8.loss_cls: 0.1630  decode.d8.loss_mask: 1.0258  decode.d8.loss_dice: 1.1182
2025/03/29 19:43:55 - mmengine - INFO - Iter(train) [16150/20000]  base_lr: 2.2699e-05 lr: 2.2699e-05  eta: 1:46:49  time: 1.1132  data_time: 0.0204  memory: 10122  loss: 22.7797  decode.loss_cls: 0.1550  decode.loss_mask: 0.9923  decode.loss_dice: 1.0786  decode.d0.loss_cls: 0.2786  decode.d0.loss_mask: 1.0015  decode.d0.loss_dice: 1.1710  decode.d1.loss_cls: 0.2403  decode.d1.loss_mask: 0.9950  decode.d1.loss_dice: 1.1039  decode.d2.loss_cls: 0.1815  decode.d2.loss_mask: 0.9916  decode.d2.loss_dice: 1.0938  decode.d3.loss_cls: 0.2373  decode.d3.loss_mask: 0.9805  decode.d3.loss_dice: 1.0588  decode.d4.loss_cls: 0.2237  decode.d4.loss_mask: 0.9706  decode.d4.loss_dice: 1.0562  decode.d5.loss_cls: 0.2025  decode.d5.loss_mask: 0.9725  decode.d5.loss_dice: 1.0646  decode.d6.loss_cls: 0.1876  decode.d6.loss_mask: 0.9879  decode.d6.loss_dice: 1.0870  decode.d7.loss_cls: 0.1987  decode.d7.loss_mask: 0.9798  decode.d7.loss_dice: 1.0519  decode.d8.loss_cls: 0.1598  decode.d8.loss_mask: 0.9932  decode.d8.loss_dice: 1.0843
2025/03/29 19:44:50 - mmengine - INFO - Iter(train) [16200/20000]  base_lr: 2.2434e-05 lr: 2.2434e-05  eta: 1:45:19  time: 1.1101  data_time: 0.0197  memory: 10127  loss: 24.0376  decode.loss_cls: 0.1695  decode.loss_mask: 1.0563  decode.loss_dice: 1.1342  decode.d0.loss_cls: 0.2299  decode.d0.loss_mask: 1.0736  decode.d0.loss_dice: 1.1678  decode.d1.loss_cls: 0.2059  decode.d1.loss_mask: 1.0805  decode.d1.loss_dice: 1.1340  decode.d2.loss_cls: 0.2045  decode.d2.loss_mask: 1.0655  decode.d2.loss_dice: 1.1479  decode.d3.loss_cls: 0.1717  decode.d3.loss_mask: 1.0711  decode.d3.loss_dice: 1.1526  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 1.0566  decode.d4.loss_dice: 1.1248  decode.d5.loss_cls: 0.1811  decode.d5.loss_mask: 1.0773  decode.d5.loss_dice: 1.1488  decode.d6.loss_cls: 0.2012  decode.d6.loss_mask: 1.0749  decode.d6.loss_dice: 1.1343  decode.d7.loss_cls: 0.1857  decode.d7.loss_mask: 1.0649  decode.d7.loss_dice: 1.1419  decode.d8.loss_cls: 0.1762  decode.d8.loss_mask: 1.0645  decode.d8.loss_dice: 1.1421
2025/03/29 19:45:47 - mmengine - INFO - Iter(train) [16250/20000]  base_lr: 2.2168e-05 lr: 2.2168e-05  eta: 1:43:50  time: 1.1139  data_time: 0.0200  memory: 10124  loss: 20.8711  decode.loss_cls: 0.1796  decode.loss_mask: 0.9249  decode.loss_dice: 0.9631  decode.d0.loss_cls: 0.2632  decode.d0.loss_mask: 0.9257  decode.d0.loss_dice: 0.9934  decode.d1.loss_cls: 0.1976  decode.d1.loss_mask: 0.9300  decode.d1.loss_dice: 0.9806  decode.d2.loss_cls: 0.1973  decode.d2.loss_mask: 0.9191  decode.d2.loss_dice: 0.9609  decode.d3.loss_cls: 0.2028  decode.d3.loss_mask: 0.9178  decode.d3.loss_dice: 0.9471  decode.d4.loss_cls: 0.1871  decode.d4.loss_mask: 0.9284  decode.d4.loss_dice: 0.9675  decode.d5.loss_cls: 0.1628  decode.d5.loss_mask: 0.9264  decode.d5.loss_dice: 0.9628  decode.d6.loss_cls: 0.2349  decode.d6.loss_mask: 0.9107  decode.d6.loss_dice: 0.9434  decode.d7.loss_cls: 0.1922  decode.d7.loss_mask: 0.9165  decode.d7.loss_dice: 0.9519  decode.d8.loss_cls: 0.1983  decode.d8.loss_mask: 0.9194  decode.d8.loss_dice: 0.9657
2025/03/29 19:46:42 - mmengine - INFO - Iter(train) [16300/20000]  base_lr: 2.1902e-05 lr: 2.1902e-05  eta: 1:42:21  time: 1.1113  data_time: 0.0199  memory: 10118  loss: 24.1975  decode.loss_cls: 0.2125  decode.loss_mask: 1.0684  decode.loss_dice: 1.1031  decode.d0.loss_cls: 0.2557  decode.d0.loss_mask: 1.1099  decode.d0.loss_dice: 1.1911  decode.d1.loss_cls: 0.2528  decode.d1.loss_mask: 1.0749  decode.d1.loss_dice: 1.1266  decode.d2.loss_cls: 0.2324  decode.d2.loss_mask: 1.0621  decode.d2.loss_dice: 1.1093  decode.d3.loss_cls: 0.1868  decode.d3.loss_mask: 1.0875  decode.d3.loss_dice: 1.1162  decode.d4.loss_cls: 0.2104  decode.d4.loss_mask: 1.0872  decode.d4.loss_dice: 1.1092  decode.d5.loss_cls: 0.2107  decode.d5.loss_mask: 1.0765  decode.d5.loss_dice: 1.1098  decode.d6.loss_cls: 0.2078  decode.d6.loss_mask: 1.0801  decode.d6.loss_dice: 1.1140  decode.d7.loss_cls: 0.2339  decode.d7.loss_mask: 1.0695  decode.d7.loss_dice: 1.1103  decode.d8.loss_cls: 0.2143  decode.d8.loss_mask: 1.0641  decode.d8.loss_dice: 1.1106
2025/03/29 19:47:38 - mmengine - INFO - Iter(train) [16350/20000]  base_lr: 2.1635e-05 lr: 2.1635e-05  eta: 1:40:52  time: 1.1120  data_time: 0.0198  memory: 10119  loss: 25.3221  decode.loss_cls: 0.1873  decode.loss_mask: 1.1156  decode.loss_dice: 1.2160  decode.d0.loss_cls: 0.2924  decode.d0.loss_mask: 1.0766  decode.d0.loss_dice: 1.2448  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 1.0820  decode.d1.loss_dice: 1.1861  decode.d2.loss_cls: 0.2389  decode.d2.loss_mask: 1.0819  decode.d2.loss_dice: 1.1999  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 1.0952  decode.d3.loss_dice: 1.2148  decode.d4.loss_cls: 0.2287  decode.d4.loss_mask: 1.0770  decode.d4.loss_dice: 1.2239  decode.d5.loss_cls: 0.2449  decode.d5.loss_mask: 1.0861  decode.d5.loss_dice: 1.1970  decode.d6.loss_cls: 0.2353  decode.d6.loss_mask: 1.0933  decode.d6.loss_dice: 1.2015  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 1.0885  decode.d7.loss_dice: 1.1992  decode.d8.loss_cls: 0.2084  decode.d8.loss_mask: 1.1036  decode.d8.loss_dice: 1.2154
2025/03/29 19:48:34 - mmengine - INFO - Iter(train) [16400/20000]  base_lr: 2.1368e-05 lr: 2.1368e-05  eta: 1:39:23  time: 1.1317  data_time: 0.0196  memory: 10122  loss: 22.8944  decode.loss_cls: 0.2013  decode.loss_mask: 0.9915  decode.loss_dice: 1.0951  decode.d0.loss_cls: 0.2839  decode.d0.loss_mask: 0.9905  decode.d0.loss_dice: 1.1680  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 0.9714  decode.d1.loss_dice: 1.0688  decode.d2.loss_cls: 0.2264  decode.d2.loss_mask: 0.9665  decode.d2.loss_dice: 1.0675  decode.d3.loss_cls: 0.2539  decode.d3.loss_mask: 0.9588  decode.d3.loss_dice: 1.0601  decode.d4.loss_cls: 0.2337  decode.d4.loss_mask: 0.9652  decode.d4.loss_dice: 1.0648  decode.d5.loss_cls: 0.2306  decode.d5.loss_mask: 0.9594  decode.d5.loss_dice: 1.0570  decode.d6.loss_cls: 0.2103  decode.d6.loss_mask: 0.9790  decode.d6.loss_dice: 1.0729  decode.d7.loss_cls: 0.2299  decode.d7.loss_mask: 0.9719  decode.d7.loss_dice: 1.0751  decode.d8.loss_cls: 0.2122  decode.d8.loss_mask: 0.9862  decode.d8.loss_dice: 1.0875
2025/03/29 19:49:30 - mmengine - INFO - Iter(train) [16450/20000]  base_lr: 2.1101e-05 lr: 2.1101e-05  eta: 1:37:54  time: 1.1111  data_time: 0.0205  memory: 10133  loss: 21.5852  decode.loss_cls: 0.1677  decode.loss_mask: 1.0140  decode.loss_dice: 0.9984  decode.d0.loss_cls: 0.2495  decode.d0.loss_mask: 1.0274  decode.d0.loss_dice: 1.0524  decode.d1.loss_cls: 0.1870  decode.d1.loss_mask: 0.9950  decode.d1.loss_dice: 0.9715  decode.d2.loss_cls: 0.1919  decode.d2.loss_mask: 0.9827  decode.d2.loss_dice: 0.9536  decode.d3.loss_cls: 0.1880  decode.d3.loss_mask: 0.9989  decode.d3.loss_dice: 0.9643  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 0.9918  decode.d4.loss_dice: 0.9540  decode.d5.loss_cls: 0.1608  decode.d5.loss_mask: 0.9765  decode.d5.loss_dice: 0.9703  decode.d6.loss_cls: 0.1725  decode.d6.loss_mask: 0.9811  decode.d6.loss_dice: 0.9637  decode.d7.loss_cls: 0.1736  decode.d7.loss_mask: 0.9792  decode.d7.loss_dice: 0.9537  decode.d8.loss_cls: 0.1573  decode.d8.loss_mask: 0.9953  decode.d8.loss_dice: 0.9928
2025/03/29 19:50:26 - mmengine - INFO - Iter(train) [16500/20000]  base_lr: 2.0833e-05 lr: 2.0833e-05  eta: 1:36:26  time: 1.1110  data_time: 0.0196  memory: 10118  loss: 21.2943  decode.loss_cls: 0.2081  decode.loss_mask: 0.9235  decode.loss_dice: 0.9522  decode.d0.loss_cls: 0.3060  decode.d0.loss_mask: 0.9291  decode.d0.loss_dice: 1.0134  decode.d1.loss_cls: 0.2673  decode.d1.loss_mask: 0.9318  decode.d1.loss_dice: 0.9765  decode.d2.loss_cls: 0.2293  decode.d2.loss_mask: 0.9259  decode.d2.loss_dice: 0.9625  decode.d3.loss_cls: 0.2399  decode.d3.loss_mask: 0.9425  decode.d3.loss_dice: 0.9629  decode.d4.loss_cls: 0.2533  decode.d4.loss_mask: 0.9227  decode.d4.loss_dice: 0.9480  decode.d5.loss_cls: 0.2382  decode.d5.loss_mask: 0.9285  decode.d5.loss_dice: 0.9698  decode.d6.loss_cls: 0.2098  decode.d6.loss_mask: 0.9282  decode.d6.loss_dice: 0.9760  decode.d7.loss_cls: 0.2038  decode.d7.loss_mask: 0.9168  decode.d7.loss_dice: 0.9343  decode.d8.loss_cls: 0.2141  decode.d8.loss_mask: 0.9185  decode.d8.loss_dice: 0.9615
2025/03/29 19:51:22 - mmengine - INFO - Iter(train) [16550/20000]  base_lr: 2.0565e-05 lr: 2.0565e-05  eta: 1:34:57  time: 1.1090  data_time: 0.0201  memory: 10129  loss: 22.6266  decode.loss_cls: 0.1515  decode.loss_mask: 1.0016  decode.loss_dice: 1.0903  decode.d0.loss_cls: 0.2231  decode.d0.loss_mask: 1.0096  decode.d0.loss_dice: 1.1551  decode.d1.loss_cls: 0.1433  decode.d1.loss_mask: 1.0026  decode.d1.loss_dice: 1.1031  decode.d2.loss_cls: 0.1677  decode.d2.loss_mask: 1.0043  decode.d2.loss_dice: 1.0870  decode.d3.loss_cls: 0.1472  decode.d3.loss_mask: 1.0123  decode.d3.loss_dice: 1.1002  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 1.0212  decode.d4.loss_dice: 1.1187  decode.d5.loss_cls: 0.1560  decode.d5.loss_mask: 1.0053  decode.d5.loss_dice: 1.0794  decode.d6.loss_cls: 0.1549  decode.d6.loss_mask: 1.0038  decode.d6.loss_dice: 1.0835  decode.d7.loss_cls: 0.1514  decode.d7.loss_mask: 0.9931  decode.d7.loss_dice: 1.0795  decode.d8.loss_cls: 0.1491  decode.d8.loss_mask: 0.9948  decode.d8.loss_dice: 1.1054
2025/03/29 19:52:18 - mmengine - INFO - Iter(train) [16600/20000]  base_lr: 2.0297e-05 lr: 2.0297e-05  eta: 1:33:29  time: 1.1179  data_time: 0.0217  memory: 10124  loss: 23.2315  decode.loss_cls: 0.1542  decode.loss_mask: 1.0809  decode.loss_dice: 1.0816  decode.d0.loss_cls: 0.1748  decode.d0.loss_mask: 1.0968  decode.d0.loss_dice: 1.1691  decode.d1.loss_cls: 0.1569  decode.d1.loss_mask: 1.0847  decode.d1.loss_dice: 1.0895  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 1.0683  decode.d2.loss_dice: 1.0647  decode.d3.loss_cls: 0.1793  decode.d3.loss_mask: 1.0717  decode.d3.loss_dice: 1.0437  decode.d4.loss_cls: 0.1788  decode.d4.loss_mask: 1.0661  decode.d4.loss_dice: 1.0528  decode.d5.loss_cls: 0.1726  decode.d5.loss_mask: 1.0672  decode.d5.loss_dice: 1.0740  decode.d6.loss_cls: 0.1686  decode.d6.loss_mask: 1.0614  decode.d6.loss_dice: 1.0849  decode.d7.loss_cls: 0.1605  decode.d7.loss_mask: 1.0792  decode.d7.loss_dice: 1.0663  decode.d8.loss_cls: 0.1571  decode.d8.loss_mask: 1.0816  decode.d8.loss_dice: 1.0761
2025/03/29 19:53:13 - mmengine - INFO - Iter(train) [16650/20000]  base_lr: 2.0028e-05 lr: 2.0028e-05  eta: 1:32:02  time: 1.1102  data_time: 0.0199  memory: 10131  loss: 23.1015  decode.loss_cls: 0.1990  decode.loss_mask: 1.0006  decode.loss_dice: 1.0780  decode.d0.loss_cls: 0.2889  decode.d0.loss_mask: 1.0003  decode.d0.loss_dice: 1.1487  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 1.0107  decode.d1.loss_dice: 1.0637  decode.d2.loss_cls: 0.2368  decode.d2.loss_mask: 0.9987  decode.d2.loss_dice: 1.0509  decode.d3.loss_cls: 0.2577  decode.d3.loss_mask: 1.0155  decode.d3.loss_dice: 1.0401  decode.d4.loss_cls: 0.2180  decode.d4.loss_mask: 1.0161  decode.d4.loss_dice: 1.0666  decode.d5.loss_cls: 0.2591  decode.d5.loss_mask: 1.0131  decode.d5.loss_dice: 1.0661  decode.d6.loss_cls: 0.2364  decode.d6.loss_mask: 0.9932  decode.d6.loss_dice: 1.0629  decode.d7.loss_cls: 0.2259  decode.d7.loss_mask: 1.0213  decode.d7.loss_dice: 1.0483  decode.d8.loss_cls: 0.2239  decode.d8.loss_mask: 0.9869  decode.d8.loss_dice: 1.0448
2025/03/29 19:54:09 - mmengine - INFO - Iter(train) [16700/20000]  base_lr: 1.9759e-05 lr: 1.9759e-05  eta: 1:30:34  time: 1.1129  data_time: 0.0197  memory: 10124  loss: 22.2163  decode.loss_cls: 0.1152  decode.loss_mask: 0.9964  decode.loss_dice: 1.0998  decode.d0.loss_cls: 0.2196  decode.d0.loss_mask: 1.0199  decode.d0.loss_dice: 1.1108  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 1.0040  decode.d1.loss_dice: 1.0810  decode.d2.loss_cls: 0.1188  decode.d2.loss_mask: 1.0045  decode.d2.loss_dice: 1.0793  decode.d3.loss_cls: 0.1448  decode.d3.loss_mask: 0.9935  decode.d3.loss_dice: 1.0573  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 0.9853  decode.d4.loss_dice: 1.0674  decode.d5.loss_cls: 0.1113  decode.d5.loss_mask: 0.9987  decode.d5.loss_dice: 1.0953  decode.d6.loss_cls: 0.1040  decode.d6.loss_mask: 0.9989  decode.d6.loss_dice: 1.0903  decode.d7.loss_cls: 0.1687  decode.d7.loss_mask: 0.9876  decode.d7.loss_dice: 1.0687  decode.d8.loss_cls: 0.1455  decode.d8.loss_mask: 0.9840  decode.d8.loss_dice: 1.0897
2025/03/29 19:55:05 - mmengine - INFO - Iter(train) [16750/20000]  base_lr: 1.9489e-05 lr: 1.9489e-05  eta: 1:29:06  time: 1.1110  data_time: 0.0205  memory: 10119  loss: 23.0742  decode.loss_cls: 0.2114  decode.loss_mask: 1.0064  decode.loss_dice: 1.0665  decode.d0.loss_cls: 0.2554  decode.d0.loss_mask: 1.0166  decode.d0.loss_dice: 1.1213  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 1.0003  decode.d1.loss_dice: 1.0636  decode.d2.loss_cls: 0.2333  decode.d2.loss_mask: 1.0092  decode.d2.loss_dice: 1.0473  decode.d3.loss_cls: 0.2256  decode.d3.loss_mask: 1.0051  decode.d3.loss_dice: 1.0562  decode.d4.loss_cls: 0.2402  decode.d4.loss_mask: 1.0029  decode.d4.loss_dice: 1.0533  decode.d5.loss_cls: 0.2443  decode.d5.loss_mask: 1.0086  decode.d5.loss_dice: 1.0497  decode.d6.loss_cls: 0.2351  decode.d6.loss_mask: 1.0009  decode.d6.loss_dice: 1.0439  decode.d7.loss_cls: 0.2356  decode.d7.loss_mask: 1.0078  decode.d7.loss_dice: 1.0463  decode.d8.loss_cls: 0.2322  decode.d8.loss_mask: 1.0085  decode.d8.loss_dice: 1.0582
2025/03/29 19:56:02 - mmengine - INFO - Iter(train) [16800/20000]  base_lr: 1.9219e-05 lr: 1.9219e-05  eta: 1:27:39  time: 1.2274  data_time: 0.0284  memory: 10121  loss: 21.6831  decode.loss_cls: 0.1532  decode.loss_mask: 0.9401  decode.loss_dice: 1.0281  decode.d0.loss_cls: 0.1926  decode.d0.loss_mask: 0.9893  decode.d0.loss_dice: 1.1196  decode.d1.loss_cls: 0.1737  decode.d1.loss_mask: 0.9551  decode.d1.loss_dice: 1.0656  decode.d2.loss_cls: 0.1955  decode.d2.loss_mask: 0.9480  decode.d2.loss_dice: 1.0369  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.9421  decode.d3.loss_dice: 1.0320  decode.d4.loss_cls: 0.1766  decode.d4.loss_mask: 0.9368  decode.d4.loss_dice: 1.0205  decode.d5.loss_cls: 0.1752  decode.d5.loss_mask: 0.9401  decode.d5.loss_dice: 1.0134  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 0.9472  decode.d6.loss_dice: 1.0163  decode.d7.loss_cls: 0.1766  decode.d7.loss_mask: 0.9622  decode.d7.loss_dice: 1.0188  decode.d8.loss_cls: 0.1740  decode.d8.loss_mask: 0.9674  decode.d8.loss_dice: 1.0427
2025/03/29 19:56:59 - mmengine - INFO - Iter(train) [16850/20000]  base_lr: 1.8948e-05 lr: 1.8948e-05  eta: 1:26:12  time: 1.1128  data_time: 0.0207  memory: 10119  loss: 22.2226  decode.loss_cls: 0.1360  decode.loss_mask: 1.0525  decode.loss_dice: 1.0271  decode.d0.loss_cls: 0.1905  decode.d0.loss_mask: 1.0596  decode.d0.loss_dice: 1.0695  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 1.0461  decode.d1.loss_dice: 1.0361  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 1.0517  decode.d2.loss_dice: 1.0334  decode.d3.loss_cls: 0.1146  decode.d3.loss_mask: 1.0683  decode.d3.loss_dice: 1.0271  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 1.0979  decode.d4.loss_dice: 1.0258  decode.d5.loss_cls: 0.0982  decode.d5.loss_mask: 1.0723  decode.d5.loss_dice: 1.0374  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 1.0685  decode.d6.loss_dice: 1.0301  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 1.0581  decode.d7.loss_dice: 1.0211  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 1.0566  decode.d8.loss_dice: 1.0289
2025/03/29 19:57:54 - mmengine - INFO - Iter(train) [16900/20000]  base_lr: 1.8677e-05 lr: 1.8677e-05  eta: 1:24:45  time: 1.1131  data_time: 0.0200  memory: 10124  loss: 23.8158  decode.loss_cls: 0.1812  decode.loss_mask: 1.0765  decode.loss_dice: 1.1248  decode.d0.loss_cls: 0.2536  decode.d0.loss_mask: 1.0852  decode.d0.loss_dice: 1.1735  decode.d1.loss_cls: 0.1626  decode.d1.loss_mask: 1.0712  decode.d1.loss_dice: 1.1346  decode.d2.loss_cls: 0.1825  decode.d2.loss_mask: 1.0634  decode.d2.loss_dice: 1.1183  decode.d3.loss_cls: 0.1704  decode.d3.loss_mask: 1.0733  decode.d3.loss_dice: 1.1190  decode.d4.loss_cls: 0.1857  decode.d4.loss_mask: 1.0560  decode.d4.loss_dice: 1.1104  decode.d5.loss_cls: 0.1353  decode.d5.loss_mask: 1.0877  decode.d5.loss_dice: 1.1405  decode.d6.loss_cls: 0.1361  decode.d6.loss_mask: 1.0898  decode.d6.loss_dice: 1.1380  decode.d7.loss_cls: 0.1488  decode.d7.loss_mask: 1.0804  decode.d7.loss_dice: 1.1351  decode.d8.loss_cls: 0.1626  decode.d8.loss_mask: 1.0899  decode.d8.loss_dice: 1.1293
2025/03/29 19:58:50 - mmengine - INFO - Iter(train) [16950/20000]  base_lr: 1.8406e-05 lr: 1.8406e-05  eta: 1:23:19  time: 1.1126  data_time: 0.0196  memory: 10120  loss: 19.4123  decode.loss_cls: 0.1410  decode.loss_mask: 0.8112  decode.loss_dice: 0.9870  decode.d0.loss_cls: 0.1723  decode.d0.loss_mask: 0.8233  decode.d0.loss_dice: 1.0252  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 0.8025  decode.d1.loss_dice: 0.9948  decode.d2.loss_cls: 0.1642  decode.d2.loss_mask: 0.8041  decode.d2.loss_dice: 0.9750  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 0.8094  decode.d3.loss_dice: 0.9889  decode.d4.loss_cls: 0.1272  decode.d4.loss_mask: 0.8114  decode.d4.loss_dice: 0.9954  decode.d5.loss_cls: 0.1184  decode.d5.loss_mask: 0.8107  decode.d5.loss_dice: 0.9960  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.8125  decode.d6.loss_dice: 1.0038  decode.d7.loss_cls: 0.1156  decode.d7.loss_mask: 0.8124  decode.d7.loss_dice: 1.0052  decode.d8.loss_cls: 0.1418  decode.d8.loss_mask: 0.8024  decode.d8.loss_dice: 0.9667
2025/03/29 19:59:46 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 19:59:46 - mmengine - INFO - Iter(train) [17000/20000]  base_lr: 1.8134e-05 lr: 1.8134e-05  eta: 1:21:52  time: 1.1120  data_time: 0.0204  memory: 10129  loss: 22.5605  decode.loss_cls: 0.1507  decode.loss_mask: 1.0599  decode.loss_dice: 1.0230  decode.d0.loss_cls: 0.2294  decode.d0.loss_mask: 1.0649  decode.d0.loss_dice: 1.0801  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 1.0375  decode.d1.loss_dice: 1.0441  decode.d2.loss_cls: 0.1819  decode.d2.loss_mask: 1.0275  decode.d2.loss_dice: 1.0259  decode.d3.loss_cls: 0.2039  decode.d3.loss_mask: 1.0303  decode.d3.loss_dice: 1.0145  decode.d4.loss_cls: 0.1681  decode.d4.loss_mask: 1.0354  decode.d4.loss_dice: 1.0308  decode.d5.loss_cls: 0.1893  decode.d5.loss_mask: 1.0304  decode.d5.loss_dice: 1.0155  decode.d6.loss_cls: 0.1866  decode.d6.loss_mask: 1.0371  decode.d6.loss_dice: 1.0183  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 1.0460  decode.d7.loss_dice: 1.0294  decode.d8.loss_cls: 0.1545  decode.d8.loss_mask: 1.0625  decode.d8.loss_dice: 1.0412
2025/03/29 20:00:42 - mmengine - INFO - Iter(train) [17050/20000]  base_lr: 1.7862e-05 lr: 1.7862e-05  eta: 1:20:26  time: 1.1144  data_time: 0.0197  memory: 10129  loss: 25.3428  decode.loss_cls: 0.3074  decode.loss_mask: 1.0951  decode.loss_dice: 1.1383  decode.d0.loss_cls: 0.3084  decode.d0.loss_mask: 1.1102  decode.d0.loss_dice: 1.2303  decode.d1.loss_cls: 0.2935  decode.d1.loss_mask: 1.0827  decode.d1.loss_dice: 1.1772  decode.d2.loss_cls: 0.3266  decode.d2.loss_mask: 1.0684  decode.d2.loss_dice: 1.1125  decode.d3.loss_cls: 0.2564  decode.d3.loss_mask: 1.1096  decode.d3.loss_dice: 1.1378  decode.d4.loss_cls: 0.2980  decode.d4.loss_mask: 1.0780  decode.d4.loss_dice: 1.1466  decode.d5.loss_cls: 0.2572  decode.d5.loss_mask: 1.1089  decode.d5.loss_dice: 1.1708  decode.d6.loss_cls: 0.2699  decode.d6.loss_mask: 1.0952  decode.d6.loss_dice: 1.1416  decode.d7.loss_cls: 0.2895  decode.d7.loss_mask: 1.0933  decode.d7.loss_dice: 1.1203  decode.d8.loss_cls: 0.2779  decode.d8.loss_mask: 1.1141  decode.d8.loss_dice: 1.1267
2025/03/29 20:01:37 - mmengine - INFO - Iter(train) [17100/20000]  base_lr: 1.7589e-05 lr: 1.7589e-05  eta: 1:18:59  time: 1.1160  data_time: 0.0203  memory: 10118  loss: 24.6006  decode.loss_cls: 0.2682  decode.loss_mask: 0.9998  decode.loss_dice: 1.1804  decode.d0.loss_cls: 0.2286  decode.d0.loss_mask: 1.0058  decode.d0.loss_dice: 1.2424  decode.d1.loss_cls: 0.2719  decode.d1.loss_mask: 1.0083  decode.d1.loss_dice: 1.1973  decode.d2.loss_cls: 0.2974  decode.d2.loss_mask: 1.0045  decode.d2.loss_dice: 1.1813  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 1.0118  decode.d3.loss_dice: 1.2201  decode.d4.loss_cls: 0.2497  decode.d4.loss_mask: 1.0066  decode.d4.loss_dice: 1.1858  decode.d5.loss_cls: 0.2693  decode.d5.loss_mask: 0.9965  decode.d5.loss_dice: 1.1817  decode.d6.loss_cls: 0.2764  decode.d6.loss_mask: 1.0156  decode.d6.loss_dice: 1.1914  decode.d7.loss_cls: 0.2669  decode.d7.loss_mask: 0.9989  decode.d7.loss_dice: 1.1740  decode.d8.loss_cls: 0.2545  decode.d8.loss_mask: 0.9971  decode.d8.loss_dice: 1.1867
2025/03/29 20:02:33 - mmengine - INFO - Iter(train) [17150/20000]  base_lr: 1.7316e-05 lr: 1.7316e-05  eta: 1:17:33  time: 1.1147  data_time: 0.0208  memory: 10117  loss: 22.9112  decode.loss_cls: 0.1833  decode.loss_mask: 1.0135  decode.loss_dice: 1.0883  decode.d0.loss_cls: 0.2422  decode.d0.loss_mask: 1.0255  decode.d0.loss_dice: 1.1427  decode.d1.loss_cls: 0.2851  decode.d1.loss_mask: 0.9879  decode.d1.loss_dice: 1.0631  decode.d2.loss_cls: 0.2201  decode.d2.loss_mask: 1.0007  decode.d2.loss_dice: 1.0675  decode.d3.loss_cls: 0.1829  decode.d3.loss_mask: 0.9902  decode.d3.loss_dice: 1.0530  decode.d4.loss_cls: 0.2287  decode.d4.loss_mask: 0.9933  decode.d4.loss_dice: 1.0645  decode.d5.loss_cls: 0.1906  decode.d5.loss_mask: 1.0105  decode.d5.loss_dice: 1.0624  decode.d6.loss_cls: 0.1958  decode.d6.loss_mask: 1.0092  decode.d6.loss_dice: 1.0598  decode.d7.loss_cls: 0.1897  decode.d7.loss_mask: 1.0131  decode.d7.loss_dice: 1.0695  decode.d8.loss_cls: 0.1948  decode.d8.loss_mask: 1.0131  decode.d8.loss_dice: 1.0701
2025/03/29 20:03:29 - mmengine - INFO - Iter(train) [17200/20000]  base_lr: 1.7043e-05 lr: 1.7043e-05  eta: 1:16:08  time: 1.1086  data_time: 0.0198  memory: 10120  loss: 21.5371  decode.loss_cls: 0.1232  decode.loss_mask: 0.9626  decode.loss_dice: 1.0307  decode.d0.loss_cls: 0.2370  decode.d0.loss_mask: 0.9970  decode.d0.loss_dice: 1.1000  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 0.9507  decode.d1.loss_dice: 1.0432  decode.d2.loss_cls: 0.1390  decode.d2.loss_mask: 0.9531  decode.d2.loss_dice: 1.0475  decode.d3.loss_cls: 0.1132  decode.d3.loss_mask: 0.9692  decode.d3.loss_dice: 1.0318  decode.d4.loss_cls: 0.1402  decode.d4.loss_mask: 0.9617  decode.d4.loss_dice: 1.0449  decode.d5.loss_cls: 0.1297  decode.d5.loss_mask: 0.9561  decode.d5.loss_dice: 1.0360  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 0.9620  decode.d6.loss_dice: 1.0302  decode.d7.loss_cls: 0.1144  decode.d7.loss_mask: 0.9689  decode.d7.loss_dice: 1.0646  decode.d8.loss_cls: 0.1281  decode.d8.loss_mask: 0.9695  decode.d8.loss_dice: 1.0567
2025/03/29 20:04:25 - mmengine - INFO - Iter(train) [17250/20000]  base_lr: 1.6768e-05 lr: 1.6768e-05  eta: 1:14:42  time: 1.1110  data_time: 0.0200  memory: 10125  loss: 22.1443  decode.loss_cls: 0.1368  decode.loss_mask: 0.9568  decode.loss_dice: 1.0772  decode.d0.loss_cls: 0.1840  decode.d0.loss_mask: 0.9671  decode.d0.loss_dice: 1.1427  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.9771  decode.d1.loss_dice: 1.1112  decode.d2.loss_cls: 0.1742  decode.d2.loss_mask: 0.9687  decode.d2.loss_dice: 1.0770  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.9739  decode.d3.loss_dice: 1.0875  decode.d4.loss_cls: 0.1384  decode.d4.loss_mask: 0.9767  decode.d4.loss_dice: 1.1039  decode.d5.loss_cls: 0.1394  decode.d5.loss_mask: 0.9622  decode.d5.loss_dice: 1.1040  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 0.9661  decode.d6.loss_dice: 1.1013  decode.d7.loss_cls: 0.1200  decode.d7.loss_mask: 0.9634  decode.d7.loss_dice: 1.0951  decode.d8.loss_cls: 0.1221  decode.d8.loss_mask: 0.9602  decode.d8.loss_dice: 1.0974
2025/03/29 20:05:21 - mmengine - INFO - Iter(train) [17300/20000]  base_lr: 1.6494e-05 lr: 1.6494e-05  eta: 1:13:16  time: 1.1137  data_time: 0.0218  memory: 10119  loss: 22.6100  decode.loss_cls: 0.3262  decode.loss_mask: 0.8611  decode.loss_dice: 1.0652  decode.d0.loss_cls: 0.3804  decode.d0.loss_mask: 0.8549  decode.d0.loss_dice: 1.1141  decode.d1.loss_cls: 0.3623  decode.d1.loss_mask: 0.8519  decode.d1.loss_dice: 1.0439  decode.d2.loss_cls: 0.3404  decode.d2.loss_mask: 0.8596  decode.d2.loss_dice: 1.0566  decode.d3.loss_cls: 0.3221  decode.d3.loss_mask: 0.8765  decode.d3.loss_dice: 1.0589  decode.d4.loss_cls: 0.3488  decode.d4.loss_mask: 0.8740  decode.d4.loss_dice: 1.0501  decode.d5.loss_cls: 0.3319  decode.d5.loss_mask: 0.8672  decode.d5.loss_dice: 1.0426  decode.d6.loss_cls: 0.3380  decode.d6.loss_mask: 0.8748  decode.d6.loss_dice: 1.0492  decode.d7.loss_cls: 0.3252  decode.d7.loss_mask: 0.8588  decode.d7.loss_dice: 1.0611  decode.d8.loss_cls: 0.3224  decode.d8.loss_mask: 0.8636  decode.d8.loss_dice: 1.0281
2025/03/29 20:06:16 - mmengine - INFO - Iter(train) [17350/20000]  base_lr: 1.6219e-05 lr: 1.6219e-05  eta: 1:11:51  time: 1.1085  data_time: 0.0198  memory: 10119  loss: 21.4467  decode.loss_cls: 0.1867  decode.loss_mask: 0.9705  decode.loss_dice: 0.9483  decode.d0.loss_cls: 0.2845  decode.d0.loss_mask: 0.9911  decode.d0.loss_dice: 0.9620  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.9754  decode.d1.loss_dice: 0.9521  decode.d2.loss_cls: 0.2091  decode.d2.loss_mask: 0.9735  decode.d2.loss_dice: 0.9649  decode.d3.loss_cls: 0.2029  decode.d3.loss_mask: 0.9673  decode.d3.loss_dice: 0.9557  decode.d4.loss_cls: 0.2150  decode.d4.loss_mask: 0.9944  decode.d4.loss_dice: 0.9359  decode.d5.loss_cls: 0.1941  decode.d5.loss_mask: 0.9862  decode.d5.loss_dice: 0.9664  decode.d6.loss_cls: 0.1977  decode.d6.loss_mask: 0.9661  decode.d6.loss_dice: 0.9470  decode.d7.loss_cls: 0.2123  decode.d7.loss_mask: 0.9724  decode.d7.loss_dice: 0.9579  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 0.9714  decode.d8.loss_dice: 0.9611
2025/03/29 20:07:12 - mmengine - INFO - Iter(train) [17400/20000]  base_lr: 1.5943e-05 lr: 1.5943e-05  eta: 1:10:26  time: 1.1083  data_time: 0.0198  memory: 10129  loss: 23.7180  decode.loss_cls: 0.1085  decode.loss_mask: 1.0747  decode.loss_dice: 1.1552  decode.d0.loss_cls: 0.2089  decode.d0.loss_mask: 1.0744  decode.d0.loss_dice: 1.1935  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 1.0503  decode.d1.loss_dice: 1.1445  decode.d2.loss_cls: 0.1877  decode.d2.loss_mask: 1.0433  decode.d2.loss_dice: 1.1270  decode.d3.loss_cls: 0.1823  decode.d3.loss_mask: 1.0322  decode.d3.loss_dice: 1.1393  decode.d4.loss_cls: 0.1499  decode.d4.loss_mask: 1.0509  decode.d4.loss_dice: 1.1437  decode.d5.loss_cls: 0.1797  decode.d5.loss_mask: 1.0399  decode.d5.loss_dice: 1.1319  decode.d6.loss_cls: 0.1658  decode.d6.loss_mask: 1.0557  decode.d6.loss_dice: 1.1495  decode.d7.loss_cls: 0.1897  decode.d7.loss_mask: 1.0522  decode.d7.loss_dice: 1.1533  decode.d8.loss_cls: 0.1381  decode.d8.loss_mask: 1.0381  decode.d8.loss_dice: 1.1389
2025/03/29 20:08:08 - mmengine - INFO - Iter(train) [17450/20000]  base_lr: 1.5667e-05 lr: 1.5667e-05  eta: 1:09:01  time: 1.1196  data_time: 0.0200  memory: 10129  loss: 23.8074  decode.loss_cls: 0.2004  decode.loss_mask: 1.0584  decode.loss_dice: 1.1318  decode.d0.loss_cls: 0.2415  decode.d0.loss_mask: 1.0780  decode.d0.loss_dice: 1.1533  decode.d1.loss_cls: 0.2242  decode.d1.loss_mask: 1.0472  decode.d1.loss_dice: 1.1153  decode.d2.loss_cls: 0.2233  decode.d2.loss_mask: 1.0364  decode.d2.loss_dice: 1.0979  decode.d3.loss_cls: 0.2276  decode.d3.loss_mask: 1.0309  decode.d3.loss_dice: 1.1039  decode.d4.loss_cls: 0.2145  decode.d4.loss_mask: 1.0438  decode.d4.loss_dice: 1.1095  decode.d5.loss_cls: 0.1820  decode.d5.loss_mask: 1.0403  decode.d5.loss_dice: 1.1060  decode.d6.loss_cls: 0.1708  decode.d6.loss_mask: 1.0533  decode.d6.loss_dice: 1.1277  decode.d7.loss_cls: 0.2354  decode.d7.loss_mask: 1.0346  decode.d7.loss_dice: 1.1111  decode.d8.loss_cls: 0.2493  decode.d8.loss_mask: 1.0356  decode.d8.loss_dice: 1.1235
2025/03/29 20:09:07 - mmengine - INFO - Iter(train) [17500/20000]  base_lr: 1.5390e-05 lr: 1.5390e-05  eta: 1:07:36  time: 1.2413  data_time: 0.0260  memory: 10124  loss: 23.3561  decode.loss_cls: 0.1415  decode.loss_mask: 1.0476  decode.loss_dice: 1.1076  decode.d0.loss_cls: 0.1883  decode.d0.loss_mask: 1.0832  decode.d0.loss_dice: 1.1888  decode.d1.loss_cls: 0.2043  decode.d1.loss_mask: 1.0417  decode.d1.loss_dice: 1.0969  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 1.0341  decode.d2.loss_dice: 1.0890  decode.d3.loss_cls: 0.1724  decode.d3.loss_mask: 1.0597  decode.d3.loss_dice: 1.1033  decode.d4.loss_cls: 0.1670  decode.d4.loss_mask: 1.0519  decode.d4.loss_dice: 1.0962  decode.d5.loss_cls: 0.1678  decode.d5.loss_mask: 1.0493  decode.d5.loss_dice: 1.1183  decode.d6.loss_cls: 0.1851  decode.d6.loss_mask: 1.0441  decode.d6.loss_dice: 1.0937  decode.d7.loss_cls: 0.1377  decode.d7.loss_mask: 1.0589  decode.d7.loss_dice: 1.1228  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 1.0477  decode.d8.loss_dice: 1.0915
2025/03/29 20:11:29 - mmengine - INFO - Iter(train) [17550/20000]  base_lr: 1.5113e-05 lr: 1.5113e-05  eta: 1:06:24  time: 2.9943  data_time: 0.0203  memory: 10126  loss: 23.7958  decode.loss_cls: 0.1832  decode.loss_mask: 1.1104  decode.loss_dice: 1.1008  decode.d0.loss_cls: 0.2388  decode.d0.loss_mask: 1.0784  decode.d0.loss_dice: 1.1245  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 1.0829  decode.d1.loss_dice: 1.0979  decode.d2.loss_cls: 0.2387  decode.d2.loss_mask: 1.0775  decode.d2.loss_dice: 1.0954  decode.d3.loss_cls: 0.2137  decode.d3.loss_mask: 1.0793  decode.d3.loss_dice: 1.0812  decode.d4.loss_cls: 0.1766  decode.d4.loss_mask: 1.0852  decode.d4.loss_dice: 1.0955  decode.d5.loss_cls: 0.1957  decode.d5.loss_mask: 1.0790  decode.d5.loss_dice: 1.0834  decode.d6.loss_cls: 0.1935  decode.d6.loss_mask: 1.0771  decode.d6.loss_dice: 1.0908  decode.d7.loss_cls: 0.1949  decode.d7.loss_mask: 1.0725  decode.d7.loss_dice: 1.0767  decode.d8.loss_cls: 0.2119  decode.d8.loss_mask: 1.0741  decode.d8.loss_dice: 1.0719
2025/03/29 20:13:59 - mmengine - INFO - Iter(train) [17600/20000]  base_lr: 1.4835e-05 lr: 1.4835e-05  eta: 1:05:12  time: 2.9720  data_time: 0.0207  memory: 10119  loss: 20.3661  decode.loss_cls: 0.1255  decode.loss_mask: 0.9372  decode.loss_dice: 0.9672  decode.d0.loss_cls: 0.1686  decode.d0.loss_mask: 0.9570  decode.d0.loss_dice: 1.0092  decode.d1.loss_cls: 0.1482  decode.d1.loss_mask: 0.9389  decode.d1.loss_dice: 0.9544  decode.d2.loss_cls: 0.1285  decode.d2.loss_mask: 0.9433  decode.d2.loss_dice: 0.9560  decode.d3.loss_cls: 0.1136  decode.d3.loss_mask: 0.9433  decode.d3.loss_dice: 0.9431  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.9411  decode.d4.loss_dice: 0.9657  decode.d5.loss_cls: 0.1251  decode.d5.loss_mask: 0.9358  decode.d5.loss_dice: 0.9488  decode.d6.loss_cls: 0.1587  decode.d6.loss_mask: 0.9370  decode.d6.loss_dice: 0.9422  decode.d7.loss_cls: 0.1353  decode.d7.loss_mask: 0.9465  decode.d7.loss_dice: 0.9463  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 0.9396  decode.d8.loss_dice: 0.9548
2025/03/29 20:16:28 - mmengine - INFO - Iter(train) [17650/20000]  base_lr: 1.4556e-05 lr: 1.4556e-05  eta: 1:03:59  time: 2.9757  data_time: 0.0207  memory: 10122  loss: 21.1804  decode.loss_cls: 0.1611  decode.loss_mask: 0.9253  decode.loss_dice: 1.0170  decode.d0.loss_cls: 0.2738  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 1.0359  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 0.9245  decode.d1.loss_dice: 1.0068  decode.d2.loss_cls: 0.2067  decode.d2.loss_mask: 0.9036  decode.d2.loss_dice: 0.9946  decode.d3.loss_cls: 0.1646  decode.d3.loss_mask: 0.9234  decode.d3.loss_dice: 1.0212  decode.d4.loss_cls: 0.1606  decode.d4.loss_mask: 0.9157  decode.d4.loss_dice: 1.0274  decode.d5.loss_cls: 0.1634  decode.d5.loss_mask: 0.9136  decode.d5.loss_dice: 1.0130  decode.d6.loss_cls: 0.1798  decode.d6.loss_mask: 0.9175  decode.d6.loss_dice: 1.0088  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.9302  decode.d7.loss_dice: 1.0225  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 0.9273  decode.d8.loss_dice: 1.0340
2025/03/29 20:18:57 - mmengine - INFO - Iter(train) [17700/20000]  base_lr: 1.4277e-05 lr: 1.4277e-05  eta: 1:02:46  time: 2.9832  data_time: 0.0204  memory: 10131  loss: 21.4137  decode.loss_cls: 0.1942  decode.loss_mask: 0.8976  decode.loss_dice: 1.0665  decode.d0.loss_cls: 0.2636  decode.d0.loss_mask: 0.9001  decode.d0.loss_dice: 1.1248  decode.d1.loss_cls: 0.1963  decode.d1.loss_mask: 0.8772  decode.d1.loss_dice: 1.0843  decode.d2.loss_cls: 0.1915  decode.d2.loss_mask: 0.8818  decode.d2.loss_dice: 1.0539  decode.d3.loss_cls: 0.1623  decode.d3.loss_mask: 0.8737  decode.d3.loss_dice: 1.0548  decode.d4.loss_cls: 0.1535  decode.d4.loss_mask: 0.8790  decode.d4.loss_dice: 1.0678  decode.d5.loss_cls: 0.1811  decode.d5.loss_mask: 0.8740  decode.d5.loss_dice: 1.0630  decode.d6.loss_cls: 0.1848  decode.d6.loss_mask: 0.8772  decode.d6.loss_dice: 1.0441  decode.d7.loss_cls: 0.2253  decode.d7.loss_mask: 0.8788  decode.d7.loss_dice: 1.0312  decode.d8.loss_cls: 0.1787  decode.d8.loss_mask: 0.8864  decode.d8.loss_dice: 1.0658
2025/03/29 20:21:27 - mmengine - INFO - Iter(train) [17750/20000]  base_lr: 1.3998e-05 lr: 1.3998e-05  eta: 1:01:33  time: 2.9874  data_time: 0.0215  memory: 10122  loss: 20.8431  decode.loss_cls: 0.2497  decode.loss_mask: 0.8710  decode.loss_dice: 0.9630  decode.d0.loss_cls: 0.2626  decode.d0.loss_mask: 0.8773  decode.d0.loss_dice: 1.0683  decode.d1.loss_cls: 0.2485  decode.d1.loss_mask: 0.8637  decode.d1.loss_dice: 0.9785  decode.d2.loss_cls: 0.2370  decode.d2.loss_mask: 0.8577  decode.d2.loss_dice: 0.9796  decode.d3.loss_cls: 0.2222  decode.d3.loss_mask: 0.8661  decode.d3.loss_dice: 0.9706  decode.d4.loss_cls: 0.2217  decode.d4.loss_mask: 0.8588  decode.d4.loss_dice: 0.9635  decode.d5.loss_cls: 0.2350  decode.d5.loss_mask: 0.8661  decode.d5.loss_dice: 0.9631  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 0.8631  decode.d6.loss_dice: 0.9689  decode.d7.loss_cls: 0.2209  decode.d7.loss_mask: 0.8760  decode.d7.loss_dice: 0.9850  decode.d8.loss_cls: 0.2435  decode.d8.loss_mask: 0.8690  decode.d8.loss_dice: 0.9643
2025/03/29 20:23:57 - mmengine - INFO - Iter(train) [17800/20000]  base_lr: 1.3717e-05 lr: 1.3717e-05  eta: 1:00:19  time: 2.9897  data_time: 0.0212  memory: 10131  loss: 21.7804  decode.loss_cls: 0.1593  decode.loss_mask: 0.9604  decode.loss_dice: 1.0320  decode.d0.loss_cls: 0.2532  decode.d0.loss_mask: 0.9722  decode.d0.loss_dice: 1.0542  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 0.9595  decode.d1.loss_dice: 1.0235  decode.d2.loss_cls: 0.1887  decode.d2.loss_mask: 0.9582  decode.d2.loss_dice: 1.0368  decode.d3.loss_cls: 0.1706  decode.d3.loss_mask: 0.9579  decode.d3.loss_dice: 1.0451  decode.d4.loss_cls: 0.1666  decode.d4.loss_mask: 0.9612  decode.d4.loss_dice: 1.0389  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 0.9649  decode.d5.loss_dice: 1.0281  decode.d6.loss_cls: 0.1956  decode.d6.loss_mask: 0.9541  decode.d6.loss_dice: 1.0215  decode.d7.loss_cls: 0.1540  decode.d7.loss_mask: 0.9586  decode.d7.loss_dice: 1.0189  decode.d8.loss_cls: 0.1433  decode.d8.loss_mask: 0.9621  decode.d8.loss_dice: 1.0421
2025/03/29 20:26:26 - mmengine - INFO - Iter(train) [17850/20000]  base_lr: 1.3437e-05 lr: 1.3437e-05  eta: 0:59:05  time: 2.9911  data_time: 0.0213  memory: 10121  loss: 22.3725  decode.loss_cls: 0.2858  decode.loss_mask: 0.8800  decode.loss_dice: 1.0725  decode.d0.loss_cls: 0.3229  decode.d0.loss_mask: 0.8648  decode.d0.loss_dice: 1.1505  decode.d1.loss_cls: 0.3391  decode.d1.loss_mask: 0.8694  decode.d1.loss_dice: 1.0662  decode.d2.loss_cls: 0.3101  decode.d2.loss_mask: 0.8708  decode.d2.loss_dice: 1.0590  decode.d3.loss_cls: 0.2982  decode.d3.loss_mask: 0.8673  decode.d3.loss_dice: 1.0393  decode.d4.loss_cls: 0.2942  decode.d4.loss_mask: 0.8646  decode.d4.loss_dice: 1.0677  decode.d5.loss_cls: 0.2782  decode.d5.loss_mask: 0.8605  decode.d5.loss_dice: 1.0701  decode.d6.loss_cls: 0.3046  decode.d6.loss_mask: 0.8574  decode.d6.loss_dice: 1.0486  decode.d7.loss_cls: 0.3136  decode.d7.loss_mask: 0.8437  decode.d7.loss_dice: 1.0550  decode.d8.loss_cls: 0.2916  decode.d8.loss_mask: 0.8634  decode.d8.loss_dice: 1.0635
2025/03/29 20:28:56 - mmengine - INFO - Iter(train) [17900/20000]  base_lr: 1.3155e-05 lr: 1.3155e-05  eta: 0:57:51  time: 2.9913  data_time: 0.0208  memory: 10117  loss: 21.6283  decode.loss_cls: 0.1338  decode.loss_mask: 0.9987  decode.loss_dice: 1.0182  decode.d0.loss_cls: 0.2068  decode.d0.loss_mask: 1.0336  decode.d0.loss_dice: 1.0154  decode.d1.loss_cls: 0.1547  decode.d1.loss_mask: 1.0265  decode.d1.loss_dice: 1.0075  decode.d2.loss_cls: 0.1495  decode.d2.loss_mask: 1.0027  decode.d2.loss_dice: 0.9999  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 1.0059  decode.d3.loss_dice: 1.0025  decode.d4.loss_cls: 0.1536  decode.d4.loss_mask: 1.0033  decode.d4.loss_dice: 1.0001  decode.d5.loss_cls: 0.0988  decode.d5.loss_mask: 1.0145  decode.d5.loss_dice: 1.0192  decode.d6.loss_cls: 0.1278  decode.d6.loss_mask: 1.0075  decode.d6.loss_dice: 1.0120  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 1.0159  decode.d7.loss_dice: 1.0109  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 1.0078  decode.d8.loss_dice: 1.0071
2025/03/29 20:31:25 - mmengine - INFO - Iter(train) [17950/20000]  base_lr: 1.2873e-05 lr: 1.2873e-05  eta: 0:56:36  time: 2.9941  data_time: 0.0205  memory: 10118  loss: 19.3380  decode.loss_cls: 0.0999  decode.loss_mask: 0.8962  decode.loss_dice: 0.9177  decode.d0.loss_cls: 0.1967  decode.d0.loss_mask: 0.9126  decode.d0.loss_dice: 0.9768  decode.d1.loss_cls: 0.1400  decode.d1.loss_mask: 0.8941  decode.d1.loss_dice: 0.9212  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 0.8845  decode.d2.loss_dice: 0.9322  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.8837  decode.d3.loss_dice: 0.9062  decode.d4.loss_cls: 0.1104  decode.d4.loss_mask: 0.8829  decode.d4.loss_dice: 0.9299  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 0.8836  decode.d5.loss_dice: 0.9211  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 0.9166  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.8893  decode.d7.loss_dice: 0.9001  decode.d8.loss_cls: 0.1213  decode.d8.loss_mask: 0.8855  decode.d8.loss_dice: 0.9172
2025/03/29 20:33:55 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 20:33:55 - mmengine - INFO - Iter(train) [18000/20000]  base_lr: 1.2590e-05 lr: 1.2590e-05  eta: 0:55:20  time: 2.9823  data_time: 0.0214  memory: 10121  loss: 19.6405  decode.loss_cls: 0.1644  decode.loss_mask: 0.8276  decode.loss_dice: 0.9626  decode.d0.loss_cls: 0.1570  decode.d0.loss_mask: 0.8368  decode.d0.loss_dice: 1.0504  decode.d1.loss_cls: 0.1768  decode.d1.loss_mask: 0.8288  decode.d1.loss_dice: 0.9930  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 0.8241  decode.d2.loss_dice: 0.9754  decode.d3.loss_cls: 0.1392  decode.d3.loss_mask: 0.8268  decode.d3.loss_dice: 0.9828  decode.d4.loss_cls: 0.1579  decode.d4.loss_mask: 0.8263  decode.d4.loss_dice: 0.9923  decode.d5.loss_cls: 0.1462  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 0.9770  decode.d6.loss_cls: 0.1567  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 0.9648  decode.d7.loss_cls: 0.1281  decode.d7.loss_mask: 0.8246  decode.d7.loss_dice: 0.9593  decode.d8.loss_cls: 0.1725  decode.d8.loss_mask: 0.8215  decode.d8.loss_dice: 0.9519
2025/03/29 20:33:55 - mmengine - INFO - Saving checkpoint at 18000 iterations
2025/03/29 20:34:06 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:01:03  time: 0.1450  data_time: 0.0026  memory: 1808  
2025/03/29 20:34:16 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:56  time: 0.2596  data_time: 0.0023  memory: 1808  
2025/03/29 20:34:29 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:52  time: 0.2548  data_time: 0.0020  memory: 1808  
2025/03/29 20:34:42 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:44  time: 0.2566  data_time: 0.0022  memory: 1808  
2025/03/29 20:34:55 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:34  time: 0.2584  data_time: 0.0021  memory: 1808  
2025/03/29 20:35:08 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:23  time: 0.2573  data_time: 0.0022  memory: 1808  
2025/03/29 20:35:21 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:11  time: 0.2581  data_time: 0.0020  memory: 1808  
2025/03/29 20:35:33 - mmengine - INFO - per class results:
2025/03/29 20:35:33 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 74.64 | 83.56 |
|      building      | 86.94 | 94.69 |
|   low_vegetation   | 47.11 | 54.02 |
|        tree        | 72.74 |  90.0 |
|        car         | 60.08 | 73.43 |
|      clutter       |  16.7 | 93.17 |
+--------------------+-------+-------+
2025/03/29 20:35:33 - mmengine - INFO - Iter(val) [398/398]    aAcc: 81.2600  mIoU: 59.7000  mAcc: 81.4800  data_time: 0.0064  time: 0.2405
2025/03/29 20:38:04 - mmengine - INFO - Iter(train) [18050/20000]  base_lr: 1.2306e-05 lr: 1.2306e-05  eta: 0:54:04  time: 3.0000  data_time: 0.0257  memory: 10124  loss: 21.8533  decode.loss_cls: 0.1944  decode.loss_mask: 0.9585  decode.loss_dice: 1.0103  decode.d0.loss_cls: 0.2587  decode.d0.loss_mask: 0.9784  decode.d0.loss_dice: 1.0827  decode.d1.loss_cls: 0.2322  decode.d1.loss_mask: 0.9346  decode.d1.loss_dice: 1.0010  decode.d2.loss_cls: 0.2508  decode.d2.loss_mask: 0.9335  decode.d2.loss_dice: 0.9943  decode.d3.loss_cls: 0.1947  decode.d3.loss_mask: 0.9534  decode.d3.loss_dice: 1.0123  decode.d4.loss_cls: 0.2137  decode.d4.loss_mask: 0.9493  decode.d4.loss_dice: 1.0254  decode.d5.loss_cls: 0.1986  decode.d5.loss_mask: 0.9538  decode.d5.loss_dice: 1.0223  decode.d6.loss_cls: 0.1989  decode.d6.loss_mask: 0.9631  decode.d6.loss_dice: 1.0076  decode.d7.loss_cls: 0.1853  decode.d7.loss_mask: 0.9556  decode.d7.loss_dice: 1.0130  decode.d8.loss_cls: 0.2152  decode.d8.loss_mask: 0.9562  decode.d8.loss_dice: 1.0050
2025/03/29 20:40:33 - mmengine - INFO - Iter(train) [18100/20000]  base_lr: 1.2022e-05 lr: 1.2022e-05  eta: 0:52:48  time: 2.9736  data_time: 0.0219  memory: 10126  loss: 24.1171  decode.loss_cls: 0.1632  decode.loss_mask: 1.0492  decode.loss_dice: 1.1733  decode.d0.loss_cls: 0.2207  decode.d0.loss_mask: 1.0897  decode.d0.loss_dice: 1.2405  decode.d1.loss_cls: 0.2114  decode.d1.loss_mask: 1.0381  decode.d1.loss_dice: 1.1798  decode.d2.loss_cls: 0.1806  decode.d2.loss_mask: 1.0601  decode.d2.loss_dice: 1.1466  decode.d3.loss_cls: 0.2030  decode.d3.loss_mask: 1.0673  decode.d3.loss_dice: 1.1524  decode.d4.loss_cls: 0.2269  decode.d4.loss_mask: 1.0325  decode.d4.loss_dice: 1.1319  decode.d5.loss_cls: 0.1708  decode.d5.loss_mask: 1.0452  decode.d5.loss_dice: 1.1732  decode.d6.loss_cls: 0.1652  decode.d6.loss_mask: 1.0547  decode.d6.loss_dice: 1.1513  decode.d7.loss_cls: 0.1554  decode.d7.loss_mask: 1.0491  decode.d7.loss_dice: 1.1587  decode.d8.loss_cls: 0.1977  decode.d8.loss_mask: 1.0517  decode.d8.loss_dice: 1.1765
2025/03/29 20:43:03 - mmengine - INFO - Iter(train) [18150/20000]  base_lr: 1.1737e-05 lr: 1.1737e-05  eta: 0:51:32  time: 3.0085  data_time: 0.0243  memory: 10126  loss: 21.7513  decode.loss_cls: 0.1637  decode.loss_mask: 0.9722  decode.loss_dice: 1.0381  decode.d0.loss_cls: 0.2658  decode.d0.loss_mask: 0.9914  decode.d0.loss_dice: 1.0581  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 0.9926  decode.d1.loss_dice: 1.0243  decode.d2.loss_cls: 0.1880  decode.d2.loss_mask: 0.9862  decode.d2.loss_dice: 1.0033  decode.d3.loss_cls: 0.1474  decode.d3.loss_mask: 0.9839  decode.d3.loss_dice: 1.0083  decode.d4.loss_cls: 0.1360  decode.d4.loss_mask: 0.9851  decode.d4.loss_dice: 1.0299  decode.d5.loss_cls: 0.1662  decode.d5.loss_mask: 0.9747  decode.d5.loss_dice: 1.0009  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 0.9710  decode.d6.loss_dice: 0.9910  decode.d7.loss_cls: 0.1471  decode.d7.loss_mask: 0.9706  decode.d7.loss_dice: 1.0397  decode.d8.loss_cls: 0.1578  decode.d8.loss_mask: 0.9786  decode.d8.loss_dice: 1.0223
2025/03/29 20:45:35 - mmengine - INFO - Iter(train) [18200/20000]  base_lr: 1.1451e-05 lr: 1.1451e-05  eta: 0:50:15  time: 3.0091  data_time: 0.0229  memory: 10133  loss: 20.2361  decode.loss_cls: 0.1094  decode.loss_mask: 0.8704  decode.loss_dice: 1.0080  decode.d0.loss_cls: 0.1970  decode.d0.loss_mask: 0.8671  decode.d0.loss_dice: 1.0615  decode.d1.loss_cls: 0.1788  decode.d1.loss_mask: 0.8560  decode.d1.loss_dice: 1.0024  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 0.8638  decode.d2.loss_dice: 1.0075  decode.d3.loss_cls: 0.1208  decode.d3.loss_mask: 0.8772  decode.d3.loss_dice: 1.0142  decode.d4.loss_cls: 0.1266  decode.d4.loss_mask: 0.8753  decode.d4.loss_dice: 0.9971  decode.d5.loss_cls: 0.1145  decode.d5.loss_mask: 0.8710  decode.d5.loss_dice: 1.0105  decode.d6.loss_cls: 0.1355  decode.d6.loss_mask: 0.8819  decode.d6.loss_dice: 1.0142  decode.d7.loss_cls: 0.1328  decode.d7.loss_mask: 0.8708  decode.d7.loss_dice: 1.0068  decode.d8.loss_cls: 0.1670  decode.d8.loss_mask: 0.8607  decode.d8.loss_dice: 0.9980
2025/03/29 20:48:07 - mmengine - INFO - Iter(train) [18250/20000]  base_lr: 1.1164e-05 lr: 1.1164e-05  eta: 0:48:58  time: 3.0048  data_time: 0.0220  memory: 10126  loss: 22.4463  decode.loss_cls: 0.1805  decode.loss_mask: 0.9475  decode.loss_dice: 1.1069  decode.d0.loss_cls: 0.2330  decode.d0.loss_mask: 0.9526  decode.d0.loss_dice: 1.1878  decode.d1.loss_cls: 0.1977  decode.d1.loss_mask: 0.9316  decode.d1.loss_dice: 1.1253  decode.d2.loss_cls: 0.1730  decode.d2.loss_mask: 0.9522  decode.d2.loss_dice: 1.1210  decode.d3.loss_cls: 0.1925  decode.d3.loss_mask: 0.9154  decode.d3.loss_dice: 1.1164  decode.d4.loss_cls: 0.2181  decode.d4.loss_mask: 0.9187  decode.d4.loss_dice: 1.1061  decode.d5.loss_cls: 0.1778  decode.d5.loss_mask: 0.9214  decode.d5.loss_dice: 1.1100  decode.d6.loss_cls: 0.1623  decode.d6.loss_mask: 0.9233  decode.d6.loss_dice: 1.1288  decode.d7.loss_cls: 0.1695  decode.d7.loss_mask: 0.9191  decode.d7.loss_dice: 1.1210  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.9384  decode.d8.loss_dice: 1.1393
2025/03/29 20:50:36 - mmengine - INFO - Iter(train) [18300/20000]  base_lr: 1.0877e-05 lr: 1.0877e-05  eta: 0:47:40  time: 3.0003  data_time: 0.0224  memory: 10124  loss: 25.5771  decode.loss_cls: 0.2515  decode.loss_mask: 1.1374  decode.loss_dice: 1.1397  decode.d0.loss_cls: 0.2758  decode.d0.loss_mask: 1.1714  decode.d0.loss_dice: 1.2306  decode.d1.loss_cls: 0.3085  decode.d1.loss_mask: 1.1549  decode.d1.loss_dice: 1.1636  decode.d2.loss_cls: 0.2453  decode.d2.loss_mask: 1.1220  decode.d2.loss_dice: 1.1658  decode.d3.loss_cls: 0.2814  decode.d3.loss_mask: 1.1511  decode.d3.loss_dice: 1.1471  decode.d4.loss_cls: 0.2294  decode.d4.loss_mask: 1.1436  decode.d4.loss_dice: 1.1786  decode.d5.loss_cls: 0.2393  decode.d5.loss_mask: 1.1189  decode.d5.loss_dice: 1.1576  decode.d6.loss_cls: 0.2161  decode.d6.loss_mask: 1.1356  decode.d6.loss_dice: 1.1585  decode.d7.loss_cls: 0.2163  decode.d7.loss_mask: 1.1453  decode.d7.loss_dice: 1.1819  decode.d8.loss_cls: 0.2402  decode.d8.loss_mask: 1.1274  decode.d8.loss_dice: 1.1423
2025/03/29 20:53:08 - mmengine - INFO - Iter(train) [18350/20000]  base_lr: 1.0588e-05 lr: 1.0588e-05  eta: 0:46:22  time: 2.9917  data_time: 0.0245  memory: 10123  loss: 22.6418  decode.loss_cls: 0.1921  decode.loss_mask: 1.0200  decode.loss_dice: 1.0333  decode.d0.loss_cls: 0.2927  decode.d0.loss_mask: 1.0536  decode.d0.loss_dice: 1.0878  decode.d1.loss_cls: 0.2125  decode.d1.loss_mask: 1.0102  decode.d1.loss_dice: 1.0331  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 1.0379  decode.d2.loss_dice: 1.0186  decode.d3.loss_cls: 0.2199  decode.d3.loss_mask: 1.0183  decode.d3.loss_dice: 1.0176  decode.d4.loss_cls: 0.1978  decode.d4.loss_mask: 1.0076  decode.d4.loss_dice: 1.0324  decode.d5.loss_cls: 0.2196  decode.d5.loss_mask: 1.0082  decode.d5.loss_dice: 1.0049  decode.d6.loss_cls: 0.2047  decode.d6.loss_mask: 1.0134  decode.d6.loss_dice: 1.0043  decode.d7.loss_cls: 0.1847  decode.d7.loss_mask: 1.0233  decode.d7.loss_dice: 1.0404  decode.d8.loss_cls: 0.1982  decode.d8.loss_mask: 1.0164  decode.d8.loss_dice: 1.0207
2025/03/29 20:55:39 - mmengine - INFO - Iter(train) [18400/20000]  base_lr: 1.0299e-05 lr: 1.0299e-05  eta: 0:45:03  time: 2.9819  data_time: 0.0226  memory: 10118  loss: 22.4233  decode.loss_cls: 0.2469  decode.loss_mask: 0.9284  decode.loss_dice: 1.0435  decode.d0.loss_cls: 0.2990  decode.d0.loss_mask: 0.9313  decode.d0.loss_dice: 1.1250  decode.d1.loss_cls: 0.3065  decode.d1.loss_mask: 0.9241  decode.d1.loss_dice: 1.0596  decode.d2.loss_cls: 0.2893  decode.d2.loss_mask: 0.9132  decode.d2.loss_dice: 1.0533  decode.d3.loss_cls: 0.3434  decode.d3.loss_mask: 0.8931  decode.d3.loss_dice: 1.0462  decode.d4.loss_cls: 0.2469  decode.d4.loss_mask: 0.9090  decode.d4.loss_dice: 1.0431  decode.d5.loss_cls: 0.2768  decode.d5.loss_mask: 0.9075  decode.d5.loss_dice: 1.0106  decode.d6.loss_cls: 0.2273  decode.d6.loss_mask: 0.9220  decode.d6.loss_dice: 1.0631  decode.d7.loss_cls: 0.2510  decode.d7.loss_mask: 0.9280  decode.d7.loss_dice: 1.0374  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 0.9220  decode.d8.loss_dice: 1.0279
2025/03/29 20:58:11 - mmengine - INFO - Iter(train) [18450/20000]  base_lr: 1.0009e-05 lr: 1.0009e-05  eta: 0:43:44  time: 3.0106  data_time: 0.0227  memory: 10133  loss: 22.5543  decode.loss_cls: 0.1614  decode.loss_mask: 0.9903  decode.loss_dice: 1.0692  decode.d0.loss_cls: 0.2610  decode.d0.loss_mask: 1.0341  decode.d0.loss_dice: 1.1601  decode.d1.loss_cls: 0.1975  decode.d1.loss_mask: 1.0000  decode.d1.loss_dice: 1.0795  decode.d2.loss_cls: 0.2173  decode.d2.loss_mask: 0.9852  decode.d2.loss_dice: 1.0486  decode.d3.loss_cls: 0.1713  decode.d3.loss_mask: 0.9976  decode.d3.loss_dice: 1.0775  decode.d4.loss_cls: 0.1617  decode.d4.loss_mask: 1.0071  decode.d4.loss_dice: 1.0504  decode.d5.loss_cls: 0.1832  decode.d5.loss_mask: 0.9879  decode.d5.loss_dice: 1.0655  decode.d6.loss_cls: 0.1624  decode.d6.loss_mask: 0.9878  decode.d6.loss_dice: 1.0615  decode.d7.loss_cls: 0.1593  decode.d7.loss_mask: 0.9949  decode.d7.loss_dice: 1.0637  decode.d8.loss_cls: 0.1732  decode.d8.loss_mask: 0.9909  decode.d8.loss_dice: 1.0543
2025/03/29 21:00:25 - mmengine - INFO - Iter(train) [18500/20000]  base_lr: 9.7180e-06 lr: 9.7180e-06  eta: 0:42:24  time: 2.9915  data_time: 0.0215  memory: 10125  loss: 22.2828  decode.loss_cls: 0.1071  decode.loss_mask: 1.0062  decode.loss_dice: 1.1045  decode.d0.loss_cls: 0.1344  decode.d0.loss_mask: 1.0241  decode.d0.loss_dice: 1.1642  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 0.9905  decode.d1.loss_dice: 1.0949  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.9883  decode.d2.loss_dice: 1.0896  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 1.0057  decode.d3.loss_dice: 1.1049  decode.d4.loss_cls: 0.0956  decode.d4.loss_mask: 1.0067  decode.d4.loss_dice: 1.1135  decode.d5.loss_cls: 0.1160  decode.d5.loss_mask: 0.9971  decode.d5.loss_dice: 1.1021  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 1.0114  decode.d6.loss_dice: 1.1238  decode.d7.loss_cls: 0.0795  decode.d7.loss_mask: 1.0117  decode.d7.loss_dice: 1.1225  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 1.0048  decode.d8.loss_dice: 1.1079
2025/03/29 21:02:57 - mmengine - INFO - Iter(train) [18550/20000]  base_lr: 9.4259e-06 lr: 9.4259e-06  eta: 0:41:04  time: 3.0220  data_time: 0.0258  memory: 10129  loss: 22.7420  decode.loss_cls: 0.1944  decode.loss_mask: 0.9728  decode.loss_dice: 1.0712  decode.d0.loss_cls: 0.2838  decode.d0.loss_mask: 0.9714  decode.d0.loss_dice: 1.1239  decode.d1.loss_cls: 0.2644  decode.d1.loss_mask: 0.9667  decode.d1.loss_dice: 1.0978  decode.d2.loss_cls: 0.2519  decode.d2.loss_mask: 0.9585  decode.d2.loss_dice: 1.0669  decode.d3.loss_cls: 0.2145  decode.d3.loss_mask: 0.9633  decode.d3.loss_dice: 1.0648  decode.d4.loss_cls: 0.2035  decode.d4.loss_mask: 0.9654  decode.d4.loss_dice: 1.0971  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 0.9695  decode.d5.loss_dice: 1.0898  decode.d6.loss_cls: 0.1793  decode.d6.loss_mask: 0.9775  decode.d6.loss_dice: 1.0862  decode.d7.loss_cls: 0.2007  decode.d7.loss_mask: 0.9756  decode.d7.loss_dice: 1.0632  decode.d8.loss_cls: 0.1915  decode.d8.loss_mask: 0.9731  decode.d8.loss_dice: 1.0856
2025/03/29 21:05:28 - mmengine - INFO - Iter(train) [18600/20000]  base_lr: 9.1329e-06 lr: 9.1329e-06  eta: 0:39:44  time: 3.0384  data_time: 0.0258  memory: 10124  loss: 24.7369  decode.loss_cls: 0.2124  decode.loss_mask: 1.1182  decode.loss_dice: 1.1318  decode.d0.loss_cls: 0.2014  decode.d0.loss_mask: 1.1689  decode.d0.loss_dice: 1.2165  decode.d1.loss_cls: 0.1651  decode.d1.loss_mask: 1.1433  decode.d1.loss_dice: 1.1863  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 1.1156  decode.d2.loss_dice: 1.1418  decode.d3.loss_cls: 0.1925  decode.d3.loss_mask: 1.1135  decode.d3.loss_dice: 1.1256  decode.d4.loss_cls: 0.2391  decode.d4.loss_mask: 1.1079  decode.d4.loss_dice: 1.1178  decode.d5.loss_cls: 0.2022  decode.d5.loss_mask: 1.1177  decode.d5.loss_dice: 1.1444  decode.d6.loss_cls: 0.1968  decode.d6.loss_mask: 1.1078  decode.d6.loss_dice: 1.1230  decode.d7.loss_cls: 0.2155  decode.d7.loss_mask: 1.1074  decode.d7.loss_dice: 1.1286  decode.d8.loss_cls: 0.2394  decode.d8.loss_mask: 1.1113  decode.d8.loss_dice: 1.1241
2025/03/29 21:08:00 - mmengine - INFO - Iter(train) [18650/20000]  base_lr: 8.8388e-06 lr: 8.8388e-06  eta: 0:38:24  time: 3.0078  data_time: 0.0230  memory: 10126  loss: 21.7102  decode.loss_cls: 0.1450  decode.loss_mask: 0.9824  decode.loss_dice: 0.9978  decode.d0.loss_cls: 0.2444  decode.d0.loss_mask: 1.0162  decode.d0.loss_dice: 1.0451  decode.d1.loss_cls: 0.1694  decode.d1.loss_mask: 1.0003  decode.d1.loss_dice: 1.0295  decode.d2.loss_cls: 0.1662  decode.d2.loss_mask: 0.9807  decode.d2.loss_dice: 1.0033  decode.d3.loss_cls: 0.1527  decode.d3.loss_mask: 1.0003  decode.d3.loss_dice: 1.0176  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 0.9855  decode.d4.loss_dice: 0.9988  decode.d5.loss_cls: 0.1478  decode.d5.loss_mask: 1.0023  decode.d5.loss_dice: 1.0079  decode.d6.loss_cls: 0.1480  decode.d6.loss_mask: 0.9899  decode.d6.loss_dice: 1.0043  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 1.0042  decode.d7.loss_dice: 1.0178  decode.d8.loss_cls: 0.1474  decode.d8.loss_mask: 0.9969  decode.d8.loss_dice: 1.0115
2025/03/29 21:10:32 - mmengine - INFO - Iter(train) [18700/20000]  base_lr: 8.5436e-06 lr: 8.5436e-06  eta: 0:37:03  time: 3.0040  data_time: 0.0241  memory: 10132  loss: 19.8253  decode.loss_cls: 0.0869  decode.loss_mask: 0.9098  decode.loss_dice: 0.9752  decode.d0.loss_cls: 0.1457  decode.d0.loss_mask: 0.9186  decode.d0.loss_dice: 1.0207  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.9116  decode.d1.loss_dice: 1.0050  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.9112  decode.d2.loss_dice: 0.9884  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.9040  decode.d3.loss_dice: 0.9774  decode.d4.loss_cls: 0.0767  decode.d4.loss_mask: 0.9050  decode.d4.loss_dice: 0.9738  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.9055  decode.d5.loss_dice: 0.9794  decode.d6.loss_cls: 0.0733  decode.d6.loss_mask: 0.9063  decode.d6.loss_dice: 0.9799  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.9005  decode.d7.loss_dice: 0.9760  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.9049  decode.d8.loss_dice: 0.9774
2025/03/29 21:13:04 - mmengine - INFO - Iter(train) [18750/20000]  base_lr: 8.2473e-06 lr: 8.2473e-06  eta: 0:35:42  time: 2.9964  data_time: 0.0226  memory: 10129  loss: 20.3824  decode.loss_cls: 0.2166  decode.loss_mask: 0.8927  decode.loss_dice: 0.9457  decode.d0.loss_cls: 0.2259  decode.d0.loss_mask: 0.8880  decode.d0.loss_dice: 1.0383  decode.d1.loss_cls: 0.1858  decode.d1.loss_mask: 0.8726  decode.d1.loss_dice: 0.9783  decode.d2.loss_cls: 0.1901  decode.d2.loss_mask: 0.8617  decode.d2.loss_dice: 0.9687  decode.d3.loss_cls: 0.2189  decode.d3.loss_mask: 0.8701  decode.d3.loss_dice: 0.9713  decode.d4.loss_cls: 0.1857  decode.d4.loss_mask: 0.8703  decode.d4.loss_dice: 0.9508  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.8659  decode.d5.loss_dice: 0.9553  decode.d6.loss_cls: 0.1813  decode.d6.loss_mask: 0.8659  decode.d6.loss_dice: 0.9536  decode.d7.loss_cls: 0.2009  decode.d7.loss_mask: 0.8713  decode.d7.loss_dice: 0.9355  decode.d8.loss_cls: 0.1968  decode.d8.loss_mask: 0.8777  decode.d8.loss_dice: 0.9626
2025/03/29 21:15:36 - mmengine - INFO - Iter(train) [18800/20000]  base_lr: 7.9498e-06 lr: 7.9498e-06  eta: 0:34:20  time: 2.9916  data_time: 0.0222  memory: 10130  loss: 22.3000  decode.loss_cls: 0.2568  decode.loss_mask: 0.9440  decode.loss_dice: 1.0534  decode.d0.loss_cls: 0.3173  decode.d0.loss_mask: 0.9383  decode.d0.loss_dice: 1.1154  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 0.9302  decode.d1.loss_dice: 1.0838  decode.d2.loss_cls: 0.2288  decode.d2.loss_mask: 0.9288  decode.d2.loss_dice: 1.0447  decode.d3.loss_cls: 0.2514  decode.d3.loss_mask: 0.9166  decode.d3.loss_dice: 1.0282  decode.d4.loss_cls: 0.2653  decode.d4.loss_mask: 0.9009  decode.d4.loss_dice: 1.0063  decode.d5.loss_cls: 0.2511  decode.d5.loss_mask: 0.9320  decode.d5.loss_dice: 1.0460  decode.d6.loss_cls: 0.2233  decode.d6.loss_mask: 0.9361  decode.d6.loss_dice: 1.0319  decode.d7.loss_cls: 0.2551  decode.d7.loss_mask: 0.9321  decode.d7.loss_dice: 1.0391  decode.d8.loss_cls: 0.2386  decode.d8.loss_mask: 0.9473  decode.d8.loss_dice: 1.0182
2025/03/29 21:18:07 - mmengine - INFO - Iter(train) [18850/20000]  base_lr: 7.6510e-06 lr: 7.6510e-06  eta: 0:32:59  time: 2.9914  data_time: 0.0224  memory: 10125  loss: 22.7296  decode.loss_cls: 0.1476  decode.loss_mask: 1.1051  decode.loss_dice: 1.0551  decode.d0.loss_cls: 0.2696  decode.d0.loss_mask: 1.0670  decode.d0.loss_dice: 1.0629  decode.d1.loss_cls: 0.1824  decode.d1.loss_mask: 1.0849  decode.d1.loss_dice: 1.0176  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 1.0536  decode.d2.loss_dice: 1.0232  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 1.0675  decode.d3.loss_dice: 1.0086  decode.d4.loss_cls: 0.1524  decode.d4.loss_mask: 1.0727  decode.d4.loss_dice: 1.0335  decode.d5.loss_cls: 0.1656  decode.d5.loss_mask: 1.0556  decode.d5.loss_dice: 1.0274  decode.d6.loss_cls: 0.1629  decode.d6.loss_mask: 1.0549  decode.d6.loss_dice: 1.0247  decode.d7.loss_cls: 0.1831  decode.d7.loss_mask: 1.0424  decode.d7.loss_dice: 1.0118  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 1.0512  decode.d8.loss_dice: 1.0322
2025/03/29 21:20:39 - mmengine - INFO - Iter(train) [18900/20000]  base_lr: 7.3510e-06 lr: 7.3510e-06  eta: 0:31:36  time: 3.0033  data_time: 0.0222  memory: 10083  loss: 20.2195  decode.loss_cls: 0.1096  decode.loss_mask: 0.9912  decode.loss_dice: 0.8990  decode.d0.loss_cls: 0.2206  decode.d0.loss_mask: 1.0016  decode.d0.loss_dice: 0.9426  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.9826  decode.d1.loss_dice: 0.9137  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.9955  decode.d2.loss_dice: 0.9214  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.9949  decode.d3.loss_dice: 0.9250  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.9983  decode.d4.loss_dice: 0.9157  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.9917  decode.d5.loss_dice: 0.9068  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 1.0030  decode.d6.loss_dice: 0.9158  decode.d7.loss_cls: 0.0725  decode.d7.loss_mask: 1.0005  decode.d7.loss_dice: 0.9289  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 0.9842  decode.d8.loss_dice: 0.9006
2025/03/29 21:23:10 - mmengine - INFO - Iter(train) [18950/20000]  base_lr: 7.0496e-06 lr: 7.0496e-06  eta: 0:30:14  time: 3.0079  data_time: 0.0215  memory: 10120  loss: 19.8089  decode.loss_cls: 0.1808  decode.loss_mask: 0.8276  decode.loss_dice: 0.9475  decode.d0.loss_cls: 0.1917  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 1.0334  decode.d1.loss_cls: 0.2240  decode.d1.loss_mask: 0.8243  decode.d1.loss_dice: 0.9672  decode.d2.loss_cls: 0.1781  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 0.9795  decode.d3.loss_cls: 0.1545  decode.d3.loss_mask: 0.8324  decode.d3.loss_dice: 0.9781  decode.d4.loss_cls: 0.1725  decode.d4.loss_mask: 0.8347  decode.d4.loss_dice: 0.9618  decode.d5.loss_cls: 0.1575  decode.d5.loss_mask: 0.8314  decode.d5.loss_dice: 0.9814  decode.d6.loss_cls: 0.1577  decode.d6.loss_mask: 0.8311  decode.d6.loss_dice: 0.9713  decode.d7.loss_cls: 0.1480  decode.d7.loss_mask: 0.8313  decode.d7.loss_dice: 0.9661  decode.d8.loss_cls: 0.1610  decode.d8.loss_mask: 0.8297  decode.d8.loss_dice: 0.9670
2025/03/29 21:25:22 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 21:25:22 - mmengine - INFO - Iter(train) [19000/20000]  base_lr: 6.7467e-06 lr: 6.7467e-06  eta: 0:28:50  time: 2.9973  data_time: 0.0203  memory: 10119  loss: 19.9215  decode.loss_cls: 0.1871  decode.loss_mask: 0.8532  decode.loss_dice: 0.9348  decode.d0.loss_cls: 0.2629  decode.d0.loss_mask: 0.8424  decode.d0.loss_dice: 1.0204  decode.d1.loss_cls: 0.1935  decode.d1.loss_mask: 0.8423  decode.d1.loss_dice: 0.9283  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.8443  decode.d2.loss_dice: 0.9434  decode.d3.loss_cls: 0.1664  decode.d3.loss_mask: 0.8454  decode.d3.loss_dice: 0.9523  decode.d4.loss_cls: 0.2018  decode.d4.loss_mask: 0.8558  decode.d4.loss_dice: 0.9364  decode.d5.loss_cls: 0.1914  decode.d5.loss_mask: 0.8461  decode.d5.loss_dice: 0.9404  decode.d6.loss_cls: 0.1696  decode.d6.loss_mask: 0.8463  decode.d6.loss_dice: 0.9418  decode.d7.loss_cls: 0.1884  decode.d7.loss_mask: 0.8492  decode.d7.loss_dice: 0.9490  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 0.8918  decode.d8.loss_dice: 0.9651
2025/03/29 21:27:51 - mmengine - INFO - Iter(train) [19050/20000]  base_lr: 6.4423e-06 lr: 6.4423e-06  eta: 0:27:26  time: 2.9923  data_time: 0.0201  memory: 10129  loss: 21.7261  decode.loss_cls: 0.1770  decode.loss_mask: 0.9389  decode.loss_dice: 1.0455  decode.d0.loss_cls: 0.3106  decode.d0.loss_mask: 0.9631  decode.d0.loss_dice: 1.0788  decode.d1.loss_cls: 0.2239  decode.d1.loss_mask: 0.9618  decode.d1.loss_dice: 1.0466  decode.d2.loss_cls: 0.1980  decode.d2.loss_mask: 0.9451  decode.d2.loss_dice: 1.0186  decode.d3.loss_cls: 0.1633  decode.d3.loss_mask: 0.9537  decode.d3.loss_dice: 1.0058  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 0.9529  decode.d4.loss_dice: 1.0180  decode.d5.loss_cls: 0.1714  decode.d5.loss_mask: 0.9380  decode.d5.loss_dice: 1.0171  decode.d6.loss_cls: 0.2035  decode.d6.loss_mask: 0.9409  decode.d6.loss_dice: 1.0014  decode.d7.loss_cls: 0.1749  decode.d7.loss_mask: 0.9446  decode.d7.loss_dice: 1.0253  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.9379  decode.d8.loss_dice: 1.0164
2025/03/29 21:30:21 - mmengine - INFO - Iter(train) [19100/20000]  base_lr: 6.1364e-06 lr: 6.1364e-06  eta: 0:26:03  time: 2.9815  data_time: 0.0204  memory: 10125  loss: 22.3482  decode.loss_cls: 0.1161  decode.loss_mask: 1.0289  decode.loss_dice: 1.0399  decode.d0.loss_cls: 0.2855  decode.d0.loss_mask: 1.0380  decode.d0.loss_dice: 1.0959  decode.d1.loss_cls: 0.1679  decode.d1.loss_mask: 1.0336  decode.d1.loss_dice: 1.0768  decode.d2.loss_cls: 0.1933  decode.d2.loss_mask: 1.0093  decode.d2.loss_dice: 1.0561  decode.d3.loss_cls: 0.1669  decode.d3.loss_mask: 1.0079  decode.d3.loss_dice: 1.0289  decode.d4.loss_cls: 0.1668  decode.d4.loss_mask: 1.0101  decode.d4.loss_dice: 1.0390  decode.d5.loss_cls: 0.1520  decode.d5.loss_mask: 1.0111  decode.d5.loss_dice: 1.0285  decode.d6.loss_cls: 0.1467  decode.d6.loss_mask: 1.0136  decode.d6.loss_dice: 1.0381  decode.d7.loss_cls: 0.1250  decode.d7.loss_mask: 1.0384  decode.d7.loss_dice: 1.0453  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 1.0224  decode.d8.loss_dice: 1.0359
2025/03/29 21:32:50 - mmengine - INFO - Iter(train) [19150/20000]  base_lr: 5.8287e-06 lr: 5.8287e-06  eta: 0:24:39  time: 2.9869  data_time: 0.0208  memory: 10075  loss: 22.3958  decode.loss_cls: 0.1474  decode.loss_mask: 0.9782  decode.loss_dice: 1.0906  decode.d0.loss_cls: 0.2296  decode.d0.loss_mask: 1.0279  decode.d0.loss_dice: 1.1684  decode.d1.loss_cls: 0.1674  decode.d1.loss_mask: 0.9700  decode.d1.loss_dice: 1.0988  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 0.9791  decode.d2.loss_dice: 1.0790  decode.d3.loss_cls: 0.1794  decode.d3.loss_mask: 0.9890  decode.d3.loss_dice: 1.0649  decode.d4.loss_cls: 0.1442  decode.d4.loss_mask: 0.9937  decode.d4.loss_dice: 1.0740  decode.d5.loss_cls: 0.1393  decode.d5.loss_mask: 0.9900  decode.d5.loss_dice: 1.0825  decode.d6.loss_cls: 0.1443  decode.d6.loss_mask: 0.9884  decode.d6.loss_dice: 1.0760  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 0.9934  decode.d7.loss_dice: 1.0726  decode.d8.loss_cls: 0.1426  decode.d8.loss_mask: 0.9865  decode.d8.loss_dice: 1.0847
2025/03/29 21:35:19 - mmengine - INFO - Iter(train) [19200/20000]  base_lr: 5.5192e-06 lr: 5.5192e-06  eta: 0:23:14  time: 2.9737  data_time: 0.0201  memory: 10119  loss: 22.9043  decode.loss_cls: 0.2028  decode.loss_mask: 1.0482  decode.loss_dice: 1.0372  decode.d0.loss_cls: 0.3215  decode.d0.loss_mask: 1.0789  decode.d0.loss_dice: 1.0996  decode.d1.loss_cls: 0.2191  decode.d1.loss_mask: 1.0640  decode.d1.loss_dice: 1.0343  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.0948  decode.d2.loss_dice: 1.0486  decode.d3.loss_cls: 0.2261  decode.d3.loss_mask: 1.0313  decode.d3.loss_dice: 0.9799  decode.d4.loss_cls: 0.2363  decode.d4.loss_mask: 1.0336  decode.d4.loss_dice: 1.0117  decode.d5.loss_cls: 0.2016  decode.d5.loss_mask: 1.0336  decode.d5.loss_dice: 1.0089  decode.d6.loss_cls: 0.1953  decode.d6.loss_mask: 1.0286  decode.d6.loss_dice: 1.0050  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 1.0287  decode.d7.loss_dice: 1.0051  decode.d8.loss_cls: 0.2109  decode.d8.loss_mask: 1.0339  decode.d8.loss_dice: 0.9995
2025/03/29 21:37:48 - mmengine - INFO - Iter(train) [19250/20000]  base_lr: 5.2077e-06 lr: 5.2077e-06  eta: 0:21:49  time: 2.9889  data_time: 0.0201  memory: 10129  loss: 19.2540  decode.loss_cls: 0.1692  decode.loss_mask: 0.7963  decode.loss_dice: 0.9367  decode.d0.loss_cls: 0.2100  decode.d0.loss_mask: 0.8026  decode.d0.loss_dice: 1.0616  decode.d1.loss_cls: 0.1393  decode.d1.loss_mask: 0.7996  decode.d1.loss_dice: 0.9924  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 0.7965  decode.d2.loss_dice: 0.9850  decode.d3.loss_cls: 0.1524  decode.d3.loss_mask: 0.7928  decode.d3.loss_dice: 0.9496  decode.d4.loss_cls: 0.1401  decode.d4.loss_mask: 0.7954  decode.d4.loss_dice: 0.9573  decode.d5.loss_cls: 0.1501  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 0.9477  decode.d6.loss_cls: 0.1356  decode.d6.loss_mask: 0.7982  decode.d6.loss_dice: 0.9609  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 0.7939  decode.d7.loss_dice: 0.9448  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 0.7999  decode.d8.loss_dice: 0.9584
2025/03/29 21:40:17 - mmengine - INFO - Iter(train) [19300/20000]  base_lr: 4.8942e-06 lr: 4.8942e-06  eta: 0:20:24  time: 2.9761  data_time: 0.0195  memory: 10129  loss: 24.8769  decode.loss_cls: 0.2078  decode.loss_mask: 1.0530  decode.loss_dice: 1.1774  decode.d0.loss_cls: 0.2923  decode.d0.loss_mask: 1.0617  decode.d0.loss_dice: 1.2777  decode.d1.loss_cls: 0.2598  decode.d1.loss_mask: 1.0509  decode.d1.loss_dice: 1.2001  decode.d2.loss_cls: 0.2643  decode.d2.loss_mask: 1.0424  decode.d2.loss_dice: 1.1773  decode.d3.loss_cls: 0.2427  decode.d3.loss_mask: 1.0497  decode.d3.loss_dice: 1.1933  decode.d4.loss_cls: 0.2773  decode.d4.loss_mask: 1.0532  decode.d4.loss_dice: 1.1590  decode.d5.loss_cls: 0.2646  decode.d5.loss_mask: 1.0488  decode.d5.loss_dice: 1.1663  decode.d6.loss_cls: 0.2455  decode.d6.loss_mask: 1.0271  decode.d6.loss_dice: 1.1692  decode.d7.loss_cls: 0.2326  decode.d7.loss_mask: 1.0449  decode.d7.loss_dice: 1.1743  decode.d8.loss_cls: 0.2607  decode.d8.loss_mask: 1.0314  decode.d8.loss_dice: 1.1715
2025/03/29 21:42:46 - mmengine - INFO - Iter(train) [19350/20000]  base_lr: 4.5784e-06 lr: 4.5784e-06  eta: 0:18:59  time: 2.9833  data_time: 0.0194  memory: 10128  loss: 21.1258  decode.loss_cls: 0.1496  decode.loss_mask: 0.9890  decode.loss_dice: 0.9622  decode.d0.loss_cls: 0.2163  decode.d0.loss_mask: 0.9985  decode.d0.loss_dice: 1.0253  decode.d1.loss_cls: 0.1756  decode.d1.loss_mask: 0.9997  decode.d1.loss_dice: 0.9734  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 1.0022  decode.d2.loss_dice: 0.9810  decode.d3.loss_cls: 0.1193  decode.d3.loss_mask: 0.9883  decode.d3.loss_dice: 0.9576  decode.d4.loss_cls: 0.1101  decode.d4.loss_mask: 0.9904  decode.d4.loss_dice: 0.9857  decode.d5.loss_cls: 0.1353  decode.d5.loss_mask: 0.9860  decode.d5.loss_dice: 0.9671  decode.d6.loss_cls: 0.1309  decode.d6.loss_mask: 0.9949  decode.d6.loss_dice: 0.9676  decode.d7.loss_cls: 0.1413  decode.d7.loss_mask: 0.9859  decode.d7.loss_dice: 0.9649  decode.d8.loss_cls: 0.1271  decode.d8.loss_mask: 1.0010  decode.d8.loss_dice: 0.9854
2025/03/29 21:45:15 - mmengine - INFO - Iter(train) [19400/20000]  base_lr: 4.2602e-06 lr: 4.2602e-06  eta: 0:17:33  time: 2.9783  data_time: 0.0208  memory: 10129  loss: 19.7127  decode.loss_cls: 0.1172  decode.loss_mask: 0.8345  decode.loss_dice: 1.0184  decode.d0.loss_cls: 0.2232  decode.d0.loss_mask: 0.8297  decode.d0.loss_dice: 1.0261  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 0.8243  decode.d1.loss_dice: 1.0007  decode.d2.loss_cls: 0.1293  decode.d2.loss_mask: 0.8048  decode.d2.loss_dice: 1.0157  decode.d3.loss_cls: 0.1283  decode.d3.loss_mask: 0.8233  decode.d3.loss_dice: 1.0054  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.8158  decode.d4.loss_dice: 1.0041  decode.d5.loss_cls: 0.1384  decode.d5.loss_mask: 0.8134  decode.d5.loss_dice: 0.9991  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.8029  decode.d6.loss_dice: 0.9877  decode.d7.loss_cls: 0.1541  decode.d7.loss_mask: 0.8231  decode.d7.loss_dice: 0.9952  decode.d8.loss_cls: 0.1198  decode.d8.loss_mask: 0.8285  decode.d8.loss_dice: 1.0001
2025/03/29 21:47:44 - mmengine - INFO - Iter(train) [19450/20000]  base_lr: 3.9393e-06 lr: 3.9393e-06  eta: 0:16:07  time: 2.9738  data_time: 0.0203  memory: 10127  loss: 21.9214  decode.loss_cls: 0.1544  decode.loss_mask: 0.9644  decode.loss_dice: 1.0479  decode.d0.loss_cls: 0.2305  decode.d0.loss_mask: 1.0033  decode.d0.loss_dice: 1.0887  decode.d1.loss_cls: 0.1735  decode.d1.loss_mask: 0.9720  decode.d1.loss_dice: 1.0404  decode.d2.loss_cls: 0.1851  decode.d2.loss_mask: 0.9782  decode.d2.loss_dice: 1.0353  decode.d3.loss_cls: 0.1959  decode.d3.loss_mask: 0.9733  decode.d3.loss_dice: 1.0340  decode.d4.loss_cls: 0.1534  decode.d4.loss_mask: 0.9836  decode.d4.loss_dice: 1.0647  decode.d5.loss_cls: 0.1533  decode.d5.loss_mask: 0.9702  decode.d5.loss_dice: 1.0438  decode.d6.loss_cls: 0.1610  decode.d6.loss_mask: 0.9705  decode.d6.loss_dice: 1.0369  decode.d7.loss_cls: 0.1483  decode.d7.loss_mask: 0.9507  decode.d7.loss_dice: 1.0294  decode.d8.loss_cls: 0.1530  decode.d8.loss_mask: 0.9706  decode.d8.loss_dice: 1.0554
2025/03/29 21:50:00 - mmengine - INFO - Iter(train) [19500/20000]  base_lr: 3.6155e-06 lr: 3.6155e-06  eta: 0:14:40  time: 2.9588  data_time: 0.0200  memory: 10122  loss: 21.9213  decode.loss_cls: 0.1638  decode.loss_mask: 0.9837  decode.loss_dice: 1.0217  decode.d0.loss_cls: 0.1874  decode.d0.loss_mask: 1.0151  decode.d0.loss_dice: 1.0963  decode.d1.loss_cls: 0.1570  decode.d1.loss_mask: 0.9899  decode.d1.loss_dice: 1.0579  decode.d2.loss_cls: 0.1507  decode.d2.loss_mask: 0.9892  decode.d2.loss_dice: 1.0371  decode.d3.loss_cls: 0.2070  decode.d3.loss_mask: 0.9805  decode.d3.loss_dice: 1.0053  decode.d4.loss_cls: 0.1542  decode.d4.loss_mask: 0.9837  decode.d4.loss_dice: 1.0406  decode.d5.loss_cls: 0.1130  decode.d5.loss_mask: 0.9970  decode.d5.loss_dice: 1.0518  decode.d6.loss_cls: 0.1887  decode.d6.loss_mask: 0.9852  decode.d6.loss_dice: 1.0247  decode.d7.loss_cls: 0.1798  decode.d7.loss_mask: 0.9790  decode.d7.loss_dice: 1.0126  decode.d8.loss_cls: 0.1744  decode.d8.loss_mask: 0.9770  decode.d8.loss_dice: 1.0170
2025/03/29 21:52:28 - mmengine - INFO - Iter(train) [19550/20000]  base_lr: 3.2884e-06 lr: 3.2884e-06  eta: 0:13:14  time: 2.9534  data_time: 0.0197  memory: 10132  loss: 23.0773  decode.loss_cls: 0.1750  decode.loss_mask: 1.0283  decode.loss_dice: 1.0752  decode.d0.loss_cls: 0.2750  decode.d0.loss_mask: 1.0052  decode.d0.loss_dice: 1.1688  decode.d1.loss_cls: 0.2095  decode.d1.loss_mask: 1.0229  decode.d1.loss_dice: 1.0900  decode.d2.loss_cls: 0.2108  decode.d2.loss_mask: 1.0259  decode.d2.loss_dice: 1.0778  decode.d3.loss_cls: 0.1827  decode.d3.loss_mask: 1.0175  decode.d3.loss_dice: 1.0841  decode.d4.loss_cls: 0.2127  decode.d4.loss_mask: 0.9991  decode.d4.loss_dice: 1.0741  decode.d5.loss_cls: 0.2048  decode.d5.loss_mask: 1.0145  decode.d5.loss_dice: 1.0714  decode.d6.loss_cls: 0.1852  decode.d6.loss_mask: 1.0194  decode.d6.loss_dice: 1.0834  decode.d7.loss_cls: 0.1861  decode.d7.loss_mask: 1.0133  decode.d7.loss_dice: 1.0781  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 1.0189  decode.d8.loss_dice: 1.0732
2025/03/29 21:54:55 - mmengine - INFO - Iter(train) [19600/20000]  base_lr: 2.9576e-06 lr: 2.9576e-06  eta: 0:11:47  time: 2.9473  data_time: 0.0205  memory: 10126  loss: 19.2097  decode.loss_cls: 0.0946  decode.loss_mask: 0.8784  decode.loss_dice: 0.9196  decode.d0.loss_cls: 0.1859  decode.d0.loss_mask: 0.8824  decode.d0.loss_dice: 0.9793  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 0.8703  decode.d1.loss_dice: 0.9271  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 0.8699  decode.d2.loss_dice: 0.9087  decode.d3.loss_cls: 0.1225  decode.d3.loss_mask: 0.8725  decode.d3.loss_dice: 0.9338  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.8706  decode.d4.loss_dice: 0.9374  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.8707  decode.d5.loss_dice: 0.9358  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.8766  decode.d6.loss_dice: 0.9322  decode.d7.loss_cls: 0.1016  decode.d7.loss_mask: 0.8783  decode.d7.loss_dice: 0.9258  decode.d8.loss_cls: 0.1127  decode.d8.loss_mask: 0.8657  decode.d8.loss_dice: 0.9229
2025/03/29 21:57:24 - mmengine - INFO - Iter(train) [19650/20000]  base_lr: 2.6227e-06 lr: 2.6227e-06  eta: 0:10:19  time: 3.0359  data_time: 0.0282  memory: 10125  loss: 22.4125  decode.loss_cls: 0.1706  decode.loss_mask: 0.9780  decode.loss_dice: 1.0652  decode.d0.loss_cls: 0.2372  decode.d0.loss_mask: 0.9861  decode.d0.loss_dice: 1.0968  decode.d1.loss_cls: 0.1765  decode.d1.loss_mask: 0.9791  decode.d1.loss_dice: 1.0723  decode.d2.loss_cls: 0.1866  decode.d2.loss_mask: 0.9827  decode.d2.loss_dice: 1.0873  decode.d3.loss_cls: 0.2157  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.0661  decode.d4.loss_cls: 0.2174  decode.d4.loss_mask: 0.9710  decode.d4.loss_dice: 1.0570  decode.d5.loss_cls: 0.1923  decode.d5.loss_mask: 0.9734  decode.d5.loss_dice: 1.0609  decode.d6.loss_cls: 0.1982  decode.d6.loss_mask: 0.9753  decode.d6.loss_dice: 1.0542  decode.d7.loss_cls: 0.1812  decode.d7.loss_mask: 0.9779  decode.d7.loss_dice: 1.0646  decode.d8.loss_cls: 0.1816  decode.d8.loss_mask: 0.9715  decode.d8.loss_dice: 1.0684
2025/03/29 21:59:53 - mmengine - INFO - Iter(train) [19700/20000]  base_lr: 2.2830e-06 lr: 2.2830e-06  eta: 0:08:52  time: 2.9553  data_time: 0.0201  memory: 10126  loss: 21.6470  decode.loss_cls: 0.1816  decode.loss_mask: 0.9190  decode.loss_dice: 1.0257  decode.d0.loss_cls: 0.2542  decode.d0.loss_mask: 0.9464  decode.d0.loss_dice: 1.1218  decode.d1.loss_cls: 0.2091  decode.d1.loss_mask: 0.9408  decode.d1.loss_dice: 1.0631  decode.d2.loss_cls: 0.1781  decode.d2.loss_mask: 0.9310  decode.d2.loss_dice: 1.0430  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 0.9226  decode.d3.loss_dice: 1.0417  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.9447  decode.d4.loss_dice: 1.0567  decode.d5.loss_cls: 0.1701  decode.d5.loss_mask: 0.9292  decode.d5.loss_dice: 1.0561  decode.d6.loss_cls: 0.1887  decode.d6.loss_mask: 0.9173  decode.d6.loss_dice: 1.0298  decode.d7.loss_cls: 0.1782  decode.d7.loss_mask: 0.9305  decode.d7.loss_dice: 1.0493  decode.d8.loss_cls: 0.1639  decode.d8.loss_mask: 0.9295  decode.d8.loss_dice: 1.0192
2025/03/29 22:02:20 - mmengine - INFO - Iter(train) [19750/20000]  base_lr: 1.9375e-06 lr: 1.9375e-06  eta: 0:07:24  time: 2.9561  data_time: 0.0207  memory: 10124  loss: 20.6176  decode.loss_cls: 0.1779  decode.loss_mask: 0.9330  decode.loss_dice: 0.9279  decode.d0.loss_cls: 0.1940  decode.d0.loss_mask: 0.9834  decode.d0.loss_dice: 1.0457  decode.d1.loss_cls: 0.2153  decode.d1.loss_mask: 0.9202  decode.d1.loss_dice: 0.9359  decode.d2.loss_cls: 0.2002  decode.d2.loss_mask: 0.9305  decode.d2.loss_dice: 0.9291  decode.d3.loss_cls: 0.1785  decode.d3.loss_mask: 0.9264  decode.d3.loss_dice: 0.9151  decode.d4.loss_cls: 0.1676  decode.d4.loss_mask: 0.9288  decode.d4.loss_dice: 0.9331  decode.d5.loss_cls: 0.1870  decode.d5.loss_mask: 0.9245  decode.d5.loss_dice: 0.9157  decode.d6.loss_cls: 0.1982  decode.d6.loss_mask: 0.9298  decode.d6.loss_dice: 0.9121  decode.d7.loss_cls: 0.1986  decode.d7.loss_mask: 0.9308  decode.d7.loss_dice: 0.9252  decode.d8.loss_cls: 0.1860  decode.d8.loss_mask: 0.9398  decode.d8.loss_dice: 0.9276
2025/03/29 22:04:48 - mmengine - INFO - Iter(train) [19800/20000]  base_lr: 1.5850e-06 lr: 1.5850e-06  eta: 0:05:55  time: 2.9527  data_time: 0.0200  memory: 10125  loss: 22.9913  decode.loss_cls: 0.1683  decode.loss_mask: 1.0428  decode.loss_dice: 1.0760  decode.d0.loss_cls: 0.1918  decode.d0.loss_mask: 1.0654  decode.d0.loss_dice: 1.1586  decode.d1.loss_cls: 0.2037  decode.d1.loss_mask: 1.0384  decode.d1.loss_dice: 1.0754  decode.d2.loss_cls: 0.1594  decode.d2.loss_mask: 1.0696  decode.d2.loss_dice: 1.0903  decode.d3.loss_cls: 0.1637  decode.d3.loss_mask: 1.0450  decode.d3.loss_dice: 1.0584  decode.d4.loss_cls: 0.1708  decode.d4.loss_mask: 1.0346  decode.d4.loss_dice: 1.0710  decode.d5.loss_cls: 0.1553  decode.d5.loss_mask: 1.0481  decode.d5.loss_dice: 1.0753  decode.d6.loss_cls: 0.1616  decode.d6.loss_mask: 1.0404  decode.d6.loss_dice: 1.0631  decode.d7.loss_cls: 0.1600  decode.d7.loss_mask: 1.0410  decode.d7.loss_dice: 1.0672  decode.d8.loss_cls: 0.1920  decode.d8.loss_mask: 1.0336  decode.d8.loss_dice: 1.0703
2025/03/29 22:07:17 - mmengine - INFO - Iter(train) [19850/20000]  base_lr: 1.2234e-06 lr: 1.2234e-06  eta: 0:04:27  time: 2.9723  data_time: 0.0206  memory: 10129  loss: 20.6731  decode.loss_cls: 0.1408  decode.loss_mask: 0.9297  decode.loss_dice: 0.9665  decode.d0.loss_cls: 0.1955  decode.d0.loss_mask: 0.9557  decode.d0.loss_dice: 1.0338  decode.d1.loss_cls: 0.1674  decode.d1.loss_mask: 0.9408  decode.d1.loss_dice: 0.9866  decode.d2.loss_cls: 0.1445  decode.d2.loss_mask: 0.9531  decode.d2.loss_dice: 0.9870  decode.d3.loss_cls: 0.1695  decode.d3.loss_mask: 0.9253  decode.d3.loss_dice: 0.9413  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 0.9366  decode.d4.loss_dice: 0.9688  decode.d5.loss_cls: 0.1338  decode.d5.loss_mask: 0.9344  decode.d5.loss_dice: 0.9736  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 0.9139  decode.d6.loss_dice: 0.9634  decode.d7.loss_cls: 0.1375  decode.d7.loss_mask: 0.9260  decode.d7.loss_dice: 0.9693  decode.d8.loss_cls: 0.1420  decode.d8.loss_mask: 0.9398  decode.d8.loss_dice: 0.9660
2025/03/29 22:08:33 - mmengine - INFO - Iter(train) [19900/20000]  base_lr: 8.4936e-07 lr: 8.4936e-07  eta: 0:02:58  time: 1.1235  data_time: 0.0245  memory: 10124  loss: 23.9305  decode.loss_cls: 0.1596  decode.loss_mask: 1.1475  decode.loss_dice: 1.0673  decode.d0.loss_cls: 0.2031  decode.d0.loss_mask: 1.1494  decode.d0.loss_dice: 1.1019  decode.d1.loss_cls: 0.1841  decode.d1.loss_mask: 1.1413  decode.d1.loss_dice: 1.0891  decode.d2.loss_cls: 0.1734  decode.d2.loss_mask: 1.1537  decode.d2.loss_dice: 1.0497  decode.d3.loss_cls: 0.1336  decode.d3.loss_mask: 1.1536  decode.d3.loss_dice: 1.0680  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 1.1507  decode.d4.loss_dice: 1.0792  decode.d5.loss_cls: 0.1805  decode.d5.loss_mask: 1.1513  decode.d5.loss_dice: 1.0771  decode.d6.loss_cls: 0.1696  decode.d6.loss_mask: 1.1488  decode.d6.loss_dice: 1.0781  decode.d7.loss_cls: 0.1788  decode.d7.loss_mask: 1.1565  decode.d7.loss_dice: 1.0699  decode.d8.loss_cls: 0.1651  decode.d8.loss_mask: 1.1466  decode.d8.loss_dice: 1.0579
2025/03/29 22:09:29 - mmengine - INFO - Iter(train) [19950/20000]  base_lr: 4.5516e-07 lr: 4.5516e-07  eta: 0:01:29  time: 1.1250  data_time: 0.0198  memory: 10121  loss: 21.9751  decode.loss_cls: 0.0940  decode.loss_mask: 1.0126  decode.loss_dice: 1.0578  decode.d0.loss_cls: 0.2028  decode.d0.loss_mask: 1.0250  decode.d0.loss_dice: 1.1341  decode.d1.loss_cls: 0.1316  decode.d1.loss_mask: 1.0066  decode.d1.loss_dice: 1.0627  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 1.0045  decode.d2.loss_dice: 1.0582  decode.d3.loss_cls: 0.1189  decode.d3.loss_mask: 1.0045  decode.d3.loss_dice: 1.0231  decode.d4.loss_cls: 0.1367  decode.d4.loss_mask: 1.0070  decode.d4.loss_dice: 1.0630  decode.d5.loss_cls: 0.1374  decode.d5.loss_mask: 1.0050  decode.d5.loss_dice: 1.0413  decode.d6.loss_cls: 0.1342  decode.d6.loss_mask: 0.9989  decode.d6.loss_dice: 1.0322  decode.d7.loss_cls: 0.1758  decode.d7.loss_mask: 0.9938  decode.d7.loss_dice: 1.0185  decode.d8.loss_cls: 0.1033  decode.d8.loss_mask: 1.0137  decode.d8.loss_dice: 1.0326
2025/03/29 22:10:25 - mmengine - INFO - Exp name: pr2vi_20250329_120645
2025/03/29 22:10:25 - mmengine - INFO - Iter(train) [20000/20000]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 1.1237  data_time: 0.0199  memory: 10120  loss: 22.0127  decode.loss_cls: 0.1718  decode.loss_mask: 0.9810  decode.loss_dice: 1.0283  decode.d0.loss_cls: 0.2432  decode.d0.loss_mask: 0.9878  decode.d0.loss_dice: 1.0991  decode.d1.loss_cls: 0.1772  decode.d1.loss_mask: 0.9745  decode.d1.loss_dice: 1.0435  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 0.9640  decode.d2.loss_dice: 1.0439  decode.d3.loss_cls: 0.2140  decode.d3.loss_mask: 0.9584  decode.d3.loss_dice: 1.0400  decode.d4.loss_cls: 0.1415  decode.d4.loss_mask: 0.9706  decode.d4.loss_dice: 1.0400  decode.d5.loss_cls: 0.1521  decode.d5.loss_mask: 0.9782  decode.d5.loss_dice: 1.0430  decode.d6.loss_cls: 0.1693  decode.d6.loss_mask: 0.9758  decode.d6.loss_dice: 1.0134  decode.d7.loss_cls: 0.1693  decode.d7.loss_mask: 0.9937  decode.d7.loss_dice: 1.0202  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 0.9845  decode.d8.loss_dice: 1.0431
2025/03/29 22:10:25 - mmengine - INFO - Saving checkpoint at 20000 iterations
2025/03/29 22:10:34 - mmengine - INFO - Iter(val) [ 50/398]    eta: 0:00:43  time: 0.1219  data_time: 0.0019  memory: 1808  
2025/03/29 22:10:40 - mmengine - INFO - Iter(val) [100/398]    eta: 0:00:36  time: 0.1228  data_time: 0.0020  memory: 1808  
2025/03/29 22:10:46 - mmengine - INFO - Iter(val) [150/398]    eta: 0:00:30  time: 0.1237  data_time: 0.0020  memory: 1808  
2025/03/29 22:10:52 - mmengine - INFO - Iter(val) [200/398]    eta: 0:00:24  time: 0.1225  data_time: 0.0018  memory: 1808  
2025/03/29 22:10:59 - mmengine - INFO - Iter(val) [250/398]    eta: 0:00:18  time: 0.1206  data_time: 0.0019  memory: 1808  
2025/03/29 22:11:05 - mmengine - INFO - Iter(val) [300/398]    eta: 0:00:12  time: 0.1207  data_time: 0.0018  memory: 1808  
2025/03/29 22:11:11 - mmengine - INFO - Iter(val) [350/398]    eta: 0:00:05  time: 0.1208  data_time: 0.0018  memory: 1808  
2025/03/29 22:11:17 - mmengine - INFO - per class results:
2025/03/29 22:11:17 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 73.85 | 82.38 |
|      building      | 86.62 | 94.59 |
|   low_vegetation   | 48.33 | 56.52 |
|        tree        | 72.94 | 89.34 |
|        car         | 59.19 | 72.21 |
|      clutter       | 17.43 | 93.04 |
+--------------------+-------+-------+
2025/03/29 22:11:17 - mmengine - INFO - Iter(val) [398/398]    aAcc: 81.3000  mIoU: 59.7300  mAcc: 81.3400  data_time: 0.0020  time: 0.1228
