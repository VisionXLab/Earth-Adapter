2025/03/28 09:48:47 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0: NVIDIA RTX A6000
    CUDA_HOME: /usr/local/cuda-12.1
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
    PyTorch: 2.1.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.1+cu121
    OpenCV: 4.10.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 0
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/03/28 09:48:47 - mmengine - INFO - Config:
crop_size = (
    512,
    512,
)
data_root = '/data/xiaoxinghhh/dataset/remote_sensing/'
dataset_type = 'ISPRSDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=2000,
        max_keep_ckpts=1,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
exp_name = 'DA_spatial_32_fft_cut_off_0.2_suf3'
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        adapter_config=dict(
            cutoff_ratio=0.2, dim=32, fft_layer=[
                21,
                22,
                23,
            ]),
        block_chunks=0,
        depth=24,
        embed_dim=1024,
        ffn_bias=True,
        ffn_layer='mlp',
        img_size=512,
        init_cfg=dict(
            checkpoint='checkpoints/dinov2_converted.pth', type='Pretrained'),
        init_values=1e-05,
        mlp_ratio=4,
        moe_adapter_type='earth_adapter',
        num_heads=16,
        patch_size=16,
        proj_bias=True,
        qkv_bias=True,
        type='MOE_Adpter_DinoVisionTransformer'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            1024,
            1024,
            1024,
            1024,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=6,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='DACS_encoder_decoder')
num_classes = 19
optim_wrapper = dict(
    constructor='PEFTOptimWrapperConstructor',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'learnable_tokens': dict(decay_mult=0.0, lr_mult=1.0),
            'level_embed': dict(decay_mult=0.0, lr_mult=1.0),
            'norm': dict(decay_mult=0.0),
            'query_embed': dict(decay_mult=0.0, lr_mult=1.0),
            'reins.scale': dict(decay_mult=0.0, lr_mult=1.0)
        }),
        norm_decay_mult=0.0))
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=20000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='potsdamRGB/img_dir/val',
            seg_map_path='potsdamRGB/ann_dir/val'),
        data_root='/data/xiaoxinghhh/dataset/remote_sensing/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                512,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        512,
        512,
    ), type='Resize'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=2000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        source_dataset=dict(
            data_prefix=dict(
                img_path='vaihingen/img_dir/train',
                seg_map_path='vaihingen/ann_dir/train'),
            data_root='/data/xiaoxinghhh/dataset/remote_sensing/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(reduce_zero_label=True, type='LoadAnnotations'),
                dict(
                    keep_ratio=True,
                    ratio_range=(
                        0.5,
                        2.0,
                    ),
                    scale=(
                        512,
                        512,
                    ),
                    type='RandomResize'),
                dict(
                    cat_max_ratio=0.75,
                    crop_size=(
                        512,
                        512,
                    ),
                    type='RandomCrop'),
                dict(prob=0.5, type='RandomFlip'),
                dict(type='PhotoMetricDistortion'),
                dict(type='PackSegInputs'),
            ],
            type='ISPRSDataset'),
        target_dataset=dict(
            data_prefix=dict(
                img_path='potsdamRGB/img_dir/train',
                seg_map_path='potsdamRGB/ann_dir/train'),
            data_root='/data/xiaoxinghhh/dataset/remote_sensing/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(reduce_zero_label=True, type='LoadAnnotations'),
                dict(
                    keep_ratio=True,
                    ratio_range=(
                        0.5,
                        2.0,
                    ),
                    scale=(
                        512,
                        512,
                    ),
                    type='RandomResize'),
                dict(
                    cat_max_ratio=0.75,
                    crop_size=(
                        512,
                        512,
                    ),
                    type='RandomCrop'),
                dict(prob=0.5, type='RandomFlip'),
                dict(type='PhotoMetricDistortion'),
                dict(type='PackSegInputs'),
            ],
            type='ISPRSDataset'),
        type='UDA_dataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            512,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='potsdamRGB/img_dir/val',
            seg_map_path='potsdamRGB/ann_dir/val'),
        data_root='/data/xiaoxinghhh/dataset/remote_sensing/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                512,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/vi2pr/DA_spatial_32_fft_cut_off_0.2_suf3/6ff2f_seed0'

2025/03/28 09:48:52 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/03/28 09:48:52 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/03/28 09:48:53 - mmengine - WARNING - Dataset UDA_dataset has no metainfo. ``dataset_meta`` in visualizer will be None.
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.scale
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.1.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.1.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.3.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.3.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.4.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.4.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.5.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.5.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.6.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.6.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.7.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.7.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.8.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.8.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.9.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.9.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.10.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.10.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.11.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.11.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.12.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.12.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.13.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.13.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.14.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.14.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.15.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.15.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.16.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.16.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.17.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.17.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.18.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.18.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.19.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.19.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.20.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.20.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.21.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.21.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.22.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.22.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.23.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.23.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.0.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.0.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.1.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.1.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.2.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.2.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.3.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.3.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.4.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.4.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.5.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.5.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.6.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.6.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.7.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.7.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.8.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.8.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.9.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.9.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.10.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.10.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.11.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.11.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.12.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.12.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.13.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.13.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.14.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.14.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.15.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.15.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.16.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.16.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.17.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.17.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.18.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.18.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.19.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.19.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.20.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.20.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.21.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.21.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.22.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.22.bias
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.23.weight
2025/03/28 09:48:53 - mmengine - INFO - set_requires_grad----refine_feat.router.23.bias
2025/03/28 09:48:53 - mmengine - INFO - Total trainable params--4917600, All params--309117280, Ratio--1.6%
2025/03/28 09:48:53 - mmengine - INFO - set_train----.refine_feat
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.scale:num of params=24
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.0.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.0.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.1.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.1.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.2.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.2.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.3.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.3.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.4.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.4.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.5.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.5.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.6.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.6.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.7.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.7.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.8.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.8.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.9.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.9.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.10.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.10.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.11.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.11.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.12.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.12.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.13.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.13.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.14.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.14.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.15.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.15.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.16.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.16.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.17.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.17.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.18.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.18.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.19.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.19.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.20.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.20.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.21.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.21.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.22.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.22.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.23.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.23.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.conv.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.conv.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.conv.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.conv.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.conv.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.conv.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight:num of params=49152
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias:num of params=192
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight:num of params=24576
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias:num of params=96
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight:num of params=49152
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias:num of params=192
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight:num of params=24576
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias:num of params=96
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight:num of params=49152
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias:num of params=192
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight:num of params=24576
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias:num of params=96
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight:num of params=49152
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias:num of params=192
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight:num of params=24576
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias:num of params=96
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight:num of params=49152
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias:num of params=192
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight:num of params=24576
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias:num of params=96
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight:num of params=49152
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias:num of params=192
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight:num of params=24576
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias:num of params=96
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.level_encoding.weight:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.conv.weight:num of params=262144
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.conv.weight:num of params=589824
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.mask_feature.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.mask_feature.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias:num of params=2048
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.1.weight:num of params=524288
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:num of params=25600
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:num of params=25600
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:num of params=768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.cls_embed.weight:num of params=1792
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.cls_embed.bias:num of params=7
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.0.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.0.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.2.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.2.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.4.weight:num of params=65536
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.4.bias:num of params=256
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.scale:num of params=24
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.0.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.1.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.2.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.3.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.4.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.5.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.6.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.7.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.8.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.9.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.10.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.11.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.12.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.13.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.14.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.15.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.16.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.17.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.18.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.19.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.20.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.21.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.22.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.weight:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.weight:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.weight:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.weight:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.bias:lr=0.0001
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.bias:weight_decay=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.layer_norm.23.bias:decay_mult=0.0
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.0.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.0.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.0.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.0.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.1.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.1.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.1.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.1.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.2.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.2.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.2.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.2.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.3.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.3.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.3.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.3.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.4.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.4.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.4.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.4.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.5.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.5.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.5.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.5.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.6.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.6.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.6.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.6.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.7.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.7.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.7.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.7.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.8.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.8.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.8.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.8.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.9.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.9.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.9.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.9.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.10.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.10.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.10.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.10.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.11.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.11.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.11.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.11.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.12.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.12.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.12.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.12.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.13.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.13.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.13.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.13.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.14.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.14.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.14.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.14.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.15.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.15.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.15.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.15.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.16.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.16.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.16.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.16.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.17.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.17.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.17.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.17.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.18.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.18.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.18.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.18.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.19.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.19.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.19.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.19.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.20.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.20.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.20.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.20.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.21.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.21.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.21.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.21.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.22.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.22.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.22.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.22.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.23.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.23.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.23.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list1.23.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.0.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.0.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.0.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.0.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.1.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.1.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.1.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.1.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.2.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.2.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.2.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.2.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.3.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.3.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.3.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.3.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.4.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.4.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.4.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.4.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.5.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.5.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.5.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.5.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.6.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.6.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.6.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.6.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.7.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.7.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.7.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.7.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.8.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.8.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.8.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.8.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.9.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.9.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.9.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.9.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.10.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.10.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.10.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.10.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.11.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.11.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.11.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.11.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.12.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.12.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.12.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.12.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.13.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.13.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.13.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.13.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.14.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.14.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.14.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.14.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.15.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.15.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.15.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.15.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.16.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.16.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.16.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.16.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.17.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.17.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.17.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.17.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.18.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.18.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.18.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.18.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.19.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.19.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.19.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.19.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.20.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.20.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.20.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.20.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.21.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.21.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.21.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.21.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.22.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.22.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.22.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.22.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.23.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.23.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.23.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list2.23.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.0.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.0.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.0.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.0.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.1.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.1.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.1.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.1.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.2.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.2.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.2.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.2.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.3.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.3.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.3.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.3.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.4.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.4.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.4.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.4.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.5.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.5.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.5.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.5.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.6.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.6.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.6.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.6.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.7.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.7.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.7.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.7.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.8.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.8.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.8.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.8.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.9.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.9.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.9.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.9.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.10.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.10.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.10.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.10.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.11.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.11.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.11.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.11.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.12.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.12.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.12.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.12.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.13.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.13.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.13.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.13.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.14.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.14.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.14.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.14.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.15.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.15.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.15.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.15.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.16.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.16.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.16.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.16.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.17.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.17.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.17.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.17.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.18.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.18.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.18.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.18.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.19.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.19.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.19.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.19.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.20.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.20.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.20.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.20.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.21.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.21.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.21.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.21.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.22.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.22.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.22.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.22.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.23.0.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.23.0.bias:num of params=32
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.23.2.weight:num of params=32768
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.mlp_list3.23.2.bias:num of params=1024
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.0.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.0.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.1.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.1.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.2.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.2.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.3.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.3.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.4.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.4.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.5.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.5.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.6.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.6.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.7.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.7.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.8.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.8.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.9.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.9.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.10.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.10.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.11.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.11.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.12.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.12.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.13.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.13.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.14.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.14.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.15.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.15.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.16.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.16.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.17.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.17.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.18.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.18.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.19.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.19.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.20.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.20.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.21.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.21.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.22.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.22.bias:num of params=3
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.23.weight:num of params=3072
2025/03/28 09:48:53 - mmengine - INFO - paramwise_options -- ema_model.backbone.refine_feat.router.23.bias:num of params=3
2025/03/28 09:48:54 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
2025/03/28 09:48:54 - mmengine - INFO - load model from: checkpoints/dinov2_converted.pth
2025/03/28 09:48:54 - mmengine - INFO - Loads checkpoint by local backend from path: checkpoints/dinov2_converted.pth
2025/03/28 09:48:55 - mmengine - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: refine_feat.scale, refine_feat.layer_norm.0.weight, refine_feat.layer_norm.0.bias, refine_feat.layer_norm.1.weight, refine_feat.layer_norm.1.bias, refine_feat.layer_norm.2.weight, refine_feat.layer_norm.2.bias, refine_feat.layer_norm.3.weight, refine_feat.layer_norm.3.bias, refine_feat.layer_norm.4.weight, refine_feat.layer_norm.4.bias, refine_feat.layer_norm.5.weight, refine_feat.layer_norm.5.bias, refine_feat.layer_norm.6.weight, refine_feat.layer_norm.6.bias, refine_feat.layer_norm.7.weight, refine_feat.layer_norm.7.bias, refine_feat.layer_norm.8.weight, refine_feat.layer_norm.8.bias, refine_feat.layer_norm.9.weight, refine_feat.layer_norm.9.bias, refine_feat.layer_norm.10.weight, refine_feat.layer_norm.10.bias, refine_feat.layer_norm.11.weight, refine_feat.layer_norm.11.bias, refine_feat.layer_norm.12.weight, refine_feat.layer_norm.12.bias, refine_feat.layer_norm.13.weight, refine_feat.layer_norm.13.bias, refine_feat.layer_norm.14.weight, refine_feat.layer_norm.14.bias, refine_feat.layer_norm.15.weight, refine_feat.layer_norm.15.bias, refine_feat.layer_norm.16.weight, refine_feat.layer_norm.16.bias, refine_feat.layer_norm.17.weight, refine_feat.layer_norm.17.bias, refine_feat.layer_norm.18.weight, refine_feat.layer_norm.18.bias, refine_feat.layer_norm.19.weight, refine_feat.layer_norm.19.bias, refine_feat.layer_norm.20.weight, refine_feat.layer_norm.20.bias, refine_feat.layer_norm.21.weight, refine_feat.layer_norm.21.bias, refine_feat.layer_norm.22.weight, refine_feat.layer_norm.22.bias, refine_feat.layer_norm.23.weight, refine_feat.layer_norm.23.bias, refine_feat.mlp_list1.0.0.weight, refine_feat.mlp_list1.0.0.bias, refine_feat.mlp_list1.0.2.weight, refine_feat.mlp_list1.0.2.bias, refine_feat.mlp_list1.1.0.weight, refine_feat.mlp_list1.1.0.bias, refine_feat.mlp_list1.1.2.weight, refine_feat.mlp_list1.1.2.bias, refine_feat.mlp_list1.2.0.weight, refine_feat.mlp_list1.2.0.bias, refine_feat.mlp_list1.2.2.weight, refine_feat.mlp_list1.2.2.bias, refine_feat.mlp_list1.3.0.weight, refine_feat.mlp_list1.3.0.bias, refine_feat.mlp_list1.3.2.weight, refine_feat.mlp_list1.3.2.bias, refine_feat.mlp_list1.4.0.weight, refine_feat.mlp_list1.4.0.bias, refine_feat.mlp_list1.4.2.weight, refine_feat.mlp_list1.4.2.bias, refine_feat.mlp_list1.5.0.weight, refine_feat.mlp_list1.5.0.bias, refine_feat.mlp_list1.5.2.weight, refine_feat.mlp_list1.5.2.bias, refine_feat.mlp_list1.6.0.weight, refine_feat.mlp_list1.6.0.bias, refine_feat.mlp_list1.6.2.weight, refine_feat.mlp_list1.6.2.bias, refine_feat.mlp_list1.7.0.weight, refine_feat.mlp_list1.7.0.bias, refine_feat.mlp_list1.7.2.weight, refine_feat.mlp_list1.7.2.bias, refine_feat.mlp_list1.8.0.weight, refine_feat.mlp_list1.8.0.bias, refine_feat.mlp_list1.8.2.weight, refine_feat.mlp_list1.8.2.bias, refine_feat.mlp_list1.9.0.weight, refine_feat.mlp_list1.9.0.bias, refine_feat.mlp_list1.9.2.weight, refine_feat.mlp_list1.9.2.bias, refine_feat.mlp_list1.10.0.weight, refine_feat.mlp_list1.10.0.bias, refine_feat.mlp_list1.10.2.weight, refine_feat.mlp_list1.10.2.bias, refine_feat.mlp_list1.11.0.weight, refine_feat.mlp_list1.11.0.bias, refine_feat.mlp_list1.11.2.weight, refine_feat.mlp_list1.11.2.bias, refine_feat.mlp_list1.12.0.weight, refine_feat.mlp_list1.12.0.bias, refine_feat.mlp_list1.12.2.weight, refine_feat.mlp_list1.12.2.bias, refine_feat.mlp_list1.13.0.weight, refine_feat.mlp_list1.13.0.bias, refine_feat.mlp_list1.13.2.weight, refine_feat.mlp_list1.13.2.bias, refine_feat.mlp_list1.14.0.weight, refine_feat.mlp_list1.14.0.bias, refine_feat.mlp_list1.14.2.weight, refine_feat.mlp_list1.14.2.bias, refine_feat.mlp_list1.15.0.weight, refine_feat.mlp_list1.15.0.bias, refine_feat.mlp_list1.15.2.weight, refine_feat.mlp_list1.15.2.bias, refine_feat.mlp_list1.16.0.weight, refine_feat.mlp_list1.16.0.bias, refine_feat.mlp_list1.16.2.weight, refine_feat.mlp_list1.16.2.bias, refine_feat.mlp_list1.17.0.weight, refine_feat.mlp_list1.17.0.bias, refine_feat.mlp_list1.17.2.weight, refine_feat.mlp_list1.17.2.bias, refine_feat.mlp_list1.18.0.weight, refine_feat.mlp_list1.18.0.bias, refine_feat.mlp_list1.18.2.weight, refine_feat.mlp_list1.18.2.bias, refine_feat.mlp_list1.19.0.weight, refine_feat.mlp_list1.19.0.bias, refine_feat.mlp_list1.19.2.weight, refine_feat.mlp_list1.19.2.bias, refine_feat.mlp_list1.20.0.weight, refine_feat.mlp_list1.20.0.bias, refine_feat.mlp_list1.20.2.weight, refine_feat.mlp_list1.20.2.bias, refine_feat.mlp_list1.21.0.weight, refine_feat.mlp_list1.21.0.bias, refine_feat.mlp_list1.21.2.weight, refine_feat.mlp_list1.21.2.bias, refine_feat.mlp_list1.22.0.weight, refine_feat.mlp_list1.22.0.bias, refine_feat.mlp_list1.22.2.weight, refine_feat.mlp_list1.22.2.bias, refine_feat.mlp_list1.23.0.weight, refine_feat.mlp_list1.23.0.bias, refine_feat.mlp_list1.23.2.weight, refine_feat.mlp_list1.23.2.bias, refine_feat.mlp_list2.0.0.weight, refine_feat.mlp_list2.0.0.bias, refine_feat.mlp_list2.0.2.weight, refine_feat.mlp_list2.0.2.bias, refine_feat.mlp_list2.1.0.weight, refine_feat.mlp_list2.1.0.bias, refine_feat.mlp_list2.1.2.weight, refine_feat.mlp_list2.1.2.bias, refine_feat.mlp_list2.2.0.weight, refine_feat.mlp_list2.2.0.bias, refine_feat.mlp_list2.2.2.weight, refine_feat.mlp_list2.2.2.bias, refine_feat.mlp_list2.3.0.weight, refine_feat.mlp_list2.3.0.bias, refine_feat.mlp_list2.3.2.weight, refine_feat.mlp_list2.3.2.bias, refine_feat.mlp_list2.4.0.weight, refine_feat.mlp_list2.4.0.bias, refine_feat.mlp_list2.4.2.weight, refine_feat.mlp_list2.4.2.bias, refine_feat.mlp_list2.5.0.weight, refine_feat.mlp_list2.5.0.bias, refine_feat.mlp_list2.5.2.weight, refine_feat.mlp_list2.5.2.bias, refine_feat.mlp_list2.6.0.weight, refine_feat.mlp_list2.6.0.bias, refine_feat.mlp_list2.6.2.weight, refine_feat.mlp_list2.6.2.bias, refine_feat.mlp_list2.7.0.weight, refine_feat.mlp_list2.7.0.bias, refine_feat.mlp_list2.7.2.weight, refine_feat.mlp_list2.7.2.bias, refine_feat.mlp_list2.8.0.weight, refine_feat.mlp_list2.8.0.bias, refine_feat.mlp_list2.8.2.weight, refine_feat.mlp_list2.8.2.bias, refine_feat.mlp_list2.9.0.weight, refine_feat.mlp_list2.9.0.bias, refine_feat.mlp_list2.9.2.weight, refine_feat.mlp_list2.9.2.bias, refine_feat.mlp_list2.10.0.weight, refine_feat.mlp_list2.10.0.bias, refine_feat.mlp_list2.10.2.weight, refine_feat.mlp_list2.10.2.bias, refine_feat.mlp_list2.11.0.weight, refine_feat.mlp_list2.11.0.bias, refine_feat.mlp_list2.11.2.weight, refine_feat.mlp_list2.11.2.bias, refine_feat.mlp_list2.12.0.weight, refine_feat.mlp_list2.12.0.bias, refine_feat.mlp_list2.12.2.weight, refine_feat.mlp_list2.12.2.bias, refine_feat.mlp_list2.13.0.weight, refine_feat.mlp_list2.13.0.bias, refine_feat.mlp_list2.13.2.weight, refine_feat.mlp_list2.13.2.bias, refine_feat.mlp_list2.14.0.weight, refine_feat.mlp_list2.14.0.bias, refine_feat.mlp_list2.14.2.weight, refine_feat.mlp_list2.14.2.bias, refine_feat.mlp_list2.15.0.weight, refine_feat.mlp_list2.15.0.bias, refine_feat.mlp_list2.15.2.weight, refine_feat.mlp_list2.15.2.bias, refine_feat.mlp_list2.16.0.weight, refine_feat.mlp_list2.16.0.bias, refine_feat.mlp_list2.16.2.weight, refine_feat.mlp_list2.16.2.bias, refine_feat.mlp_list2.17.0.weight, refine_feat.mlp_list2.17.0.bias, refine_feat.mlp_list2.17.2.weight, refine_feat.mlp_list2.17.2.bias, refine_feat.mlp_list2.18.0.weight, refine_feat.mlp_list2.18.0.bias, refine_feat.mlp_list2.18.2.weight, refine_feat.mlp_list2.18.2.bias, refine_feat.mlp_list2.19.0.weight, refine_feat.mlp_list2.19.0.bias, refine_feat.mlp_list2.19.2.weight, refine_feat.mlp_list2.19.2.bias, refine_feat.mlp_list2.20.0.weight, refine_feat.mlp_list2.20.0.bias, refine_feat.mlp_list2.20.2.weight, refine_feat.mlp_list2.20.2.bias, refine_feat.mlp_list2.21.0.weight, refine_feat.mlp_list2.21.0.bias, refine_feat.mlp_list2.21.2.weight, refine_feat.mlp_list2.21.2.bias, refine_feat.mlp_list2.22.0.weight, refine_feat.mlp_list2.22.0.bias, refine_feat.mlp_list2.22.2.weight, refine_feat.mlp_list2.22.2.bias, refine_feat.mlp_list2.23.0.weight, refine_feat.mlp_list2.23.0.bias, refine_feat.mlp_list2.23.2.weight, refine_feat.mlp_list2.23.2.bias, refine_feat.mlp_list3.0.0.weight, refine_feat.mlp_list3.0.0.bias, refine_feat.mlp_list3.0.2.weight, refine_feat.mlp_list3.0.2.bias, refine_feat.mlp_list3.1.0.weight, refine_feat.mlp_list3.1.0.bias, refine_feat.mlp_list3.1.2.weight, refine_feat.mlp_list3.1.2.bias, refine_feat.mlp_list3.2.0.weight, refine_feat.mlp_list3.2.0.bias, refine_feat.mlp_list3.2.2.weight, refine_feat.mlp_list3.2.2.bias, refine_feat.mlp_list3.3.0.weight, refine_feat.mlp_list3.3.0.bias, refine_feat.mlp_list3.3.2.weight, refine_feat.mlp_list3.3.2.bias, refine_feat.mlp_list3.4.0.weight, refine_feat.mlp_list3.4.0.bias, refine_feat.mlp_list3.4.2.weight, refine_feat.mlp_list3.4.2.bias, refine_feat.mlp_list3.5.0.weight, refine_feat.mlp_list3.5.0.bias, refine_feat.mlp_list3.5.2.weight, refine_feat.mlp_list3.5.2.bias, refine_feat.mlp_list3.6.0.weight, refine_feat.mlp_list3.6.0.bias, refine_feat.mlp_list3.6.2.weight, refine_feat.mlp_list3.6.2.bias, refine_feat.mlp_list3.7.0.weight, refine_feat.mlp_list3.7.0.bias, refine_feat.mlp_list3.7.2.weight, refine_feat.mlp_list3.7.2.bias, refine_feat.mlp_list3.8.0.weight, refine_feat.mlp_list3.8.0.bias, refine_feat.mlp_list3.8.2.weight, refine_feat.mlp_list3.8.2.bias, refine_feat.mlp_list3.9.0.weight, refine_feat.mlp_list3.9.0.bias, refine_feat.mlp_list3.9.2.weight, refine_feat.mlp_list3.9.2.bias, refine_feat.mlp_list3.10.0.weight, refine_feat.mlp_list3.10.0.bias, refine_feat.mlp_list3.10.2.weight, refine_feat.mlp_list3.10.2.bias, refine_feat.mlp_list3.11.0.weight, refine_feat.mlp_list3.11.0.bias, refine_feat.mlp_list3.11.2.weight, refine_feat.mlp_list3.11.2.bias, refine_feat.mlp_list3.12.0.weight, refine_feat.mlp_list3.12.0.bias, refine_feat.mlp_list3.12.2.weight, refine_feat.mlp_list3.12.2.bias, refine_feat.mlp_list3.13.0.weight, refine_feat.mlp_list3.13.0.bias, refine_feat.mlp_list3.13.2.weight, refine_feat.mlp_list3.13.2.bias, refine_feat.mlp_list3.14.0.weight, refine_feat.mlp_list3.14.0.bias, refine_feat.mlp_list3.14.2.weight, refine_feat.mlp_list3.14.2.bias, refine_feat.mlp_list3.15.0.weight, refine_feat.mlp_list3.15.0.bias, refine_feat.mlp_list3.15.2.weight, refine_feat.mlp_list3.15.2.bias, refine_feat.mlp_list3.16.0.weight, refine_feat.mlp_list3.16.0.bias, refine_feat.mlp_list3.16.2.weight, refine_feat.mlp_list3.16.2.bias, refine_feat.mlp_list3.17.0.weight, refine_feat.mlp_list3.17.0.bias, refine_feat.mlp_list3.17.2.weight, refine_feat.mlp_list3.17.2.bias, refine_feat.mlp_list3.18.0.weight, refine_feat.mlp_list3.18.0.bias, refine_feat.mlp_list3.18.2.weight, refine_feat.mlp_list3.18.2.bias, refine_feat.mlp_list3.19.0.weight, refine_feat.mlp_list3.19.0.bias, refine_feat.mlp_list3.19.2.weight, refine_feat.mlp_list3.19.2.bias, refine_feat.mlp_list3.20.0.weight, refine_feat.mlp_list3.20.0.bias, refine_feat.mlp_list3.20.2.weight, refine_feat.mlp_list3.20.2.bias, refine_feat.mlp_list3.21.0.weight, refine_feat.mlp_list3.21.0.bias, refine_feat.mlp_list3.21.2.weight, refine_feat.mlp_list3.21.2.bias, refine_feat.mlp_list3.22.0.weight, refine_feat.mlp_list3.22.0.bias, refine_feat.mlp_list3.22.2.weight, refine_feat.mlp_list3.22.2.bias, refine_feat.mlp_list3.23.0.weight, refine_feat.mlp_list3.23.0.bias, refine_feat.mlp_list3.23.2.weight, refine_feat.mlp_list3.23.2.bias, refine_feat.router.0.weight, refine_feat.router.0.bias, refine_feat.router.1.weight, refine_feat.router.1.bias, refine_feat.router.2.weight, refine_feat.router.2.bias, refine_feat.router.3.weight, refine_feat.router.3.bias, refine_feat.router.4.weight, refine_feat.router.4.bias, refine_feat.router.5.weight, refine_feat.router.5.bias, refine_feat.router.6.weight, refine_feat.router.6.bias, refine_feat.router.7.weight, refine_feat.router.7.bias, refine_feat.router.8.weight, refine_feat.router.8.bias, refine_feat.router.9.weight, refine_feat.router.9.bias, refine_feat.router.10.weight, refine_feat.router.10.bias, refine_feat.router.11.weight, refine_feat.router.11.bias, refine_feat.router.12.weight, refine_feat.router.12.bias, refine_feat.router.13.weight, refine_feat.router.13.bias, refine_feat.router.14.weight, refine_feat.router.14.bias, refine_feat.router.15.weight, refine_feat.router.15.bias, refine_feat.router.16.weight, refine_feat.router.16.bias, refine_feat.router.17.weight, refine_feat.router.17.bias, refine_feat.router.18.weight, refine_feat.router.18.bias, refine_feat.router.19.weight, refine_feat.router.19.bias, refine_feat.router.20.weight, refine_feat.router.20.bias, refine_feat.router.21.weight, refine_feat.router.21.bias, refine_feat.router.22.weight, refine_feat.router.22.bias, refine_feat.router.23.weight, refine_feat.router.23.bias

2025/03/28 09:48:55 - mmengine - INFO - load model from: checkpoints/dinov2_converted.pth
2025/03/28 09:48:55 - mmengine - INFO - Loads checkpoint by local backend from path: checkpoints/dinov2_converted.pth
Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.pos_embed - torch.Size([1, 1025, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.mask_token - torch.Size([1, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.patch_embed.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.norm.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.norm.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.refine_feat.scale - torch.Size([24]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.4.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.5.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.5.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.6.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.6.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.7.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.7.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.8.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.8.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.9.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.9.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.10.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.10.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.11.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.11.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.12.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.12.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.13.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.13.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.14.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.14.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.15.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.15.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.16.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.16.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.17.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.17.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.18.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.18.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.19.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.19.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.20.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.20.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.21.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.21.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.22.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.22.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.23.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.layer_norm.23.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.0.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.0.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.1.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.1.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.1.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.2.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.2.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.2.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.3.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.3.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.3.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.4.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.4.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.4.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.5.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.5.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.5.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.6.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.6.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.6.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.7.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.7.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.7.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.8.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.8.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.8.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.9.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.9.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.9.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.10.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.10.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.10.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.11.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.11.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.11.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.12.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.12.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.12.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.13.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.13.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.13.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.14.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.14.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.14.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.15.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.15.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.15.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.16.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.16.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.16.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.17.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.17.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.17.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.18.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.18.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.18.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.19.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.19.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.19.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.20.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.20.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.20.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.21.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.21.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.21.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.22.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.22.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.22.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.23.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.23.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.23.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list1.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.0.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.0.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.1.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.1.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.1.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.2.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.2.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.2.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.3.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.3.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.3.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.4.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.4.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.4.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.5.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.5.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.5.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.6.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.6.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.6.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.7.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.7.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.7.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.8.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.8.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.8.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.9.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.9.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.9.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.10.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.10.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.10.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.11.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.11.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.11.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.12.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.12.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.12.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.13.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.13.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.13.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.14.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.14.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.14.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.15.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.15.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.15.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.16.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.16.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.16.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.17.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.17.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.17.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.18.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.18.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.18.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.19.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.19.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.19.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.20.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.20.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.20.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.21.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.21.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.21.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.22.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.22.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.22.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.23.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.23.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.23.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list2.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.0.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.0.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.1.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.1.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.1.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.2.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.2.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.2.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.3.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.3.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.3.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.4.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.4.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.4.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.5.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.5.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.5.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.6.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.6.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.6.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.7.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.7.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.7.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.8.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.8.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.8.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.9.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.9.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.9.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.10.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.10.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.10.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.11.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.11.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.11.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.12.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.12.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.12.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.13.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.13.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.13.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.14.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.14.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.14.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.15.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.15.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.15.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.16.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.16.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.16.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.17.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.17.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.17.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.18.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.18.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.18.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.19.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.19.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.19.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.20.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.20.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.20.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.21.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.21.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.21.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.22.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.22.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.22.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.23.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.23.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.23.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.mlp_list3.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.0.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.1.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.2.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.2.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.3.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.3.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.4.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.4.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.5.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.5.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.6.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.6.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.7.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.7.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.8.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.8.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.9.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.9.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.10.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.10.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.11.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.11.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.12.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.12.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.13.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.13.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.14.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.14.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.15.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.15.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.16.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.16.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.17.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.17.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.18.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.18.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.19.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.19.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.20.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.20.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.21.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.21.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.22.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.22.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.23.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

backbone.refine_feat.router.23.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.cls_embed.weight - torch.Size([7, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.cls_embed.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.cls_token - torch.Size([1, 1, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.pos_embed - torch.Size([1, 1025, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.mask_token - torch.Size([1, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.patch_embed.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.0.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.1.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.2.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.3.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.4.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.5.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.6.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.7.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.8.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.9.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.10.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.11.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.12.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.13.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.14.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.15.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.16.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.17.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.18.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.19.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.20.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.21.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.22.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.blocks.23.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.norm.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.norm.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

ema_model.backbone.refine_feat.scale - torch.Size([24]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.4.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.5.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.5.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.6.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.6.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.7.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.7.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.8.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.8.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.9.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.9.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.10.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.10.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.11.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.11.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.12.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.12.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.13.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.13.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.14.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.14.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.15.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.15.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.16.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.16.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.17.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.17.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.18.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.18.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.19.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.19.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.20.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.20.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.21.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.21.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.22.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.22.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.23.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.layer_norm.23.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.0.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.0.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.1.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.1.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.1.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.2.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.2.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.2.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.3.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.3.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.3.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.4.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.4.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.4.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.5.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.5.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.5.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.6.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.6.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.6.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.7.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.7.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.7.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.8.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.8.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.8.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.9.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.9.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.9.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.10.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.10.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.10.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.11.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.11.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.11.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.12.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.12.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.12.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.13.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.13.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.13.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.14.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.14.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.14.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.15.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.15.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.15.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.16.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.16.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.16.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.17.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.17.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.17.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.18.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.18.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.18.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.19.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.19.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.19.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.20.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.20.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.20.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.21.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.21.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.21.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.22.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.22.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.22.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.23.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.23.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.23.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list1.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.0.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.0.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.1.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.1.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.1.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.2.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.2.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.2.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.3.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.3.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.3.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.4.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.4.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.4.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.5.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.5.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.5.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.6.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.6.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.6.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.7.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.7.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.7.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.8.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.8.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.8.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.9.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.9.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.9.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.10.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.10.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.10.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.11.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.11.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.11.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.12.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.12.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.12.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.13.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.13.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.13.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.14.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.14.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.14.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.15.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.15.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.15.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.16.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.16.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.16.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.17.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.17.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.17.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.18.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.18.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.18.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.19.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.19.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.19.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.20.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.20.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.20.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.21.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.21.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.21.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.22.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.22.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.22.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.23.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.23.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.23.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list2.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.0.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.0.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.1.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.1.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.1.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.2.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.2.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.2.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.3.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.3.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.3.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.4.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.4.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.4.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.5.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.5.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.5.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.6.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.6.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.6.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.7.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.7.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.7.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.8.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.8.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.8.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.9.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.9.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.9.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.10.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.10.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.10.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.11.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.11.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.11.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.12.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.12.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.12.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.13.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.13.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.13.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.14.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.14.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.14.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.15.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.15.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.15.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.16.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.16.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.16.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.17.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.17.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.17.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.18.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.18.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.18.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.19.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.19.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.19.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.20.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.20.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.20.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.21.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.21.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.21.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.22.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.22.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.22.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.23.0.weight - torch.Size([32, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.23.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.23.2.weight - torch.Size([1024, 32]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.mlp_list3.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.0.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.1.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.2.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.2.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.3.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.3.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.4.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.4.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.5.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.5.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.6.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.6.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.7.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.7.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.8.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.8.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.9.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.9.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.10.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.10.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.11.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.11.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.12.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.12.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.13.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.13.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.14.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.14.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.15.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.15.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.16.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.16.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.17.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.17.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.18.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.18.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.19.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.19.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.20.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.20.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.21.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.21.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.22.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.22.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.23.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.backbone.refine_feat.router.23.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

ema_model.decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.cls_embed.weight - torch.Size([7, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.cls_embed.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  

ema_model.decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DACS_encoder_decoder  
2025/03/28 09:48:56 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/03/28 09:48:56 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/03/28 09:48:56 - mmengine - INFO - Checkpoints will be saved to /data/xiaoxinghhh/code/my_mmcv/work_dirs/vi2pr/DA_spatial_32_fft_cut_off_0.2_suf3/6ff2f_seed0.
2025/03/28 09:49:23 - mmengine - INFO - Iter(train) [   50/20000]  base_lr: 9.9779e-05 lr: 9.9779e-05  eta: 2:57:52  time: 0.5055  data_time: 0.0205  memory: 7310  loss: 77.4769  decode.loss_cls: 2.2196  decode.loss_mask: 2.8584  decode.loss_dice: 3.8291  decode.d0.loss_cls: 3.6839  decode.d0.loss_mask: 2.4091  decode.d0.loss_dice: 2.9990  decode.d1.loss_cls: 1.2950  decode.d1.loss_mask: 2.5173  decode.d1.loss_dice: 2.8892  decode.d2.loss_cls: 1.1590  decode.d2.loss_mask: 2.5207  decode.d2.loss_dice: 2.9155  decode.d3.loss_cls: 1.2341  decode.d3.loss_mask: 2.5090  decode.d3.loss_dice: 2.9135  decode.d4.loss_cls: 1.4511  decode.d4.loss_mask: 2.5396  decode.d4.loss_dice: 2.9435  decode.d5.loss_cls: 1.6573  decode.d5.loss_mask: 2.5048  decode.d5.loss_dice: 3.1319  decode.d6.loss_cls: 1.9314  decode.d6.loss_mask: 2.7824  decode.d6.loss_dice: 3.2885  decode.d7.loss_cls: 2.0905  decode.d7.loss_mask: 2.8000  decode.d7.loss_dice: 3.5817  decode.d8.loss_cls: 2.1969  decode.d8.loss_mask: 2.8136  decode.d8.loss_dice: 3.8114
2025/03/28 09:49:48 - mmengine - INFO - Iter(train) [  100/20000]  base_lr: 9.9554e-05 lr: 9.9554e-05  eta: 2:53:24  time: 0.5010  data_time: 0.0211  memory: 6853  loss: 55.2494  decode.loss_cls: 0.7165  decode.loss_mask: 2.4134  decode.loss_dice: 2.5882  decode.d0.loss_cls: 3.3778  decode.d0.loss_mask: 2.1356  decode.d0.loss_dice: 2.4695  decode.d1.loss_cls: 0.6645  decode.d1.loss_mask: 2.1999  decode.d1.loss_dice: 2.2885  decode.d2.loss_cls: 0.4974  decode.d2.loss_mask: 2.2239  decode.d2.loss_dice: 2.3175  decode.d3.loss_cls: 0.4969  decode.d3.loss_mask: 2.2484  decode.d3.loss_dice: 2.3492  decode.d4.loss_cls: 0.5271  decode.d4.loss_mask: 2.2498  decode.d4.loss_dice: 2.3482  decode.d5.loss_cls: 0.4582  decode.d5.loss_mask: 2.3330  decode.d5.loss_dice: 2.3274  decode.d6.loss_cls: 0.5083  decode.d6.loss_mask: 2.2942  decode.d6.loss_dice: 2.4057  decode.d7.loss_cls: 0.5873  decode.d7.loss_mask: 2.3207  decode.d7.loss_dice: 2.4330  decode.d8.loss_cls: 0.6412  decode.d8.loss_mask: 2.3217  decode.d8.loss_dice: 2.5063
2025/03/28 09:50:14 - mmengine - INFO - Iter(train) [  150/20000]  base_lr: 9.9329e-05 lr: 9.9329e-05  eta: 2:51:12  time: 0.5141  data_time: 0.0223  memory: 6844  loss: 45.1395  decode.loss_cls: 0.3917  decode.loss_mask: 1.8993  decode.loss_dice: 2.1822  decode.d0.loss_cls: 3.0838  decode.d0.loss_mask: 1.6726  decode.d0.loss_dice: 2.1788  decode.d1.loss_cls: 0.3070  decode.d1.loss_mask: 1.7491  decode.d1.loss_dice: 2.0610  decode.d2.loss_cls: 0.2292  decode.d2.loss_mask: 1.7668  decode.d2.loss_dice: 2.1080  decode.d3.loss_cls: 0.2465  decode.d3.loss_mask: 1.7454  decode.d3.loss_dice: 2.0625  decode.d4.loss_cls: 0.2404  decode.d4.loss_mask: 1.7982  decode.d4.loss_dice: 2.1278  decode.d5.loss_cls: 0.2399  decode.d5.loss_mask: 1.8172  decode.d5.loss_dice: 2.1513  decode.d6.loss_cls: 0.2710  decode.d6.loss_mask: 1.8281  decode.d6.loss_dice: 2.1954  decode.d7.loss_cls: 0.3121  decode.d7.loss_mask: 1.8514  decode.d7.loss_dice: 2.1657  decode.d8.loss_cls: 0.3621  decode.d8.loss_mask: 1.8899  decode.d8.loss_dice: 2.2050
2025/03/28 09:50:39 - mmengine - INFO - Iter(train) [  200/20000]  base_lr: 9.9104e-05 lr: 9.9104e-05  eta: 2:50:19  time: 0.5029  data_time: 0.0209  memory: 6846  loss: 45.0480  decode.loss_cls: 0.2301  decode.loss_mask: 1.8593  decode.loss_dice: 2.2355  decode.d0.loss_cls: 2.8893  decode.d0.loss_mask: 1.7210  decode.d0.loss_dice: 2.1583  decode.d1.loss_cls: 0.2747  decode.d1.loss_mask: 1.8378  decode.d1.loss_dice: 2.1277  decode.d2.loss_cls: 0.2243  decode.d2.loss_mask: 1.8514  decode.d2.loss_dice: 2.1483  decode.d3.loss_cls: 0.1730  decode.d3.loss_mask: 1.8650  decode.d3.loss_dice: 2.1171  decode.d4.loss_cls: 0.1541  decode.d4.loss_mask: 1.8820  decode.d4.loss_dice: 2.1463  decode.d5.loss_cls: 0.1792  decode.d5.loss_mask: 1.8883  decode.d5.loss_dice: 2.2121  decode.d6.loss_cls: 0.1553  decode.d6.loss_mask: 1.9182  decode.d6.loss_dice: 2.1838  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.9105  decode.d7.loss_dice: 2.2122  decode.d8.loss_cls: 0.2170  decode.d8.loss_mask: 1.8820  decode.d8.loss_dice: 2.2186
2025/03/28 09:51:04 - mmengine - INFO - Iter(train) [  250/20000]  base_lr: 9.8879e-05 lr: 9.8879e-05  eta: 2:48:57  time: 0.5022  data_time: 0.0212  memory: 6852  loss: 39.9457  decode.loss_cls: 0.2853  decode.loss_mask: 1.5812  decode.loss_dice: 1.9528  decode.d0.loss_cls: 2.7171  decode.d0.loss_mask: 1.4621  decode.d0.loss_dice: 2.0041  decode.d1.loss_cls: 0.2154  decode.d1.loss_mask: 1.5280  decode.d1.loss_dice: 1.9145  decode.d2.loss_cls: 0.2204  decode.d2.loss_mask: 1.5369  decode.d2.loss_dice: 1.9398  decode.d3.loss_cls: 0.2180  decode.d3.loss_mask: 1.5251  decode.d3.loss_dice: 1.8999  decode.d4.loss_cls: 0.2677  decode.d4.loss_mask: 1.5447  decode.d4.loss_dice: 1.9203  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 1.5247  decode.d5.loss_dice: 1.9676  decode.d6.loss_cls: 0.2660  decode.d6.loss_mask: 1.5656  decode.d6.loss_dice: 2.0099  decode.d7.loss_cls: 0.2200  decode.d7.loss_mask: 1.5939  decode.d7.loss_dice: 1.9955  decode.d8.loss_cls: 0.2771  decode.d8.loss_mask: 1.5864  decode.d8.loss_dice: 1.9512
2025/03/28 09:51:29 - mmengine - INFO - Iter(train) [  300/20000]  base_lr: 9.8653e-05 lr: 9.8653e-05  eta: 2:47:57  time: 0.5033  data_time: 0.0203  memory: 6840  loss: 45.7396  decode.loss_cls: 0.2669  decode.loss_mask: 2.0809  decode.loss_dice: 2.0813  decode.d0.loss_cls: 2.7117  decode.d0.loss_mask: 1.9494  decode.d0.loss_dice: 2.0481  decode.d1.loss_cls: 0.2004  decode.d1.loss_mask: 1.9608  decode.d1.loss_dice: 2.0150  decode.d2.loss_cls: 0.2455  decode.d2.loss_mask: 2.0251  decode.d2.loss_dice: 2.0263  decode.d3.loss_cls: 0.2237  decode.d3.loss_mask: 2.0003  decode.d3.loss_dice: 2.0123  decode.d4.loss_cls: 0.2552  decode.d4.loss_mask: 2.0502  decode.d4.loss_dice: 2.0307  decode.d5.loss_cls: 0.2295  decode.d5.loss_mask: 2.0502  decode.d5.loss_dice: 2.0569  decode.d6.loss_cls: 0.2356  decode.d6.loss_mask: 2.0447  decode.d6.loss_dice: 2.1147  decode.d7.loss_cls: 0.2515  decode.d7.loss_mask: 2.0671  decode.d7.loss_dice: 2.1327  decode.d8.loss_cls: 0.2690  decode.d8.loss_mask: 2.0324  decode.d8.loss_dice: 2.0714
2025/03/28 09:51:55 - mmengine - INFO - Iter(train) [  350/20000]  base_lr: 9.8428e-05 lr: 9.8428e-05  eta: 2:47:10  time: 0.5042  data_time: 0.0204  memory: 6851  loss: 38.8811  decode.loss_cls: 0.1742  decode.loss_mask: 1.6173  decode.loss_dice: 1.8684  decode.d0.loss_cls: 2.4268  decode.d0.loss_mask: 1.5675  decode.d0.loss_dice: 1.8818  decode.d1.loss_cls: 0.1917  decode.d1.loss_mask: 1.6390  decode.d1.loss_dice: 1.8669  decode.d2.loss_cls: 0.1652  decode.d2.loss_mask: 1.6139  decode.d2.loss_dice: 1.8710  decode.d3.loss_cls: 0.1548  decode.d3.loss_mask: 1.6118  decode.d3.loss_dice: 1.8768  decode.d4.loss_cls: 0.1476  decode.d4.loss_mask: 1.6096  decode.d4.loss_dice: 1.9042  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 1.6124  decode.d5.loss_dice: 1.9018  decode.d6.loss_cls: 0.1484  decode.d6.loss_mask: 1.6036  decode.d6.loss_dice: 1.9179  decode.d7.loss_cls: 0.1506  decode.d7.loss_mask: 1.6295  decode.d7.loss_dice: 1.9044  decode.d8.loss_cls: 0.1694  decode.d8.loss_mask: 1.6229  decode.d8.loss_dice: 1.8840
2025/03/28 09:52:20 - mmengine - INFO - Iter(train) [  400/20000]  base_lr: 9.8203e-05 lr: 9.8203e-05  eta: 2:46:36  time: 0.5039  data_time: 0.0207  memory: 6855  loss: 36.7711  decode.loss_cls: 0.1313  decode.loss_mask: 1.5517  decode.loss_dice: 1.7841  decode.d0.loss_cls: 2.3630  decode.d0.loss_mask: 1.5149  decode.d0.loss_dice: 1.8023  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 1.5386  decode.d1.loss_dice: 1.7567  decode.d2.loss_cls: 0.1136  decode.d2.loss_mask: 1.5340  decode.d2.loss_dice: 1.7712  decode.d3.loss_cls: 0.1199  decode.d3.loss_mask: 1.5420  decode.d3.loss_dice: 1.7680  decode.d4.loss_cls: 0.1488  decode.d4.loss_mask: 1.5392  decode.d4.loss_dice: 1.7665  decode.d5.loss_cls: 0.1790  decode.d5.loss_mask: 1.5293  decode.d5.loss_dice: 1.7632  decode.d6.loss_cls: 0.1442  decode.d6.loss_mask: 1.5412  decode.d6.loss_dice: 1.7618  decode.d7.loss_cls: 0.1673  decode.d7.loss_mask: 1.5280  decode.d7.loss_dice: 1.7740  decode.d8.loss_cls: 0.1514  decode.d8.loss_mask: 1.5536  decode.d8.loss_dice: 1.7806
2025/03/28 09:52:45 - mmengine - INFO - Iter(train) [  450/20000]  base_lr: 9.7977e-05 lr: 9.7977e-05  eta: 2:45:58  time: 0.5029  data_time: 0.0205  memory: 6850  loss: 37.6041  decode.loss_cls: 0.1008  decode.loss_mask: 1.6634  decode.loss_dice: 1.8050  decode.d0.loss_cls: 2.2709  decode.d0.loss_mask: 1.5568  decode.d0.loss_dice: 1.8197  decode.d1.loss_cls: 0.1540  decode.d1.loss_mask: 1.6488  decode.d1.loss_dice: 1.7949  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 1.6536  decode.d2.loss_dice: 1.8140  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 1.6591  decode.d3.loss_dice: 1.7914  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 1.6511  decode.d4.loss_dice: 1.8026  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 1.6537  decode.d5.loss_dice: 1.8009  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 1.6461  decode.d6.loss_dice: 1.8021  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 1.6405  decode.d7.loss_dice: 1.8110  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 1.6607  decode.d8.loss_dice: 1.7867
2025/03/28 09:53:10 - mmengine - INFO - Iter(train) [  500/20000]  base_lr: 9.7752e-05 lr: 9.7752e-05  eta: 2:45:24  time: 0.5062  data_time: 0.0212  memory: 6842  loss: 34.5562  decode.loss_cls: 0.1130  decode.loss_mask: 1.4503  decode.loss_dice: 1.7011  decode.d0.loss_cls: 2.0449  decode.d0.loss_mask: 1.4104  decode.d0.loss_dice: 1.6534  decode.d1.loss_cls: 0.1362  decode.d1.loss_mask: 1.4517  decode.d1.loss_dice: 1.6506  decode.d2.loss_cls: 0.1617  decode.d2.loss_mask: 1.4450  decode.d2.loss_dice: 1.6726  decode.d3.loss_cls: 0.1707  decode.d3.loss_mask: 1.4507  decode.d3.loss_dice: 1.6468  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 1.4550  decode.d4.loss_dice: 1.6739  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 1.4578  decode.d5.loss_dice: 1.7170  decode.d6.loss_cls: 0.1139  decode.d6.loss_mask: 1.4483  decode.d6.loss_dice: 1.6984  decode.d7.loss_cls: 0.1642  decode.d7.loss_mask: 1.4322  decode.d7.loss_dice: 1.7047  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 1.4866  decode.d8.loss_dice: 1.7181
2025/03/28 09:53:36 - mmengine - INFO - Iter(train) [  550/20000]  base_lr: 9.7526e-05 lr: 9.7526e-05  eta: 2:44:56  time: 0.5056  data_time: 0.0212  memory: 6840  loss: 35.7719  decode.loss_cls: 0.1310  decode.loss_mask: 1.6628  decode.loss_dice: 1.5823  decode.d0.loss_cls: 1.9915  decode.d0.loss_mask: 1.5886  decode.d0.loss_dice: 1.6489  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 1.6350  decode.d1.loss_dice: 1.6298  decode.d2.loss_cls: 0.1177  decode.d2.loss_mask: 1.6465  decode.d2.loss_dice: 1.6445  decode.d3.loss_cls: 0.1179  decode.d3.loss_mask: 1.6516  decode.d3.loss_dice: 1.6307  decode.d4.loss_cls: 0.1306  decode.d4.loss_mask: 1.6839  decode.d4.loss_dice: 1.6176  decode.d5.loss_cls: 0.1154  decode.d5.loss_mask: 1.6816  decode.d5.loss_dice: 1.5898  decode.d6.loss_cls: 0.1149  decode.d6.loss_mask: 1.6675  decode.d6.loss_dice: 1.5967  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 1.7285  decode.d7.loss_dice: 1.5846  decode.d8.loss_cls: 0.1195  decode.d8.loss_mask: 1.6657  decode.d8.loss_dice: 1.6092
2025/03/28 09:54:02 - mmengine - INFO - Iter(train) [  600/20000]  base_lr: 9.7300e-05 lr: 9.7300e-05  eta: 2:44:42  time: 0.5328  data_time: 0.0241  memory: 6852  loss: 35.9635  decode.loss_cls: 0.2284  decode.loss_mask: 1.6377  decode.loss_dice: 1.6215  decode.d0.loss_cls: 1.8930  decode.d0.loss_mask: 1.6017  decode.d0.loss_dice: 1.6624  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 1.6125  decode.d1.loss_dice: 1.6045  decode.d2.loss_cls: 0.1718  decode.d2.loss_mask: 1.6262  decode.d2.loss_dice: 1.6205  decode.d3.loss_cls: 0.1633  decode.d3.loss_mask: 1.6175  decode.d3.loss_dice: 1.6238  decode.d4.loss_cls: 0.1723  decode.d4.loss_mask: 1.6281  decode.d4.loss_dice: 1.6162  decode.d5.loss_cls: 0.1604  decode.d5.loss_mask: 1.6282  decode.d5.loss_dice: 1.6185  decode.d6.loss_cls: 0.1540  decode.d6.loss_mask: 1.6249  decode.d6.loss_dice: 1.6274  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 1.6319  decode.d7.loss_dice: 1.6321  decode.d8.loss_cls: 0.1969  decode.d8.loss_mask: 1.6251  decode.d8.loss_dice: 1.6027
2025/03/28 09:54:28 - mmengine - INFO - Iter(train) [  650/20000]  base_lr: 9.7075e-05 lr: 9.7075e-05  eta: 2:44:55  time: 0.5304  data_time: 0.0246  memory: 6850  loss: 32.3240  decode.loss_cls: 0.1079  decode.loss_mask: 1.4220  decode.loss_dice: 1.5354  decode.d0.loss_cls: 1.7644  decode.d0.loss_mask: 1.3947  decode.d0.loss_dice: 1.5408  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 1.4291  decode.d1.loss_dice: 1.5101  decode.d2.loss_cls: 0.1013  decode.d2.loss_mask: 1.4141  decode.d2.loss_dice: 1.5524  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 1.4256  decode.d3.loss_dice: 1.5429  decode.d4.loss_cls: 0.0967  decode.d4.loss_mask: 1.4187  decode.d4.loss_dice: 1.5471  decode.d5.loss_cls: 0.0934  decode.d5.loss_mask: 1.4203  decode.d5.loss_dice: 1.5499  decode.d6.loss_cls: 0.0967  decode.d6.loss_mask: 1.4241  decode.d6.loss_dice: 1.5500  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 1.4245  decode.d7.loss_dice: 1.5375  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 1.4232  decode.d8.loss_dice: 1.5317
2025/03/28 09:54:55 - mmengine - INFO - Iter(train) [  700/20000]  base_lr: 9.6849e-05 lr: 9.6849e-05  eta: 2:44:53  time: 0.5206  data_time: 0.0238  memory: 6852  loss: 36.7957  decode.loss_cls: 0.0400  decode.loss_mask: 1.7149  decode.loss_dice: 1.7518  decode.d0.loss_cls: 1.6262  decode.d0.loss_mask: 1.6696  decode.d0.loss_dice: 1.7659  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 1.6936  decode.d1.loss_dice: 1.7249  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 1.6873  decode.d2.loss_dice: 1.7305  decode.d3.loss_cls: 0.1000  decode.d3.loss_mask: 1.6864  decode.d3.loss_dice: 1.7334  decode.d4.loss_cls: 0.1016  decode.d4.loss_mask: 1.6869  decode.d4.loss_dice: 1.7365  decode.d5.loss_cls: 0.0993  decode.d5.loss_mask: 1.6783  decode.d5.loss_dice: 1.7323  decode.d6.loss_cls: 0.1063  decode.d6.loss_mask: 1.6851  decode.d6.loss_dice: 1.7419  decode.d7.loss_cls: 0.1079  decode.d7.loss_mask: 1.6914  decode.d7.loss_dice: 1.7290  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 1.6958  decode.d8.loss_dice: 1.7441
2025/03/28 09:55:21 - mmengine - INFO - Iter(train) [  750/20000]  base_lr: 9.6623e-05 lr: 9.6623e-05  eta: 2:44:30  time: 0.5223  data_time: 0.0234  memory: 6852  loss: 32.6542  decode.loss_cls: 0.2186  decode.loss_mask: 1.4286  decode.loss_dice: 1.5314  decode.d0.loss_cls: 1.5688  decode.d0.loss_mask: 1.4240  decode.d0.loss_dice: 1.5898  decode.d1.loss_cls: 0.1221  decode.d1.loss_mask: 1.4312  decode.d1.loss_dice: 1.5430  decode.d2.loss_cls: 0.1275  decode.d2.loss_mask: 1.4320  decode.d2.loss_dice: 1.5296  decode.d3.loss_cls: 0.1426  decode.d3.loss_mask: 1.4511  decode.d3.loss_dice: 1.5330  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 1.4242  decode.d4.loss_dice: 1.5410  decode.d5.loss_cls: 0.1423  decode.d5.loss_mask: 1.4257  decode.d5.loss_dice: 1.5284  decode.d6.loss_cls: 0.1360  decode.d6.loss_mask: 1.4418  decode.d6.loss_dice: 1.5391  decode.d7.loss_cls: 0.1509  decode.d7.loss_mask: 1.4424  decode.d7.loss_dice: 1.5486  decode.d8.loss_cls: 0.1584  decode.d8.loss_mask: 1.4310  decode.d8.loss_dice: 1.5360
2025/03/28 09:55:46 - mmengine - INFO - Iter(train) [  800/20000]  base_lr: 9.6397e-05 lr: 9.6397e-05  eta: 2:44:02  time: 0.5104  data_time: 0.0229  memory: 6849  loss: 33.7085  decode.loss_cls: 0.0715  decode.loss_mask: 1.6165  decode.loss_dice: 1.5460  decode.d0.loss_cls: 1.4668  decode.d0.loss_mask: 1.5986  decode.d0.loss_dice: 1.5095  decode.d1.loss_cls: 0.1290  decode.d1.loss_mask: 1.6050  decode.d1.loss_dice: 1.4825  decode.d2.loss_cls: 0.1410  decode.d2.loss_mask: 1.5914  decode.d2.loss_dice: 1.4866  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 1.5942  decode.d3.loss_dice: 1.4907  decode.d4.loss_cls: 0.1358  decode.d4.loss_mask: 1.5949  decode.d4.loss_dice: 1.5138  decode.d5.loss_cls: 0.1402  decode.d5.loss_mask: 1.5842  decode.d5.loss_dice: 1.5096  decode.d6.loss_cls: 0.1327  decode.d6.loss_mask: 1.6083  decode.d6.loss_dice: 1.5172  decode.d7.loss_cls: 0.1483  decode.d7.loss_mask: 1.5859  decode.d7.loss_dice: 1.5112  decode.d8.loss_cls: 0.1456  decode.d8.loss_mask: 1.5987  decode.d8.loss_dice: 1.5130
2025/03/28 09:56:11 - mmengine - INFO - Iter(train) [  850/20000]  base_lr: 9.6171e-05 lr: 9.6171e-05  eta: 2:43:31  time: 0.5175  data_time: 0.0224  memory: 6850  loss: 32.0147  decode.loss_cls: 0.0512  decode.loss_mask: 1.5127  decode.loss_dice: 1.5298  decode.d0.loss_cls: 1.2937  decode.d0.loss_mask: 1.5041  decode.d0.loss_dice: 1.5080  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 1.5239  decode.d1.loss_dice: 1.4985  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 1.5266  decode.d2.loss_dice: 1.4913  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 1.5193  decode.d3.loss_dice: 1.4938  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 1.4946  decode.d4.loss_dice: 1.5110  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 1.5049  decode.d5.loss_dice: 1.5248  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 1.5054  decode.d6.loss_dice: 1.5120  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 1.5053  decode.d7.loss_dice: 1.5178  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 1.4960  decode.d8.loss_dice: 1.5158
2025/03/28 09:56:37 - mmengine - INFO - Iter(train) [  900/20000]  base_lr: 9.5945e-05 lr: 9.5945e-05  eta: 2:43:05  time: 0.4998  data_time: 0.0203  memory: 6835  loss: 30.5187  decode.loss_cls: 0.0805  decode.loss_mask: 1.4468  decode.loss_dice: 1.4127  decode.d0.loss_cls: 1.2546  decode.d0.loss_mask: 1.4194  decode.d0.loss_dice: 1.4264  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 1.4389  decode.d1.loss_dice: 1.3962  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 1.4543  decode.d2.loss_dice: 1.4146  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 1.4444  decode.d3.loss_dice: 1.4062  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 1.4538  decode.d4.loss_dice: 1.4037  decode.d5.loss_cls: 0.0848  decode.d5.loss_mask: 1.4401  decode.d5.loss_dice: 1.4179  decode.d6.loss_cls: 0.0831  decode.d6.loss_mask: 1.4401  decode.d6.loss_dice: 1.4193  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 1.4428  decode.d7.loss_dice: 1.4291  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 1.4487  decode.d8.loss_dice: 1.4101
2025/03/28 09:57:02 - mmengine - INFO - Iter(train) [  950/20000]  base_lr: 9.5719e-05 lr: 9.5719e-05  eta: 2:42:30  time: 0.5106  data_time: 0.0218  memory: 6856  loss: 32.3330  decode.loss_cls: 0.1451  decode.loss_mask: 1.4074  decode.loss_dice: 1.5719  decode.d0.loss_cls: 1.1725  decode.d0.loss_mask: 1.3854  decode.d0.loss_dice: 1.5915  decode.d1.loss_cls: 0.1225  decode.d1.loss_mask: 1.4142  decode.d1.loss_dice: 1.5716  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 1.4134  decode.d2.loss_dice: 1.5910  decode.d3.loss_cls: 0.1293  decode.d3.loss_mask: 1.4256  decode.d3.loss_dice: 1.5976  decode.d4.loss_cls: 0.1439  decode.d4.loss_mask: 1.4125  decode.d4.loss_dice: 1.5969  decode.d5.loss_cls: 0.1420  decode.d5.loss_mask: 1.4126  decode.d5.loss_dice: 1.5851  decode.d6.loss_cls: 0.1372  decode.d6.loss_mask: 1.4105  decode.d6.loss_dice: 1.5672  decode.d7.loss_cls: 0.1394  decode.d7.loss_mask: 1.4146  decode.d7.loss_dice: 1.5714  decode.d8.loss_cls: 0.1393  decode.d8.loss_mask: 1.4197  decode.d8.loss_dice: 1.5725
2025/03/28 09:57:28 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 09:57:28 - mmengine - INFO - Iter(train) [ 1000/20000]  base_lr: 9.5493e-05 lr: 9.5493e-05  eta: 2:42:09  time: 0.4981  data_time: 0.0206  memory: 6850  loss: 31.3339  decode.loss_cls: 0.0574  decode.loss_mask: 1.3595  decode.loss_dice: 1.6141  decode.d0.loss_cls: 1.0395  decode.d0.loss_mask: 1.3782  decode.d0.loss_dice: 1.6249  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 1.3689  decode.d1.loss_dice: 1.6100  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 1.3592  decode.d2.loss_dice: 1.6258  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 1.3533  decode.d3.loss_dice: 1.6077  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 1.3595  decode.d4.loss_dice: 1.6089  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 1.3632  decode.d5.loss_dice: 1.6180  decode.d6.loss_cls: 0.0598  decode.d6.loss_mask: 1.3702  decode.d6.loss_dice: 1.6225  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 1.3619  decode.d7.loss_dice: 1.6066  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 1.3596  decode.d8.loss_dice: 1.6099
2025/03/28 09:57:53 - mmengine - INFO - Iter(train) [ 1050/20000]  base_lr: 9.5267e-05 lr: 9.5267e-05  eta: 2:41:35  time: 0.4977  data_time: 0.0207  memory: 6849  loss: 31.1098  decode.loss_cls: 0.1037  decode.loss_mask: 1.3637  decode.loss_dice: 1.5732  decode.d0.loss_cls: 1.0148  decode.d0.loss_mask: 1.3261  decode.d0.loss_dice: 1.6269  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 1.3452  decode.d1.loss_dice: 1.5482  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 1.3464  decode.d2.loss_dice: 1.5613  decode.d3.loss_cls: 0.1121  decode.d3.loss_mask: 1.3431  decode.d3.loss_dice: 1.5618  decode.d4.loss_cls: 0.1171  decode.d4.loss_mask: 1.3386  decode.d4.loss_dice: 1.5682  decode.d5.loss_cls: 0.1151  decode.d5.loss_mask: 1.3473  decode.d5.loss_dice: 1.5804  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 1.3342  decode.d6.loss_dice: 1.5500  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 1.3515  decode.d7.loss_dice: 1.5637  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 1.3664  decode.d8.loss_dice: 1.5780
2025/03/28 09:58:19 - mmengine - INFO - Iter(train) [ 1100/20000]  base_lr: 9.5040e-05 lr: 9.5040e-05  eta: 2:41:06  time: 0.4999  data_time: 0.0208  memory: 6835  loss: 34.1645  decode.loss_cls: 0.0285  decode.loss_mask: 1.6421  decode.loss_dice: 1.6568  decode.d0.loss_cls: 0.8974  decode.d0.loss_mask: 1.6308  decode.d0.loss_dice: 1.6437  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 1.6347  decode.d1.loss_dice: 1.6561  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 1.6381  decode.d2.loss_dice: 1.6641  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 1.6383  decode.d3.loss_dice: 1.6558  decode.d4.loss_cls: 0.0271  decode.d4.loss_mask: 1.6536  decode.d4.loss_dice: 1.6474  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 1.6565  decode.d5.loss_dice: 1.6329  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 1.6499  decode.d6.loss_dice: 1.6618  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 1.6549  decode.d7.loss_dice: 1.6570  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 1.6510  decode.d8.loss_dice: 1.6459
2025/03/28 09:58:44 - mmengine - INFO - Iter(train) [ 1150/20000]  base_lr: 9.4814e-05 lr: 9.4814e-05  eta: 2:40:44  time: 0.5247  data_time: 0.0208  memory: 6836  loss: 33.4174  decode.loss_cls: 0.1614  decode.loss_mask: 1.5852  decode.loss_dice: 1.5644  decode.d0.loss_cls: 0.8459  decode.d0.loss_mask: 1.5782  decode.d0.loss_dice: 1.5807  decode.d1.loss_cls: 0.1223  decode.d1.loss_mask: 1.5877  decode.d1.loss_dice: 1.5593  decode.d2.loss_cls: 0.1187  decode.d2.loss_mask: 1.5770  decode.d2.loss_dice: 1.5636  decode.d3.loss_cls: 0.1338  decode.d3.loss_mask: 1.5695  decode.d3.loss_dice: 1.5543  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 1.5906  decode.d4.loss_dice: 1.5819  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 1.5777  decode.d5.loss_dice: 1.5606  decode.d6.loss_cls: 0.1727  decode.d6.loss_mask: 1.5818  decode.d6.loss_dice: 1.5529  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 1.5895  decode.d7.loss_dice: 1.5732  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 1.5678  decode.d8.loss_dice: 1.5382
2025/03/28 09:59:10 - mmengine - INFO - Iter(train) [ 1200/20000]  base_lr: 9.4588e-05 lr: 9.4588e-05  eta: 2:40:25  time: 0.5042  data_time: 0.0216  memory: 6848  loss: 31.6223  decode.loss_cls: 0.0853  decode.loss_mask: 1.4919  decode.loss_dice: 1.5489  decode.d0.loss_cls: 0.7642  decode.d0.loss_mask: 1.4910  decode.d0.loss_dice: 1.5556  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 1.4899  decode.d1.loss_dice: 1.5395  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 1.4925  decode.d2.loss_dice: 1.5278  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 1.4945  decode.d3.loss_dice: 1.5222  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 1.4946  decode.d4.loss_dice: 1.5425  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 1.4884  decode.d5.loss_dice: 1.5355  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 1.4951  decode.d6.loss_dice: 1.5256  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 1.4907  decode.d7.loss_dice: 1.5230  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 1.4880  decode.d8.loss_dice: 1.5397
2025/03/28 09:59:36 - mmengine - INFO - Iter(train) [ 1250/20000]  base_lr: 9.4361e-05 lr: 9.4361e-05  eta: 2:39:55  time: 0.5296  data_time: 0.0239  memory: 6839  loss: 29.3874  decode.loss_cls: 0.0218  decode.loss_mask: 1.3925  decode.loss_dice: 1.4715  decode.d0.loss_cls: 0.6891  decode.d0.loss_mask: 1.3884  decode.d0.loss_dice: 1.4693  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 1.3911  decode.d1.loss_dice: 1.4486  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 1.3957  decode.d2.loss_dice: 1.4518  decode.d3.loss_cls: 0.0210  decode.d3.loss_mask: 1.3936  decode.d3.loss_dice: 1.4477  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 1.3895  decode.d4.loss_dice: 1.4458  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 1.3899  decode.d5.loss_dice: 1.4567  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 1.3923  decode.d6.loss_dice: 1.4515  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 1.4035  decode.d7.loss_dice: 1.4671  decode.d8.loss_cls: 0.0205  decode.d8.loss_mask: 1.3984  decode.d8.loss_dice: 1.4617
2025/03/28 10:00:02 - mmengine - INFO - Iter(train) [ 1300/20000]  base_lr: 9.4135e-05 lr: 9.4135e-05  eta: 2:39:40  time: 0.5092  data_time: 0.0217  memory: 6845  loss: 29.2506  decode.loss_cls: 0.1840  decode.loss_mask: 1.3355  decode.loss_dice: 1.3922  decode.d0.loss_cls: 0.7085  decode.d0.loss_mask: 1.3079  decode.d0.loss_dice: 1.4157  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 1.3309  decode.d1.loss_dice: 1.3969  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 1.3423  decode.d2.loss_dice: 1.3821  decode.d3.loss_cls: 0.1570  decode.d3.loss_mask: 1.3342  decode.d3.loss_dice: 1.3688  decode.d4.loss_cls: 0.2036  decode.d4.loss_mask: 1.3255  decode.d4.loss_dice: 1.3786  decode.d5.loss_cls: 0.1807  decode.d5.loss_mask: 1.3315  decode.d5.loss_dice: 1.3741  decode.d6.loss_cls: 0.1768  decode.d6.loss_mask: 1.3372  decode.d6.loss_dice: 1.3800  decode.d7.loss_cls: 0.1782  decode.d7.loss_mask: 1.3279  decode.d7.loss_dice: 1.3615  decode.d8.loss_cls: 0.1349  decode.d8.loss_mask: 1.3337  decode.d8.loss_dice: 1.3841
2025/03/28 10:00:27 - mmengine - INFO - Iter(train) [ 1350/20000]  base_lr: 9.3908e-05 lr: 9.3908e-05  eta: 2:39:08  time: 0.5017  data_time: 0.0213  memory: 6852  loss: 32.0140  decode.loss_cls: 0.0899  decode.loss_mask: 1.4803  decode.loss_dice: 1.5852  decode.d0.loss_cls: 0.6046  decode.d0.loss_mask: 1.4725  decode.d0.loss_dice: 1.5755  decode.d1.loss_cls: 0.0675  decode.d1.loss_mask: 1.4772  decode.d1.loss_dice: 1.5743  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 1.4826  decode.d2.loss_dice: 1.5798  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 1.4818  decode.d3.loss_dice: 1.5850  decode.d4.loss_cls: 0.0966  decode.d4.loss_mask: 1.4839  decode.d4.loss_dice: 1.5718  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 1.4881  decode.d5.loss_dice: 1.5725  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 1.4896  decode.d6.loss_dice: 1.5806  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 1.4948  decode.d7.loss_dice: 1.5919  decode.d8.loss_cls: 0.0814  decode.d8.loss_mask: 1.4894  decode.d8.loss_dice: 1.5949
2025/03/28 10:00:52 - mmengine - INFO - Iter(train) [ 1400/20000]  base_lr: 9.3682e-05 lr: 9.3682e-05  eta: 2:38:37  time: 0.5019  data_time: 0.0208  memory: 6849  loss: 29.2096  decode.loss_cls: 0.0923  decode.loss_mask: 1.2997  decode.loss_dice: 1.4506  decode.d0.loss_cls: 0.5617  decode.d0.loss_mask: 1.2808  decode.d0.loss_dice: 1.5112  decode.d1.loss_cls: 0.0948  decode.d1.loss_mask: 1.3044  decode.d1.loss_dice: 1.4710  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 1.3325  decode.d2.loss_dice: 1.4697  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 1.3288  decode.d3.loss_dice: 1.4600  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 1.3322  decode.d4.loss_dice: 1.4623  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 1.3256  decode.d5.loss_dice: 1.4685  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 1.3083  decode.d6.loss_dice: 1.4553  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 1.3205  decode.d7.loss_dice: 1.4623  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 1.3199  decode.d8.loss_dice: 1.4683
2025/03/28 10:01:18 - mmengine - INFO - Iter(train) [ 1450/20000]  base_lr: 9.3455e-05 lr: 9.3455e-05  eta: 2:38:16  time: 0.5249  data_time: 0.0243  memory: 6837  loss: 29.2618  decode.loss_cls: 0.0210  decode.loss_mask: 1.4005  decode.loss_dice: 1.4534  decode.d0.loss_cls: 0.5100  decode.d0.loss_mask: 1.3824  decode.d0.loss_dice: 1.4497  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 1.3811  decode.d1.loss_dice: 1.4502  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 1.3981  decode.d2.loss_dice: 1.4720  decode.d3.loss_cls: 0.0207  decode.d3.loss_mask: 1.3953  decode.d3.loss_dice: 1.4609  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 1.4007  decode.d4.loss_dice: 1.4747  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 1.3946  decode.d5.loss_dice: 1.4708  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 1.4051  decode.d6.loss_dice: 1.4733  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 1.3867  decode.d7.loss_dice: 1.4590  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 1.3950  decode.d8.loss_dice: 1.4466
2025/03/28 10:01:43 - mmengine - INFO - Iter(train) [ 1500/20000]  base_lr: 9.3228e-05 lr: 9.3228e-05  eta: 2:37:44  time: 0.4999  data_time: 0.0207  memory: 6845  loss: 28.3609  decode.loss_cls: 0.1204  decode.loss_mask: 1.1976  decode.loss_dice: 1.4875  decode.d0.loss_cls: 0.5380  decode.d0.loss_mask: 1.2031  decode.d0.loss_dice: 1.5082  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 1.1972  decode.d1.loss_dice: 1.4954  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 1.1968  decode.d2.loss_dice: 1.4841  decode.d3.loss_cls: 0.0986  decode.d3.loss_mask: 1.2016  decode.d3.loss_dice: 1.5038  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 1.2003  decode.d4.loss_dice: 1.5083  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 1.2016  decode.d5.loss_dice: 1.4799  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 1.2080  decode.d6.loss_dice: 1.4933  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 1.2011  decode.d7.loss_dice: 1.4850  decode.d8.loss_cls: 0.0983  decode.d8.loss_mask: 1.2095  decode.d8.loss_dice: 1.4948
2025/03/28 10:02:09 - mmengine - INFO - Iter(train) [ 1550/20000]  base_lr: 9.3001e-05 lr: 9.3001e-05  eta: 2:37:13  time: 0.5006  data_time: 0.0208  memory: 6850  loss: 26.9281  decode.loss_cls: 0.1010  decode.loss_mask: 1.2106  decode.loss_dice: 1.3522  decode.d0.loss_cls: 0.4995  decode.d0.loss_mask: 1.2033  decode.d0.loss_dice: 1.3961  decode.d1.loss_cls: 0.1114  decode.d1.loss_mask: 1.1942  decode.d1.loss_dice: 1.3606  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 1.1942  decode.d2.loss_dice: 1.3413  decode.d3.loss_cls: 0.1553  decode.d3.loss_mask: 1.1877  decode.d3.loss_dice: 1.3280  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 1.2029  decode.d4.loss_dice: 1.3291  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 1.2013  decode.d5.loss_dice: 1.3473  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 1.1953  decode.d6.loss_dice: 1.3594  decode.d7.loss_cls: 0.0971  decode.d7.loss_mask: 1.1992  decode.d7.loss_dice: 1.3454  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 1.2055  decode.d8.loss_dice: 1.3533
2025/03/28 10:02:34 - mmengine - INFO - Iter(train) [ 1600/20000]  base_lr: 9.2774e-05 lr: 9.2774e-05  eta: 2:36:42  time: 0.5017  data_time: 0.0209  memory: 6834  loss: 28.0818  decode.loss_cls: 0.0436  decode.loss_mask: 1.3169  decode.loss_dice: 1.4324  decode.d0.loss_cls: 0.4083  decode.d0.loss_mask: 1.3245  decode.d0.loss_dice: 1.4165  decode.d1.loss_cls: 0.0336  decode.d1.loss_mask: 1.3087  decode.d1.loss_dice: 1.4078  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 1.3149  decode.d2.loss_dice: 1.4152  decode.d3.loss_cls: 0.0318  decode.d3.loss_mask: 1.3136  decode.d3.loss_dice: 1.4262  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 1.3153  decode.d4.loss_dice: 1.4363  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 1.3137  decode.d5.loss_dice: 1.4288  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 1.3022  decode.d6.loss_dice: 1.4093  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 1.3204  decode.d7.loss_dice: 1.4342  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 1.3066  decode.d8.loss_dice: 1.4151
2025/03/28 10:02:59 - mmengine - INFO - Iter(train) [ 1650/20000]  base_lr: 9.2548e-05 lr: 9.2548e-05  eta: 2:36:14  time: 0.5072  data_time: 0.0213  memory: 6848  loss: 29.0484  decode.loss_cls: 0.1124  decode.loss_mask: 1.3390  decode.loss_dice: 1.4168  decode.d0.loss_cls: 0.4344  decode.d0.loss_mask: 1.2849  decode.d0.loss_dice: 1.4028  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 1.3393  decode.d1.loss_dice: 1.4202  decode.d2.loss_cls: 0.0556  decode.d2.loss_mask: 1.3460  decode.d2.loss_dice: 1.4336  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 1.3555  decode.d3.loss_dice: 1.4317  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 1.3497  decode.d4.loss_dice: 1.4541  decode.d5.loss_cls: 0.0940  decode.d5.loss_mask: 1.3639  decode.d5.loss_dice: 1.4408  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 1.3523  decode.d6.loss_dice: 1.4476  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 1.3533  decode.d7.loss_dice: 1.4636  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 1.3643  decode.d8.loss_dice: 1.4553
2025/03/28 10:03:25 - mmengine - INFO - Iter(train) [ 1700/20000]  base_lr: 9.2321e-05 lr: 9.2321e-05  eta: 2:35:49  time: 0.5133  data_time: 0.0224  memory: 6840  loss: 29.1944  decode.loss_cls: 0.0118  decode.loss_mask: 1.4645  decode.loss_dice: 1.3990  decode.d0.loss_cls: 0.3388  decode.d0.loss_mask: 1.4699  decode.d0.loss_dice: 1.4116  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 1.4685  decode.d1.loss_dice: 1.3821  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 1.4720  decode.d2.loss_dice: 1.3682  decode.d3.loss_cls: 0.0224  decode.d3.loss_mask: 1.4767  decode.d3.loss_dice: 1.3952  decode.d4.loss_cls: 0.0627  decode.d4.loss_mask: 1.4740  decode.d4.loss_dice: 1.3844  decode.d5.loss_cls: 0.0259  decode.d5.loss_mask: 1.4712  decode.d5.loss_dice: 1.3964  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 1.4680  decode.d6.loss_dice: 1.4019  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 1.4779  decode.d7.loss_dice: 1.3912  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 1.4683  decode.d8.loss_dice: 1.3901
2025/03/28 10:03:39 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 10:03:50 - mmengine - INFO - Iter(train) [ 1750/20000]  base_lr: 9.2094e-05 lr: 9.2094e-05  eta: 2:35:26  time: 0.5330  data_time: 0.0242  memory: 6847  loss: 31.2045  decode.loss_cls: 0.1007  decode.loss_mask: 1.4949  decode.loss_dice: 1.5520  decode.d0.loss_cls: 0.3773  decode.d0.loss_mask: 1.5009  decode.d0.loss_dice: 1.5230  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 1.4669  decode.d1.loss_dice: 1.5157  decode.d2.loss_cls: 0.0450  decode.d2.loss_mask: 1.4820  decode.d2.loss_dice: 1.5235  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 1.4782  decode.d3.loss_dice: 1.5281  decode.d4.loss_cls: 0.0755  decode.d4.loss_mask: 1.4872  decode.d4.loss_dice: 1.5267  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 1.4796  decode.d5.loss_dice: 1.5269  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 1.4931  decode.d6.loss_dice: 1.5171  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 1.4975  decode.d7.loss_dice: 1.5298  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 1.4943  decode.d8.loss_dice: 1.5515
2025/03/28 10:04:16 - mmengine - INFO - Iter(train) [ 1800/20000]  base_lr: 9.1866e-05 lr: 9.1866e-05  eta: 2:34:58  time: 0.5007  data_time: 0.0209  memory: 6836  loss: 29.5940  decode.loss_cls: 0.0242  decode.loss_mask: 1.5163  decode.loss_dice: 1.3978  decode.d0.loss_cls: 0.3234  decode.d0.loss_mask: 1.5165  decode.d0.loss_dice: 1.3937  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 1.5123  decode.d1.loss_dice: 1.3777  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 1.5074  decode.d2.loss_dice: 1.3659  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 1.5018  decode.d3.loss_dice: 1.3789  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 1.5124  decode.d4.loss_dice: 1.3898  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 1.5118  decode.d5.loss_dice: 1.4056  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 1.5212  decode.d6.loss_dice: 1.3919  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 1.5204  decode.d7.loss_dice: 1.4047  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 1.5164  decode.d8.loss_dice: 1.3889
2025/03/28 10:04:41 - mmengine - INFO - Iter(train) [ 1850/20000]  base_lr: 9.1639e-05 lr: 9.1639e-05  eta: 2:34:29  time: 0.5044  data_time: 0.0203  memory: 6852  loss: 28.8920  decode.loss_cls: 0.0388  decode.loss_mask: 1.5169  decode.loss_dice: 1.3130  decode.d0.loss_cls: 0.2919  decode.d0.loss_mask: 1.5047  decode.d0.loss_dice: 1.3047  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 1.5042  decode.d1.loss_dice: 1.3100  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 1.5049  decode.d2.loss_dice: 1.3047  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 1.5077  decode.d3.loss_dice: 1.3237  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 1.5047  decode.d4.loss_dice: 1.3126  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 1.5138  decode.d5.loss_dice: 1.3186  decode.d6.loss_cls: 0.0377  decode.d6.loss_mask: 1.5136  decode.d6.loss_dice: 1.3276  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 1.5204  decode.d7.loss_dice: 1.3346  decode.d8.loss_cls: 0.0374  decode.d8.loss_mask: 1.5167  decode.d8.loss_dice: 1.3250
2025/03/28 10:05:06 - mmengine - INFO - Iter(train) [ 1900/20000]  base_lr: 9.1412e-05 lr: 9.1412e-05  eta: 2:34:03  time: 0.5121  data_time: 0.0227  memory: 6836  loss: 25.5771  decode.loss_cls: 0.0233  decode.loss_mask: 1.2825  decode.loss_dice: 1.1854  decode.d0.loss_cls: 0.2902  decode.d0.loss_mask: 1.2908  decode.d0.loss_dice: 1.2159  decode.d1.loss_cls: 0.0786  decode.d1.loss_mask: 1.2947  decode.d1.loss_dice: 1.1907  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 1.2970  decode.d2.loss_dice: 1.1924  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 1.2949  decode.d3.loss_dice: 1.2173  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 1.2853  decode.d4.loss_dice: 1.2202  decode.d5.loss_cls: 0.0273  decode.d5.loss_mask: 1.2979  decode.d5.loss_dice: 1.2252  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 1.2946  decode.d6.loss_dice: 1.2258  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 1.2859  decode.d7.loss_dice: 1.2245  decode.d8.loss_cls: 0.0255  decode.d8.loss_mask: 1.2892  decode.d8.loss_dice: 1.1978
2025/03/28 10:05:31 - mmengine - INFO - Iter(train) [ 1950/20000]  base_lr: 9.1185e-05 lr: 9.1185e-05  eta: 2:33:33  time: 0.5017  data_time: 0.0204  memory: 6853  loss: 29.6123  decode.loss_cls: 0.1844  decode.loss_mask: 1.2359  decode.loss_dice: 1.5269  decode.d0.loss_cls: 0.3036  decode.d0.loss_mask: 1.2497  decode.d0.loss_dice: 1.5999  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 1.2367  decode.d1.loss_dice: 1.5364  decode.d2.loss_cls: 0.1701  decode.d2.loss_mask: 1.2381  decode.d2.loss_dice: 1.5308  decode.d3.loss_cls: 0.1810  decode.d3.loss_mask: 1.2328  decode.d3.loss_dice: 1.5066  decode.d4.loss_cls: 0.1805  decode.d4.loss_mask: 1.2324  decode.d4.loss_dice: 1.5273  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 1.2280  decode.d5.loss_dice: 1.5307  decode.d6.loss_cls: 0.1796  decode.d6.loss_mask: 1.2274  decode.d6.loss_dice: 1.5193  decode.d7.loss_cls: 0.1694  decode.d7.loss_mask: 1.2366  decode.d7.loss_dice: 1.5297  decode.d8.loss_cls: 0.1732  decode.d8.loss_mask: 1.2470  decode.d8.loss_dice: 1.5172
2025/03/28 10:05:58 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 10:05:58 - mmengine - INFO - Iter(train) [ 2000/20000]  base_lr: 9.0957e-05 lr: 9.0957e-05  eta: 2:33:14  time: 0.5065  data_time: 0.0213  memory: 6844  loss: 26.1059  decode.loss_cls: 0.0367  decode.loss_mask: 1.2291  decode.loss_dice: 1.3081  decode.d0.loss_cls: 0.2362  decode.d0.loss_mask: 1.2601  decode.d0.loss_dice: 1.3139  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 1.2579  decode.d1.loss_dice: 1.3159  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 1.2502  decode.d2.loss_dice: 1.3083  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 1.2356  decode.d3.loss_dice: 1.3189  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 1.2400  decode.d4.loss_dice: 1.3154  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 1.2381  decode.d5.loss_dice: 1.3236  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 1.2367  decode.d6.loss_dice: 1.3224  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 1.2438  decode.d7.loss_dice: 1.3188  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 1.2465  decode.d8.loss_dice: 1.3204
2025/03/28 10:05:58 - mmengine - INFO - Saving checkpoint at 2000 iterations
2025/03/28 10:06:03 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:05  time: 0.0850  data_time: 0.0019  memory: 3068  
2025/03/28 10:06:07 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:51  time: 0.0846  data_time: 0.0018  memory: 3068  
2025/03/28 10:06:12 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:44  time: 0.0847  data_time: 0.0018  memory: 3068  
2025/03/28 10:06:16 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:38  time: 0.0848  data_time: 0.0018  memory: 3068  
2025/03/28 10:06:20 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:33  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 10:06:25 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:29  time: 0.0879  data_time: 0.0020  memory: 3068  
2025/03/28 10:06:29 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:24  time: 0.0850  data_time: 0.0019  memory: 3068  
2025/03/28 10:06:33 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:19  time: 0.0850  data_time: 0.0018  memory: 3068  
2025/03/28 10:06:37 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:15  time: 0.0855  data_time: 0.0020  memory: 3068  
2025/03/28 10:06:42 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:10  time: 0.0849  data_time: 0.0017  memory: 3068  
2025/03/28 10:06:46 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:06  time: 0.0848  data_time: 0.0018  memory: 3068  
2025/03/28 10:06:50 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:01  time: 0.0870  data_time: 0.0019  memory: 3068  
2025/03/28 10:06:54 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:57  time: 0.0849  data_time: 0.0019  memory: 3068  
2025/03/28 10:06:59 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:53  time: 0.0850  data_time: 0.0019  memory: 3068  
2025/03/28 10:07:03 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:49  time: 0.1080  data_time: 0.0019  memory: 3068  
2025/03/28 10:07:08 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:44  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 10:07:12 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:40  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 10:07:16 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:36  time: 0.0862  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:20 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:31  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:25 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:27  time: 0.0856  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:29 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:23  time: 0.0855  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:33 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0857  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:38 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:14  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:42 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:10  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:46 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 10:07:50 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0851  data_time: 0.0018  memory: 3068  
2025/03/28 10:07:55 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:57  time: 0.0877  data_time: 0.0020  memory: 3068  
2025/03/28 10:07:59 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 10:08:03 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0856  data_time: 0.0019  memory: 3068  
2025/03/28 10:08:08 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0861  data_time: 0.0020  memory: 3068  
2025/03/28 10:08:12 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:40  time: 0.0883  data_time: 0.0020  memory: 3068  
2025/03/28 10:08:16 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0874  data_time: 0.0019  memory: 3068  
2025/03/28 10:08:21 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 10:08:25 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:27  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 10:08:29 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 10:08:34 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0874  data_time: 0.0021  memory: 3068  
2025/03/28 10:08:38 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0855  data_time: 0.0019  memory: 3068  
2025/03/28 10:08:42 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 10:08:46 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 10:08:51 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0855  data_time: 0.0020  memory: 3068  
2025/03/28 10:08:52 - mmengine - INFO - per class results:
2025/03/28 10:08:52 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 66.74 | 94.65 |
|      building      |  82.7 | 91.34 |
|   low_vegetation   | 58.91 | 80.86 |
|        tree        | 28.97 | 29.81 |
|        car         | 72.11 | 86.04 |
|      clutter       |  3.07 |  3.24 |
+--------------------+-------+-------+
2025/03/28 10:08:52 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 75.4400  mIoU: 52.0800  mAcc: 64.3200  data_time: 0.0020  time: 0.0860
2025/03/28 10:08:53 - mmengine - INFO - The best checkpoint with 52.0800 mIoU at 2000 iter is saved to best_mIoU_iter_2000.pth.
2025/03/28 10:09:19 - mmengine - INFO - Iter(train) [ 2050/20000]  base_lr: 9.0730e-05 lr: 9.0730e-05  eta: 2:32:58  time: 0.5009  data_time: 0.0206  memory: 6852  loss: 30.8991  decode.loss_cls: 0.0743  decode.loss_mask: 1.4926  decode.loss_dice: 1.5442  decode.d0.loss_cls: 0.2439  decode.d0.loss_mask: 1.5299  decode.d0.loss_dice: 1.5318  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 1.5101  decode.d1.loss_dice: 1.5121  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 1.5050  decode.d2.loss_dice: 1.5066  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 1.4948  decode.d3.loss_dice: 1.5145  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 1.4941  decode.d4.loss_dice: 1.5021  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 1.5002  decode.d5.loss_dice: 1.5213  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 1.4932  decode.d6.loss_dice: 1.5128  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 1.5051  decode.d7.loss_dice: 1.5222  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 1.4954  decode.d8.loss_dice: 1.5349
2025/03/28 10:09:44 - mmengine - INFO - Iter(train) [ 2100/20000]  base_lr: 9.0502e-05 lr: 9.0502e-05  eta: 2:32:32  time: 0.5065  data_time: 0.0217  memory: 6851  loss: 25.2804  decode.loss_cls: 0.0531  decode.loss_mask: 1.1670  decode.loss_dice: 1.2995  decode.d0.loss_cls: 0.2377  decode.d0.loss_mask: 1.1626  decode.d0.loss_dice: 1.2889  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 1.1625  decode.d1.loss_dice: 1.2893  decode.d2.loss_cls: 0.0299  decode.d2.loss_mask: 1.1636  decode.d2.loss_dice: 1.2829  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 1.1641  decode.d3.loss_dice: 1.2917  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 1.1603  decode.d4.loss_dice: 1.2826  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 1.1662  decode.d5.loss_dice: 1.2974  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 1.1630  decode.d6.loss_dice: 1.2932  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 1.1624  decode.d7.loss_dice: 1.2914  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 1.1648  decode.d8.loss_dice: 1.3116
2025/03/28 10:10:10 - mmengine - INFO - Iter(train) [ 2150/20000]  base_lr: 9.0275e-05 lr: 9.0275e-05  eta: 2:32:07  time: 0.5217  data_time: 0.0230  memory: 6849  loss: 29.7007  decode.loss_cls: 0.1412  decode.loss_mask: 1.4426  decode.loss_dice: 1.3916  decode.d0.loss_cls: 0.2603  decode.d0.loss_mask: 1.4618  decode.d0.loss_dice: 1.4034  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 1.4452  decode.d1.loss_dice: 1.3892  decode.d2.loss_cls: 0.1247  decode.d2.loss_mask: 1.4412  decode.d2.loss_dice: 1.3737  decode.d3.loss_cls: 0.0880  decode.d3.loss_mask: 1.4344  decode.d3.loss_dice: 1.3960  decode.d4.loss_cls: 0.1497  decode.d4.loss_mask: 1.4364  decode.d4.loss_dice: 1.3860  decode.d5.loss_cls: 0.1297  decode.d5.loss_mask: 1.4336  decode.d5.loss_dice: 1.3970  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 1.4338  decode.d6.loss_dice: 1.3843  decode.d7.loss_cls: 0.1042  decode.d7.loss_mask: 1.4535  decode.d7.loss_dice: 1.3962  decode.d8.loss_cls: 0.1154  decode.d8.loss_mask: 1.4428  decode.d8.loss_dice: 1.4071
2025/03/28 10:10:35 - mmengine - INFO - Iter(train) [ 2200/20000]  base_lr: 9.0047e-05 lr: 9.0047e-05  eta: 2:31:41  time: 0.5039  data_time: 0.0208  memory: 6852  loss: 26.6608  decode.loss_cls: 0.0544  decode.loss_mask: 1.2363  decode.loss_dice: 1.3396  decode.d0.loss_cls: 0.2052  decode.d0.loss_mask: 1.2421  decode.d0.loss_dice: 1.3491  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 1.2674  decode.d1.loss_dice: 1.3402  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 1.2454  decode.d2.loss_dice: 1.3316  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 1.2295  decode.d3.loss_dice: 1.3330  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 1.2478  decode.d4.loss_dice: 1.3493  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 1.2405  decode.d5.loss_dice: 1.3505  decode.d6.loss_cls: 0.0727  decode.d6.loss_mask: 1.2380  decode.d6.loss_dice: 1.3431  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 1.2316  decode.d7.loss_dice: 1.3437  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 1.2552  decode.d8.loss_dice: 1.3369
2025/03/28 10:11:01 - mmengine - INFO - Iter(train) [ 2250/20000]  base_lr: 8.9820e-05 lr: 8.9820e-05  eta: 2:31:13  time: 0.5014  data_time: 0.0205  memory: 6853  loss: 28.5954  decode.loss_cls: 0.0123  decode.loss_mask: 1.5035  decode.loss_dice: 1.3370  decode.d0.loss_cls: 0.1737  decode.d0.loss_mask: 1.4817  decode.d0.loss_dice: 1.3246  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 1.4852  decode.d1.loss_dice: 1.3338  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 1.4879  decode.d2.loss_dice: 1.3441  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 1.4946  decode.d3.loss_dice: 1.3397  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 1.4879  decode.d4.loss_dice: 1.3347  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 1.4932  decode.d5.loss_dice: 1.3504  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 1.4947  decode.d6.loss_dice: 1.3421  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 1.4887  decode.d7.loss_dice: 1.3342  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 1.4963  decode.d8.loss_dice: 1.3336
2025/03/28 10:11:27 - mmengine - INFO - Iter(train) [ 2300/20000]  base_lr: 8.9592e-05 lr: 8.9592e-05  eta: 2:30:52  time: 0.5288  data_time: 0.0218  memory: 6857  loss: 27.0737  decode.loss_cls: 0.0707  decode.loss_mask: 1.2756  decode.loss_dice: 1.3569  decode.d0.loss_cls: 0.1992  decode.d0.loss_mask: 1.2552  decode.d0.loss_dice: 1.3953  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 1.2587  decode.d1.loss_dice: 1.3633  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 1.2682  decode.d2.loss_dice: 1.3541  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 1.2698  decode.d3.loss_dice: 1.3523  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 1.2670  decode.d4.loss_dice: 1.3723  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 1.2643  decode.d5.loss_dice: 1.3589  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 1.2703  decode.d6.loss_dice: 1.3664  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 1.2731  decode.d7.loss_dice: 1.3622  decode.d8.loss_cls: 0.0675  decode.d8.loss_mask: 1.2767  decode.d8.loss_dice: 1.3635
2025/03/28 10:11:52 - mmengine - INFO - Iter(train) [ 2350/20000]  base_lr: 8.9364e-05 lr: 8.9364e-05  eta: 2:30:25  time: 0.5173  data_time: 0.0204  memory: 6835  loss: 26.1005  decode.loss_cls: 0.0555  decode.loss_mask: 1.2248  decode.loss_dice: 1.3147  decode.d0.loss_cls: 0.1696  decode.d0.loss_mask: 1.2404  decode.d0.loss_dice: 1.2967  decode.d1.loss_cls: 0.0410  decode.d1.loss_mask: 1.2382  decode.d1.loss_dice: 1.3157  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 1.2338  decode.d2.loss_dice: 1.3165  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 1.2240  decode.d3.loss_dice: 1.3247  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 1.2345  decode.d4.loss_dice: 1.3104  decode.d5.loss_cls: 0.0530  decode.d5.loss_mask: 1.2290  decode.d5.loss_dice: 1.3350  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 1.2314  decode.d6.loss_dice: 1.3275  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 1.2250  decode.d7.loss_dice: 1.3395  decode.d8.loss_cls: 0.0482  decode.d8.loss_mask: 1.2291  decode.d8.loss_dice: 1.3070
2025/03/28 10:12:17 - mmengine - INFO - Iter(train) [ 2400/20000]  base_lr: 8.9136e-05 lr: 8.9136e-05  eta: 2:29:57  time: 0.5032  data_time: 0.0207  memory: 6845  loss: 25.2070  decode.loss_cls: 0.0586  decode.loss_mask: 1.1742  decode.loss_dice: 1.2785  decode.d0.loss_cls: 0.2336  decode.d0.loss_mask: 1.1597  decode.d0.loss_dice: 1.2587  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 1.1902  decode.d1.loss_dice: 1.2700  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 1.1742  decode.d2.loss_dice: 1.2818  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 1.1439  decode.d3.loss_dice: 1.2727  decode.d4.loss_cls: 0.0767  decode.d4.loss_mask: 1.1414  decode.d4.loss_dice: 1.2829  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 1.1618  decode.d5.loss_dice: 1.2986  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 1.1686  decode.d6.loss_dice: 1.2786  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 1.1656  decode.d7.loss_dice: 1.2873  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 1.1729  decode.d8.loss_dice: 1.2952
2025/03/28 10:12:43 - mmengine - INFO - Iter(train) [ 2450/20000]  base_lr: 8.8908e-05 lr: 8.8908e-05  eta: 2:29:30  time: 0.5044  data_time: 0.0208  memory: 6838  loss: 27.4783  decode.loss_cls: 0.0303  decode.loss_mask: 1.3305  decode.loss_dice: 1.3908  decode.d0.loss_cls: 0.2059  decode.d0.loss_mask: 1.2897  decode.d0.loss_dice: 1.3772  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 1.2925  decode.d1.loss_dice: 1.3824  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 1.2860  decode.d2.loss_dice: 1.3676  decode.d3.loss_cls: 0.0755  decode.d3.loss_mask: 1.2857  decode.d3.loss_dice: 1.3549  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 1.2746  decode.d4.loss_dice: 1.3550  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 1.2780  decode.d5.loss_dice: 1.3652  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 1.2693  decode.d6.loss_dice: 1.3638  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 1.2732  decode.d7.loss_dice: 1.3746  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 1.2942  decode.d8.loss_dice: 1.3832
2025/03/28 10:13:09 - mmengine - INFO - Iter(train) [ 2500/20000]  base_lr: 8.8680e-05 lr: 8.8680e-05  eta: 2:29:09  time: 0.5320  data_time: 0.0257  memory: 6850  loss: 29.4127  decode.loss_cls: 0.0609  decode.loss_mask: 1.4575  decode.loss_dice: 1.4258  decode.d0.loss_cls: 0.1925  decode.d0.loss_mask: 1.4753  decode.d0.loss_dice: 1.4120  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 1.4650  decode.d1.loss_dice: 1.4425  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 1.4499  decode.d2.loss_dice: 1.3969  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 1.4468  decode.d3.loss_dice: 1.3971  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 1.4551  decode.d4.loss_dice: 1.4169  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 1.4575  decode.d5.loss_dice: 1.3915  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 1.4587  decode.d6.loss_dice: 1.4248  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 1.4695  decode.d7.loss_dice: 1.3975  decode.d8.loss_cls: 0.0644  decode.d8.loss_mask: 1.4621  decode.d8.loss_dice: 1.4093
2025/03/28 10:13:35 - mmengine - INFO - Iter(train) [ 2550/20000]  base_lr: 8.8452e-05 lr: 8.8452e-05  eta: 2:28:44  time: 0.5041  data_time: 0.0206  memory: 6851  loss: 24.3895  decode.loss_cls: 0.0673  decode.loss_mask: 1.1183  decode.loss_dice: 1.2172  decode.d0.loss_cls: 0.2028  decode.d0.loss_mask: 1.1083  decode.d0.loss_dice: 1.2220  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 1.1315  decode.d1.loss_dice: 1.2171  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 1.1291  decode.d2.loss_dice: 1.2179  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 1.1344  decode.d3.loss_dice: 1.2218  decode.d4.loss_cls: 0.0982  decode.d4.loss_mask: 1.1290  decode.d4.loss_dice: 1.2119  decode.d5.loss_cls: 0.1073  decode.d5.loss_mask: 1.1293  decode.d5.loss_dice: 1.2162  decode.d6.loss_cls: 0.0981  decode.d6.loss_mask: 1.1345  decode.d6.loss_dice: 1.2183  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 1.1258  decode.d7.loss_dice: 1.2091  decode.d8.loss_cls: 0.0692  decode.d8.loss_mask: 1.1216  decode.d8.loss_dice: 1.2088
2025/03/28 10:14:00 - mmengine - INFO - Iter(train) [ 2600/20000]  base_lr: 8.8224e-05 lr: 8.8224e-05  eta: 2:28:17  time: 0.5088  data_time: 0.0209  memory: 6854  loss: 23.7266  decode.loss_cls: 0.0284  decode.loss_mask: 1.1769  decode.loss_dice: 1.1525  decode.d0.loss_cls: 0.1583  decode.d0.loss_mask: 1.1928  decode.d0.loss_dice: 1.1351  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 1.1850  decode.d1.loss_dice: 1.1340  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 1.1978  decode.d2.loss_dice: 1.1409  decode.d3.loss_cls: 0.0189  decode.d3.loss_mask: 1.1862  decode.d3.loss_dice: 1.1258  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 1.1780  decode.d4.loss_dice: 1.1371  decode.d5.loss_cls: 0.0500  decode.d5.loss_mask: 1.1831  decode.d5.loss_dice: 1.1478  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 1.1736  decode.d6.loss_dice: 1.1362  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 1.1799  decode.d7.loss_dice: 1.1402  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 1.1815  decode.d8.loss_dice: 1.1447
2025/03/28 10:14:25 - mmengine - INFO - Iter(train) [ 2650/20000]  base_lr: 8.7996e-05 lr: 8.7996e-05  eta: 2:27:49  time: 0.5008  data_time: 0.0208  memory: 6852  loss: 29.3111  decode.loss_cls: 0.0205  decode.loss_mask: 1.5325  decode.loss_dice: 1.3568  decode.d0.loss_cls: 0.1384  decode.d0.loss_mask: 1.5426  decode.d0.loss_dice: 1.3547  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 1.5368  decode.d1.loss_dice: 1.3678  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 1.5293  decode.d2.loss_dice: 1.3534  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 1.5372  decode.d3.loss_dice: 1.3543  decode.d4.loss_cls: 0.0282  decode.d4.loss_mask: 1.5355  decode.d4.loss_dice: 1.3614  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 1.5210  decode.d5.loss_dice: 1.3668  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 1.5309  decode.d6.loss_dice: 1.3646  decode.d7.loss_cls: 0.0238  decode.d7.loss_mask: 1.5375  decode.d7.loss_dice: 1.3657  decode.d8.loss_cls: 0.0252  decode.d8.loss_mask: 1.5317  decode.d8.loss_dice: 1.3685
2025/03/28 10:14:50 - mmengine - INFO - Iter(train) [ 2700/20000]  base_lr: 8.7768e-05 lr: 8.7768e-05  eta: 2:27:21  time: 0.5049  data_time: 0.0210  memory: 6840  loss: 26.5487  decode.loss_cls: 0.1367  decode.loss_mask: 1.2423  decode.loss_dice: 1.2745  decode.d0.loss_cls: 0.1618  decode.d0.loss_mask: 1.2430  decode.d0.loss_dice: 1.2762  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 1.2568  decode.d1.loss_dice: 1.2758  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 1.2546  decode.d2.loss_dice: 1.2776  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 1.2579  decode.d3.loss_dice: 1.2672  decode.d4.loss_cls: 0.1741  decode.d4.loss_mask: 1.2442  decode.d4.loss_dice: 1.2685  decode.d5.loss_cls: 0.1110  decode.d5.loss_mask: 1.2541  decode.d5.loss_dice: 1.2796  decode.d6.loss_cls: 0.1298  decode.d6.loss_mask: 1.2471  decode.d6.loss_dice: 1.2757  decode.d7.loss_cls: 0.1802  decode.d7.loss_mask: 1.2434  decode.d7.loss_dice: 1.2738  decode.d8.loss_cls: 0.0920  decode.d8.loss_mask: 1.2449  decode.d8.loss_dice: 1.2607
2025/03/28 10:15:16 - mmengine - INFO - Iter(train) [ 2750/20000]  base_lr: 8.7539e-05 lr: 8.7539e-05  eta: 2:26:57  time: 0.5064  data_time: 0.0206  memory: 6851  loss: 31.0919  decode.loss_cls: 0.0243  decode.loss_mask: 1.4781  decode.loss_dice: 1.5891  decode.d0.loss_cls: 0.1227  decode.d0.loss_mask: 1.4761  decode.d0.loss_dice: 1.5766  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 1.4420  decode.d1.loss_dice: 1.5851  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 1.4592  decode.d2.loss_dice: 1.6016  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 1.4490  decode.d3.loss_dice: 1.5887  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 1.4755  decode.d4.loss_dice: 1.5781  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 1.4699  decode.d5.loss_dice: 1.5996  decode.d6.loss_cls: 0.1129  decode.d6.loss_mask: 1.4469  decode.d6.loss_dice: 1.5793  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 1.4637  decode.d7.loss_dice: 1.5882  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 1.4709  decode.d8.loss_dice: 1.6047
2025/03/28 10:15:41 - mmengine - INFO - Iter(train) [ 2800/20000]  base_lr: 8.7311e-05 lr: 8.7311e-05  eta: 2:26:29  time: 0.5008  data_time: 0.0207  memory: 6848  loss: 25.6679  decode.loss_cls: 0.0531  decode.loss_mask: 1.2226  decode.loss_dice: 1.2826  decode.d0.loss_cls: 0.1356  decode.d0.loss_mask: 1.2229  decode.d0.loss_dice: 1.2978  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 1.2215  decode.d1.loss_dice: 1.2818  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 1.2318  decode.d2.loss_dice: 1.2766  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 1.2276  decode.d3.loss_dice: 1.2802  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 1.2279  decode.d4.loss_dice: 1.2804  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 1.2280  decode.d5.loss_dice: 1.2739  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 1.2292  decode.d6.loss_dice: 1.2770  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 1.2291  decode.d7.loss_dice: 1.2778  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 1.2269  decode.d8.loss_dice: 1.2775
2025/03/28 10:16:07 - mmengine - INFO - Iter(train) [ 2850/20000]  base_lr: 8.7082e-05 lr: 8.7082e-05  eta: 2:26:02  time: 0.5064  data_time: 0.0204  memory: 6845  loss: 27.0292  decode.loss_cls: 0.0548  decode.loss_mask: 1.2852  decode.loss_dice: 1.3669  decode.d0.loss_cls: 0.1256  decode.d0.loss_mask: 1.2701  decode.d0.loss_dice: 1.3312  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 1.2843  decode.d1.loss_dice: 1.3624  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 1.2863  decode.d2.loss_dice: 1.3629  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 1.2881  decode.d3.loss_dice: 1.3702  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 1.2803  decode.d4.loss_dice: 1.3613  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 1.2781  decode.d5.loss_dice: 1.3641  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 1.2910  decode.d6.loss_dice: 1.3620  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 1.2915  decode.d7.loss_dice: 1.3657  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 1.2866  decode.d8.loss_dice: 1.3570
2025/03/28 10:16:32 - mmengine - INFO - Iter(train) [ 2900/20000]  base_lr: 8.6854e-05 lr: 8.6854e-05  eta: 2:25:37  time: 0.5048  data_time: 0.0208  memory: 6853  loss: 26.3634  decode.loss_cls: 0.1067  decode.loss_mask: 1.2893  decode.loss_dice: 1.2451  decode.d0.loss_cls: 0.1980  decode.d0.loss_mask: 1.2748  decode.d0.loss_dice: 1.2262  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 1.2630  decode.d1.loss_dice: 1.2306  decode.d2.loss_cls: 0.0898  decode.d2.loss_mask: 1.2689  decode.d2.loss_dice: 1.2375  decode.d3.loss_cls: 0.0876  decode.d3.loss_mask: 1.2658  decode.d3.loss_dice: 1.2324  decode.d4.loss_cls: 0.1307  decode.d4.loss_mask: 1.2679  decode.d4.loss_dice: 1.2368  decode.d5.loss_cls: 0.1621  decode.d5.loss_mask: 1.2631  decode.d5.loss_dice: 1.2385  decode.d6.loss_cls: 0.1445  decode.d6.loss_mask: 1.2771  decode.d6.loss_dice: 1.2447  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 1.2918  decode.d7.loss_dice: 1.2632  decode.d8.loss_cls: 0.1067  decode.d8.loss_mask: 1.2908  decode.d8.loss_dice: 1.2493
2025/03/28 10:16:57 - mmengine - INFO - Iter(train) [ 2950/20000]  base_lr: 8.6625e-05 lr: 8.6625e-05  eta: 2:25:09  time: 0.5039  data_time: 0.0210  memory: 6838  loss: 25.1489  decode.loss_cls: 0.0462  decode.loss_mask: 1.2556  decode.loss_dice: 1.2117  decode.d0.loss_cls: 0.1570  decode.d0.loss_mask: 1.2584  decode.d0.loss_dice: 1.2010  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 1.2489  decode.d1.loss_dice: 1.2033  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 1.2463  decode.d2.loss_dice: 1.1977  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 1.2454  decode.d3.loss_dice: 1.1795  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 1.2455  decode.d4.loss_dice: 1.1917  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 1.2452  decode.d5.loss_dice: 1.1855  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 1.2516  decode.d6.loss_dice: 1.1968  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 1.2576  decode.d7.loss_dice: 1.1975  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 1.2373  decode.d8.loss_dice: 1.1886
2025/03/28 10:17:23 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 10:17:23 - mmengine - INFO - Iter(train) [ 3000/20000]  base_lr: 8.6397e-05 lr: 8.6397e-05  eta: 2:24:43  time: 0.5168  data_time: 0.0233  memory: 6851  loss: 26.2069  decode.loss_cls: 0.0167  decode.loss_mask: 1.3320  decode.loss_dice: 1.2924  decode.d0.loss_cls: 0.1076  decode.d0.loss_mask: 1.3154  decode.d0.loss_dice: 1.2892  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 1.3272  decode.d1.loss_dice: 1.2727  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 1.3201  decode.d2.loss_dice: 1.2662  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 1.3187  decode.d3.loss_dice: 1.2565  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 1.3135  decode.d4.loss_dice: 1.2635  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 1.3161  decode.d5.loss_dice: 1.2758  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 1.3111  decode.d6.loss_dice: 1.2783  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 1.3188  decode.d7.loss_dice: 1.2830  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 1.3253  decode.d8.loss_dice: 1.2755
2025/03/28 10:17:48 - mmengine - INFO - Iter(train) [ 3050/20000]  base_lr: 8.6168e-05 lr: 8.6168e-05  eta: 2:24:16  time: 0.5023  data_time: 0.0204  memory: 6839  loss: 26.0573  decode.loss_cls: 0.0367  decode.loss_mask: 1.3001  decode.loss_dice: 1.2530  decode.d0.loss_cls: 0.1634  decode.d0.loss_mask: 1.2888  decode.d0.loss_dice: 1.2592  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 1.3114  decode.d1.loss_dice: 1.2507  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 1.2992  decode.d2.loss_dice: 1.2532  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 1.2985  decode.d3.loss_dice: 1.2452  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 1.3081  decode.d4.loss_dice: 1.2459  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 1.3093  decode.d5.loss_dice: 1.2585  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 1.3087  decode.d6.loss_dice: 1.2416  decode.d7.loss_cls: 0.0366  decode.d7.loss_mask: 1.3142  decode.d7.loss_dice: 1.2535  decode.d8.loss_cls: 0.0332  decode.d8.loss_mask: 1.3004  decode.d8.loss_dice: 1.2633
2025/03/28 10:18:14 - mmengine - INFO - Iter(train) [ 3100/20000]  base_lr: 8.5939e-05 lr: 8.5939e-05  eta: 2:23:53  time: 0.5227  data_time: 0.0234  memory: 6836  loss: 26.2959  decode.loss_cls: 0.2120  decode.loss_mask: 1.2045  decode.loss_dice: 1.3183  decode.d0.loss_cls: 0.2121  decode.d0.loss_mask: 1.1798  decode.d0.loss_dice: 1.3399  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 1.1933  decode.d1.loss_dice: 1.3124  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 1.1910  decode.d2.loss_dice: 1.2884  decode.d3.loss_cls: 0.0819  decode.d3.loss_mask: 1.1970  decode.d3.loss_dice: 1.2981  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 1.1854  decode.d4.loss_dice: 1.3050  decode.d5.loss_cls: 0.1076  decode.d5.loss_mask: 1.1949  decode.d5.loss_dice: 1.3097  decode.d6.loss_cls: 0.1272  decode.d6.loss_mask: 1.1980  decode.d6.loss_dice: 1.2908  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 1.1946  decode.d7.loss_dice: 1.3055  decode.d8.loss_cls: 0.1309  decode.d8.loss_mask: 1.2039  decode.d8.loss_dice: 1.2972
2025/03/28 10:18:39 - mmengine - INFO - Iter(train) [ 3150/20000]  base_lr: 8.5710e-05 lr: 8.5710e-05  eta: 2:23:25  time: 0.5018  data_time: 0.0213  memory: 6847  loss: 26.9559  decode.loss_cls: 0.0696  decode.loss_mask: 1.3392  decode.loss_dice: 1.2571  decode.d0.loss_cls: 0.1390  decode.d0.loss_mask: 1.3450  decode.d0.loss_dice: 1.2922  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 1.3406  decode.d1.loss_dice: 1.2597  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 1.3370  decode.d2.loss_dice: 1.2598  decode.d3.loss_cls: 0.1347  decode.d3.loss_mask: 1.3356  decode.d3.loss_dice: 1.2445  decode.d4.loss_cls: 0.1401  decode.d4.loss_mask: 1.3387  decode.d4.loss_dice: 1.2412  decode.d5.loss_cls: 0.1355  decode.d5.loss_mask: 1.3339  decode.d5.loss_dice: 1.2463  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 1.3408  decode.d6.loss_dice: 1.2504  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 1.3388  decode.d7.loss_dice: 1.2667  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 1.3348  decode.d8.loss_dice: 1.2623
2025/03/28 10:19:04 - mmengine - INFO - Iter(train) [ 3200/20000]  base_lr: 8.5481e-05 lr: 8.5481e-05  eta: 2:22:58  time: 0.5003  data_time: 0.0203  memory: 6851  loss: 25.9364  decode.loss_cls: 0.0779  decode.loss_mask: 1.2563  decode.loss_dice: 1.2902  decode.d0.loss_cls: 0.1205  decode.d0.loss_mask: 1.2774  decode.d0.loss_dice: 1.2825  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 1.2317  decode.d1.loss_dice: 1.2633  decode.d2.loss_cls: 0.0752  decode.d2.loss_mask: 1.2283  decode.d2.loss_dice: 1.2710  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 1.2242  decode.d3.loss_dice: 1.2864  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 1.2243  decode.d4.loss_dice: 1.2735  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 1.2245  decode.d5.loss_dice: 1.2780  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 1.2198  decode.d6.loss_dice: 1.2742  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 1.2352  decode.d7.loss_dice: 1.2793  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 1.2302  decode.d8.loss_dice: 1.2921
2025/03/28 10:19:30 - mmengine - INFO - Iter(train) [ 3250/20000]  base_lr: 8.5252e-05 lr: 8.5252e-05  eta: 2:22:34  time: 0.5280  data_time: 0.0242  memory: 6849  loss: 26.4199  decode.loss_cls: 0.0789  decode.loss_mask: 1.1508  decode.loss_dice: 1.3900  decode.d0.loss_cls: 0.1527  decode.d0.loss_mask: 1.1722  decode.d0.loss_dice: 1.3780  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 1.1733  decode.d1.loss_dice: 1.3906  decode.d2.loss_cls: 0.1790  decode.d2.loss_mask: 1.1688  decode.d2.loss_dice: 1.3660  decode.d3.loss_cls: 0.0828  decode.d3.loss_mask: 1.1687  decode.d3.loss_dice: 1.3876  decode.d4.loss_cls: 0.0969  decode.d4.loss_mask: 1.1610  decode.d4.loss_dice: 1.3819  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 1.1647  decode.d5.loss_dice: 1.3939  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 1.1602  decode.d6.loss_dice: 1.3881  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 1.1494  decode.d7.loss_dice: 1.3906  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 1.1553  decode.d8.loss_dice: 1.3962
2025/03/28 10:19:56 - mmengine - INFO - Iter(train) [ 3300/20000]  base_lr: 8.5023e-05 lr: 8.5023e-05  eta: 2:22:07  time: 0.5017  data_time: 0.0208  memory: 6849  loss: 25.0255  decode.loss_cls: 0.0326  decode.loss_mask: 1.1919  decode.loss_dice: 1.2614  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 1.2195  decode.d0.loss_dice: 1.2752  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 1.1953  decode.d1.loss_dice: 1.2794  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 1.1953  decode.d2.loss_dice: 1.2728  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 1.1933  decode.d3.loss_dice: 1.2648  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 1.1954  decode.d4.loss_dice: 1.2780  decode.d5.loss_cls: 0.0296  decode.d5.loss_mask: 1.1916  decode.d5.loss_dice: 1.2644  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 1.1749  decode.d6.loss_dice: 1.2713  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 1.1787  decode.d7.loss_dice: 1.2801  decode.d8.loss_cls: 0.0312  decode.d8.loss_mask: 1.1803  decode.d8.loss_dice: 1.2560
2025/03/28 10:20:21 - mmengine - INFO - Iter(train) [ 3350/20000]  base_lr: 8.4794e-05 lr: 8.4794e-05  eta: 2:21:40  time: 0.5049  data_time: 0.0208  memory: 6852  loss: 22.9016  decode.loss_cls: 0.0249  decode.loss_mask: 1.1587  decode.loss_dice: 1.0959  decode.d0.loss_cls: 0.1124  decode.d0.loss_mask: 1.1680  decode.d0.loss_dice: 1.0962  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 1.1744  decode.d1.loss_dice: 1.1049  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 1.1651  decode.d2.loss_dice: 1.0969  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 1.1534  decode.d3.loss_dice: 1.0961  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 1.1555  decode.d4.loss_dice: 1.0992  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 1.1618  decode.d5.loss_dice: 1.1031  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 1.1616  decode.d6.loss_dice: 1.1108  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 1.1665  decode.d7.loss_dice: 1.1026  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 1.1608  decode.d8.loss_dice: 1.1042
2025/03/28 10:20:46 - mmengine - INFO - Iter(train) [ 3400/20000]  base_lr: 8.4565e-05 lr: 8.4565e-05  eta: 2:21:14  time: 0.5051  data_time: 0.0209  memory: 6845  loss: 23.5294  decode.loss_cls: 0.0117  decode.loss_mask: 1.1835  decode.loss_dice: 1.1594  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 1.1837  decode.d0.loss_dice: 1.1336  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 1.1765  decode.d1.loss_dice: 1.1389  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 1.1775  decode.d2.loss_dice: 1.1497  decode.d3.loss_cls: 0.0156  decode.d3.loss_mask: 1.1767  decode.d3.loss_dice: 1.1562  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 1.1743  decode.d4.loss_dice: 1.1588  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 1.1730  decode.d5.loss_dice: 1.1525  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 1.1744  decode.d6.loss_dice: 1.1615  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 1.1749  decode.d7.loss_dice: 1.1607  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 1.1764  decode.d8.loss_dice: 1.1643
2025/03/28 10:21:11 - mmengine - INFO - Iter(train) [ 3450/20000]  base_lr: 8.4336e-05 lr: 8.4336e-05  eta: 2:20:46  time: 0.5069  data_time: 0.0217  memory: 6854  loss: 23.8488  decode.loss_cls: 0.0218  decode.loss_mask: 1.1444  decode.loss_dice: 1.1962  decode.d0.loss_cls: 0.0982  decode.d0.loss_mask: 1.1463  decode.d0.loss_dice: 1.2111  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 1.1340  decode.d1.loss_dice: 1.1936  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 1.1427  decode.d2.loss_dice: 1.1963  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 1.1487  decode.d3.loss_dice: 1.2073  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 1.1586  decode.d4.loss_dice: 1.2016  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 1.1619  decode.d5.loss_dice: 1.1813  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 1.1554  decode.d6.loss_dice: 1.1849  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 1.1541  decode.d7.loss_dice: 1.1879  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 1.1464  decode.d8.loss_dice: 1.1948
2025/03/28 10:21:37 - mmengine - INFO - Iter(train) [ 3500/20000]  base_lr: 8.4106e-05 lr: 8.4106e-05  eta: 2:20:20  time: 0.5165  data_time: 0.0229  memory: 6847  loss: 27.7506  decode.loss_cls: 0.0527  decode.loss_mask: 1.4643  decode.loss_dice: 1.2362  decode.d0.loss_cls: 0.1273  decode.d0.loss_mask: 1.4676  decode.d0.loss_dice: 1.2513  decode.d1.loss_cls: 0.0675  decode.d1.loss_mask: 1.4565  decode.d1.loss_dice: 1.2453  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 1.4541  decode.d2.loss_dice: 1.2711  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 1.4644  decode.d3.loss_dice: 1.2690  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 1.4572  decode.d4.loss_dice: 1.2589  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 1.4653  decode.d5.loss_dice: 1.2471  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 1.4675  decode.d6.loss_dice: 1.2434  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 1.4552  decode.d7.loss_dice: 1.2490  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 1.4598  decode.d8.loss_dice: 1.2473
2025/03/28 10:22:02 - mmengine - INFO - Iter(train) [ 3550/20000]  base_lr: 8.3877e-05 lr: 8.3877e-05  eta: 2:19:55  time: 0.5101  data_time: 0.0216  memory: 6851  loss: 26.6098  decode.loss_cls: 0.0267  decode.loss_mask: 1.2730  decode.loss_dice: 1.3135  decode.d0.loss_cls: 0.1008  decode.d0.loss_mask: 1.2980  decode.d0.loss_dice: 1.3043  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 1.2770  decode.d1.loss_dice: 1.3053  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 1.2727  decode.d2.loss_dice: 1.3023  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 1.2729  decode.d3.loss_dice: 1.3070  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 1.2669  decode.d4.loss_dice: 1.2950  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 1.2730  decode.d5.loss_dice: 1.3068  decode.d6.loss_cls: 0.1385  decode.d6.loss_mask: 1.2676  decode.d6.loss_dice: 1.2934  decode.d7.loss_cls: 0.1400  decode.d7.loss_mask: 1.2708  decode.d7.loss_dice: 1.2920  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 1.2720  decode.d8.loss_dice: 1.2947
2025/03/28 10:22:28 - mmengine - INFO - Iter(train) [ 3600/20000]  base_lr: 8.3647e-05 lr: 8.3647e-05  eta: 2:19:28  time: 0.5018  data_time: 0.0208  memory: 6846  loss: 23.0538  decode.loss_cls: 0.0221  decode.loss_mask: 1.1327  decode.loss_dice: 1.1364  decode.d0.loss_cls: 0.1027  decode.d0.loss_mask: 1.1534  decode.d0.loss_dice: 1.1470  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 1.1429  decode.d1.loss_dice: 1.1279  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 1.1395  decode.d2.loss_dice: 1.1359  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 1.1323  decode.d3.loss_dice: 1.1367  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 1.1361  decode.d4.loss_dice: 1.1365  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 1.1334  decode.d5.loss_dice: 1.1402  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 1.1396  decode.d6.loss_dice: 1.1433  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 1.1387  decode.d7.loss_dice: 1.1472  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 1.1295  decode.d8.loss_dice: 1.1431
2025/03/28 10:22:53 - mmengine - INFO - Iter(train) [ 3650/20000]  base_lr: 8.3418e-05 lr: 8.3418e-05  eta: 2:19:02  time: 0.5083  data_time: 0.0209  memory: 6835  loss: 28.7189  decode.loss_cls: 0.0095  decode.loss_mask: 1.4606  decode.loss_dice: 1.3651  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 1.4713  decode.d0.loss_dice: 1.3594  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 1.4704  decode.d1.loss_dice: 1.3418  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 1.4753  decode.d2.loss_dice: 1.3791  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 1.4698  decode.d3.loss_dice: 1.3810  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 1.4694  decode.d4.loss_dice: 1.3832  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 1.4649  decode.d5.loss_dice: 1.3818  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 1.4590  decode.d6.loss_dice: 1.3597  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 1.4698  decode.d7.loss_dice: 1.3493  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 1.4812  decode.d8.loss_dice: 1.3757
2025/03/28 10:23:18 - mmengine - INFO - Iter(train) [ 3700/20000]  base_lr: 8.3188e-05 lr: 8.3188e-05  eta: 2:18:35  time: 0.5014  data_time: 0.0205  memory: 6848  loss: 23.2399  decode.loss_cls: 0.0225  decode.loss_mask: 1.1075  decode.loss_dice: 1.1839  decode.d0.loss_cls: 0.1012  decode.d0.loss_mask: 1.1082  decode.d0.loss_dice: 1.1755  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 1.1026  decode.d1.loss_dice: 1.1947  decode.d2.loss_cls: 0.0198  decode.d2.loss_mask: 1.0996  decode.d2.loss_dice: 1.1862  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 1.1077  decode.d3.loss_dice: 1.1797  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 1.0965  decode.d4.loss_dice: 1.1888  decode.d5.loss_cls: 0.0193  decode.d5.loss_mask: 1.1052  decode.d5.loss_dice: 1.1867  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 1.0970  decode.d6.loss_dice: 1.1849  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 1.0921  decode.d7.loss_dice: 1.1818  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 1.0983  decode.d8.loss_dice: 1.1901
2025/03/28 10:23:44 - mmengine - INFO - Iter(train) [ 3750/20000]  base_lr: 8.2958e-05 lr: 8.2958e-05  eta: 2:18:11  time: 0.5133  data_time: 0.0226  memory: 6845  loss: 26.5282  decode.loss_cls: 0.0135  decode.loss_mask: 1.4339  decode.loss_dice: 1.2139  decode.d0.loss_cls: 0.0858  decode.d0.loss_mask: 1.4000  decode.d0.loss_dice: 1.1897  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 1.4070  decode.d1.loss_dice: 1.2024  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 1.4211  decode.d2.loss_dice: 1.2108  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 1.4226  decode.d3.loss_dice: 1.2139  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 1.4189  decode.d4.loss_dice: 1.2065  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 1.4214  decode.d5.loss_dice: 1.2065  decode.d6.loss_cls: 0.0195  decode.d6.loss_mask: 1.4275  decode.d6.loss_dice: 1.2179  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 1.4292  decode.d7.loss_dice: 1.2112  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 1.4236  decode.d8.loss_dice: 1.2199
2025/03/28 10:24:09 - mmengine - INFO - Iter(train) [ 3800/20000]  base_lr: 8.2729e-05 lr: 8.2729e-05  eta: 2:17:44  time: 0.5051  data_time: 0.0202  memory: 6834  loss: 23.7820  decode.loss_cls: 0.0248  decode.loss_mask: 1.2040  decode.loss_dice: 1.1779  decode.d0.loss_cls: 0.1223  decode.d0.loss_mask: 1.1777  decode.d0.loss_dice: 1.1428  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 1.1731  decode.d1.loss_dice: 1.1541  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 1.1736  decode.d2.loss_dice: 1.1666  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 1.1740  decode.d3.loss_dice: 1.1643  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 1.1768  decode.d4.loss_dice: 1.1711  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 1.1812  decode.d5.loss_dice: 1.1534  decode.d6.loss_cls: 0.0333  decode.d6.loss_mask: 1.1741  decode.d6.loss_dice: 1.1454  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 1.1772  decode.d7.loss_dice: 1.1678  decode.d8.loss_cls: 0.0325  decode.d8.loss_mask: 1.1902  decode.d8.loss_dice: 1.1695
2025/03/28 10:24:35 - mmengine - INFO - Iter(train) [ 3850/20000]  base_lr: 8.2499e-05 lr: 8.2499e-05  eta: 2:17:19  time: 0.5038  data_time: 0.0206  memory: 6852  loss: 26.6732  decode.loss_cls: 0.0412  decode.loss_mask: 1.3519  decode.loss_dice: 1.2513  decode.d0.loss_cls: 0.1581  decode.d0.loss_mask: 1.3358  decode.d0.loss_dice: 1.2728  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 1.3503  decode.d1.loss_dice: 1.2570  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 1.3357  decode.d2.loss_dice: 1.2523  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 1.3606  decode.d3.loss_dice: 1.2473  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 1.3512  decode.d4.loss_dice: 1.2626  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 1.3663  decode.d5.loss_dice: 1.2656  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 1.3292  decode.d6.loss_dice: 1.2603  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 1.3452  decode.d7.loss_dice: 1.2608  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 1.3627  decode.d8.loss_dice: 1.2611
2025/03/28 10:25:01 - mmengine - INFO - Iter(train) [ 3900/20000]  base_lr: 8.2269e-05 lr: 8.2269e-05  eta: 2:16:55  time: 0.5080  data_time: 0.0219  memory: 6850  loss: 22.9106  decode.loss_cls: 0.0843  decode.loss_mask: 1.0825  decode.loss_dice: 1.1061  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 1.1141  decode.d0.loss_dice: 1.1069  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 1.0644  decode.d1.loss_dice: 1.1032  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 1.0705  decode.d2.loss_dice: 1.1233  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 1.1128  decode.d3.loss_dice: 1.1390  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 1.0806  decode.d4.loss_dice: 1.1370  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 1.0786  decode.d5.loss_dice: 1.1102  decode.d6.loss_cls: 0.0670  decode.d6.loss_mask: 1.0836  decode.d6.loss_dice: 1.1257  decode.d7.loss_cls: 0.1244  decode.d7.loss_mask: 1.0879  decode.d7.loss_dice: 1.1443  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 1.0802  decode.d8.loss_dice: 1.1115
2025/03/28 10:25:26 - mmengine - INFO - Iter(train) [ 3950/20000]  base_lr: 8.2039e-05 lr: 8.2039e-05  eta: 2:16:29  time: 0.5042  data_time: 0.0206  memory: 6849  loss: 21.6016  decode.loss_cls: 0.0073  decode.loss_mask: 1.1284  decode.loss_dice: 1.0019  decode.d0.loss_cls: 0.0643  decode.d0.loss_mask: 1.1469  decode.d0.loss_dice: 1.0195  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 1.1246  decode.d1.loss_dice: 1.0133  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 1.1302  decode.d2.loss_dice: 1.0260  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 1.1224  decode.d3.loss_dice: 1.0191  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 1.1239  decode.d4.loss_dice: 1.0153  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 1.1366  decode.d5.loss_dice: 1.0170  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 1.1259  decode.d6.loss_dice: 1.0107  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 1.1230  decode.d7.loss_dice: 1.0154  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 1.1294  decode.d8.loss_dice: 1.0211
2025/03/28 10:25:52 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 10:25:52 - mmengine - INFO - Iter(train) [ 4000/20000]  base_lr: 8.1809e-05 lr: 8.1809e-05  eta: 2:16:06  time: 0.5133  data_time: 0.0226  memory: 6834  loss: 22.6009  decode.loss_cls: 0.0258  decode.loss_mask: 1.0522  decode.loss_dice: 1.1571  decode.d0.loss_cls: 0.0927  decode.d0.loss_mask: 1.0736  decode.d0.loss_dice: 1.1687  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 1.0529  decode.d1.loss_dice: 1.1553  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 1.0565  decode.d2.loss_dice: 1.1485  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 1.0565  decode.d3.loss_dice: 1.1596  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 1.0526  decode.d4.loss_dice: 1.1252  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 1.0548  decode.d5.loss_dice: 1.1385  decode.d6.loss_cls: 0.0436  decode.d6.loss_mask: 1.0563  decode.d6.loss_dice: 1.1409  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 1.0564  decode.d7.loss_dice: 1.1433  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 1.0476  decode.d8.loss_dice: 1.1679
2025/03/28 10:25:52 - mmengine - INFO - Saving checkpoint at 4000 iterations
2025/03/28 10:25:58 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:47  time: 0.0845  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:02 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:42  time: 0.0843  data_time: 0.0017  memory: 3070  
2025/03/28 10:26:06 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:38  time: 0.0846  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:10 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:33  time: 0.0844  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:14 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:29  time: 0.0845  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:19 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:25  time: 0.0877  data_time: 0.0020  memory: 3070  
2025/03/28 10:26:23 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:21  time: 0.0847  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:27 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:17  time: 0.0846  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:32 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0858  data_time: 0.0019  memory: 3070  
2025/03/28 10:26:36 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:08  time: 0.0848  data_time: 0.0019  memory: 3070  
2025/03/28 10:26:40 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:04  time: 0.0845  data_time: 0.0018  memory: 3070  
2025/03/28 10:26:44 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:00  time: 0.0877  data_time: 0.0020  memory: 3070  
2025/03/28 10:26:49 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0849  data_time: 0.0019  memory: 3070  
2025/03/28 10:26:53 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:51  time: 0.0847  data_time: 0.0017  memory: 3070  
2025/03/28 10:26:57 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:47  time: 0.0848  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:01 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:43  time: 0.0848  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:06 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0848  data_time: 0.0019  memory: 3070  
2025/03/28 10:27:10 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:34  time: 0.0849  data_time: 0.0019  memory: 3070  
2025/03/28 10:27:14 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:30  time: 0.0849  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:18 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:23 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0850  data_time: 0.0019  memory: 3070  
2025/03/28 10:27:27 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:17  time: 0.0848  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:31 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:13  time: 0.0848  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:35 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0850  data_time: 0.0019  memory: 3070  
2025/03/28 10:27:40 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0847  data_time: 0.0017  memory: 3070  
2025/03/28 10:27:44 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:00  time: 0.0849  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:48 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0852  data_time: 0.0020  memory: 3070  
2025/03/28 10:27:52 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0849  data_time: 0.0018  memory: 3070  
2025/03/28 10:27:57 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0848  data_time: 0.0018  memory: 3070  
2025/03/28 10:28:01 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:43  time: 0.0847  data_time: 0.0017  memory: 3070  
2025/03/28 10:28:05 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0850  data_time: 0.0019  memory: 3070  
2025/03/28 10:28:09 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0849  data_time: 0.0019  memory: 3070  
2025/03/28 10:28:14 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0849  data_time: 0.0018  memory: 3070  
2025/03/28 10:28:18 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:26  time: 0.0848  data_time: 0.0018  memory: 3070  
2025/03/28 10:28:22 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 10:28:27 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0850  data_time: 0.0017  memory: 3070  
2025/03/28 10:28:31 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0851  data_time: 0.0019  memory: 3070  
2025/03/28 10:28:35 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 10:28:39 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 10:28:44 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0853  data_time: 0.0019  memory: 3070  
2025/03/28 10:28:45 - mmengine - INFO - per class results:
2025/03/28 10:28:45 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 68.42 | 94.44 |
|      building      |  84.8 | 93.15 |
|   low_vegetation   | 59.15 | 82.32 |
|        tree        | 30.57 | 31.56 |
|        car         |  75.2 |  90.9 |
|      clutter       |  2.27 |  2.31 |
+--------------------+-------+-------+
2025/03/28 10:28:45 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.4700  mIoU: 53.4000  mAcc: 65.7800  data_time: 0.0019  time: 0.0850
2025/03/28 10:28:45 - mmengine - INFO - The previous best checkpoint /data/xiaoxinghhh/code/my_mmcv/work_dirs/vi2pr/DA_spatial_32_fft_cut_off_0.2_suf3/6ff2f_seed0/best_mIoU_iter_2000.pth is removed
2025/03/28 10:28:46 - mmengine - INFO - The best checkpoint with 53.4000 mIoU at 4000 iter is saved to best_mIoU_iter_4000.pth.
2025/03/28 10:29:40 - mmengine - INFO - Iter(train) [ 4050/20000]  base_lr: 8.1579e-05 lr: 8.1579e-05  eta: 2:17:36  time: 1.0709  data_time: 0.0230  memory: 10764  loss: 45.9601  decode.loss_cls: 0.0843  decode.loss_mask: 1.2558  decode.loss_dice: 1.3274  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 1.2776  decode.d0.loss_dice: 1.3250  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 1.2819  decode.d1.loss_dice: 1.3066  decode.d2.loss_cls: 0.0844  decode.d2.loss_mask: 1.2858  decode.d2.loss_dice: 1.3086  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 1.2669  decode.d3.loss_dice: 1.3392  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 1.2704  decode.d4.loss_dice: 1.3277  decode.d5.loss_cls: 0.0915  decode.d5.loss_mask: 1.2638  decode.d5.loss_dice: 1.3224  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 1.2488  decode.d6.loss_dice: 1.3045  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 1.2576  decode.d7.loss_dice: 1.3112  decode.d8.loss_cls: 0.1089  decode.d8.loss_mask: 1.2547  decode.d8.loss_dice: 1.3382  mix_decode.loss_cls: 0.1165  mix_decode.loss_mask: 0.8782  mix_decode.loss_dice: 0.8870  mix_decode.d0.loss_cls: 0.2280  mix_decode.d0.loss_mask: 0.8663  mix_decode.d0.loss_dice: 0.8909  mix_decode.d1.loss_cls: 0.1914  mix_decode.d1.loss_mask: 0.8882  mix_decode.d1.loss_dice: 0.8793  mix_decode.d2.loss_cls: 0.1498  mix_decode.d2.loss_mask: 0.8948  mix_decode.d2.loss_dice: 0.8878  mix_decode.d3.loss_cls: 0.1651  mix_decode.d3.loss_mask: 0.8883  mix_decode.d3.loss_dice: 0.8868  mix_decode.d4.loss_cls: 0.1671  mix_decode.d4.loss_mask: 0.8873  mix_decode.d4.loss_dice: 0.8700  mix_decode.d5.loss_cls: 0.1565  mix_decode.d5.loss_mask: 0.8797  mix_decode.d5.loss_dice: 0.8753  mix_decode.d6.loss_cls: 0.1443  mix_decode.d6.loss_mask: 0.8786  mix_decode.d6.loss_dice: 0.8690  mix_decode.d7.loss_cls: 0.1471  mix_decode.d7.loss_mask: 0.8763  mix_decode.d7.loss_dice: 0.8761  mix_decode.d8.loss_cls: 0.1346  mix_decode.d8.loss_mask: 0.8755  mix_decode.d8.loss_dice: 0.8864
2025/03/28 10:30:33 - mmengine - INFO - Iter(train) [ 4100/20000]  base_lr: 8.1349e-05 lr: 8.1349e-05  eta: 2:18:58  time: 1.0694  data_time: 0.0221  memory: 10763  loss: 46.9131  decode.loss_cls: 0.1932  decode.loss_mask: 1.2014  decode.loss_dice: 1.3013  decode.d0.loss_cls: 0.1525  decode.d0.loss_mask: 1.2109  decode.d0.loss_dice: 1.3132  decode.d1.loss_cls: 0.1601  decode.d1.loss_mask: 1.1959  decode.d1.loss_dice: 1.3279  decode.d2.loss_cls: 0.1969  decode.d2.loss_mask: 1.1948  decode.d2.loss_dice: 1.3383  decode.d3.loss_cls: 0.1936  decode.d3.loss_mask: 1.2218  decode.d3.loss_dice: 1.3343  decode.d4.loss_cls: 0.1767  decode.d4.loss_mask: 1.2183  decode.d4.loss_dice: 1.3099  decode.d5.loss_cls: 0.1855  decode.d5.loss_mask: 1.2175  decode.d5.loss_dice: 1.3081  decode.d6.loss_cls: 0.1930  decode.d6.loss_mask: 1.2068  decode.d6.loss_dice: 1.3080  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 1.1931  decode.d7.loss_dice: 1.3238  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 1.2048  decode.d8.loss_dice: 1.3034  mix_decode.loss_cls: 0.2164  mix_decode.loss_mask: 0.8497  mix_decode.loss_dice: 0.9348  mix_decode.d0.loss_cls: 0.2441  mix_decode.d0.loss_mask: 0.8490  mix_decode.d0.loss_dice: 0.9519  mix_decode.d1.loss_cls: 0.2512  mix_decode.d1.loss_mask: 0.8140  mix_decode.d1.loss_dice: 0.9339  mix_decode.d2.loss_cls: 0.2536  mix_decode.d2.loss_mask: 0.8115  mix_decode.d2.loss_dice: 0.9324  mix_decode.d3.loss_cls: 0.2301  mix_decode.d3.loss_mask: 0.8377  mix_decode.d3.loss_dice: 0.9250  mix_decode.d4.loss_cls: 0.2082  mix_decode.d4.loss_mask: 0.8409  mix_decode.d4.loss_dice: 0.9264  mix_decode.d5.loss_cls: 0.2053  mix_decode.d5.loss_mask: 0.8372  mix_decode.d5.loss_dice: 0.9359  mix_decode.d6.loss_cls: 0.2402  mix_decode.d6.loss_mask: 0.8162  mix_decode.d6.loss_dice: 0.9189  mix_decode.d7.loss_cls: 0.1750  mix_decode.d7.loss_mask: 0.8321  mix_decode.d7.loss_dice: 0.9522  mix_decode.d8.loss_cls: 0.1783  mix_decode.d8.loss_mask: 0.8416  mix_decode.d8.loss_dice: 0.9354
2025/03/28 10:31:27 - mmengine - INFO - Iter(train) [ 4150/20000]  base_lr: 8.1118e-05 lr: 8.1118e-05  eta: 2:20:17  time: 1.0718  data_time: 0.0221  memory: 10774  loss: 44.9694  decode.loss_cls: 0.0857  decode.loss_mask: 1.2814  decode.loss_dice: 1.2841  decode.d0.loss_cls: 0.1050  decode.d0.loss_mask: 1.3134  decode.d0.loss_dice: 1.2432  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 1.2888  decode.d1.loss_dice: 1.2457  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 1.2788  decode.d2.loss_dice: 1.2509  decode.d3.loss_cls: 0.0866  decode.d3.loss_mask: 1.2816  decode.d3.loss_dice: 1.2698  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 1.2835  decode.d4.loss_dice: 1.2701  decode.d5.loss_cls: 0.0827  decode.d5.loss_mask: 1.2899  decode.d5.loss_dice: 1.2623  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 1.2809  decode.d6.loss_dice: 1.2491  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 1.2888  decode.d7.loss_dice: 1.2604  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 1.2767  decode.d8.loss_dice: 1.2664  mix_decode.loss_cls: 0.1511  mix_decode.loss_mask: 0.7795  mix_decode.loss_dice: 0.9126  mix_decode.d0.loss_cls: 0.2092  mix_decode.d0.loss_mask: 0.7738  mix_decode.d0.loss_dice: 0.8744  mix_decode.d1.loss_cls: 0.1794  mix_decode.d1.loss_mask: 0.7896  mix_decode.d1.loss_dice: 0.8900  mix_decode.d2.loss_cls: 0.2039  mix_decode.d2.loss_mask: 0.7753  mix_decode.d2.loss_dice: 0.8979  mix_decode.d3.loss_cls: 0.2013  mix_decode.d3.loss_mask: 0.7827  mix_decode.d3.loss_dice: 0.8993  mix_decode.d4.loss_cls: 0.1805  mix_decode.d4.loss_mask: 0.7960  mix_decode.d4.loss_dice: 0.9009  mix_decode.d5.loss_cls: 0.1696  mix_decode.d5.loss_mask: 0.7873  mix_decode.d5.loss_dice: 0.9097  mix_decode.d6.loss_cls: 0.1548  mix_decode.d6.loss_mask: 0.7918  mix_decode.d6.loss_dice: 0.9136  mix_decode.d7.loss_cls: 0.1766  mix_decode.d7.loss_mask: 0.7833  mix_decode.d7.loss_dice: 0.8996  mix_decode.d8.loss_cls: 0.1908  mix_decode.d8.loss_mask: 0.7845  mix_decode.d8.loss_dice: 0.8997
2025/03/28 10:32:21 - mmengine - INFO - Iter(train) [ 4200/20000]  base_lr: 8.0888e-05 lr: 8.0888e-05  eta: 2:21:32  time: 1.0778  data_time: 0.0235  memory: 10773  loss: 41.2545  decode.loss_cls: 0.1320  decode.loss_mask: 1.1823  decode.loss_dice: 1.1756  decode.d0.loss_cls: 0.1242  decode.d0.loss_mask: 1.1984  decode.d0.loss_dice: 1.1719  decode.d1.loss_cls: 0.0861  decode.d1.loss_mask: 1.1833  decode.d1.loss_dice: 1.1750  decode.d2.loss_cls: 0.1295  decode.d2.loss_mask: 1.1828  decode.d2.loss_dice: 1.1617  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 1.1871  decode.d3.loss_dice: 1.1806  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 1.1924  decode.d4.loss_dice: 1.1878  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 1.1800  decode.d5.loss_dice: 1.1858  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 1.1845  decode.d6.loss_dice: 1.1835  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 1.1828  decode.d7.loss_dice: 1.1802  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 1.1814  decode.d8.loss_dice: 1.1683  mix_decode.loss_cls: 0.1217  mix_decode.loss_mask: 0.7073  mix_decode.loss_dice: 0.8277  mix_decode.d0.loss_cls: 0.0908  mix_decode.d0.loss_mask: 0.7284  mix_decode.d0.loss_dice: 0.8466  mix_decode.d1.loss_cls: 0.0656  mix_decode.d1.loss_mask: 0.7175  mix_decode.d1.loss_dice: 0.8451  mix_decode.d2.loss_cls: 0.0928  mix_decode.d2.loss_mask: 0.7115  mix_decode.d2.loss_dice: 0.8351  mix_decode.d3.loss_cls: 0.1211  mix_decode.d3.loss_mask: 0.7080  mix_decode.d3.loss_dice: 0.8332  mix_decode.d4.loss_cls: 0.1408  mix_decode.d4.loss_mask: 0.7091  mix_decode.d4.loss_dice: 0.8348  mix_decode.d5.loss_cls: 0.1414  mix_decode.d5.loss_mask: 0.7061  mix_decode.d5.loss_dice: 0.8223  mix_decode.d6.loss_cls: 0.1169  mix_decode.d6.loss_mask: 0.7106  mix_decode.d6.loss_dice: 0.8262  mix_decode.d7.loss_cls: 0.1094  mix_decode.d7.loss_mask: 0.7158  mix_decode.d7.loss_dice: 0.8285  mix_decode.d8.loss_cls: 0.1000  mix_decode.d8.loss_mask: 0.7113  mix_decode.d8.loss_dice: 0.8207
2025/03/28 10:33:14 - mmengine - INFO - Iter(train) [ 4250/20000]  base_lr: 8.0658e-05 lr: 8.0658e-05  eta: 2:22:44  time: 1.0695  data_time: 0.0222  memory: 10770  loss: 43.5464  decode.loss_cls: 0.0404  decode.loss_mask: 1.3262  decode.loss_dice: 1.3691  decode.d0.loss_cls: 0.1298  decode.d0.loss_mask: 1.3283  decode.d0.loss_dice: 1.3391  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 1.3159  decode.d1.loss_dice: 1.3703  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 1.3116  decode.d2.loss_dice: 1.3728  decode.d3.loss_cls: 0.1130  decode.d3.loss_mask: 1.3074  decode.d3.loss_dice: 1.3755  decode.d4.loss_cls: 0.1340  decode.d4.loss_mask: 1.3096  decode.d4.loss_dice: 1.3269  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 1.3250  decode.d5.loss_dice: 1.2977  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 1.3182  decode.d6.loss_dice: 1.3145  decode.d7.loss_cls: 0.0837  decode.d7.loss_mask: 1.3116  decode.d7.loss_dice: 1.3361  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 1.3171  decode.d8.loss_dice: 1.3655  mix_decode.loss_cls: 0.1129  mix_decode.loss_mask: 0.6537  mix_decode.loss_dice: 0.8251  mix_decode.d0.loss_cls: 0.1166  mix_decode.d0.loss_mask: 0.6502  mix_decode.d0.loss_dice: 0.8031  mix_decode.d1.loss_cls: 0.1178  mix_decode.d1.loss_mask: 0.6501  mix_decode.d1.loss_dice: 0.8144  mix_decode.d2.loss_cls: 0.0961  mix_decode.d2.loss_mask: 0.6538  mix_decode.d2.loss_dice: 0.8372  mix_decode.d3.loss_cls: 0.1178  mix_decode.d3.loss_mask: 0.6616  mix_decode.d3.loss_dice: 0.8339  mix_decode.d4.loss_cls: 0.1194  mix_decode.d4.loss_mask: 0.6747  mix_decode.d4.loss_dice: 0.8146  mix_decode.d5.loss_cls: 0.1238  mix_decode.d5.loss_mask: 0.6818  mix_decode.d5.loss_dice: 0.7955  mix_decode.d6.loss_cls: 0.1434  mix_decode.d6.loss_mask: 0.6537  mix_decode.d6.loss_dice: 0.8100  mix_decode.d7.loss_cls: 0.1480  mix_decode.d7.loss_mask: 0.6667  mix_decode.d7.loss_dice: 0.8259  mix_decode.d8.loss_cls: 0.1144  mix_decode.d8.loss_mask: 0.6594  mix_decode.d8.loss_dice: 0.8357
2025/03/28 10:34:08 - mmengine - INFO - Iter(train) [ 4300/20000]  base_lr: 8.0427e-05 lr: 8.0427e-05  eta: 2:23:55  time: 1.0753  data_time: 0.0226  memory: 10772  loss: 38.9797  decode.loss_cls: 0.1164  decode.loss_mask: 1.1654  decode.loss_dice: 1.1611  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 1.1827  decode.d0.loss_dice: 1.2134  decode.d1.loss_cls: 0.0986  decode.d1.loss_mask: 1.1566  decode.d1.loss_dice: 1.1642  decode.d2.loss_cls: 0.1106  decode.d2.loss_mask: 1.1534  decode.d2.loss_dice: 1.1594  decode.d3.loss_cls: 0.1231  decode.d3.loss_mask: 1.1646  decode.d3.loss_dice: 1.1837  decode.d4.loss_cls: 0.1095  decode.d4.loss_mask: 1.1644  decode.d4.loss_dice: 1.1633  decode.d5.loss_cls: 0.1066  decode.d5.loss_mask: 1.1664  decode.d5.loss_dice: 1.1825  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 1.1698  decode.d6.loss_dice: 1.1621  decode.d7.loss_cls: 0.1183  decode.d7.loss_mask: 1.1611  decode.d7.loss_dice: 1.1777  decode.d8.loss_cls: 0.1313  decode.d8.loss_mask: 1.1540  decode.d8.loss_dice: 1.1872  mix_decode.loss_cls: 0.1179  mix_decode.loss_mask: 0.6281  mix_decode.loss_dice: 0.7128  mix_decode.d0.loss_cls: 0.1211  mix_decode.d0.loss_mask: 0.6285  mix_decode.d0.loss_dice: 0.7172  mix_decode.d1.loss_cls: 0.0901  mix_decode.d1.loss_mask: 0.6325  mix_decode.d1.loss_dice: 0.6957  mix_decode.d2.loss_cls: 0.0877  mix_decode.d2.loss_mask: 0.6355  mix_decode.d2.loss_dice: 0.6963  mix_decode.d3.loss_cls: 0.1212  mix_decode.d3.loss_mask: 0.6365  mix_decode.d3.loss_dice: 0.7074  mix_decode.d4.loss_cls: 0.1158  mix_decode.d4.loss_mask: 0.6326  mix_decode.d4.loss_dice: 0.7002  mix_decode.d5.loss_cls: 0.1397  mix_decode.d5.loss_mask: 0.6313  mix_decode.d5.loss_dice: 0.7064  mix_decode.d6.loss_cls: 0.1022  mix_decode.d6.loss_mask: 0.6300  mix_decode.d6.loss_dice: 0.6908  mix_decode.d7.loss_cls: 0.1121  mix_decode.d7.loss_mask: 0.6288  mix_decode.d7.loss_dice: 0.7124  mix_decode.d8.loss_cls: 0.1202  mix_decode.d8.loss_mask: 0.6299  mix_decode.d8.loss_dice: 0.7116
2025/03/28 10:35:02 - mmengine - INFO - Iter(train) [ 4350/20000]  base_lr: 8.0197e-05 lr: 8.0197e-05  eta: 2:25:01  time: 1.0681  data_time: 0.0221  memory: 10773  loss: 42.9931  decode.loss_cls: 0.0173  decode.loss_mask: 1.3846  decode.loss_dice: 1.3633  decode.d0.loss_cls: 0.1153  decode.d0.loss_mask: 1.3233  decode.d0.loss_dice: 1.3393  decode.d1.loss_cls: 0.0249  decode.d1.loss_mask: 1.3981  decode.d1.loss_dice: 1.3651  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 1.3907  decode.d2.loss_dice: 1.3720  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 1.3734  decode.d3.loss_dice: 1.3566  decode.d4.loss_cls: 0.0259  decode.d4.loss_mask: 1.3989  decode.d4.loss_dice: 1.3422  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 1.3838  decode.d5.loss_dice: 1.3572  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 1.3894  decode.d6.loss_dice: 1.3727  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 1.4023  decode.d7.loss_dice: 1.3540  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 1.3811  decode.d8.loss_dice: 1.3725  mix_decode.loss_cls: 0.1006  mix_decode.loss_mask: 0.6287  mix_decode.loss_dice: 0.8081  mix_decode.d0.loss_cls: 0.0997  mix_decode.d0.loss_mask: 0.6363  mix_decode.d0.loss_dice: 0.8179  mix_decode.d1.loss_cls: 0.0773  mix_decode.d1.loss_mask: 0.6331  mix_decode.d1.loss_dice: 0.8125  mix_decode.d2.loss_cls: 0.0987  mix_decode.d2.loss_mask: 0.6269  mix_decode.d2.loss_dice: 0.8143  mix_decode.d3.loss_cls: 0.0617  mix_decode.d3.loss_mask: 0.6251  mix_decode.d3.loss_dice: 0.8042  mix_decode.d4.loss_cls: 0.0447  mix_decode.d4.loss_mask: 0.6360  mix_decode.d4.loss_dice: 0.8069  mix_decode.d5.loss_cls: 0.1010  mix_decode.d5.loss_mask: 0.6255  mix_decode.d5.loss_dice: 0.8163  mix_decode.d6.loss_cls: 0.0635  mix_decode.d6.loss_mask: 0.6278  mix_decode.d6.loss_dice: 0.8231  mix_decode.d7.loss_cls: 0.0863  mix_decode.d7.loss_mask: 0.6277  mix_decode.d7.loss_dice: 0.8017  mix_decode.d8.loss_cls: 0.0842  mix_decode.d8.loss_mask: 0.6462  mix_decode.d8.loss_dice: 0.8141
2025/03/28 10:35:56 - mmengine - INFO - Iter(train) [ 4400/20000]  base_lr: 7.9966e-05 lr: 7.9966e-05  eta: 2:26:05  time: 1.0733  data_time: 0.0227  memory: 10770  loss: 38.3750  decode.loss_cls: 0.0780  decode.loss_mask: 1.0528  decode.loss_dice: 1.2267  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 1.0608  decode.d0.loss_dice: 1.2501  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 1.0591  decode.d1.loss_dice: 1.2570  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 1.0455  decode.d2.loss_dice: 1.2414  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 1.0572  decode.d3.loss_dice: 1.2540  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 1.0569  decode.d4.loss_dice: 1.2537  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 1.0617  decode.d5.loss_dice: 1.2358  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 1.0589  decode.d6.loss_dice: 1.2331  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 1.0567  decode.d7.loss_dice: 1.2372  decode.d8.loss_cls: 0.0713  decode.d8.loss_mask: 1.0520  decode.d8.loss_dice: 1.2457  mix_decode.loss_cls: 0.1168  mix_decode.loss_mask: 0.6667  mix_decode.loss_dice: 0.7101  mix_decode.d0.loss_cls: 0.1007  mix_decode.d0.loss_mask: 0.6612  mix_decode.d0.loss_dice: 0.7230  mix_decode.d1.loss_cls: 0.1140  mix_decode.d1.loss_mask: 0.6551  mix_decode.d1.loss_dice: 0.6977  mix_decode.d2.loss_cls: 0.1311  mix_decode.d2.loss_mask: 0.6503  mix_decode.d2.loss_dice: 0.7060  mix_decode.d3.loss_cls: 0.0899  mix_decode.d3.loss_mask: 0.6783  mix_decode.d3.loss_dice: 0.7050  mix_decode.d4.loss_cls: 0.0945  mix_decode.d4.loss_mask: 0.6723  mix_decode.d4.loss_dice: 0.6967  mix_decode.d5.loss_cls: 0.1106  mix_decode.d5.loss_mask: 0.6697  mix_decode.d5.loss_dice: 0.6940  mix_decode.d6.loss_cls: 0.1095  mix_decode.d6.loss_mask: 0.6764  mix_decode.d6.loss_dice: 0.6957  mix_decode.d7.loss_cls: 0.1092  mix_decode.d7.loss_mask: 0.6681  mix_decode.d7.loss_dice: 0.7130  mix_decode.d8.loss_cls: 0.1001  mix_decode.d8.loss_mask: 0.6650  mix_decode.d8.loss_dice: 0.7077
2025/03/28 10:36:49 - mmengine - INFO - Iter(train) [ 4450/20000]  base_lr: 7.9735e-05 lr: 7.9735e-05  eta: 2:27:06  time: 1.0696  data_time: 0.0223  memory: 10772  loss: 41.3169  decode.loss_cls: 0.0668  decode.loss_mask: 1.1888  decode.loss_dice: 1.2200  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 1.2022  decode.d0.loss_dice: 1.2398  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 1.1892  decode.d1.loss_dice: 1.2276  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 1.1872  decode.d2.loss_dice: 1.2337  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 1.1902  decode.d3.loss_dice: 1.2382  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 1.1965  decode.d4.loss_dice: 1.2337  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 1.1950  decode.d5.loss_dice: 1.2295  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 1.1930  decode.d6.loss_dice: 1.2211  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 1.1924  decode.d7.loss_dice: 1.2249  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 1.1857  decode.d8.loss_dice: 1.2411  mix_decode.loss_cls: 0.1119  mix_decode.loss_mask: 0.6730  mix_decode.loss_dice: 0.8446  mix_decode.d0.loss_cls: 0.1289  mix_decode.d0.loss_mask: 0.6565  mix_decode.d0.loss_dice: 0.8399  mix_decode.d1.loss_cls: 0.1371  mix_decode.d1.loss_mask: 0.6719  mix_decode.d1.loss_dice: 0.8320  mix_decode.d2.loss_cls: 0.1356  mix_decode.d2.loss_mask: 0.6713  mix_decode.d2.loss_dice: 0.8358  mix_decode.d3.loss_cls: 0.1468  mix_decode.d3.loss_mask: 0.6706  mix_decode.d3.loss_dice: 0.8349  mix_decode.d4.loss_cls: 0.1361  mix_decode.d4.loss_mask: 0.6770  mix_decode.d4.loss_dice: 0.8399  mix_decode.d5.loss_cls: 0.1192  mix_decode.d5.loss_mask: 0.6797  mix_decode.d5.loss_dice: 0.8601  mix_decode.d6.loss_cls: 0.1093  mix_decode.d6.loss_mask: 0.6811  mix_decode.d6.loss_dice: 0.8428  mix_decode.d7.loss_cls: 0.1329  mix_decode.d7.loss_mask: 0.6784  mix_decode.d7.loss_dice: 0.8510  mix_decode.d8.loss_cls: 0.1405  mix_decode.d8.loss_mask: 0.6805  mix_decode.d8.loss_dice: 0.8439
2025/03/28 10:37:43 - mmengine - INFO - Iter(train) [ 4500/20000]  base_lr: 7.9504e-05 lr: 7.9504e-05  eta: 2:28:05  time: 1.0734  data_time: 0.0229  memory: 10782  loss: 39.9739  decode.loss_cls: 0.1251  decode.loss_mask: 1.0758  decode.loss_dice: 1.1110  decode.d0.loss_cls: 0.1595  decode.d0.loss_mask: 1.0772  decode.d0.loss_dice: 1.1535  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 1.0681  decode.d1.loss_dice: 1.1163  decode.d2.loss_cls: 0.1584  decode.d2.loss_mask: 1.0655  decode.d2.loss_dice: 1.1260  decode.d3.loss_cls: 0.1610  decode.d3.loss_mask: 1.0753  decode.d3.loss_dice: 1.1264  decode.d4.loss_cls: 0.1630  decode.d4.loss_mask: 1.0799  decode.d4.loss_dice: 1.1359  decode.d5.loss_cls: 0.1553  decode.d5.loss_mask: 1.0738  decode.d5.loss_dice: 1.1364  decode.d6.loss_cls: 0.1443  decode.d6.loss_mask: 1.0764  decode.d6.loss_dice: 1.1206  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 1.0746  decode.d7.loss_dice: 1.1156  decode.d8.loss_cls: 0.1418  decode.d8.loss_mask: 1.0723  decode.d8.loss_dice: 1.1130  mix_decode.loss_cls: 0.1352  mix_decode.loss_mask: 0.6140  mix_decode.loss_dice: 0.9065  mix_decode.d0.loss_cls: 0.1208  mix_decode.d0.loss_mask: 0.6066  mix_decode.d0.loss_dice: 0.9182  mix_decode.d1.loss_cls: 0.1201  mix_decode.d1.loss_mask: 0.6004  mix_decode.d1.loss_dice: 0.8900  mix_decode.d2.loss_cls: 0.1357  mix_decode.d2.loss_mask: 0.6068  mix_decode.d2.loss_dice: 0.8934  mix_decode.d3.loss_cls: 0.1676  mix_decode.d3.loss_mask: 0.6117  mix_decode.d3.loss_dice: 0.8858  mix_decode.d4.loss_cls: 0.1528  mix_decode.d4.loss_mask: 0.6037  mix_decode.d4.loss_dice: 0.8943  mix_decode.d5.loss_cls: 0.1482  mix_decode.d5.loss_mask: 0.6082  mix_decode.d5.loss_dice: 0.8953  mix_decode.d6.loss_cls: 0.1809  mix_decode.d6.loss_mask: 0.6040  mix_decode.d6.loss_dice: 0.8847  mix_decode.d7.loss_cls: 0.1458  mix_decode.d7.loss_mask: 0.6083  mix_decode.d7.loss_dice: 0.8849  mix_decode.d8.loss_cls: 0.1029  mix_decode.d8.loss_mask: 0.6150  mix_decode.d8.loss_dice: 0.9012
2025/03/28 10:38:36 - mmengine - INFO - Iter(train) [ 4550/20000]  base_lr: 7.9274e-05 lr: 7.9274e-05  eta: 2:29:01  time: 1.0663  data_time: 0.0228  memory: 10765  loss: 43.6761  decode.loss_cls: 0.0364  decode.loss_mask: 1.3185  decode.loss_dice: 1.2259  decode.d0.loss_cls: 0.1151  decode.d0.loss_mask: 1.2845  decode.d0.loss_dice: 1.2139  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 1.3182  decode.d1.loss_dice: 1.2467  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 1.3112  decode.d2.loss_dice: 1.2523  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 1.3065  decode.d3.loss_dice: 1.2623  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 1.3148  decode.d4.loss_dice: 1.2441  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 1.3052  decode.d5.loss_dice: 1.2658  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 1.3147  decode.d6.loss_dice: 1.2198  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 1.3199  decode.d7.loss_dice: 1.2257  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 1.3161  decode.d8.loss_dice: 1.2228  mix_decode.loss_cls: 0.1051  mix_decode.loss_mask: 0.8085  mix_decode.loss_dice: 0.8760  mix_decode.d0.loss_cls: 0.0999  mix_decode.d0.loss_mask: 0.7749  mix_decode.d0.loss_dice: 0.8734  mix_decode.d1.loss_cls: 0.0958  mix_decode.d1.loss_mask: 0.7898  mix_decode.d1.loss_dice: 0.8751  mix_decode.d2.loss_cls: 0.0959  mix_decode.d2.loss_mask: 0.7955  mix_decode.d2.loss_dice: 0.8865  mix_decode.d3.loss_cls: 0.0728  mix_decode.d3.loss_mask: 0.8150  mix_decode.d3.loss_dice: 0.8822  mix_decode.d4.loss_cls: 0.0968  mix_decode.d4.loss_mask: 0.7958  mix_decode.d4.loss_dice: 0.8902  mix_decode.d5.loss_cls: 0.0720  mix_decode.d5.loss_mask: 0.8112  mix_decode.d5.loss_dice: 0.8901  mix_decode.d6.loss_cls: 0.0879  mix_decode.d6.loss_mask: 0.7840  mix_decode.d6.loss_dice: 0.8700  mix_decode.d7.loss_cls: 0.0654  mix_decode.d7.loss_mask: 0.8136  mix_decode.d7.loss_dice: 0.8822  mix_decode.d8.loss_cls: 0.0935  mix_decode.d8.loss_mask: 0.7924  mix_decode.d8.loss_dice: 0.8832
2025/03/28 10:39:30 - mmengine - INFO - Iter(train) [ 4600/20000]  base_lr: 7.9043e-05 lr: 7.9043e-05  eta: 2:29:54  time: 1.0674  data_time: 0.0220  memory: 10774  loss: 45.6919  decode.loss_cls: 0.0288  decode.loss_mask: 1.4621  decode.loss_dice: 1.4113  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 1.4943  decode.d0.loss_dice: 1.4012  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 1.4788  decode.d1.loss_dice: 1.4122  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 1.4690  decode.d2.loss_dice: 1.4033  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 1.4645  decode.d3.loss_dice: 1.4115  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 1.4575  decode.d4.loss_dice: 1.3974  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 1.4634  decode.d5.loss_dice: 1.4215  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 1.4630  decode.d6.loss_dice: 1.4068  decode.d7.loss_cls: 0.0267  decode.d7.loss_mask: 1.4708  decode.d7.loss_dice: 1.4112  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 1.4673  decode.d8.loss_dice: 1.4131  mix_decode.loss_cls: 0.1212  mix_decode.loss_mask: 0.6735  mix_decode.loss_dice: 0.8635  mix_decode.d0.loss_cls: 0.1135  mix_decode.d0.loss_mask: 0.6803  mix_decode.d0.loss_dice: 0.8801  mix_decode.d1.loss_cls: 0.1053  mix_decode.d1.loss_mask: 0.6716  mix_decode.d1.loss_dice: 0.8559  mix_decode.d2.loss_cls: 0.1038  mix_decode.d2.loss_mask: 0.6651  mix_decode.d2.loss_dice: 0.8494  mix_decode.d3.loss_cls: 0.0882  mix_decode.d3.loss_mask: 0.6705  mix_decode.d3.loss_dice: 0.8462  mix_decode.d4.loss_cls: 0.1029  mix_decode.d4.loss_mask: 0.6752  mix_decode.d4.loss_dice: 0.8511  mix_decode.d5.loss_cls: 0.0955  mix_decode.d5.loss_mask: 0.6763  mix_decode.d5.loss_dice: 0.8627  mix_decode.d6.loss_cls: 0.1003  mix_decode.d6.loss_mask: 0.6713  mix_decode.d6.loss_dice: 0.8559  mix_decode.d7.loss_cls: 0.1158  mix_decode.d7.loss_mask: 0.6723  mix_decode.d7.loss_dice: 0.8693  mix_decode.d8.loss_cls: 0.1214  mix_decode.d8.loss_mask: 0.6735  mix_decode.d8.loss_dice: 0.8663
2025/03/28 10:40:23 - mmengine - INFO - Iter(train) [ 4650/20000]  base_lr: 7.8812e-05 lr: 7.8812e-05  eta: 2:30:45  time: 1.0844  data_time: 0.0246  memory: 10765  loss: 38.5627  decode.loss_cls: 0.0883  decode.loss_mask: 1.0434  decode.loss_dice: 1.2845  decode.d0.loss_cls: 0.1134  decode.d0.loss_mask: 1.0405  decode.d0.loss_dice: 1.2579  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 1.0401  decode.d1.loss_dice: 1.2944  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 1.0419  decode.d2.loss_dice: 1.3270  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 1.0401  decode.d3.loss_dice: 1.3007  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 1.0399  decode.d4.loss_dice: 1.2906  decode.d5.loss_cls: 0.0808  decode.d5.loss_mask: 1.0464  decode.d5.loss_dice: 1.3221  decode.d6.loss_cls: 0.1092  decode.d6.loss_mask: 1.0411  decode.d6.loss_dice: 1.2723  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 1.0462  decode.d7.loss_dice: 1.2672  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 1.0395  decode.d8.loss_dice: 1.2893  mix_decode.loss_cls: 0.1204  mix_decode.loss_mask: 0.5808  mix_decode.loss_dice: 0.7561  mix_decode.d0.loss_cls: 0.1280  mix_decode.d0.loss_mask: 0.5682  mix_decode.d0.loss_dice: 0.7529  mix_decode.d1.loss_cls: 0.1122  mix_decode.d1.loss_mask: 0.5752  mix_decode.d1.loss_dice: 0.7581  mix_decode.d2.loss_cls: 0.1077  mix_decode.d2.loss_mask: 0.5731  mix_decode.d2.loss_dice: 0.7611  mix_decode.d3.loss_cls: 0.0991  mix_decode.d3.loss_mask: 0.5726  mix_decode.d3.loss_dice: 0.7567  mix_decode.d4.loss_cls: 0.0993  mix_decode.d4.loss_mask: 0.5730  mix_decode.d4.loss_dice: 0.7535  mix_decode.d5.loss_cls: 0.1113  mix_decode.d5.loss_mask: 0.5725  mix_decode.d5.loss_dice: 0.7549  mix_decode.d6.loss_cls: 0.1083  mix_decode.d6.loss_mask: 0.5728  mix_decode.d6.loss_dice: 0.7405  mix_decode.d7.loss_cls: 0.1401  mix_decode.d7.loss_mask: 0.5764  mix_decode.d7.loss_dice: 0.7450  mix_decode.d8.loss_cls: 0.1222  mix_decode.d8.loss_mask: 0.5751  mix_decode.d8.loss_dice: 0.7556
2025/03/28 10:41:17 - mmengine - INFO - Iter(train) [ 4700/20000]  base_lr: 7.8581e-05 lr: 7.8581e-05  eta: 2:31:35  time: 1.0844  data_time: 0.0234  memory: 10774  loss: 38.8801  decode.loss_cls: 0.0293  decode.loss_mask: 1.1651  decode.loss_dice: 1.1143  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 1.1737  decode.d0.loss_dice: 1.1542  decode.d1.loss_cls: 0.0402  decode.d1.loss_mask: 1.1644  decode.d1.loss_dice: 1.1003  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 1.1627  decode.d2.loss_dice: 1.1019  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 1.1683  decode.d3.loss_dice: 1.1172  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 1.1716  decode.d4.loss_dice: 1.1082  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 1.1695  decode.d5.loss_dice: 1.0936  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 1.1638  decode.d6.loss_dice: 1.0930  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 1.1694  decode.d7.loss_dice: 1.1013  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 1.1695  decode.d8.loss_dice: 1.1081  mix_decode.loss_cls: 0.0787  mix_decode.loss_mask: 0.6985  mix_decode.loss_dice: 0.7663  mix_decode.d0.loss_cls: 0.1161  mix_decode.d0.loss_mask: 0.6981  mix_decode.d0.loss_dice: 0.7892  mix_decode.d1.loss_cls: 0.1077  mix_decode.d1.loss_mask: 0.6929  mix_decode.d1.loss_dice: 0.7582  mix_decode.d2.loss_cls: 0.1290  mix_decode.d2.loss_mask: 0.6935  mix_decode.d2.loss_dice: 0.7583  mix_decode.d3.loss_cls: 0.1372  mix_decode.d3.loss_mask: 0.6944  mix_decode.d3.loss_dice: 0.7641  mix_decode.d4.loss_cls: 0.1477  mix_decode.d4.loss_mask: 0.6926  mix_decode.d4.loss_dice: 0.7683  mix_decode.d5.loss_cls: 0.1114  mix_decode.d5.loss_mask: 0.6945  mix_decode.d5.loss_dice: 0.7665  mix_decode.d6.loss_cls: 0.0885  mix_decode.d6.loss_mask: 0.6976  mix_decode.d6.loss_dice: 0.7511  mix_decode.d7.loss_cls: 0.1250  mix_decode.d7.loss_mask: 0.6916  mix_decode.d7.loss_dice: 0.7541  mix_decode.d8.loss_cls: 0.0776  mix_decode.d8.loss_mask: 0.7041  mix_decode.d8.loss_dice: 0.7648
2025/03/28 10:42:11 - mmengine - INFO - Iter(train) [ 4750/20000]  base_lr: 7.8349e-05 lr: 7.8349e-05  eta: 2:32:22  time: 1.0697  data_time: 0.0221  memory: 10769  loss: 38.9004  decode.loss_cls: 0.0772  decode.loss_mask: 1.0797  decode.loss_dice: 1.2115  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 1.1064  decode.d0.loss_dice: 1.2676  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 1.0773  decode.d1.loss_dice: 1.2235  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 1.0806  decode.d2.loss_dice: 1.2142  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 1.0725  decode.d3.loss_dice: 1.2098  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 1.0748  decode.d4.loss_dice: 1.2450  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 1.0720  decode.d5.loss_dice: 1.2288  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 1.0847  decode.d6.loss_dice: 1.2399  decode.d7.loss_cls: 0.0754  decode.d7.loss_mask: 1.0783  decode.d7.loss_dice: 1.2175  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 1.0856  decode.d8.loss_dice: 1.2452  mix_decode.loss_cls: 0.0939  mix_decode.loss_mask: 0.6122  mix_decode.loss_dice: 0.7817  mix_decode.d0.loss_cls: 0.1073  mix_decode.d0.loss_mask: 0.6219  mix_decode.d0.loss_dice: 0.8025  mix_decode.d1.loss_cls: 0.0960  mix_decode.d1.loss_mask: 0.6176  mix_decode.d1.loss_dice: 0.7816  mix_decode.d2.loss_cls: 0.1188  mix_decode.d2.loss_mask: 0.6207  mix_decode.d2.loss_dice: 0.7739  mix_decode.d3.loss_cls: 0.1057  mix_decode.d3.loss_mask: 0.6199  mix_decode.d3.loss_dice: 0.7780  mix_decode.d4.loss_cls: 0.0875  mix_decode.d4.loss_mask: 0.6128  mix_decode.d4.loss_dice: 0.7827  mix_decode.d5.loss_cls: 0.0859  mix_decode.d5.loss_mask: 0.6141  mix_decode.d5.loss_dice: 0.7892  mix_decode.d6.loss_cls: 0.0922  mix_decode.d6.loss_mask: 0.6186  mix_decode.d6.loss_dice: 0.7899  mix_decode.d7.loss_cls: 0.0909  mix_decode.d7.loss_mask: 0.6124  mix_decode.d7.loss_dice: 0.8078  mix_decode.d8.loss_cls: 0.1116  mix_decode.d8.loss_mask: 0.6154  mix_decode.d8.loss_dice: 0.7818
2025/03/28 10:43:05 - mmengine - INFO - Iter(train) [ 4800/20000]  base_lr: 7.8118e-05 lr: 7.8118e-05  eta: 2:33:07  time: 1.0888  data_time: 0.0242  memory: 10778  loss: 42.0096  decode.loss_cls: 0.0726  decode.loss_mask: 1.2686  decode.loss_dice: 1.2550  decode.d0.loss_cls: 0.1127  decode.d0.loss_mask: 1.2775  decode.d0.loss_dice: 1.2562  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 1.2634  decode.d1.loss_dice: 1.2808  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 1.2670  decode.d2.loss_dice: 1.2724  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 1.2637  decode.d3.loss_dice: 1.2752  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 1.2661  decode.d4.loss_dice: 1.2705  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 1.2599  decode.d5.loss_dice: 1.2670  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 1.2633  decode.d6.loss_dice: 1.2464  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 1.2656  decode.d7.loss_dice: 1.2740  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 1.2721  decode.d8.loss_dice: 1.2651  mix_decode.loss_cls: 0.0930  mix_decode.loss_mask: 0.7222  mix_decode.loss_dice: 0.7688  mix_decode.d0.loss_cls: 0.1036  mix_decode.d0.loss_mask: 0.7103  mix_decode.d0.loss_dice: 0.7949  mix_decode.d1.loss_cls: 0.0984  mix_decode.d1.loss_mask: 0.7325  mix_decode.d1.loss_dice: 0.7835  mix_decode.d2.loss_cls: 0.0767  mix_decode.d2.loss_mask: 0.7261  mix_decode.d2.loss_dice: 0.7707  mix_decode.d3.loss_cls: 0.0819  mix_decode.d3.loss_mask: 0.7272  mix_decode.d3.loss_dice: 0.7889  mix_decode.d4.loss_cls: 0.0777  mix_decode.d4.loss_mask: 0.7288  mix_decode.d4.loss_dice: 0.7660  mix_decode.d5.loss_cls: 0.0884  mix_decode.d5.loss_mask: 0.7292  mix_decode.d5.loss_dice: 0.7796  mix_decode.d6.loss_cls: 0.1152  mix_decode.d6.loss_mask: 0.7309  mix_decode.d6.loss_dice: 0.7781  mix_decode.d7.loss_cls: 0.1163  mix_decode.d7.loss_mask: 0.7311  mix_decode.d7.loss_dice: 0.7805  mix_decode.d8.loss_cls: 0.0817  mix_decode.d8.loss_mask: 0.7486  mix_decode.d8.loss_dice: 0.7819
2025/03/28 10:43:58 - mmengine - INFO - Iter(train) [ 4850/20000]  base_lr: 7.7887e-05 lr: 7.7887e-05  eta: 2:33:50  time: 1.0687  data_time: 0.0225  memory: 10770  loss: 41.8831  decode.loss_cls: 0.0191  decode.loss_mask: 1.2919  decode.loss_dice: 1.2114  decode.d0.loss_cls: 0.0817  decode.d0.loss_mask: 1.3161  decode.d0.loss_dice: 1.2118  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 1.2965  decode.d1.loss_dice: 1.2194  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 1.2939  decode.d2.loss_dice: 1.2008  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 1.2935  decode.d3.loss_dice: 1.1971  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 1.2904  decode.d4.loss_dice: 1.1882  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 1.2984  decode.d5.loss_dice: 1.2124  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 1.2939  decode.d6.loss_dice: 1.2040  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 1.2915  decode.d7.loss_dice: 1.2148  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 1.2909  decode.d8.loss_dice: 1.2131  mix_decode.loss_cls: 0.1599  mix_decode.loss_mask: 0.6723  mix_decode.loss_dice: 0.8177  mix_decode.d0.loss_cls: 0.1296  mix_decode.d0.loss_mask: 0.6809  mix_decode.d0.loss_dice: 0.8620  mix_decode.d1.loss_cls: 0.1666  mix_decode.d1.loss_mask: 0.6579  mix_decode.d1.loss_dice: 0.8232  mix_decode.d2.loss_cls: 0.1669  mix_decode.d2.loss_mask: 0.6693  mix_decode.d2.loss_dice: 0.8171  mix_decode.d3.loss_cls: 0.1960  mix_decode.d3.loss_mask: 0.6575  mix_decode.d3.loss_dice: 0.7867  mix_decode.d4.loss_cls: 0.1854  mix_decode.d4.loss_mask: 0.6668  mix_decode.d4.loss_dice: 0.8002  mix_decode.d5.loss_cls: 0.1970  mix_decode.d5.loss_mask: 0.6443  mix_decode.d5.loss_dice: 0.7873  mix_decode.d6.loss_cls: 0.1419  mix_decode.d6.loss_mask: 0.6764  mix_decode.d6.loss_dice: 0.8538  mix_decode.d7.loss_cls: 0.2456  mix_decode.d7.loss_mask: 0.6521  mix_decode.d7.loss_dice: 0.8065  mix_decode.d8.loss_cls: 0.2417  mix_decode.d8.loss_mask: 0.6543  mix_decode.d8.loss_dice: 0.7818
2025/03/28 10:44:52 - mmengine - INFO - Iter(train) [ 4900/20000]  base_lr: 7.7655e-05 lr: 7.7655e-05  eta: 2:34:31  time: 1.0700  data_time: 0.0225  memory: 10772  loss: 45.4982  decode.loss_cls: 0.0316  decode.loss_mask: 1.4848  decode.loss_dice: 1.3490  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 1.4927  decode.d0.loss_dice: 1.3667  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 1.4746  decode.d1.loss_dice: 1.3371  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 1.4740  decode.d2.loss_dice: 1.3309  decode.d3.loss_cls: 0.0817  decode.d3.loss_mask: 1.4807  decode.d3.loss_dice: 1.3243  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 1.4670  decode.d4.loss_dice: 1.3236  decode.d5.loss_cls: 0.0835  decode.d5.loss_mask: 1.4803  decode.d5.loss_dice: 1.3418  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 1.4710  decode.d6.loss_dice: 1.3389  decode.d7.loss_cls: 0.0911  decode.d7.loss_mask: 1.4718  decode.d7.loss_dice: 1.3300  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 1.4817  decode.d8.loss_dice: 1.3526  mix_decode.loss_cls: 0.0610  mix_decode.loss_mask: 0.7591  mix_decode.loss_dice: 0.8377  mix_decode.d0.loss_cls: 0.0526  mix_decode.d0.loss_mask: 0.7726  mix_decode.d0.loss_dice: 0.8541  mix_decode.d1.loss_cls: 0.0630  mix_decode.d1.loss_mask: 0.7602  mix_decode.d1.loss_dice: 0.8313  mix_decode.d2.loss_cls: 0.0613  mix_decode.d2.loss_mask: 0.7642  mix_decode.d2.loss_dice: 0.8316  mix_decode.d3.loss_cls: 0.0683  mix_decode.d3.loss_mask: 0.7647  mix_decode.d3.loss_dice: 0.8286  mix_decode.d4.loss_cls: 0.0728  mix_decode.d4.loss_mask: 0.7612  mix_decode.d4.loss_dice: 0.8367  mix_decode.d5.loss_cls: 0.0400  mix_decode.d5.loss_mask: 0.7658  mix_decode.d5.loss_dice: 0.8488  mix_decode.d6.loss_cls: 0.0399  mix_decode.d6.loss_mask: 0.7615  mix_decode.d6.loss_dice: 0.8430  mix_decode.d7.loss_cls: 0.0342  mix_decode.d7.loss_mask: 0.7610  mix_decode.d7.loss_dice: 0.8561  mix_decode.d8.loss_cls: 0.0603  mix_decode.d8.loss_mask: 0.7644  mix_decode.d8.loss_dice: 0.8421
2025/03/28 10:45:46 - mmengine - INFO - Iter(train) [ 4950/20000]  base_lr: 7.7424e-05 lr: 7.7424e-05  eta: 2:35:12  time: 1.0795  data_time: 0.0231  memory: 10774  loss: 39.2356  decode.loss_cls: 0.0956  decode.loss_mask: 1.2120  decode.loss_dice: 1.2724  decode.d0.loss_cls: 0.1270  decode.d0.loss_mask: 1.2225  decode.d0.loss_dice: 1.3020  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 1.2079  decode.d1.loss_dice: 1.2846  decode.d2.loss_cls: 0.0902  decode.d2.loss_mask: 1.2087  decode.d2.loss_dice: 1.2922  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 1.2065  decode.d3.loss_dice: 1.2898  decode.d4.loss_cls: 0.1037  decode.d4.loss_mask: 1.2037  decode.d4.loss_dice: 1.2723  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 1.2075  decode.d5.loss_dice: 1.2665  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 1.2049  decode.d6.loss_dice: 1.2690  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 1.2128  decode.d7.loss_dice: 1.2682  decode.d8.loss_cls: 0.1143  decode.d8.loss_mask: 1.2074  decode.d8.loss_dice: 1.2992  mix_decode.loss_cls: 0.0385  mix_decode.loss_mask: 0.5901  mix_decode.loss_dice: 0.6879  mix_decode.d0.loss_cls: 0.0554  mix_decode.d0.loss_mask: 0.5944  mix_decode.d0.loss_dice: 0.6969  mix_decode.d1.loss_cls: 0.0216  mix_decode.d1.loss_mask: 0.5898  mix_decode.d1.loss_dice: 0.7039  mix_decode.d2.loss_cls: 0.0419  mix_decode.d2.loss_mask: 0.5983  mix_decode.d2.loss_dice: 0.6966  mix_decode.d3.loss_cls: 0.0364  mix_decode.d3.loss_mask: 0.5942  mix_decode.d3.loss_dice: 0.6935  mix_decode.d4.loss_cls: 0.0439  mix_decode.d4.loss_mask: 0.5931  mix_decode.d4.loss_dice: 0.6984  mix_decode.d5.loss_cls: 0.0440  mix_decode.d5.loss_mask: 0.5934  mix_decode.d5.loss_dice: 0.6970  mix_decode.d6.loss_cls: 0.0434  mix_decode.d6.loss_mask: 0.5922  mix_decode.d6.loss_dice: 0.6897  mix_decode.d7.loss_cls: 0.0449  mix_decode.d7.loss_mask: 0.5863  mix_decode.d7.loss_dice: 0.6935  mix_decode.d8.loss_cls: 0.0453  mix_decode.d8.loss_mask: 0.5897  mix_decode.d8.loss_dice: 0.6953
2025/03/28 10:46:40 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 10:46:40 - mmengine - INFO - Iter(train) [ 5000/20000]  base_lr: 7.7192e-05 lr: 7.7192e-05  eta: 2:35:50  time: 1.0765  data_time: 0.0238  memory: 10771  loss: 37.3125  decode.loss_cls: 0.0261  decode.loss_mask: 1.0300  decode.loss_dice: 1.1155  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 1.0315  decode.d0.loss_dice: 1.1163  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 1.0142  decode.d1.loss_dice: 1.1110  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 1.0159  decode.d2.loss_dice: 1.1187  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 1.0224  decode.d3.loss_dice: 1.1142  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 1.0246  decode.d4.loss_dice: 1.1036  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 1.0227  decode.d5.loss_dice: 1.1235  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 1.0244  decode.d6.loss_dice: 1.1068  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 1.0270  decode.d7.loss_dice: 1.1237  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 1.0266  decode.d8.loss_dice: 1.1107  mix_decode.loss_cls: 0.1638  mix_decode.loss_mask: 0.5822  mix_decode.loss_dice: 0.8021  mix_decode.d0.loss_cls: 0.1048  mix_decode.d0.loss_mask: 0.5981  mix_decode.d0.loss_dice: 0.8538  mix_decode.d1.loss_cls: 0.1371  mix_decode.d1.loss_mask: 0.5859  mix_decode.d1.loss_dice: 0.8003  mix_decode.d2.loss_cls: 0.1376  mix_decode.d2.loss_mask: 0.6111  mix_decode.d2.loss_dice: 0.8049  mix_decode.d3.loss_cls: 0.1380  mix_decode.d3.loss_mask: 0.5992  mix_decode.d3.loss_dice: 0.8107  mix_decode.d4.loss_cls: 0.1848  mix_decode.d4.loss_mask: 0.6006  mix_decode.d4.loss_dice: 0.8060  mix_decode.d5.loss_cls: 0.1615  mix_decode.d5.loss_mask: 0.6114  mix_decode.d5.loss_dice: 0.8205  mix_decode.d6.loss_cls: 0.1646  mix_decode.d6.loss_mask: 0.6162  mix_decode.d6.loss_dice: 0.8143  mix_decode.d7.loss_cls: 0.1257  mix_decode.d7.loss_mask: 0.6118  mix_decode.d7.loss_dice: 0.8269  mix_decode.d8.loss_cls: 0.1525  mix_decode.d8.loss_mask: 0.5816  mix_decode.d8.loss_dice: 0.8167
2025/03/28 10:47:34 - mmengine - INFO - Iter(train) [ 5050/20000]  base_lr: 7.6961e-05 lr: 7.6961e-05  eta: 2:36:26  time: 1.0953  data_time: 0.0242  memory: 10770  loss: 39.9207  decode.loss_cls: 0.0812  decode.loss_mask: 1.1564  decode.loss_dice: 1.1840  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 1.1856  decode.d0.loss_dice: 1.2206  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 1.1525  decode.d1.loss_dice: 1.1800  decode.d2.loss_cls: 0.0894  decode.d2.loss_mask: 1.1621  decode.d2.loss_dice: 1.1906  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 1.1517  decode.d3.loss_dice: 1.1706  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 1.1543  decode.d4.loss_dice: 1.1646  decode.d5.loss_cls: 0.0878  decode.d5.loss_mask: 1.1480  decode.d5.loss_dice: 1.1652  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 1.1551  decode.d6.loss_dice: 1.1775  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 1.1500  decode.d7.loss_dice: 1.1898  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 1.1590  decode.d8.loss_dice: 1.1555  mix_decode.loss_cls: 0.1234  mix_decode.loss_mask: 0.6514  mix_decode.loss_dice: 0.7999  mix_decode.d0.loss_cls: 0.1307  mix_decode.d0.loss_mask: 0.6613  mix_decode.d0.loss_dice: 0.8119  mix_decode.d1.loss_cls: 0.1547  mix_decode.d1.loss_mask: 0.6396  mix_decode.d1.loss_dice: 0.7834  mix_decode.d2.loss_cls: 0.1628  mix_decode.d2.loss_mask: 0.6420  mix_decode.d2.loss_dice: 0.7829  mix_decode.d3.loss_cls: 0.1452  mix_decode.d3.loss_mask: 0.6546  mix_decode.d3.loss_dice: 0.7899  mix_decode.d4.loss_cls: 0.1811  mix_decode.d4.loss_mask: 0.6515  mix_decode.d4.loss_dice: 0.8000  mix_decode.d5.loss_cls: 0.1036  mix_decode.d5.loss_mask: 0.6505  mix_decode.d5.loss_dice: 0.7933  mix_decode.d6.loss_cls: 0.1199  mix_decode.d6.loss_mask: 0.6554  mix_decode.d6.loss_dice: 0.7853  mix_decode.d7.loss_cls: 0.1044  mix_decode.d7.loss_mask: 0.6475  mix_decode.d7.loss_dice: 0.8037  mix_decode.d8.loss_cls: 0.0818  mix_decode.d8.loss_mask: 0.6494  mix_decode.d8.loss_dice: 0.7917
2025/03/28 10:48:28 - mmengine - INFO - Iter(train) [ 5100/20000]  base_lr: 7.6729e-05 lr: 7.6729e-05  eta: 2:37:02  time: 1.0863  data_time: 0.0234  memory: 10771  loss: 35.9767  decode.loss_cls: 0.0395  decode.loss_mask: 1.0410  decode.loss_dice: 1.1193  decode.d0.loss_cls: 0.1023  decode.d0.loss_mask: 1.0716  decode.d0.loss_dice: 1.1411  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 1.0460  decode.d1.loss_dice: 1.1037  decode.d2.loss_cls: 0.0377  decode.d2.loss_mask: 1.0352  decode.d2.loss_dice: 1.1206  decode.d3.loss_cls: 0.0347  decode.d3.loss_mask: 1.0322  decode.d3.loss_dice: 1.1257  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 1.0393  decode.d4.loss_dice: 1.1073  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 1.0377  decode.d5.loss_dice: 1.1075  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 1.0413  decode.d6.loss_dice: 1.1242  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 1.0410  decode.d7.loss_dice: 1.1257  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 1.0436  decode.d8.loss_dice: 1.1260  mix_decode.loss_cls: 0.0732  mix_decode.loss_mask: 0.6188  mix_decode.loss_dice: 0.7038  mix_decode.d0.loss_cls: 0.1071  mix_decode.d0.loss_mask: 0.6251  mix_decode.d0.loss_dice: 0.7052  mix_decode.d1.loss_cls: 0.0788  mix_decode.d1.loss_mask: 0.6150  mix_decode.d1.loss_dice: 0.6852  mix_decode.d2.loss_cls: 0.0548  mix_decode.d2.loss_mask: 0.6113  mix_decode.d2.loss_dice: 0.7026  mix_decode.d3.loss_cls: 0.0583  mix_decode.d3.loss_mask: 0.6116  mix_decode.d3.loss_dice: 0.7042  mix_decode.d4.loss_cls: 0.0770  mix_decode.d4.loss_mask: 0.6159  mix_decode.d4.loss_dice: 0.6965  mix_decode.d5.loss_cls: 0.0721  mix_decode.d5.loss_mask: 0.6123  mix_decode.d5.loss_dice: 0.6895  mix_decode.d6.loss_cls: 0.0542  mix_decode.d6.loss_mask: 0.6182  mix_decode.d6.loss_dice: 0.7075  mix_decode.d7.loss_cls: 0.0881  mix_decode.d7.loss_mask: 0.6151  mix_decode.d7.loss_dice: 0.6924  mix_decode.d8.loss_cls: 0.0797  mix_decode.d8.loss_mask: 0.6187  mix_decode.d8.loss_dice: 0.7061
2025/03/28 10:49:22 - mmengine - INFO - Iter(train) [ 5150/20000]  base_lr: 7.6497e-05 lr: 7.6497e-05  eta: 2:37:33  time: 1.0729  data_time: 0.0220  memory: 10774  loss: 33.3362  decode.loss_cls: 0.0602  decode.loss_mask: 0.9963  decode.loss_dice: 1.0434  decode.d0.loss_cls: 0.1407  decode.d0.loss_mask: 0.9996  decode.d0.loss_dice: 1.0496  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.9792  decode.d1.loss_dice: 1.0842  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.9833  decode.d2.loss_dice: 1.0706  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.9848  decode.d3.loss_dice: 1.0652  decode.d4.loss_cls: 0.0670  decode.d4.loss_mask: 0.9936  decode.d4.loss_dice: 1.0557  decode.d5.loss_cls: 0.0618  decode.d5.loss_mask: 0.9975  decode.d5.loss_dice: 1.0673  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.9865  decode.d6.loss_dice: 1.0594  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.9884  decode.d7.loss_dice: 1.0626  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.9936  decode.d8.loss_dice: 1.0431  mix_decode.loss_cls: 0.0702  mix_decode.loss_mask: 0.5083  mix_decode.loss_dice: 0.6292  mix_decode.d0.loss_cls: 0.0928  mix_decode.d0.loss_mask: 0.5166  mix_decode.d0.loss_dice: 0.6309  mix_decode.d1.loss_cls: 0.0509  mix_decode.d1.loss_mask: 0.5141  mix_decode.d1.loss_dice: 0.6393  mix_decode.d2.loss_cls: 0.0903  mix_decode.d2.loss_mask: 0.5009  mix_decode.d2.loss_dice: 0.6153  mix_decode.d3.loss_cls: 0.1153  mix_decode.d3.loss_mask: 0.5078  mix_decode.d3.loss_dice: 0.6209  mix_decode.d4.loss_cls: 0.1136  mix_decode.d4.loss_mask: 0.5054  mix_decode.d4.loss_dice: 0.6086  mix_decode.d5.loss_cls: 0.0642  mix_decode.d5.loss_mask: 0.5106  mix_decode.d5.loss_dice: 0.6258  mix_decode.d6.loss_cls: 0.0488  mix_decode.d6.loss_mask: 0.5151  mix_decode.d6.loss_dice: 0.6278  mix_decode.d7.loss_cls: 0.0773  mix_decode.d7.loss_mask: 0.5163  mix_decode.d7.loss_dice: 0.6331  mix_decode.d8.loss_cls: 0.0680  mix_decode.d8.loss_mask: 0.5067  mix_decode.d8.loss_dice: 0.6200
2025/03/28 10:50:15 - mmengine - INFO - Iter(train) [ 5200/20000]  base_lr: 7.6265e-05 lr: 7.6265e-05  eta: 2:38:03  time: 1.0716  data_time: 0.0222  memory: 10781  loss: 37.1328  decode.loss_cls: 0.0278  decode.loss_mask: 1.1654  decode.loss_dice: 1.1464  decode.d0.loss_cls: 0.0749  decode.d0.loss_mask: 1.1676  decode.d0.loss_dice: 1.1350  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 1.1598  decode.d1.loss_dice: 1.1593  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 1.1596  decode.d2.loss_dice: 1.1648  decode.d3.loss_cls: 0.0296  decode.d3.loss_mask: 1.1679  decode.d3.loss_dice: 1.1638  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 1.1669  decode.d4.loss_dice: 1.1642  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 1.1619  decode.d5.loss_dice: 1.1597  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 1.1676  decode.d6.loss_dice: 1.1603  decode.d7.loss_cls: 0.0758  decode.d7.loss_mask: 1.1723  decode.d7.loss_dice: 1.1482  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 1.1642  decode.d8.loss_dice: 1.1564  mix_decode.loss_cls: 0.1254  mix_decode.loss_mask: 0.4959  mix_decode.loss_dice: 0.7153  mix_decode.d0.loss_cls: 0.1658  mix_decode.d0.loss_mask: 0.4929  mix_decode.d0.loss_dice: 0.7319  mix_decode.d1.loss_cls: 0.1926  mix_decode.d1.loss_mask: 0.4901  mix_decode.d1.loss_dice: 0.6878  mix_decode.d2.loss_cls: 0.1540  mix_decode.d2.loss_mask: 0.4996  mix_decode.d2.loss_dice: 0.6920  mix_decode.d3.loss_cls: 0.1635  mix_decode.d3.loss_mask: 0.4950  mix_decode.d3.loss_dice: 0.6658  mix_decode.d4.loss_cls: 0.1587  mix_decode.d4.loss_mask: 0.4996  mix_decode.d4.loss_dice: 0.7031  mix_decode.d5.loss_cls: 0.1283  mix_decode.d5.loss_mask: 0.4951  mix_decode.d5.loss_dice: 0.7112  mix_decode.d6.loss_cls: 0.1537  mix_decode.d6.loss_mask: 0.4992  mix_decode.d6.loss_dice: 0.7104  mix_decode.d7.loss_cls: 0.1431  mix_decode.d7.loss_mask: 0.4977  mix_decode.d7.loss_dice: 0.7221  mix_decode.d8.loss_cls: 0.1530  mix_decode.d8.loss_mask: 0.5028  mix_decode.d8.loss_dice: 0.7034
2025/03/28 10:51:09 - mmengine - INFO - Iter(train) [ 5250/20000]  base_lr: 7.6034e-05 lr: 7.6034e-05  eta: 2:38:32  time: 1.0687  data_time: 0.0220  memory: 10770  loss: 34.9536  decode.loss_cls: 0.0511  decode.loss_mask: 1.1593  decode.loss_dice: 1.1079  decode.d0.loss_cls: 0.1302  decode.d0.loss_mask: 1.1635  decode.d0.loss_dice: 1.0943  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 1.1433  decode.d1.loss_dice: 1.0900  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 1.1568  decode.d2.loss_dice: 1.0994  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 1.1491  decode.d3.loss_dice: 1.1078  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 1.1493  decode.d4.loss_dice: 1.1068  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 1.1576  decode.d5.loss_dice: 1.1135  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 1.1579  decode.d6.loss_dice: 1.1172  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 1.1484  decode.d7.loss_dice: 1.1009  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 1.1544  decode.d8.loss_dice: 1.1121  mix_decode.loss_cls: 0.0595  mix_decode.loss_mask: 0.5596  mix_decode.loss_dice: 0.5707  mix_decode.d0.loss_cls: 0.0615  mix_decode.d0.loss_mask: 0.5510  mix_decode.d0.loss_dice: 0.5800  mix_decode.d1.loss_cls: 0.0455  mix_decode.d1.loss_mask: 0.5511  mix_decode.d1.loss_dice: 0.5849  mix_decode.d2.loss_cls: 0.0544  mix_decode.d2.loss_mask: 0.5506  mix_decode.d2.loss_dice: 0.5760  mix_decode.d3.loss_cls: 0.0531  mix_decode.d3.loss_mask: 0.5463  mix_decode.d3.loss_dice: 0.5738  mix_decode.d4.loss_cls: 0.0512  mix_decode.d4.loss_mask: 0.5473  mix_decode.d4.loss_dice: 0.5805  mix_decode.d5.loss_cls: 0.0435  mix_decode.d5.loss_mask: 0.5467  mix_decode.d5.loss_dice: 0.5739  mix_decode.d6.loss_cls: 0.0374  mix_decode.d6.loss_mask: 0.5533  mix_decode.d6.loss_dice: 0.5694  mix_decode.d7.loss_cls: 0.0635  mix_decode.d7.loss_mask: 0.5540  mix_decode.d7.loss_dice: 0.5813  mix_decode.d8.loss_cls: 0.0415  mix_decode.d8.loss_mask: 0.5479  mix_decode.d8.loss_dice: 0.5815
2025/03/28 10:52:03 - mmengine - INFO - Iter(train) [ 5300/20000]  base_lr: 7.5802e-05 lr: 7.5802e-05  eta: 2:38:59  time: 1.0727  data_time: 0.0225  memory: 10767  loss: 36.4192  decode.loss_cls: 0.0650  decode.loss_mask: 1.1616  decode.loss_dice: 1.0309  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 1.1779  decode.d0.loss_dice: 1.0335  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 1.1584  decode.d1.loss_dice: 1.0240  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 1.1676  decode.d2.loss_dice: 1.0142  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 1.1588  decode.d3.loss_dice: 0.9977  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 1.1640  decode.d4.loss_dice: 1.0198  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 1.1670  decode.d5.loss_dice: 1.0303  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 1.1672  decode.d6.loss_dice: 0.9834  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 1.1642  decode.d7.loss_dice: 0.9861  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 1.1594  decode.d8.loss_dice: 1.0270  mix_decode.loss_cls: 0.1435  mix_decode.loss_mask: 0.6156  mix_decode.loss_dice: 0.6384  mix_decode.d0.loss_cls: 0.1532  mix_decode.d0.loss_mask: 0.6138  mix_decode.d0.loss_dice: 0.6695  mix_decode.d1.loss_cls: 0.1611  mix_decode.d1.loss_mask: 0.6044  mix_decode.d1.loss_dice: 0.6338  mix_decode.d2.loss_cls: 0.1704  mix_decode.d2.loss_mask: 0.6096  mix_decode.d2.loss_dice: 0.6300  mix_decode.d3.loss_cls: 0.1613  mix_decode.d3.loss_mask: 0.6043  mix_decode.d3.loss_dice: 0.6379  mix_decode.d4.loss_cls: 0.1569  mix_decode.d4.loss_mask: 0.6074  mix_decode.d4.loss_dice: 0.6395  mix_decode.d5.loss_cls: 0.1499  mix_decode.d5.loss_mask: 0.6142  mix_decode.d5.loss_dice: 0.6388  mix_decode.d6.loss_cls: 0.1595  mix_decode.d6.loss_mask: 0.6230  mix_decode.d6.loss_dice: 0.6297  mix_decode.d7.loss_cls: 0.1480  mix_decode.d7.loss_mask: 0.6154  mix_decode.d7.loss_dice: 0.6449  mix_decode.d8.loss_cls: 0.1302  mix_decode.d8.loss_mask: 0.6118  mix_decode.d8.loss_dice: 0.6421
2025/03/28 10:52:57 - mmengine - INFO - Iter(train) [ 5350/20000]  base_lr: 7.5569e-05 lr: 7.5569e-05  eta: 2:39:25  time: 1.0685  data_time: 0.0220  memory: 10768  loss: 34.6491  decode.loss_cls: 0.0106  decode.loss_mask: 1.0054  decode.loss_dice: 1.0895  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 1.0168  decode.d0.loss_dice: 1.0715  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 1.0097  decode.d1.loss_dice: 1.0894  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 1.0135  decode.d2.loss_dice: 1.0901  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 1.0047  decode.d3.loss_dice: 1.0896  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 1.0135  decode.d4.loss_dice: 1.0867  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 1.0122  decode.d5.loss_dice: 1.0864  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 1.0062  decode.d6.loss_dice: 1.0919  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 1.0087  decode.d7.loss_dice: 1.0888  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 1.0120  decode.d8.loss_dice: 1.1009  mix_decode.loss_cls: 0.0925  mix_decode.loss_mask: 0.4984  mix_decode.loss_dice: 0.7566  mix_decode.d0.loss_cls: 0.0880  mix_decode.d0.loss_mask: 0.4960  mix_decode.d0.loss_dice: 0.7855  mix_decode.d1.loss_cls: 0.0701  mix_decode.d1.loss_mask: 0.4954  mix_decode.d1.loss_dice: 0.7586  mix_decode.d2.loss_cls: 0.0622  mix_decode.d2.loss_mask: 0.4996  mix_decode.d2.loss_dice: 0.7742  mix_decode.d3.loss_cls: 0.1026  mix_decode.d3.loss_mask: 0.4963  mix_decode.d3.loss_dice: 0.7490  mix_decode.d4.loss_cls: 0.0775  mix_decode.d4.loss_mask: 0.4948  mix_decode.d4.loss_dice: 0.7655  mix_decode.d5.loss_cls: 0.0768  mix_decode.d5.loss_mask: 0.4996  mix_decode.d5.loss_dice: 0.7814  mix_decode.d6.loss_cls: 0.0965  mix_decode.d6.loss_mask: 0.4959  mix_decode.d6.loss_dice: 0.7798  mix_decode.d7.loss_cls: 0.0732  mix_decode.d7.loss_mask: 0.4899  mix_decode.d7.loss_dice: 0.7882  mix_decode.d8.loss_cls: 0.0851  mix_decode.d8.loss_mask: 0.4897  mix_decode.d8.loss_dice: 0.7501
2025/03/28 10:53:50 - mmengine - INFO - Iter(train) [ 5400/20000]  base_lr: 7.5337e-05 lr: 7.5337e-05  eta: 2:39:49  time: 1.0723  data_time: 0.0223  memory: 10770  loss: 35.0431  decode.loss_cls: 0.0199  decode.loss_mask: 1.0465  decode.loss_dice: 1.0652  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 1.0646  decode.d0.loss_dice: 1.0644  decode.d1.loss_cls: 0.0326  decode.d1.loss_mask: 1.0523  decode.d1.loss_dice: 1.0730  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 1.0665  decode.d2.loss_dice: 1.0672  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 1.0613  decode.d3.loss_dice: 1.0675  decode.d4.loss_cls: 0.0248  decode.d4.loss_mask: 1.0628  decode.d4.loss_dice: 1.0681  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 1.0592  decode.d5.loss_dice: 1.0589  decode.d6.loss_cls: 0.0203  decode.d6.loss_mask: 1.0637  decode.d6.loss_dice: 1.0640  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 1.0561  decode.d7.loss_dice: 1.0616  decode.d8.loss_cls: 0.0247  decode.d8.loss_mask: 1.0545  decode.d8.loss_dice: 1.0640  mix_decode.loss_cls: 0.0653  mix_decode.loss_mask: 0.5693  mix_decode.loss_dice: 0.6839  mix_decode.d0.loss_cls: 0.1335  mix_decode.d0.loss_mask: 0.5592  mix_decode.d0.loss_dice: 0.7103  mix_decode.d1.loss_cls: 0.0913  mix_decode.d1.loss_mask: 0.5678  mix_decode.d1.loss_dice: 0.6625  mix_decode.d2.loss_cls: 0.1179  mix_decode.d2.loss_mask: 0.5707  mix_decode.d2.loss_dice: 0.6670  mix_decode.d3.loss_cls: 0.0939  mix_decode.d3.loss_mask: 0.5796  mix_decode.d3.loss_dice: 0.6619  mix_decode.d4.loss_cls: 0.0889  mix_decode.d4.loss_mask: 0.5696  mix_decode.d4.loss_dice: 0.6876  mix_decode.d5.loss_cls: 0.1076  mix_decode.d5.loss_mask: 0.5764  mix_decode.d5.loss_dice: 0.6856  mix_decode.d6.loss_cls: 0.0980  mix_decode.d6.loss_mask: 0.5770  mix_decode.d6.loss_dice: 0.6862  mix_decode.d7.loss_cls: 0.1234  mix_decode.d7.loss_mask: 0.5624  mix_decode.d7.loss_dice: 0.6725  mix_decode.d8.loss_cls: 0.0822  mix_decode.d8.loss_mask: 0.5655  mix_decode.d8.loss_dice: 0.6935
2025/03/28 10:54:44 - mmengine - INFO - Iter(train) [ 5450/20000]  base_lr: 7.5105e-05 lr: 7.5105e-05  eta: 2:40:12  time: 1.0764  data_time: 0.0224  memory: 10774  loss: 36.4019  decode.loss_cls: 0.0406  decode.loss_mask: 0.9316  decode.loss_dice: 0.9878  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.9300  decode.d0.loss_dice: 0.9840  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.9433  decode.d1.loss_dice: 0.9881  decode.d2.loss_cls: 0.0347  decode.d2.loss_mask: 0.9411  decode.d2.loss_dice: 0.9830  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.9494  decode.d3.loss_dice: 0.9863  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.9451  decode.d4.loss_dice: 0.9803  decode.d5.loss_cls: 0.0411  decode.d5.loss_mask: 0.9433  decode.d5.loss_dice: 0.9780  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.9400  decode.d6.loss_dice: 0.9855  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.9332  decode.d7.loss_dice: 0.9787  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.9407  decode.d8.loss_dice: 0.9835  mix_decode.loss_cls: 0.1003  mix_decode.loss_mask: 0.7309  mix_decode.loss_dice: 0.8293  mix_decode.d0.loss_cls: 0.1394  mix_decode.d0.loss_mask: 0.7086  mix_decode.d0.loss_dice: 0.8729  mix_decode.d1.loss_cls: 0.1021  mix_decode.d1.loss_mask: 0.7246  mix_decode.d1.loss_dice: 0.8429  mix_decode.d2.loss_cls: 0.1267  mix_decode.d2.loss_mask: 0.7216  mix_decode.d2.loss_dice: 0.8367  mix_decode.d3.loss_cls: 0.1121  mix_decode.d3.loss_mask: 0.7253  mix_decode.d3.loss_dice: 0.8274  mix_decode.d4.loss_cls: 0.1146  mix_decode.d4.loss_mask: 0.7281  mix_decode.d4.loss_dice: 0.8221  mix_decode.d5.loss_cls: 0.1227  mix_decode.d5.loss_mask: 0.7380  mix_decode.d5.loss_dice: 0.8294  mix_decode.d6.loss_cls: 0.1210  mix_decode.d6.loss_mask: 0.7260  mix_decode.d6.loss_dice: 0.8372  mix_decode.d7.loss_cls: 0.0960  mix_decode.d7.loss_mask: 0.7215  mix_decode.d7.loss_dice: 0.8297  mix_decode.d8.loss_cls: 0.0973  mix_decode.d8.loss_mask: 0.7276  mix_decode.d8.loss_dice: 0.8351
2025/03/28 10:55:38 - mmengine - INFO - Iter(train) [ 5500/20000]  base_lr: 7.4873e-05 lr: 7.4873e-05  eta: 2:40:34  time: 1.0904  data_time: 0.0244  memory: 10771  loss: 37.2939  decode.loss_cls: 0.0191  decode.loss_mask: 1.2092  decode.loss_dice: 1.1408  decode.d0.loss_cls: 0.0935  decode.d0.loss_mask: 1.1906  decode.d0.loss_dice: 1.1647  decode.d1.loss_cls: 0.0272  decode.d1.loss_mask: 1.1998  decode.d1.loss_dice: 1.1459  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 1.2036  decode.d2.loss_dice: 1.1411  decode.d3.loss_cls: 0.0224  decode.d3.loss_mask: 1.2047  decode.d3.loss_dice: 1.1422  decode.d4.loss_cls: 0.0218  decode.d4.loss_mask: 1.2234  decode.d4.loss_dice: 1.1561  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 1.2140  decode.d5.loss_dice: 1.1513  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 1.2126  decode.d6.loss_dice: 1.1468  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 1.2031  decode.d7.loss_dice: 1.1519  decode.d8.loss_cls: 0.0202  decode.d8.loss_mask: 1.2067  decode.d8.loss_dice: 1.1512  mix_decode.loss_cls: 0.0592  mix_decode.loss_mask: 0.5780  mix_decode.loss_dice: 0.6789  mix_decode.d0.loss_cls: 0.0543  mix_decode.d0.loss_mask: 0.5754  mix_decode.d0.loss_dice: 0.7201  mix_decode.d1.loss_cls: 0.1216  mix_decode.d1.loss_mask: 0.5788  mix_decode.d1.loss_dice: 0.6786  mix_decode.d2.loss_cls: 0.1083  mix_decode.d2.loss_mask: 0.5827  mix_decode.d2.loss_dice: 0.6832  mix_decode.d3.loss_cls: 0.0931  mix_decode.d3.loss_mask: 0.5789  mix_decode.d3.loss_dice: 0.6739  mix_decode.d4.loss_cls: 0.0952  mix_decode.d4.loss_mask: 0.5747  mix_decode.d4.loss_dice: 0.6733  mix_decode.d5.loss_cls: 0.0800  mix_decode.d5.loss_mask: 0.5798  mix_decode.d5.loss_dice: 0.6772  mix_decode.d6.loss_cls: 0.0628  mix_decode.d6.loss_mask: 0.5753  mix_decode.d6.loss_dice: 0.6813  mix_decode.d7.loss_cls: 0.0968  mix_decode.d7.loss_mask: 0.5753  mix_decode.d7.loss_dice: 0.6813  mix_decode.d8.loss_cls: 0.0658  mix_decode.d8.loss_mask: 0.5798  mix_decode.d8.loss_dice: 0.6812
2025/03/28 10:56:31 - mmengine - INFO - Iter(train) [ 5550/20000]  base_lr: 7.4640e-05 lr: 7.4640e-05  eta: 2:40:54  time: 1.0730  data_time: 0.0221  memory: 10778  loss: 36.5516  decode.loss_cls: 0.0782  decode.loss_mask: 0.9748  decode.loss_dice: 1.1016  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.9764  decode.d0.loss_dice: 1.1228  decode.d1.loss_cls: 0.0913  decode.d1.loss_mask: 0.9769  decode.d1.loss_dice: 1.1166  decode.d2.loss_cls: 0.1235  decode.d2.loss_mask: 0.9729  decode.d2.loss_dice: 1.0975  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.9792  decode.d3.loss_dice: 1.1013  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.9710  decode.d4.loss_dice: 1.1030  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.9707  decode.d5.loss_dice: 1.1135  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.9708  decode.d6.loss_dice: 1.0976  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.9748  decode.d7.loss_dice: 1.1045  decode.d8.loss_cls: 0.0803  decode.d8.loss_mask: 0.9653  decode.d8.loss_dice: 1.1212  mix_decode.loss_cls: 0.0764  mix_decode.loss_mask: 0.6191  mix_decode.loss_dice: 0.7652  mix_decode.d0.loss_cls: 0.1295  mix_decode.d0.loss_mask: 0.6193  mix_decode.d0.loss_dice: 0.7980  mix_decode.d1.loss_cls: 0.0896  mix_decode.d1.loss_mask: 0.6207  mix_decode.d1.loss_dice: 0.7690  mix_decode.d2.loss_cls: 0.0723  mix_decode.d2.loss_mask: 0.6397  mix_decode.d2.loss_dice: 0.7668  mix_decode.d3.loss_cls: 0.1017  mix_decode.d3.loss_mask: 0.6302  mix_decode.d3.loss_dice: 0.7634  mix_decode.d4.loss_cls: 0.0809  mix_decode.d4.loss_mask: 0.6435  mix_decode.d4.loss_dice: 0.7911  mix_decode.d5.loss_cls: 0.0775  mix_decode.d5.loss_mask: 0.6436  mix_decode.d5.loss_dice: 0.7794  mix_decode.d6.loss_cls: 0.0877  mix_decode.d6.loss_mask: 0.6395  mix_decode.d6.loss_dice: 0.7594  mix_decode.d7.loss_cls: 0.0642  mix_decode.d7.loss_mask: 0.6344  mix_decode.d7.loss_dice: 0.7798  mix_decode.d8.loss_cls: 0.0607  mix_decode.d8.loss_mask: 0.6362  mix_decode.d8.loss_dice: 0.7776
2025/03/28 10:57:25 - mmengine - INFO - Iter(train) [ 5600/20000]  base_lr: 7.4408e-05 lr: 7.4408e-05  eta: 2:41:13  time: 1.0848  data_time: 0.0221  memory: 10768  loss: 34.5399  decode.loss_cls: 0.0413  decode.loss_mask: 0.9069  decode.loss_dice: 1.0999  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.9074  decode.d0.loss_dice: 1.1326  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.9014  decode.d1.loss_dice: 1.1127  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.9008  decode.d2.loss_dice: 1.0847  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.9047  decode.d3.loss_dice: 1.1337  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.9017  decode.d4.loss_dice: 1.1432  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.9054  decode.d5.loss_dice: 1.1325  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.9000  decode.d6.loss_dice: 1.1321  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.9082  decode.d7.loss_dice: 1.1388  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.9042  decode.d8.loss_dice: 1.1076  mix_decode.loss_cls: 0.1439  mix_decode.loss_mask: 0.5043  mix_decode.loss_dice: 0.7304  mix_decode.d0.loss_cls: 0.1650  mix_decode.d0.loss_mask: 0.5037  mix_decode.d0.loss_dice: 0.7613  mix_decode.d1.loss_cls: 0.1523  mix_decode.d1.loss_mask: 0.5018  mix_decode.d1.loss_dice: 0.7240  mix_decode.d2.loss_cls: 0.1494  mix_decode.d2.loss_mask: 0.5030  mix_decode.d2.loss_dice: 0.7298  mix_decode.d3.loss_cls: 0.1274  mix_decode.d3.loss_mask: 0.5036  mix_decode.d3.loss_dice: 0.7240  mix_decode.d4.loss_cls: 0.1317  mix_decode.d4.loss_mask: 0.5126  mix_decode.d4.loss_dice: 0.7425  mix_decode.d5.loss_cls: 0.1420  mix_decode.d5.loss_mask: 0.5080  mix_decode.d5.loss_dice: 0.7343  mix_decode.d6.loss_cls: 0.1348  mix_decode.d6.loss_mask: 0.5060  mix_decode.d6.loss_dice: 0.7350  mix_decode.d7.loss_cls: 0.1260  mix_decode.d7.loss_mask: 0.5037  mix_decode.d7.loss_dice: 0.7330  mix_decode.d8.loss_cls: 0.1348  mix_decode.d8.loss_mask: 0.5078  mix_decode.d8.loss_dice: 0.7398
2025/03/28 10:58:19 - mmengine - INFO - Iter(train) [ 5650/20000]  base_lr: 7.4175e-05 lr: 7.4175e-05  eta: 2:41:30  time: 1.0688  data_time: 0.0221  memory: 10778  loss: 34.3891  decode.loss_cls: 0.0501  decode.loss_mask: 1.0409  decode.loss_dice: 0.9936  decode.d0.loss_cls: 0.1372  decode.d0.loss_mask: 1.0492  decode.d0.loss_dice: 1.0037  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 1.0382  decode.d1.loss_dice: 1.0084  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 1.0379  decode.d2.loss_dice: 0.9804  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 1.0435  decode.d3.loss_dice: 0.9976  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 1.0432  decode.d4.loss_dice: 1.0023  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 1.0392  decode.d5.loss_dice: 1.0046  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 1.0370  decode.d6.loss_dice: 0.9703  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 1.0439  decode.d7.loss_dice: 0.9803  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 1.0394  decode.d8.loss_dice: 0.9896  mix_decode.loss_cls: 0.0632  mix_decode.loss_mask: 0.5265  mix_decode.loss_dice: 0.7355  mix_decode.d0.loss_cls: 0.0524  mix_decode.d0.loss_mask: 0.5382  mix_decode.d0.loss_dice: 0.7570  mix_decode.d1.loss_cls: 0.0656  mix_decode.d1.loss_mask: 0.5313  mix_decode.d1.loss_dice: 0.7377  mix_decode.d2.loss_cls: 0.0926  mix_decode.d2.loss_mask: 0.5320  mix_decode.d2.loss_dice: 0.7208  mix_decode.d3.loss_cls: 0.0682  mix_decode.d3.loss_mask: 0.5355  mix_decode.d3.loss_dice: 0.7381  mix_decode.d4.loss_cls: 0.0893  mix_decode.d4.loss_mask: 0.5279  mix_decode.d4.loss_dice: 0.7379  mix_decode.d5.loss_cls: 0.0526  mix_decode.d5.loss_mask: 0.5290  mix_decode.d5.loss_dice: 0.7420  mix_decode.d6.loss_cls: 0.0672  mix_decode.d6.loss_mask: 0.5329  mix_decode.d6.loss_dice: 0.7461  mix_decode.d7.loss_cls: 0.0521  mix_decode.d7.loss_mask: 0.5371  mix_decode.d7.loss_dice: 0.7395  mix_decode.d8.loss_cls: 0.0933  mix_decode.d8.loss_mask: 0.5269  mix_decode.d8.loss_dice: 0.7387
2025/03/28 10:59:12 - mmengine - INFO - Iter(train) [ 5700/20000]  base_lr: 7.3943e-05 lr: 7.3943e-05  eta: 2:41:46  time: 1.0676  data_time: 0.0223  memory: 10765  loss: 35.7228  decode.loss_cls: 0.0232  decode.loss_mask: 1.1167  decode.loss_dice: 0.9958  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 1.1435  decode.d0.loss_dice: 0.9707  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 1.1191  decode.d1.loss_dice: 0.9956  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 1.1123  decode.d2.loss_dice: 1.0050  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 1.1134  decode.d3.loss_dice: 1.0082  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 1.1128  decode.d4.loss_dice: 0.9889  decode.d5.loss_cls: 0.0216  decode.d5.loss_mask: 1.1228  decode.d5.loss_dice: 0.9958  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 1.1122  decode.d6.loss_dice: 1.0010  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 1.1139  decode.d7.loss_dice: 0.9860  decode.d8.loss_cls: 0.0255  decode.d8.loss_mask: 1.1116  decode.d8.loss_dice: 0.9906  mix_decode.loss_cls: 0.1029  mix_decode.loss_mask: 0.6170  mix_decode.loss_dice: 0.7055  mix_decode.d0.loss_cls: 0.1070  mix_decode.d0.loss_mask: 0.6171  mix_decode.d0.loss_dice: 0.7321  mix_decode.d1.loss_cls: 0.1252  mix_decode.d1.loss_mask: 0.6037  mix_decode.d1.loss_dice: 0.7128  mix_decode.d2.loss_cls: 0.1081  mix_decode.d2.loss_mask: 0.6026  mix_decode.d2.loss_dice: 0.7241  mix_decode.d3.loss_cls: 0.0952  mix_decode.d3.loss_mask: 0.6188  mix_decode.d3.loss_dice: 0.7177  mix_decode.d4.loss_cls: 0.0851  mix_decode.d4.loss_mask: 0.6225  mix_decode.d4.loss_dice: 0.7305  mix_decode.d5.loss_cls: 0.1001  mix_decode.d5.loss_mask: 0.6154  mix_decode.d5.loss_dice: 0.7204  mix_decode.d6.loss_cls: 0.1234  mix_decode.d6.loss_mask: 0.6006  mix_decode.d6.loss_dice: 0.7004  mix_decode.d7.loss_cls: 0.0954  mix_decode.d7.loss_mask: 0.6157  mix_decode.d7.loss_dice: 0.7126  mix_decode.d8.loss_cls: 0.0968  mix_decode.d8.loss_mask: 0.6109  mix_decode.d8.loss_dice: 0.7190
2025/03/28 11:00:06 - mmengine - INFO - Iter(train) [ 5750/20000]  base_lr: 7.3710e-05 lr: 7.3710e-05  eta: 2:42:01  time: 1.0733  data_time: 0.0226  memory: 10778  loss: 38.2776  decode.loss_cls: 0.0561  decode.loss_mask: 1.2506  decode.loss_dice: 1.1769  decode.d0.loss_cls: 0.1244  decode.d0.loss_mask: 1.2510  decode.d0.loss_dice: 1.1658  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 1.2484  decode.d1.loss_dice: 1.2033  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 1.2492  decode.d2.loss_dice: 1.1902  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 1.2396  decode.d3.loss_dice: 1.1684  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 1.2399  decode.d4.loss_dice: 1.1817  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 1.2430  decode.d5.loss_dice: 1.1884  decode.d6.loss_cls: 0.0678  decode.d6.loss_mask: 1.2464  decode.d6.loss_dice: 1.1789  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 1.2556  decode.d7.loss_dice: 1.1858  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 1.2518  decode.d8.loss_dice: 1.1858  mix_decode.loss_cls: 0.0461  mix_decode.loss_mask: 0.6047  mix_decode.loss_dice: 0.6679  mix_decode.d0.loss_cls: 0.0943  mix_decode.d0.loss_mask: 0.6042  mix_decode.d0.loss_dice: 0.6895  mix_decode.d1.loss_cls: 0.0418  mix_decode.d1.loss_mask: 0.6070  mix_decode.d1.loss_dice: 0.6653  mix_decode.d2.loss_cls: 0.0494  mix_decode.d2.loss_mask: 0.6111  mix_decode.d2.loss_dice: 0.6711  mix_decode.d3.loss_cls: 0.0364  mix_decode.d3.loss_mask: 0.6005  mix_decode.d3.loss_dice: 0.6683  mix_decode.d4.loss_cls: 0.0624  mix_decode.d4.loss_mask: 0.5937  mix_decode.d4.loss_dice: 0.6660  mix_decode.d5.loss_cls: 0.0653  mix_decode.d5.loss_mask: 0.6015  mix_decode.d5.loss_dice: 0.6729  mix_decode.d6.loss_cls: 0.0806  mix_decode.d6.loss_mask: 0.5997  mix_decode.d6.loss_dice: 0.6682  mix_decode.d7.loss_cls: 0.0394  mix_decode.d7.loss_mask: 0.6140  mix_decode.d7.loss_dice: 0.6734  mix_decode.d8.loss_cls: 0.0727  mix_decode.d8.loss_mask: 0.6093  mix_decode.d8.loss_dice: 0.6677
2025/03/28 11:01:00 - mmengine - INFO - Iter(train) [ 5800/20000]  base_lr: 7.3477e-05 lr: 7.3477e-05  eta: 2:42:15  time: 1.0740  data_time: 0.0224  memory: 10780  loss: 37.4008  decode.loss_cls: 0.0196  decode.loss_mask: 1.2601  decode.loss_dice: 1.0911  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 1.2921  decode.d0.loss_dice: 1.0684  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 1.2628  decode.d1.loss_dice: 1.0971  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 1.2581  decode.d2.loss_dice: 1.0908  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 1.2588  decode.d3.loss_dice: 1.0908  decode.d4.loss_cls: 0.0195  decode.d4.loss_mask: 1.2585  decode.d4.loss_dice: 1.0972  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 1.2633  decode.d5.loss_dice: 1.1007  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 1.2557  decode.d6.loss_dice: 1.1065  decode.d7.loss_cls: 0.0173  decode.d7.loss_mask: 1.2600  decode.d7.loss_dice: 1.0910  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 1.2625  decode.d8.loss_dice: 1.1052  mix_decode.loss_cls: 0.0872  mix_decode.loss_mask: 0.6005  mix_decode.loss_dice: 0.6775  mix_decode.d0.loss_cls: 0.0868  mix_decode.d0.loss_mask: 0.6122  mix_decode.d0.loss_dice: 0.6778  mix_decode.d1.loss_cls: 0.0817  mix_decode.d1.loss_mask: 0.5941  mix_decode.d1.loss_dice: 0.6636  mix_decode.d2.loss_cls: 0.0974  mix_decode.d2.loss_mask: 0.5958  mix_decode.d2.loss_dice: 0.6645  mix_decode.d3.loss_cls: 0.1029  mix_decode.d3.loss_mask: 0.5870  mix_decode.d3.loss_dice: 0.6642  mix_decode.d4.loss_cls: 0.0948  mix_decode.d4.loss_mask: 0.5882  mix_decode.d4.loss_dice: 0.6729  mix_decode.d5.loss_cls: 0.0894  mix_decode.d5.loss_mask: 0.5905  mix_decode.d5.loss_dice: 0.6750  mix_decode.d6.loss_cls: 0.0737  mix_decode.d6.loss_mask: 0.5984  mix_decode.d6.loss_dice: 0.6794  mix_decode.d7.loss_cls: 0.0647  mix_decode.d7.loss_mask: 0.5946  mix_decode.d7.loss_dice: 0.6888  mix_decode.d8.loss_cls: 0.0811  mix_decode.d8.loss_mask: 0.5990  mix_decode.d8.loss_dice: 0.6790
2025/03/28 11:01:53 - mmengine - INFO - Iter(train) [ 5850/20000]  base_lr: 7.3244e-05 lr: 7.3244e-05  eta: 2:42:28  time: 1.0713  data_time: 0.0219  memory: 10773  loss: 33.4483  decode.loss_cls: 0.0968  decode.loss_mask: 0.9312  decode.loss_dice: 1.0626  decode.d0.loss_cls: 0.1257  decode.d0.loss_mask: 0.9420  decode.d0.loss_dice: 1.0692  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.9456  decode.d1.loss_dice: 1.0607  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.9363  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 0.0947  decode.d3.loss_mask: 0.9334  decode.d3.loss_dice: 1.0656  decode.d4.loss_cls: 0.0970  decode.d4.loss_mask: 0.9397  decode.d4.loss_dice: 1.0411  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.9390  decode.d5.loss_dice: 1.0505  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.9377  decode.d6.loss_dice: 1.0620  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.9340  decode.d7.loss_dice: 1.0411  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 0.9404  decode.d8.loss_dice: 1.0454  mix_decode.loss_cls: 0.1095  mix_decode.loss_mask: 0.4714  mix_decode.loss_dice: 0.6574  mix_decode.d0.loss_cls: 0.1261  mix_decode.d0.loss_mask: 0.4696  mix_decode.d0.loss_dice: 0.6783  mix_decode.d1.loss_cls: 0.1199  mix_decode.d1.loss_mask: 0.4748  mix_decode.d1.loss_dice: 0.6767  mix_decode.d2.loss_cls: 0.1437  mix_decode.d2.loss_mask: 0.4695  mix_decode.d2.loss_dice: 0.6515  mix_decode.d3.loss_cls: 0.1223  mix_decode.d3.loss_mask: 0.4747  mix_decode.d3.loss_dice: 0.6606  mix_decode.d4.loss_cls: 0.0984  mix_decode.d4.loss_mask: 0.4732  mix_decode.d4.loss_dice: 0.6552  mix_decode.d5.loss_cls: 0.1271  mix_decode.d5.loss_mask: 0.4724  mix_decode.d5.loss_dice: 0.6625  mix_decode.d6.loss_cls: 0.1017  mix_decode.d6.loss_mask: 0.4756  mix_decode.d6.loss_dice: 0.6824  mix_decode.d7.loss_cls: 0.0904  mix_decode.d7.loss_mask: 0.4771  mix_decode.d7.loss_dice: 0.6776  mix_decode.d8.loss_cls: 0.0741  mix_decode.d8.loss_mask: 0.4866  mix_decode.d8.loss_dice: 0.6683
2025/03/28 11:02:47 - mmengine - INFO - Iter(train) [ 5900/20000]  base_lr: 7.3011e-05 lr: 7.3011e-05  eta: 2:42:39  time: 1.0682  data_time: 0.0223  memory: 10770  loss: 37.7333  decode.loss_cls: 0.0439  decode.loss_mask: 1.0839  decode.loss_dice: 1.1138  decode.d0.loss_cls: 0.0953  decode.d0.loss_mask: 1.0795  decode.d0.loss_dice: 1.1104  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 1.0801  decode.d1.loss_dice: 1.1105  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 1.0753  decode.d2.loss_dice: 1.0909  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 1.0754  decode.d3.loss_dice: 1.0730  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 1.0758  decode.d4.loss_dice: 1.1006  decode.d5.loss_cls: 0.1021  decode.d5.loss_mask: 1.0767  decode.d5.loss_dice: 1.0990  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 1.0862  decode.d6.loss_dice: 1.1032  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 1.0906  decode.d7.loss_dice: 1.1008  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 1.0883  decode.d8.loss_dice: 1.0951  mix_decode.loss_cls: 0.1000  mix_decode.loss_mask: 0.6549  mix_decode.loss_dice: 0.7299  mix_decode.d0.loss_cls: 0.1200  mix_decode.d0.loss_mask: 0.6676  mix_decode.d0.loss_dice: 0.7711  mix_decode.d1.loss_cls: 0.1142  mix_decode.d1.loss_mask: 0.6515  mix_decode.d1.loss_dice: 0.7336  mix_decode.d2.loss_cls: 0.1090  mix_decode.d2.loss_mask: 0.6615  mix_decode.d2.loss_dice: 0.7461  mix_decode.d3.loss_cls: 0.1169  mix_decode.d3.loss_mask: 0.6814  mix_decode.d3.loss_dice: 0.7304  mix_decode.d4.loss_cls: 0.1100  mix_decode.d4.loss_mask: 0.6545  mix_decode.d4.loss_dice: 0.7451  mix_decode.d5.loss_cls: 0.1230  mix_decode.d5.loss_mask: 0.6633  mix_decode.d5.loss_dice: 0.7455  mix_decode.d6.loss_cls: 0.0846  mix_decode.d6.loss_mask: 0.6799  mix_decode.d6.loss_dice: 0.7429  mix_decode.d7.loss_cls: 0.0788  mix_decode.d7.loss_mask: 0.6904  mix_decode.d7.loss_dice: 0.7362  mix_decode.d8.loss_cls: 0.1034  mix_decode.d8.loss_mask: 0.6663  mix_decode.d8.loss_dice: 0.7267
2025/03/28 11:03:40 - mmengine - INFO - Iter(train) [ 5950/20000]  base_lr: 7.2778e-05 lr: 7.2778e-05  eta: 2:42:49  time: 1.0692  data_time: 0.0224  memory: 10774  loss: 34.2757  decode.loss_cls: 0.0701  decode.loss_mask: 1.0970  decode.loss_dice: 1.0469  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 1.1117  decode.d0.loss_dice: 1.0442  decode.d1.loss_cls: 0.0994  decode.d1.loss_mask: 1.1112  decode.d1.loss_dice: 1.0265  decode.d2.loss_cls: 0.1120  decode.d2.loss_mask: 1.0994  decode.d2.loss_dice: 1.0284  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 1.0983  decode.d3.loss_dice: 1.0422  decode.d4.loss_cls: 0.1060  decode.d4.loss_mask: 1.1031  decode.d4.loss_dice: 1.0524  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 1.0912  decode.d5.loss_dice: 1.0376  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 1.0945  decode.d6.loss_dice: 1.0225  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 1.0986  decode.d7.loss_dice: 1.0433  decode.d8.loss_cls: 0.0900  decode.d8.loss_mask: 1.0962  decode.d8.loss_dice: 1.0383  mix_decode.loss_cls: 0.0318  mix_decode.loss_mask: 0.4947  mix_decode.loss_dice: 0.6687  mix_decode.d0.loss_cls: 0.0599  mix_decode.d0.loss_mask: 0.4968  mix_decode.d0.loss_dice: 0.6813  mix_decode.d1.loss_cls: 0.0329  mix_decode.d1.loss_mask: 0.4975  mix_decode.d1.loss_dice: 0.6557  mix_decode.d2.loss_cls: 0.0275  mix_decode.d2.loss_mask: 0.4932  mix_decode.d2.loss_dice: 0.6633  mix_decode.d3.loss_cls: 0.0306  mix_decode.d3.loss_mask: 0.4993  mix_decode.d3.loss_dice: 0.6609  mix_decode.d4.loss_cls: 0.0552  mix_decode.d4.loss_mask: 0.4942  mix_decode.d4.loss_dice: 0.6724  mix_decode.d5.loss_cls: 0.0389  mix_decode.d5.loss_mask: 0.4934  mix_decode.d5.loss_dice: 0.6766  mix_decode.d6.loss_cls: 0.0366  mix_decode.d6.loss_mask: 0.4959  mix_decode.d6.loss_dice: 0.6703  mix_decode.d7.loss_cls: 0.0281  mix_decode.d7.loss_mask: 0.4920  mix_decode.d7.loss_dice: 0.6745  mix_decode.d8.loss_cls: 0.0313  mix_decode.d8.loss_mask: 0.4932  mix_decode.d8.loss_dice: 0.6745
2025/03/28 11:04:34 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 11:04:34 - mmengine - INFO - Iter(train) [ 6000/20000]  base_lr: 7.2545e-05 lr: 7.2545e-05  eta: 2:42:58  time: 1.0782  data_time: 0.0238  memory: 10776  loss: 37.5717  decode.loss_cls: 0.0321  decode.loss_mask: 1.1073  decode.loss_dice: 1.1369  decode.d0.loss_cls: 0.0691  decode.d0.loss_mask: 1.1065  decode.d0.loss_dice: 1.1003  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 1.0995  decode.d1.loss_dice: 1.1506  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 1.1016  decode.d2.loss_dice: 1.1704  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 1.1054  decode.d3.loss_dice: 1.1593  decode.d4.loss_cls: 0.0298  decode.d4.loss_mask: 1.1047  decode.d4.loss_dice: 1.1365  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 1.1086  decode.d5.loss_dice: 1.1341  decode.d6.loss_cls: 0.0335  decode.d6.loss_mask: 1.1108  decode.d6.loss_dice: 1.1404  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 1.1112  decode.d7.loss_dice: 1.1461  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 1.1122  decode.d8.loss_dice: 1.1390  mix_decode.loss_cls: 0.1209  mix_decode.loss_mask: 0.5843  mix_decode.loss_dice: 0.7569  mix_decode.d0.loss_cls: 0.1498  mix_decode.d0.loss_mask: 0.5687  mix_decode.d0.loss_dice: 0.7701  mix_decode.d1.loss_cls: 0.1467  mix_decode.d1.loss_mask: 0.5721  mix_decode.d1.loss_dice: 0.7542  mix_decode.d2.loss_cls: 0.1167  mix_decode.d2.loss_mask: 0.5878  mix_decode.d2.loss_dice: 0.7611  mix_decode.d3.loss_cls: 0.1775  mix_decode.d3.loss_mask: 0.5783  mix_decode.d3.loss_dice: 0.7398  mix_decode.d4.loss_cls: 0.1775  mix_decode.d4.loss_mask: 0.5747  mix_decode.d4.loss_dice: 0.7363  mix_decode.d5.loss_cls: 0.1328  mix_decode.d5.loss_mask: 0.5792  mix_decode.d5.loss_dice: 0.7257  mix_decode.d6.loss_cls: 0.1525  mix_decode.d6.loss_mask: 0.5789  mix_decode.d6.loss_dice: 0.7502  mix_decode.d7.loss_cls: 0.1431  mix_decode.d7.loss_mask: 0.5766  mix_decode.d7.loss_dice: 0.7356  mix_decode.d8.loss_cls: 0.1171  mix_decode.d8.loss_mask: 0.5999  mix_decode.d8.loss_dice: 0.7423
2025/03/28 11:04:34 - mmengine - INFO - Saving checkpoint at 6000 iterations
2025/03/28 11:04:39 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0848  data_time: 0.0019  memory: 3070  
2025/03/28 11:04:44 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:43  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 11:04:48 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:39  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 11:04:52 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:34  time: 0.0855  data_time: 0.0020  memory: 3070  
2025/03/28 11:04:56 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0847  data_time: 0.0018  memory: 3070  
2025/03/28 11:05:01 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:26  time: 0.0849  data_time: 0.0017  memory: 3070  
2025/03/28 11:05:05 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:21  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 11:05:09 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:17  time: 0.0858  data_time: 0.0018  memory: 3070  
2025/03/28 11:05:14 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:14  time: 0.1035  data_time: 0.0020  memory: 3070  
2025/03/28 11:05:18 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:09  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 11:05:22 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:05  time: 0.0878  data_time: 0.0019  memory: 3070  
2025/03/28 11:05:26 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:01  time: 0.0850  data_time: 0.0017  memory: 3070  
2025/03/28 11:05:31 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:57  time: 0.0883  data_time: 0.0019  memory: 3070  
2025/03/28 11:05:35 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:52  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 11:05:39 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:48  time: 0.0855  data_time: 0.0019  memory: 3070  
2025/03/28 11:05:44 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:44  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 11:05:48 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 11:05:52 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 11:05:56 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:31  time: 0.0883  data_time: 0.0020  memory: 3070  
2025/03/28 11:06:01 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:27  time: 0.0854  data_time: 0.0019  memory: 3070  
2025/03/28 11:06:05 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0854  data_time: 0.0019  memory: 3070  
2025/03/28 11:06:09 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 11:06:14 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:14  time: 0.0854  data_time: 0.0018  memory: 3070  
2025/03/28 11:06:18 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0853  data_time: 0.0019  memory: 3070  
2025/03/28 11:06:22 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0851  data_time: 0.0019  memory: 3070  
2025/03/28 11:06:26 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 11:06:31 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:57  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 11:06:35 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0851  data_time: 0.0017  memory: 3070  
2025/03/28 11:06:39 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 11:06:43 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 11:06:48 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 11:06:52 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0853  data_time: 0.0019  memory: 3070  
2025/03/28 11:06:56 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0854  data_time: 0.0018  memory: 3070  
2025/03/28 11:07:01 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:27  time: 0.0853  data_time: 0.0019  memory: 3070  
2025/03/28 11:07:05 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 11:07:09 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0854  data_time: 0.0019  memory: 3070  
2025/03/28 11:07:14 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0882  data_time: 0.0020  memory: 3070  
2025/03/28 11:07:18 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 11:07:22 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 11:07:26 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 11:07:28 - mmengine - INFO - per class results:
2025/03/28 11:07:28 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 75.26 | 91.35 |
|      building      | 87.99 | 95.22 |
|   low_vegetation   |  64.8 | 87.27 |
|        tree        | 50.98 | 54.85 |
|        car         |  77.0 | 87.84 |
|      clutter       | 17.25 |  19.8 |
+--------------------+-------+-------+
2025/03/28 11:07:28 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 81.7800  mIoU: 62.2100  mAcc: 72.7200  data_time: 0.0019  time: 0.0856
2025/03/28 11:07:28 - mmengine - INFO - The previous best checkpoint /data/xiaoxinghhh/code/my_mmcv/work_dirs/vi2pr/DA_spatial_32_fft_cut_off_0.2_suf3/6ff2f_seed0/best_mIoU_iter_4000.pth is removed
2025/03/28 11:07:28 - mmengine - INFO - The best checkpoint with 62.2100 mIoU at 6000 iter is saved to best_mIoU_iter_6000.pth.
2025/03/28 11:08:23 - mmengine - INFO - Iter(train) [ 6050/20000]  base_lr: 7.2312e-05 lr: 7.2312e-05  eta: 2:43:10  time: 1.0725  data_time: 0.0222  memory: 10773  loss: 35.4781  decode.loss_cls: 0.0813  decode.loss_mask: 1.0636  decode.loss_dice: 1.0877  decode.d0.loss_cls: 0.1051  decode.d0.loss_mask: 1.0697  decode.d0.loss_dice: 1.1398  decode.d1.loss_cls: 0.1529  decode.d1.loss_mask: 1.0547  decode.d1.loss_dice: 1.0507  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 1.0641  decode.d2.loss_dice: 1.0383  decode.d3.loss_cls: 0.1209  decode.d3.loss_mask: 1.0604  decode.d3.loss_dice: 1.0480  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 1.0497  decode.d4.loss_dice: 1.0524  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 1.0692  decode.d5.loss_dice: 1.0669  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 1.0692  decode.d6.loss_dice: 1.0516  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 1.0707  decode.d7.loss_dice: 1.0580  decode.d8.loss_cls: 0.1022  decode.d8.loss_mask: 1.0718  decode.d8.loss_dice: 1.0775  mix_decode.loss_cls: 0.0972  mix_decode.loss_mask: 0.5113  mix_decode.loss_dice: 0.6900  mix_decode.d0.loss_cls: 0.1147  mix_decode.d0.loss_mask: 0.5197  mix_decode.d0.loss_dice: 0.7270  mix_decode.d1.loss_cls: 0.0948  mix_decode.d1.loss_mask: 0.5136  mix_decode.d1.loss_dice: 0.6761  mix_decode.d2.loss_cls: 0.0888  mix_decode.d2.loss_mask: 0.5162  mix_decode.d2.loss_dice: 0.6718  mix_decode.d3.loss_cls: 0.0863  mix_decode.d3.loss_mask: 0.5163  mix_decode.d3.loss_dice: 0.6912  mix_decode.d4.loss_cls: 0.0869  mix_decode.d4.loss_mask: 0.5143  mix_decode.d4.loss_dice: 0.6773  mix_decode.d5.loss_cls: 0.0964  mix_decode.d5.loss_mask: 0.5182  mix_decode.d5.loss_dice: 0.6685  mix_decode.d6.loss_cls: 0.1153  mix_decode.d6.loss_mask: 0.5225  mix_decode.d6.loss_dice: 0.6903  mix_decode.d7.loss_cls: 0.1201  mix_decode.d7.loss_mask: 0.5201  mix_decode.d7.loss_dice: 0.6927  mix_decode.d8.loss_cls: 0.1105  mix_decode.d8.loss_mask: 0.5182  mix_decode.d8.loss_dice: 0.6648
2025/03/28 11:09:17 - mmengine - INFO - Iter(train) [ 6100/20000]  base_lr: 7.2079e-05 lr: 7.2079e-05  eta: 2:43:18  time: 1.0751  data_time: 0.0229  memory: 10782  loss: 37.6607  decode.loss_cls: 0.0714  decode.loss_mask: 1.1281  decode.loss_dice: 1.1245  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 1.1585  decode.d0.loss_dice: 1.1469  decode.d1.loss_cls: 0.0748  decode.d1.loss_mask: 1.1324  decode.d1.loss_dice: 1.1158  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 1.1295  decode.d2.loss_dice: 1.1415  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 1.1268  decode.d3.loss_dice: 1.1155  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 1.1275  decode.d4.loss_dice: 1.1049  decode.d5.loss_cls: 0.0827  decode.d5.loss_mask: 1.1309  decode.d5.loss_dice: 1.1205  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 1.1338  decode.d6.loss_dice: 1.1451  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 1.1295  decode.d7.loss_dice: 1.1376  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 1.1358  decode.d8.loss_dice: 1.1441  mix_decode.loss_cls: 0.0629  mix_decode.loss_mask: 0.6121  mix_decode.loss_dice: 0.7345  mix_decode.d0.loss_cls: 0.1074  mix_decode.d0.loss_mask: 0.6143  mix_decode.d0.loss_dice: 0.7483  mix_decode.d1.loss_cls: 0.1036  mix_decode.d1.loss_mask: 0.6119  mix_decode.d1.loss_dice: 0.7274  mix_decode.d2.loss_cls: 0.0944  mix_decode.d2.loss_mask: 0.6092  mix_decode.d2.loss_dice: 0.7305  mix_decode.d3.loss_cls: 0.0913  mix_decode.d3.loss_mask: 0.6164  mix_decode.d3.loss_dice: 0.7152  mix_decode.d4.loss_cls: 0.0671  mix_decode.d4.loss_mask: 0.6159  mix_decode.d4.loss_dice: 0.7212  mix_decode.d5.loss_cls: 0.0645  mix_decode.d5.loss_mask: 0.6107  mix_decode.d5.loss_dice: 0.7276  mix_decode.d6.loss_cls: 0.0692  mix_decode.d6.loss_mask: 0.6178  mix_decode.d6.loss_dice: 0.7294  mix_decode.d7.loss_cls: 0.0886  mix_decode.d7.loss_mask: 0.6134  mix_decode.d7.loss_dice: 0.7393  mix_decode.d8.loss_cls: 0.0752  mix_decode.d8.loss_mask: 0.6099  mix_decode.d8.loss_dice: 0.7277
2025/03/28 11:10:11 - mmengine - INFO - Iter(train) [ 6150/20000]  base_lr: 7.1845e-05 lr: 7.1845e-05  eta: 2:43:25  time: 1.0738  data_time: 0.0228  memory: 10773  loss: 34.3647  decode.loss_cls: 0.0158  decode.loss_mask: 1.1074  decode.loss_dice: 1.0374  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 1.1296  decode.d0.loss_dice: 0.9984  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 1.1202  decode.d1.loss_dice: 1.0062  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 1.1149  decode.d2.loss_dice: 1.0356  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 1.1075  decode.d3.loss_dice: 1.0414  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 1.1088  decode.d4.loss_dice: 1.0289  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 1.1027  decode.d5.loss_dice: 1.0295  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 1.1076  decode.d6.loss_dice: 1.0330  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 1.1116  decode.d7.loss_dice: 1.0365  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 1.1052  decode.d8.loss_dice: 1.0214  mix_decode.loss_cls: 0.0574  mix_decode.loss_mask: 0.4988  mix_decode.loss_dice: 0.7115  mix_decode.d0.loss_cls: 0.0608  mix_decode.d0.loss_mask: 0.4963  mix_decode.d0.loss_dice: 0.7390  mix_decode.d1.loss_cls: 0.0681  mix_decode.d1.loss_mask: 0.5054  mix_decode.d1.loss_dice: 0.7057  mix_decode.d2.loss_cls: 0.0657  mix_decode.d2.loss_mask: 0.4954  mix_decode.d2.loss_dice: 0.7017  mix_decode.d3.loss_cls: 0.0622  mix_decode.d3.loss_mask: 0.5010  mix_decode.d3.loss_dice: 0.7074  mix_decode.d4.loss_cls: 0.0705  mix_decode.d4.loss_mask: 0.5006  mix_decode.d4.loss_dice: 0.7021  mix_decode.d5.loss_cls: 0.0854  mix_decode.d5.loss_mask: 0.4965  mix_decode.d5.loss_dice: 0.6956  mix_decode.d6.loss_cls: 0.0753  mix_decode.d6.loss_mask: 0.4946  mix_decode.d6.loss_dice: 0.6969  mix_decode.d7.loss_cls: 0.0759  mix_decode.d7.loss_mask: 0.4951  mix_decode.d7.loss_dice: 0.7119  mix_decode.d8.loss_cls: 0.0650  mix_decode.d8.loss_mask: 0.4984  mix_decode.d8.loss_dice: 0.7124
2025/03/28 11:11:04 - mmengine - INFO - Iter(train) [ 6200/20000]  base_lr: 7.1612e-05 lr: 7.1612e-05  eta: 2:43:29  time: 1.0681  data_time: 0.0222  memory: 10767  loss: 34.6548  decode.loss_cls: 0.1122  decode.loss_mask: 0.9598  decode.loss_dice: 0.9596  decode.d0.loss_cls: 0.1206  decode.d0.loss_mask: 0.9679  decode.d0.loss_dice: 0.9760  decode.d1.loss_cls: 0.1117  decode.d1.loss_mask: 0.9484  decode.d1.loss_dice: 0.9414  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 0.9562  decode.d2.loss_dice: 0.9595  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.9551  decode.d3.loss_dice: 0.9429  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 0.9555  decode.d4.loss_dice: 0.9463  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.9527  decode.d5.loss_dice: 0.9627  decode.d6.loss_cls: 0.1097  decode.d6.loss_mask: 0.9535  decode.d6.loss_dice: 0.9544  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 0.9519  decode.d7.loss_dice: 0.9536  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.9520  decode.d8.loss_dice: 0.9464  mix_decode.loss_cls: 0.0477  mix_decode.loss_mask: 0.6374  mix_decode.loss_dice: 0.7504  mix_decode.d0.loss_cls: 0.0636  mix_decode.d0.loss_mask: 0.6266  mix_decode.d0.loss_dice: 0.7695  mix_decode.d1.loss_cls: 0.0749  mix_decode.d1.loss_mask: 0.6256  mix_decode.d1.loss_dice: 0.7557  mix_decode.d2.loss_cls: 0.0876  mix_decode.d2.loss_mask: 0.6294  mix_decode.d2.loss_dice: 0.7347  mix_decode.d3.loss_cls: 0.0757  mix_decode.d3.loss_mask: 0.6329  mix_decode.d3.loss_dice: 0.7370  mix_decode.d4.loss_cls: 0.0692  mix_decode.d4.loss_mask: 0.6262  mix_decode.d4.loss_dice: 0.7506  mix_decode.d5.loss_cls: 0.0858  mix_decode.d5.loss_mask: 0.6206  mix_decode.d5.loss_dice: 0.7432  mix_decode.d6.loss_cls: 0.0779  mix_decode.d6.loss_mask: 0.6318  mix_decode.d6.loss_dice: 0.7359  mix_decode.d7.loss_cls: 0.0634  mix_decode.d7.loss_mask: 0.6311  mix_decode.d7.loss_dice: 0.7498  mix_decode.d8.loss_cls: 0.0578  mix_decode.d8.loss_mask: 0.6318  mix_decode.d8.loss_dice: 0.7588
2025/03/28 11:11:58 - mmengine - INFO - Iter(train) [ 6250/20000]  base_lr: 7.1378e-05 lr: 7.1378e-05  eta: 2:43:34  time: 1.0699  data_time: 0.0222  memory: 10768  loss: 38.8081  decode.loss_cls: 0.0357  decode.loss_mask: 1.1892  decode.loss_dice: 1.2148  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 1.1904  decode.d0.loss_dice: 1.2293  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 1.1822  decode.d1.loss_dice: 1.2192  decode.d2.loss_cls: 0.0672  decode.d2.loss_mask: 1.1850  decode.d2.loss_dice: 1.2216  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 1.1869  decode.d3.loss_dice: 1.2285  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 1.1856  decode.d4.loss_dice: 1.2208  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 1.2001  decode.d5.loss_dice: 1.2227  decode.d6.loss_cls: 0.0340  decode.d6.loss_mask: 1.1913  decode.d6.loss_dice: 1.2194  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 1.1842  decode.d7.loss_dice: 1.2085  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 1.2021  decode.d8.loss_dice: 1.2472  mix_decode.loss_cls: 0.1304  mix_decode.loss_mask: 0.5676  mix_decode.loss_dice: 0.7032  mix_decode.d0.loss_cls: 0.0961  mix_decode.d0.loss_mask: 0.5886  mix_decode.d0.loss_dice: 0.7459  mix_decode.d1.loss_cls: 0.1684  mix_decode.d1.loss_mask: 0.5649  mix_decode.d1.loss_dice: 0.7029  mix_decode.d2.loss_cls: 0.1490  mix_decode.d2.loss_mask: 0.5643  mix_decode.d2.loss_dice: 0.7041  mix_decode.d3.loss_cls: 0.1629  mix_decode.d3.loss_mask: 0.5660  mix_decode.d3.loss_dice: 0.6957  mix_decode.d4.loss_cls: 0.1642  mix_decode.d4.loss_mask: 0.5599  mix_decode.d4.loss_dice: 0.7105  mix_decode.d5.loss_cls: 0.1354  mix_decode.d5.loss_mask: 0.5793  mix_decode.d5.loss_dice: 0.7121  mix_decode.d6.loss_cls: 0.1403  mix_decode.d6.loss_mask: 0.5650  mix_decode.d6.loss_dice: 0.7131  mix_decode.d7.loss_cls: 0.1612  mix_decode.d7.loss_mask: 0.5618  mix_decode.d7.loss_dice: 0.7099  mix_decode.d8.loss_cls: 0.1535  mix_decode.d8.loss_mask: 0.5629  mix_decode.d8.loss_dice: 0.6930
2025/03/28 11:12:52 - mmengine - INFO - Iter(train) [ 6300/20000]  base_lr: 7.1144e-05 lr: 7.1144e-05  eta: 2:43:37  time: 1.0737  data_time: 0.0225  memory: 10770  loss: 34.2797  decode.loss_cls: 0.0290  decode.loss_mask: 1.1001  decode.loss_dice: 0.9732  decode.d0.loss_cls: 0.1024  decode.d0.loss_mask: 1.0980  decode.d0.loss_dice: 0.9938  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 1.0987  decode.d1.loss_dice: 0.9690  decode.d2.loss_cls: 0.0317  decode.d2.loss_mask: 1.1081  decode.d2.loss_dice: 0.9938  decode.d3.loss_cls: 0.0307  decode.d3.loss_mask: 1.1048  decode.d3.loss_dice: 0.9610  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 1.1097  decode.d4.loss_dice: 0.9625  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 1.1057  decode.d5.loss_dice: 0.9738  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 1.1148  decode.d6.loss_dice: 0.9941  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 1.1120  decode.d7.loss_dice: 0.9778  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 1.1022  decode.d8.loss_dice: 0.9744  mix_decode.loss_cls: 0.0759  mix_decode.loss_mask: 0.5813  mix_decode.loss_dice: 0.6588  mix_decode.d0.loss_cls: 0.1017  mix_decode.d0.loss_mask: 0.5788  mix_decode.d0.loss_dice: 0.6805  mix_decode.d1.loss_cls: 0.0713  mix_decode.d1.loss_mask: 0.5775  mix_decode.d1.loss_dice: 0.6244  mix_decode.d2.loss_cls: 0.0859  mix_decode.d2.loss_mask: 0.5776  mix_decode.d2.loss_dice: 0.6285  mix_decode.d3.loss_cls: 0.0970  mix_decode.d3.loss_mask: 0.5783  mix_decode.d3.loss_dice: 0.6148  mix_decode.d4.loss_cls: 0.1031  mix_decode.d4.loss_mask: 0.5828  mix_decode.d4.loss_dice: 0.6321  mix_decode.d5.loss_cls: 0.0839  mix_decode.d5.loss_mask: 0.5890  mix_decode.d5.loss_dice: 0.6250  mix_decode.d6.loss_cls: 0.0850  mix_decode.d6.loss_mask: 0.5905  mix_decode.d6.loss_dice: 0.6381  mix_decode.d7.loss_cls: 0.0970  mix_decode.d7.loss_mask: 0.5852  mix_decode.d7.loss_dice: 0.6368  mix_decode.d8.loss_cls: 0.0913  mix_decode.d8.loss_mask: 0.5781  mix_decode.d8.loss_dice: 0.6231
2025/03/28 11:13:46 - mmengine - INFO - Iter(train) [ 6350/20000]  base_lr: 7.0911e-05 lr: 7.0911e-05  eta: 2:43:40  time: 1.0804  data_time: 0.0229  memory: 10774  loss: 33.3014  decode.loss_cls: 0.0311  decode.loss_mask: 1.0559  decode.loss_dice: 0.9616  decode.d0.loss_cls: 0.0969  decode.d0.loss_mask: 1.0522  decode.d0.loss_dice: 0.9704  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 1.0461  decode.d1.loss_dice: 0.9699  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 1.0472  decode.d2.loss_dice: 0.9703  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 1.0435  decode.d3.loss_dice: 0.9676  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 1.0520  decode.d4.loss_dice: 0.9582  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 1.0544  decode.d5.loss_dice: 0.9454  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 1.0444  decode.d6.loss_dice: 0.9358  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 1.0464  decode.d7.loss_dice: 0.9570  decode.d8.loss_cls: 0.0287  decode.d8.loss_mask: 1.0523  decode.d8.loss_dice: 0.9598  mix_decode.loss_cls: 0.1303  mix_decode.loss_mask: 0.5183  mix_decode.loss_dice: 0.6408  mix_decode.d0.loss_cls: 0.1115  mix_decode.d0.loss_mask: 0.5217  mix_decode.d0.loss_dice: 0.6632  mix_decode.d1.loss_cls: 0.1249  mix_decode.d1.loss_mask: 0.5249  mix_decode.d1.loss_dice: 0.6297  mix_decode.d2.loss_cls: 0.1510  mix_decode.d2.loss_mask: 0.5224  mix_decode.d2.loss_dice: 0.6275  mix_decode.d3.loss_cls: 0.1046  mix_decode.d3.loss_mask: 0.5208  mix_decode.d3.loss_dice: 0.6324  mix_decode.d4.loss_cls: 0.1284  mix_decode.d4.loss_mask: 0.5158  mix_decode.d4.loss_dice: 0.6217  mix_decode.d5.loss_cls: 0.1097  mix_decode.d5.loss_mask: 0.5364  mix_decode.d5.loss_dice: 0.6209  mix_decode.d6.loss_cls: 0.1422  mix_decode.d6.loss_mask: 0.5368  mix_decode.d6.loss_dice: 0.6223  mix_decode.d7.loss_cls: 0.0952  mix_decode.d7.loss_mask: 0.5272  mix_decode.d7.loss_dice: 0.6548  mix_decode.d8.loss_cls: 0.1129  mix_decode.d8.loss_mask: 0.5309  mix_decode.d8.loss_dice: 0.6329
2025/03/28 11:14:40 - mmengine - INFO - Iter(train) [ 6400/20000]  base_lr: 7.0677e-05 lr: 7.0677e-05  eta: 2:43:42  time: 1.0726  data_time: 0.0227  memory: 10777  loss: 37.3734  decode.loss_cls: 0.0332  decode.loss_mask: 1.1635  decode.loss_dice: 1.1543  decode.d0.loss_cls: 0.1147  decode.d0.loss_mask: 1.1916  decode.d0.loss_dice: 1.1752  decode.d1.loss_cls: 0.0406  decode.d1.loss_mask: 1.1533  decode.d1.loss_dice: 1.1598  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 1.1474  decode.d2.loss_dice: 1.1615  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 1.1500  decode.d3.loss_dice: 1.1575  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 1.1433  decode.d4.loss_dice: 1.1537  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 1.1578  decode.d5.loss_dice: 1.1526  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 1.1547  decode.d6.loss_dice: 1.1517  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 1.1679  decode.d7.loss_dice: 1.1427  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 1.1531  decode.d8.loss_dice: 1.1510  mix_decode.loss_cls: 0.0685  mix_decode.loss_mask: 0.5950  mix_decode.loss_dice: 0.7055  mix_decode.d0.loss_cls: 0.1346  mix_decode.d0.loss_mask: 0.5577  mix_decode.d0.loss_dice: 0.7070  mix_decode.d1.loss_cls: 0.0784  mix_decode.d1.loss_mask: 0.5853  mix_decode.d1.loss_dice: 0.7185  mix_decode.d2.loss_cls: 0.0476  mix_decode.d2.loss_mask: 0.5904  mix_decode.d2.loss_dice: 0.7182  mix_decode.d3.loss_cls: 0.0819  mix_decode.d3.loss_mask: 0.5823  mix_decode.d3.loss_dice: 0.7081  mix_decode.d4.loss_cls: 0.0934  mix_decode.d4.loss_mask: 0.5841  mix_decode.d4.loss_dice: 0.7074  mix_decode.d5.loss_cls: 0.0855  mix_decode.d5.loss_mask: 0.5927  mix_decode.d5.loss_dice: 0.7018  mix_decode.d6.loss_cls: 0.0738  mix_decode.d6.loss_mask: 0.5990  mix_decode.d6.loss_dice: 0.7090  mix_decode.d7.loss_cls: 0.0571  mix_decode.d7.loss_mask: 0.6080  mix_decode.d7.loss_dice: 0.7153  mix_decode.d8.loss_cls: 0.0961  mix_decode.d8.loss_mask: 0.5884  mix_decode.d8.loss_dice: 0.6960
2025/03/28 11:15:34 - mmengine - INFO - Iter(train) [ 6450/20000]  base_lr: 7.0443e-05 lr: 7.0443e-05  eta: 2:43:44  time: 1.0730  data_time: 0.0225  memory: 10772  loss: 39.5468  decode.loss_cls: 0.1226  decode.loss_mask: 1.3270  decode.loss_dice: 1.1983  decode.d0.loss_cls: 0.1540  decode.d0.loss_mask: 1.3373  decode.d0.loss_dice: 1.2345  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 1.2850  decode.d1.loss_dice: 1.2202  decode.d2.loss_cls: 0.0880  decode.d2.loss_mask: 1.3366  decode.d2.loss_dice: 1.2024  decode.d3.loss_cls: 0.0846  decode.d3.loss_mask: 1.3207  decode.d3.loss_dice: 1.1780  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 1.3313  decode.d4.loss_dice: 1.2231  decode.d5.loss_cls: 0.1323  decode.d5.loss_mask: 1.3274  decode.d5.loss_dice: 1.2192  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 1.3333  decode.d6.loss_dice: 1.2136  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 1.3244  decode.d7.loss_dice: 1.2169  decode.d8.loss_cls: 0.1595  decode.d8.loss_mask: 1.2847  decode.d8.loss_dice: 1.2051  mix_decode.loss_cls: 0.0834  mix_decode.loss_mask: 0.5741  mix_decode.loss_dice: 0.6314  mix_decode.d0.loss_cls: 0.1245  mix_decode.d0.loss_mask: 0.5788  mix_decode.d0.loss_dice: 0.6458  mix_decode.d1.loss_cls: 0.1300  mix_decode.d1.loss_mask: 0.5707  mix_decode.d1.loss_dice: 0.6308  mix_decode.d2.loss_cls: 0.1081  mix_decode.d2.loss_mask: 0.5749  mix_decode.d2.loss_dice: 0.6244  mix_decode.d3.loss_cls: 0.1042  mix_decode.d3.loss_mask: 0.5725  mix_decode.d3.loss_dice: 0.6303  mix_decode.d4.loss_cls: 0.1296  mix_decode.d4.loss_mask: 0.5536  mix_decode.d4.loss_dice: 0.6362  mix_decode.d5.loss_cls: 0.0844  mix_decode.d5.loss_mask: 0.5648  mix_decode.d5.loss_dice: 0.6289  mix_decode.d6.loss_cls: 0.1009  mix_decode.d6.loss_mask: 0.5694  mix_decode.d6.loss_dice: 0.6139  mix_decode.d7.loss_cls: 0.1082  mix_decode.d7.loss_mask: 0.5697  mix_decode.d7.loss_dice: 0.6344  mix_decode.d8.loss_cls: 0.1001  mix_decode.d8.loss_mask: 0.5679  mix_decode.d8.loss_dice: 0.6384
2025/03/28 11:16:27 - mmengine - INFO - Iter(train) [ 6500/20000]  base_lr: 7.0209e-05 lr: 7.0209e-05  eta: 2:43:44  time: 1.0704  data_time: 0.0219  memory: 10776  loss: 34.6071  decode.loss_cls: 0.0770  decode.loss_mask: 1.1199  decode.loss_dice: 1.0167  decode.d0.loss_cls: 0.1026  decode.d0.loss_mask: 1.1088  decode.d0.loss_dice: 1.0711  decode.d1.loss_cls: 0.1008  decode.d1.loss_mask: 1.1197  decode.d1.loss_dice: 1.0050  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 1.1216  decode.d2.loss_dice: 1.0120  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 1.1134  decode.d3.loss_dice: 1.0006  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 1.1195  decode.d4.loss_dice: 0.9966  decode.d5.loss_cls: 0.0974  decode.d5.loss_mask: 1.1279  decode.d5.loss_dice: 1.0117  decode.d6.loss_cls: 0.1017  decode.d6.loss_mask: 1.1145  decode.d6.loss_dice: 0.9904  decode.d7.loss_cls: 0.1038  decode.d7.loss_mask: 1.1242  decode.d7.loss_dice: 1.0241  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 1.1172  decode.d8.loss_dice: 1.0096  mix_decode.loss_cls: 0.0802  mix_decode.loss_mask: 0.4567  mix_decode.loss_dice: 0.6770  mix_decode.d0.loss_cls: 0.1116  mix_decode.d0.loss_mask: 0.4505  mix_decode.d0.loss_dice: 0.7249  mix_decode.d1.loss_cls: 0.1148  mix_decode.d1.loss_mask: 0.4556  mix_decode.d1.loss_dice: 0.6778  mix_decode.d2.loss_cls: 0.0938  mix_decode.d2.loss_mask: 0.4546  mix_decode.d2.loss_dice: 0.6565  mix_decode.d3.loss_cls: 0.1105  mix_decode.d3.loss_mask: 0.4536  mix_decode.d3.loss_dice: 0.6687  mix_decode.d4.loss_cls: 0.1136  mix_decode.d4.loss_mask: 0.4544  mix_decode.d4.loss_dice: 0.6707  mix_decode.d5.loss_cls: 0.1077  mix_decode.d5.loss_mask: 0.4542  mix_decode.d5.loss_dice: 0.6624  mix_decode.d6.loss_cls: 0.1126  mix_decode.d6.loss_mask: 0.4576  mix_decode.d6.loss_dice: 0.6817  mix_decode.d7.loss_cls: 0.0810  mix_decode.d7.loss_mask: 0.4545  mix_decode.d7.loss_dice: 0.6806  mix_decode.d8.loss_cls: 0.0787  mix_decode.d8.loss_mask: 0.4542  mix_decode.d8.loss_dice: 0.6930
2025/03/28 11:17:21 - mmengine - INFO - Iter(train) [ 6550/20000]  base_lr: 6.9975e-05 lr: 6.9975e-05  eta: 2:43:42  time: 1.0669  data_time: 0.0219  memory: 10775  loss: 37.6448  decode.loss_cls: 0.0547  decode.loss_mask: 1.2858  decode.loss_dice: 1.1075  decode.d0.loss_cls: 0.0861  decode.d0.loss_mask: 1.3076  decode.d0.loss_dice: 1.0926  decode.d1.loss_cls: 0.0224  decode.d1.loss_mask: 1.3027  decode.d1.loss_dice: 1.1147  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 1.2991  decode.d2.loss_dice: 1.1195  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 1.2884  decode.d3.loss_dice: 1.1180  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 1.2889  decode.d4.loss_dice: 1.1211  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 1.2928  decode.d5.loss_dice: 1.1248  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 1.2964  decode.d6.loss_dice: 1.1109  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 1.3004  decode.d7.loss_dice: 1.1155  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 1.2981  decode.d8.loss_dice: 1.1172  mix_decode.loss_cls: 0.0735  mix_decode.loss_mask: 0.5683  mix_decode.loss_dice: 0.6686  mix_decode.d0.loss_cls: 0.0727  mix_decode.d0.loss_mask: 0.5702  mix_decode.d0.loss_dice: 0.6948  mix_decode.d1.loss_cls: 0.0655  mix_decode.d1.loss_mask: 0.5647  mix_decode.d1.loss_dice: 0.6718  mix_decode.d2.loss_cls: 0.0936  mix_decode.d2.loss_mask: 0.5683  mix_decode.d2.loss_dice: 0.6636  mix_decode.d3.loss_cls: 0.0727  mix_decode.d3.loss_mask: 0.5683  mix_decode.d3.loss_dice: 0.6883  mix_decode.d4.loss_cls: 0.0647  mix_decode.d4.loss_mask: 0.5662  mix_decode.d4.loss_dice: 0.6740  mix_decode.d5.loss_cls: 0.0605  mix_decode.d5.loss_mask: 0.5690  mix_decode.d5.loss_dice: 0.6752  mix_decode.d6.loss_cls: 0.0612  mix_decode.d6.loss_mask: 0.5659  mix_decode.d6.loss_dice: 0.6895  mix_decode.d7.loss_cls: 0.0634  mix_decode.d7.loss_mask: 0.5664  mix_decode.d7.loss_dice: 0.6956  mix_decode.d8.loss_cls: 0.0660  mix_decode.d8.loss_mask: 0.5738  mix_decode.d8.loss_dice: 0.6850
2025/03/28 11:18:14 - mmengine - INFO - Iter(train) [ 6600/20000]  base_lr: 6.9741e-05 lr: 6.9741e-05  eta: 2:43:41  time: 1.0709  data_time: 0.0222  memory: 10779  loss: 34.6474  decode.loss_cls: 0.0383  decode.loss_mask: 1.1784  decode.loss_dice: 1.0351  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 1.2073  decode.d0.loss_dice: 1.0881  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 1.1818  decode.d1.loss_dice: 1.0707  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 1.1801  decode.d2.loss_dice: 1.0387  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 1.1802  decode.d3.loss_dice: 1.0599  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 1.1842  decode.d4.loss_dice: 1.0770  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 1.1877  decode.d5.loss_dice: 1.0576  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 1.1849  decode.d6.loss_dice: 1.0708  decode.d7.loss_cls: 0.0409  decode.d7.loss_mask: 1.1835  decode.d7.loss_dice: 1.0791  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 1.1797  decode.d8.loss_dice: 1.0467  mix_decode.loss_cls: 0.0600  mix_decode.loss_mask: 0.4799  mix_decode.loss_dice: 0.6040  mix_decode.d0.loss_cls: 0.0913  mix_decode.d0.loss_mask: 0.4778  mix_decode.d0.loss_dice: 0.6262  mix_decode.d1.loss_cls: 0.1121  mix_decode.d1.loss_mask: 0.4744  mix_decode.d1.loss_dice: 0.6024  mix_decode.d2.loss_cls: 0.1198  mix_decode.d2.loss_mask: 0.4732  mix_decode.d2.loss_dice: 0.6066  mix_decode.d3.loss_cls: 0.0813  mix_decode.d3.loss_mask: 0.4723  mix_decode.d3.loss_dice: 0.6019  mix_decode.d4.loss_cls: 0.0883  mix_decode.d4.loss_mask: 0.4779  mix_decode.d4.loss_dice: 0.5894  mix_decode.d5.loss_cls: 0.1012  mix_decode.d5.loss_mask: 0.4795  mix_decode.d5.loss_dice: 0.6013  mix_decode.d6.loss_cls: 0.0829  mix_decode.d6.loss_mask: 0.4743  mix_decode.d6.loss_dice: 0.6118  mix_decode.d7.loss_cls: 0.0856  mix_decode.d7.loss_mask: 0.4824  mix_decode.d7.loss_dice: 0.6122  mix_decode.d8.loss_cls: 0.0563  mix_decode.d8.loss_mask: 0.4873  mix_decode.d8.loss_dice: 0.6272
2025/03/28 11:19:08 - mmengine - INFO - Iter(train) [ 6650/20000]  base_lr: 6.9507e-05 lr: 6.9507e-05  eta: 2:43:39  time: 1.0726  data_time: 0.0227  memory: 10770  loss: 35.3824  decode.loss_cls: 0.0232  decode.loss_mask: 1.1142  decode.loss_dice: 1.0047  decode.d0.loss_cls: 0.0962  decode.d0.loss_mask: 1.1445  decode.d0.loss_dice: 0.9957  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 1.1262  decode.d1.loss_dice: 1.0053  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 1.1208  decode.d2.loss_dice: 1.0031  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 1.1131  decode.d3.loss_dice: 1.0069  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 1.1148  decode.d4.loss_dice: 1.0079  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 1.1202  decode.d5.loss_dice: 1.0095  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 1.1130  decode.d6.loss_dice: 0.9971  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 1.1173  decode.d7.loss_dice: 1.0090  decode.d8.loss_cls: 0.0218  decode.d8.loss_mask: 1.1073  decode.d8.loss_dice: 1.0060  mix_decode.loss_cls: 0.0915  mix_decode.loss_mask: 0.5601  mix_decode.loss_dice: 0.7382  mix_decode.d0.loss_cls: 0.0533  mix_decode.d0.loss_mask: 0.5639  mix_decode.d0.loss_dice: 0.7553  mix_decode.d1.loss_cls: 0.1064  mix_decode.d1.loss_mask: 0.5510  mix_decode.d1.loss_dice: 0.7252  mix_decode.d2.loss_cls: 0.0990  mix_decode.d2.loss_mask: 0.5517  mix_decode.d2.loss_dice: 0.7306  mix_decode.d3.loss_cls: 0.1310  mix_decode.d3.loss_mask: 0.5525  mix_decode.d3.loss_dice: 0.7235  mix_decode.d4.loss_cls: 0.1016  mix_decode.d4.loss_mask: 0.5596  mix_decode.d4.loss_dice: 0.7275  mix_decode.d5.loss_cls: 0.1021  mix_decode.d5.loss_mask: 0.5619  mix_decode.d5.loss_dice: 0.7385  mix_decode.d6.loss_cls: 0.0937  mix_decode.d6.loss_mask: 0.5561  mix_decode.d6.loss_dice: 0.7320  mix_decode.d7.loss_cls: 0.0914  mix_decode.d7.loss_mask: 0.5632  mix_decode.d7.loss_dice: 0.7274  mix_decode.d8.loss_cls: 0.0757  mix_decode.d8.loss_mask: 0.5623  mix_decode.d8.loss_dice: 0.7314
2025/03/28 11:20:02 - mmengine - INFO - Iter(train) [ 6700/20000]  base_lr: 6.9272e-05 lr: 6.9272e-05  eta: 2:43:35  time: 1.0736  data_time: 0.0221  memory: 10774  loss: 40.0614  decode.loss_cls: 0.0398  decode.loss_mask: 1.2245  decode.loss_dice: 1.2295  decode.d0.loss_cls: 0.1115  decode.d0.loss_mask: 1.2250  decode.d0.loss_dice: 1.2092  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 1.2308  decode.d1.loss_dice: 1.2089  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 1.2362  decode.d2.loss_dice: 1.1971  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 1.2257  decode.d3.loss_dice: 1.2059  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 1.2157  decode.d4.loss_dice: 1.2139  decode.d5.loss_cls: 0.0452  decode.d5.loss_mask: 1.2173  decode.d5.loss_dice: 1.2004  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 1.2167  decode.d6.loss_dice: 1.2050  decode.d7.loss_cls: 0.0964  decode.d7.loss_mask: 1.2250  decode.d7.loss_dice: 1.2130  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 1.2193  decode.d8.loss_dice: 1.2095  mix_decode.loss_cls: 0.0526  mix_decode.loss_mask: 0.6990  mix_decode.loss_dice: 0.7281  mix_decode.d0.loss_cls: 0.1040  mix_decode.d0.loss_mask: 0.7164  mix_decode.d0.loss_dice: 0.7223  mix_decode.d1.loss_cls: 0.0824  mix_decode.d1.loss_mask: 0.6957  mix_decode.d1.loss_dice: 0.7189  mix_decode.d2.loss_cls: 0.0722  mix_decode.d2.loss_mask: 0.6982  mix_decode.d2.loss_dice: 0.7176  mix_decode.d3.loss_cls: 0.0771  mix_decode.d3.loss_mask: 0.6979  mix_decode.d3.loss_dice: 0.7165  mix_decode.d4.loss_cls: 0.0854  mix_decode.d4.loss_mask: 0.6940  mix_decode.d4.loss_dice: 0.7200  mix_decode.d5.loss_cls: 0.0576  mix_decode.d5.loss_mask: 0.7268  mix_decode.d5.loss_dice: 0.7357  mix_decode.d6.loss_cls: 0.0791  mix_decode.d6.loss_mask: 0.6914  mix_decode.d6.loss_dice: 0.7150  mix_decode.d7.loss_cls: 0.0541  mix_decode.d7.loss_mask: 0.7356  mix_decode.d7.loss_dice: 0.7368  mix_decode.d8.loss_cls: 0.0485  mix_decode.d8.loss_mask: 0.7416  mix_decode.d8.loss_dice: 0.7333
2025/03/28 11:20:56 - mmengine - INFO - Iter(train) [ 6750/20000]  base_lr: 6.9038e-05 lr: 6.9038e-05  eta: 2:43:32  time: 1.0744  data_time: 0.0226  memory: 10777  loss: 32.5810  decode.loss_cls: 0.0458  decode.loss_mask: 1.0914  decode.loss_dice: 0.9262  decode.d0.loss_cls: 0.1004  decode.d0.loss_mask: 1.0936  decode.d0.loss_dice: 0.9308  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 1.0852  decode.d1.loss_dice: 0.9367  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 1.0872  decode.d2.loss_dice: 0.9369  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 1.0831  decode.d3.loss_dice: 0.9266  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 1.0810  decode.d4.loss_dice: 0.9396  decode.d5.loss_cls: 0.0245  decode.d5.loss_mask: 1.0791  decode.d5.loss_dice: 0.9416  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 1.0851  decode.d6.loss_dice: 0.9352  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 1.0848  decode.d7.loss_dice: 0.9340  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 1.0906  decode.d8.loss_dice: 0.9393  mix_decode.loss_cls: 0.1046  mix_decode.loss_mask: 0.5224  mix_decode.loss_dice: 0.5498  mix_decode.d0.loss_cls: 0.1002  mix_decode.d0.loss_mask: 0.5281  mix_decode.d0.loss_dice: 0.6086  mix_decode.d1.loss_cls: 0.0904  mix_decode.d1.loss_mask: 0.5232  mix_decode.d1.loss_dice: 0.5764  mix_decode.d2.loss_cls: 0.1053  mix_decode.d2.loss_mask: 0.5256  mix_decode.d2.loss_dice: 0.5573  mix_decode.d3.loss_cls: 0.1120  mix_decode.d3.loss_mask: 0.5230  mix_decode.d3.loss_dice: 0.5633  mix_decode.d4.loss_cls: 0.1109  mix_decode.d4.loss_mask: 0.5265  mix_decode.d4.loss_dice: 0.5725  mix_decode.d5.loss_cls: 0.1248  mix_decode.d5.loss_mask: 0.5147  mix_decode.d5.loss_dice: 0.5646  mix_decode.d6.loss_cls: 0.1326  mix_decode.d6.loss_mask: 0.5173  mix_decode.d6.loss_dice: 0.5583  mix_decode.d7.loss_cls: 0.1257  mix_decode.d7.loss_mask: 0.5210  mix_decode.d7.loss_dice: 0.5565  mix_decode.d8.loss_cls: 0.1138  mix_decode.d8.loss_mask: 0.5247  mix_decode.d8.loss_dice: 0.5562
2025/03/28 11:21:49 - mmengine - INFO - Iter(train) [ 6800/20000]  base_lr: 6.8803e-05 lr: 6.8803e-05  eta: 2:43:27  time: 1.0769  data_time: 0.0228  memory: 10785  loss: 34.4553  decode.loss_cls: 0.0166  decode.loss_mask: 1.0441  decode.loss_dice: 1.0590  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 1.0455  decode.d0.loss_dice: 1.0697  decode.d1.loss_cls: 0.0235  decode.d1.loss_mask: 1.0370  decode.d1.loss_dice: 1.0628  decode.d2.loss_cls: 0.0211  decode.d2.loss_mask: 1.0290  decode.d2.loss_dice: 1.0613  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 1.0348  decode.d3.loss_dice: 1.0612  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 1.0399  decode.d4.loss_dice: 1.0632  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 1.0449  decode.d5.loss_dice: 1.0569  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 1.0414  decode.d6.loss_dice: 1.0544  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 1.0440  decode.d7.loss_dice: 1.0620  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 1.0451  decode.d8.loss_dice: 1.0700  mix_decode.loss_cls: 0.1052  mix_decode.loss_mask: 0.5422  mix_decode.loss_dice: 0.6508  mix_decode.d0.loss_cls: 0.1848  mix_decode.d0.loss_mask: 0.5053  mix_decode.d0.loss_dice: 0.6894  mix_decode.d1.loss_cls: 0.1370  mix_decode.d1.loss_mask: 0.5071  mix_decode.d1.loss_dice: 0.6437  mix_decode.d2.loss_cls: 0.1296  mix_decode.d2.loss_mask: 0.5270  mix_decode.d2.loss_dice: 0.6596  mix_decode.d3.loss_cls: 0.1235  mix_decode.d3.loss_mask: 0.5234  mix_decode.d3.loss_dice: 0.6392  mix_decode.d4.loss_cls: 0.1523  mix_decode.d4.loss_mask: 0.5120  mix_decode.d4.loss_dice: 0.6508  mix_decode.d5.loss_cls: 0.1357  mix_decode.d5.loss_mask: 0.5321  mix_decode.d5.loss_dice: 0.6449  mix_decode.d6.loss_cls: 0.1346  mix_decode.d6.loss_mask: 0.5378  mix_decode.d6.loss_dice: 0.6370  mix_decode.d7.loss_cls: 0.1221  mix_decode.d7.loss_mask: 0.5481  mix_decode.d7.loss_dice: 0.6593  mix_decode.d8.loss_cls: 0.1376  mix_decode.d8.loss_mask: 0.5457  mix_decode.d8.loss_dice: 0.6604
2025/03/28 11:22:43 - mmengine - INFO - Iter(train) [ 6850/20000]  base_lr: 6.8569e-05 lr: 6.8569e-05  eta: 2:43:22  time: 1.0742  data_time: 0.0227  memory: 10776  loss: 38.0998  decode.loss_cls: 0.0534  decode.loss_mask: 1.2470  decode.loss_dice: 1.0637  decode.d0.loss_cls: 0.1405  decode.d0.loss_mask: 1.2408  decode.d0.loss_dice: 1.0571  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 1.2393  decode.d1.loss_dice: 1.0489  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 1.2418  decode.d2.loss_dice: 1.0552  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 1.2452  decode.d3.loss_dice: 1.0246  decode.d4.loss_cls: 0.0957  decode.d4.loss_mask: 1.2411  decode.d4.loss_dice: 1.0380  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 1.2511  decode.d5.loss_dice: 1.0500  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 1.2488  decode.d6.loss_dice: 1.0184  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 1.2444  decode.d7.loss_dice: 1.0536  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 1.2404  decode.d8.loss_dice: 1.0561  mix_decode.loss_cls: 0.1090  mix_decode.loss_mask: 0.6585  mix_decode.loss_dice: 0.7077  mix_decode.d0.loss_cls: 0.1450  mix_decode.d0.loss_mask: 0.6200  mix_decode.d0.loss_dice: 0.7340  mix_decode.d1.loss_cls: 0.0740  mix_decode.d1.loss_mask: 0.6505  mix_decode.d1.loss_dice: 0.7040  mix_decode.d2.loss_cls: 0.0960  mix_decode.d2.loss_mask: 0.6418  mix_decode.d2.loss_dice: 0.7066  mix_decode.d3.loss_cls: 0.1087  mix_decode.d3.loss_mask: 0.6244  mix_decode.d3.loss_dice: 0.6953  mix_decode.d4.loss_cls: 0.1053  mix_decode.d4.loss_mask: 0.6485  mix_decode.d4.loss_dice: 0.6979  mix_decode.d5.loss_cls: 0.0981  mix_decode.d5.loss_mask: 0.6441  mix_decode.d5.loss_dice: 0.6989  mix_decode.d6.loss_cls: 0.0961  mix_decode.d6.loss_mask: 0.6133  mix_decode.d6.loss_dice: 0.7114  mix_decode.d7.loss_cls: 0.0963  mix_decode.d7.loss_mask: 0.6143  mix_decode.d7.loss_dice: 0.6805  mix_decode.d8.loss_cls: 0.1012  mix_decode.d8.loss_mask: 0.6334  mix_decode.d8.loss_dice: 0.6939
2025/03/28 11:23:37 - mmengine - INFO - Iter(train) [ 6900/20000]  base_lr: 6.8334e-05 lr: 6.8334e-05  eta: 2:43:15  time: 1.0667  data_time: 0.0220  memory: 10779  loss: 35.7795  decode.loss_cls: 0.0233  decode.loss_mask: 1.0321  decode.loss_dice: 1.0737  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 1.0717  decode.d0.loss_dice: 1.0749  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 1.0368  decode.d1.loss_dice: 1.0754  decode.d2.loss_cls: 0.0253  decode.d2.loss_mask: 1.0387  decode.d2.loss_dice: 1.0845  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 1.0384  decode.d3.loss_dice: 1.0790  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 1.0381  decode.d4.loss_dice: 1.0715  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 1.0348  decode.d5.loss_dice: 1.0695  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 1.0347  decode.d6.loss_dice: 1.0552  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 1.0371  decode.d7.loss_dice: 1.0720  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 1.0340  decode.d8.loss_dice: 1.0647  mix_decode.loss_cls: 0.0891  mix_decode.loss_mask: 0.5378  mix_decode.loss_dice: 0.7760  mix_decode.d0.loss_cls: 0.0726  mix_decode.d0.loss_mask: 0.5411  mix_decode.d0.loss_dice: 0.8155  mix_decode.d1.loss_cls: 0.1322  mix_decode.d1.loss_mask: 0.5411  mix_decode.d1.loss_dice: 0.7805  mix_decode.d2.loss_cls: 0.1190  mix_decode.d2.loss_mask: 0.5409  mix_decode.d2.loss_dice: 0.7575  mix_decode.d3.loss_cls: 0.1174  mix_decode.d3.loss_mask: 0.5397  mix_decode.d3.loss_dice: 0.7607  mix_decode.d4.loss_cls: 0.1263  mix_decode.d4.loss_mask: 0.5363  mix_decode.d4.loss_dice: 0.7607  mix_decode.d5.loss_cls: 0.1270  mix_decode.d5.loss_mask: 0.5383  mix_decode.d5.loss_dice: 0.7609  mix_decode.d6.loss_cls: 0.0947  mix_decode.d6.loss_mask: 0.5385  mix_decode.d6.loss_dice: 0.7660  mix_decode.d7.loss_cls: 0.1078  mix_decode.d7.loss_mask: 0.5362  mix_decode.d7.loss_dice: 0.7646  mix_decode.d8.loss_cls: 0.1056  mix_decode.d8.loss_mask: 0.5416  mix_decode.d8.loss_dice: 0.7669
2025/03/28 11:24:31 - mmengine - INFO - Iter(train) [ 6950/20000]  base_lr: 6.8099e-05 lr: 6.8099e-05  eta: 2:43:09  time: 1.0852  data_time: 0.0237  memory: 10775  loss: 31.0319  decode.loss_cls: 0.0324  decode.loss_mask: 1.0181  decode.loss_dice: 1.0560  decode.d0.loss_cls: 0.1112  decode.d0.loss_mask: 1.0062  decode.d0.loss_dice: 1.0446  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 1.0165  decode.d1.loss_dice: 1.0373  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 1.0176  decode.d2.loss_dice: 1.0304  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 1.0108  decode.d3.loss_dice: 1.0494  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 1.0211  decode.d4.loss_dice: 1.0295  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 1.0160  decode.d5.loss_dice: 1.0272  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 1.0239  decode.d6.loss_dice: 1.0355  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 1.0205  decode.d7.loss_dice: 1.0396  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 1.0169  decode.d8.loss_dice: 1.0439  mix_decode.loss_cls: 0.0595  mix_decode.loss_mask: 0.4275  mix_decode.loss_dice: 0.4777  mix_decode.d0.loss_cls: 0.1151  mix_decode.d0.loss_mask: 0.4298  mix_decode.d0.loss_dice: 0.4992  mix_decode.d1.loss_cls: 0.1184  mix_decode.d1.loss_mask: 0.4275  mix_decode.d1.loss_dice: 0.4751  mix_decode.d2.loss_cls: 0.0915  mix_decode.d2.loss_mask: 0.4318  mix_decode.d2.loss_dice: 0.4864  mix_decode.d3.loss_cls: 0.0863  mix_decode.d3.loss_mask: 0.4302  mix_decode.d3.loss_dice: 0.4849  mix_decode.d4.loss_cls: 0.0823  mix_decode.d4.loss_mask: 0.4293  mix_decode.d4.loss_dice: 0.4765  mix_decode.d5.loss_cls: 0.0661  mix_decode.d5.loss_mask: 0.4296  mix_decode.d5.loss_dice: 0.4801  mix_decode.d6.loss_cls: 0.0516  mix_decode.d6.loss_mask: 0.4337  mix_decode.d6.loss_dice: 0.4940  mix_decode.d7.loss_cls: 0.0642  mix_decode.d7.loss_mask: 0.4344  mix_decode.d7.loss_dice: 0.4921  mix_decode.d8.loss_cls: 0.0717  mix_decode.d8.loss_mask: 0.4289  mix_decode.d8.loss_dice: 0.4887
2025/03/28 11:25:24 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 11:25:24 - mmengine - INFO - Iter(train) [ 7000/20000]  base_lr: 6.7864e-05 lr: 6.7864e-05  eta: 2:43:01  time: 1.0743  data_time: 0.0229  memory: 10779  loss: 38.0089  decode.loss_cls: 0.0585  decode.loss_mask: 1.1072  decode.loss_dice: 1.1914  decode.d0.loss_cls: 0.1350  decode.d0.loss_mask: 1.1185  decode.d0.loss_dice: 1.1949  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 1.1167  decode.d1.loss_dice: 1.2041  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 1.1089  decode.d2.loss_dice: 1.1555  decode.d3.loss_cls: 0.1123  decode.d3.loss_mask: 1.1192  decode.d3.loss_dice: 1.1764  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 1.1123  decode.d4.loss_dice: 1.1547  decode.d5.loss_cls: 0.1397  decode.d5.loss_mask: 1.1115  decode.d5.loss_dice: 1.1721  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 1.1247  decode.d6.loss_dice: 1.2079  decode.d7.loss_cls: 0.0881  decode.d7.loss_mask: 1.1162  decode.d7.loss_dice: 1.1850  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 1.1080  decode.d8.loss_dice: 1.2048  mix_decode.loss_cls: 0.1670  mix_decode.loss_mask: 0.5150  mix_decode.loss_dice: 0.7079  mix_decode.d0.loss_cls: 0.2648  mix_decode.d0.loss_mask: 0.4881  mix_decode.d0.loss_dice: 0.7339  mix_decode.d1.loss_cls: 0.1907  mix_decode.d1.loss_mask: 0.5262  mix_decode.d1.loss_dice: 0.7014  mix_decode.d2.loss_cls: 0.1746  mix_decode.d2.loss_mask: 0.5208  mix_decode.d2.loss_dice: 0.6986  mix_decode.d3.loss_cls: 0.1731  mix_decode.d3.loss_mask: 0.5280  mix_decode.d3.loss_dice: 0.7011  mix_decode.d4.loss_cls: 0.1755  mix_decode.d4.loss_mask: 0.4966  mix_decode.d4.loss_dice: 0.7016  mix_decode.d5.loss_cls: 0.2208  mix_decode.d5.loss_mask: 0.4915  mix_decode.d5.loss_dice: 0.6919  mix_decode.d6.loss_cls: 0.1794  mix_decode.d6.loss_mask: 0.4915  mix_decode.d6.loss_dice: 0.6901  mix_decode.d7.loss_cls: 0.2004  mix_decode.d7.loss_mask: 0.4906  mix_decode.d7.loss_dice: 0.7075  mix_decode.d8.loss_cls: 0.1877  mix_decode.d8.loss_mask: 0.5117  mix_decode.d8.loss_dice: 0.7131
2025/03/28 11:26:18 - mmengine - INFO - Iter(train) [ 7050/20000]  base_lr: 6.7629e-05 lr: 6.7629e-05  eta: 2:42:53  time: 1.0757  data_time: 0.0228  memory: 10770  loss: 33.7807  decode.loss_cls: 0.0215  decode.loss_mask: 1.0150  decode.loss_dice: 1.0130  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 1.0305  decode.d0.loss_dice: 0.9634  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 1.0221  decode.d1.loss_dice: 0.9871  decode.d2.loss_cls: 0.0461  decode.d2.loss_mask: 1.0290  decode.d2.loss_dice: 0.9855  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 1.0284  decode.d3.loss_dice: 0.9923  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 1.0228  decode.d4.loss_dice: 0.9973  decode.d5.loss_cls: 0.0223  decode.d5.loss_mask: 1.0257  decode.d5.loss_dice: 0.9991  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 1.0171  decode.d6.loss_dice: 0.9968  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 1.0180  decode.d7.loss_dice: 0.9937  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 1.0151  decode.d8.loss_dice: 1.0061  mix_decode.loss_cls: 0.1014  mix_decode.loss_mask: 0.5262  mix_decode.loss_dice: 0.6973  mix_decode.d0.loss_cls: 0.1422  mix_decode.d0.loss_mask: 0.4996  mix_decode.d0.loss_dice: 0.7194  mix_decode.d1.loss_cls: 0.1335  mix_decode.d1.loss_mask: 0.5157  mix_decode.d1.loss_dice: 0.6664  mix_decode.d2.loss_cls: 0.1220  mix_decode.d2.loss_mask: 0.5067  mix_decode.d2.loss_dice: 0.6971  mix_decode.d3.loss_cls: 0.1349  mix_decode.d3.loss_mask: 0.5032  mix_decode.d3.loss_dice: 0.6888  mix_decode.d4.loss_cls: 0.1375  mix_decode.d4.loss_mask: 0.5123  mix_decode.d4.loss_dice: 0.6885  mix_decode.d5.loss_cls: 0.1274  mix_decode.d5.loss_mask: 0.5042  mix_decode.d5.loss_dice: 0.6694  mix_decode.d6.loss_cls: 0.1207  mix_decode.d6.loss_mask: 0.5023  mix_decode.d6.loss_dice: 0.7039  mix_decode.d7.loss_cls: 0.1459  mix_decode.d7.loss_mask: 0.4962  mix_decode.d7.loss_dice: 0.6872  mix_decode.d8.loss_cls: 0.1602  mix_decode.d8.loss_mask: 0.5141  mix_decode.d8.loss_dice: 0.6902
2025/03/28 11:27:12 - mmengine - INFO - Iter(train) [ 7100/20000]  base_lr: 6.7394e-05 lr: 6.7394e-05  eta: 2:42:45  time: 1.0792  data_time: 0.0235  memory: 10776  loss: 34.1280  decode.loss_cls: 0.1384  decode.loss_mask: 1.0557  decode.loss_dice: 1.2074  decode.d0.loss_cls: 0.2132  decode.d0.loss_mask: 0.9481  decode.d0.loss_dice: 1.2221  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 0.9289  decode.d1.loss_dice: 1.1772  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.9994  decode.d2.loss_dice: 1.1671  decode.d3.loss_cls: 0.1413  decode.d3.loss_mask: 0.9983  decode.d3.loss_dice: 1.1593  decode.d4.loss_cls: 0.1586  decode.d4.loss_mask: 1.0021  decode.d4.loss_dice: 1.1672  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 1.0057  decode.d5.loss_dice: 1.1965  decode.d6.loss_cls: 0.1605  decode.d6.loss_mask: 0.9976  decode.d6.loss_dice: 1.1870  decode.d7.loss_cls: 0.1684  decode.d7.loss_mask: 0.9999  decode.d7.loss_dice: 1.1677  decode.d8.loss_cls: 0.1704  decode.d8.loss_mask: 1.0081  decode.d8.loss_dice: 1.1999  mix_decode.loss_cls: 0.0430  mix_decode.loss_mask: 0.4861  mix_decode.loss_dice: 0.5407  mix_decode.d0.loss_cls: 0.0695  mix_decode.d0.loss_mask: 0.4937  mix_decode.d0.loss_dice: 0.5367  mix_decode.d1.loss_cls: 0.0486  mix_decode.d1.loss_mask: 0.4843  mix_decode.d1.loss_dice: 0.5227  mix_decode.d2.loss_cls: 0.0356  mix_decode.d2.loss_mask: 0.4835  mix_decode.d2.loss_dice: 0.5356  mix_decode.d3.loss_cls: 0.0446  mix_decode.d3.loss_mask: 0.4828  mix_decode.d3.loss_dice: 0.5381  mix_decode.d4.loss_cls: 0.0498  mix_decode.d4.loss_mask: 0.4843  mix_decode.d4.loss_dice: 0.5396  mix_decode.d5.loss_cls: 0.0405  mix_decode.d5.loss_mask: 0.4846  mix_decode.d5.loss_dice: 0.5297  mix_decode.d6.loss_cls: 0.0395  mix_decode.d6.loss_mask: 0.4846  mix_decode.d6.loss_dice: 0.5419  mix_decode.d7.loss_cls: 0.0226  mix_decode.d7.loss_mask: 0.4859  mix_decode.d7.loss_dice: 0.5372  mix_decode.d8.loss_cls: 0.0351  mix_decode.d8.loss_mask: 0.4855  mix_decode.d8.loss_dice: 0.5425
2025/03/28 11:28:06 - mmengine - INFO - Iter(train) [ 7150/20000]  base_lr: 6.7159e-05 lr: 6.7159e-05  eta: 2:42:36  time: 1.0753  data_time: 0.0221  memory: 10773  loss: 36.5867  decode.loss_cls: 0.0352  decode.loss_mask: 1.0666  decode.loss_dice: 1.1407  decode.d0.loss_cls: 0.1060  decode.d0.loss_mask: 1.0708  decode.d0.loss_dice: 1.0973  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 1.0749  decode.d1.loss_dice: 1.1400  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 1.0732  decode.d2.loss_dice: 1.1386  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 1.0661  decode.d3.loss_dice: 1.1297  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 1.0666  decode.d4.loss_dice: 1.1329  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 1.0714  decode.d5.loss_dice: 1.1365  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 1.0650  decode.d6.loss_dice: 1.1319  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 1.0608  decode.d7.loss_dice: 1.1283  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 1.0619  decode.d8.loss_dice: 1.1375  mix_decode.loss_cls: 0.1687  mix_decode.loss_mask: 0.4769  mix_decode.loss_dice: 0.7582  mix_decode.d0.loss_cls: 0.1340  mix_decode.d0.loss_mask: 0.4901  mix_decode.d0.loss_dice: 0.8332  mix_decode.d1.loss_cls: 0.1557  mix_decode.d1.loss_mask: 0.4770  mix_decode.d1.loss_dice: 0.7838  mix_decode.d2.loss_cls: 0.1656  mix_decode.d2.loss_mask: 0.4757  mix_decode.d2.loss_dice: 0.7629  mix_decode.d3.loss_cls: 0.1763  mix_decode.d3.loss_mask: 0.4824  mix_decode.d3.loss_dice: 0.7663  mix_decode.d4.loss_cls: 0.1329  mix_decode.d4.loss_mask: 0.4977  mix_decode.d4.loss_dice: 0.7706  mix_decode.d5.loss_cls: 0.1203  mix_decode.d5.loss_mask: 0.4938  mix_decode.d5.loss_dice: 0.7795  mix_decode.d6.loss_cls: 0.1292  mix_decode.d6.loss_mask: 0.4797  mix_decode.d6.loss_dice: 0.7849  mix_decode.d7.loss_cls: 0.1117  mix_decode.d7.loss_mask: 0.4845  mix_decode.d7.loss_dice: 0.7933  mix_decode.d8.loss_cls: 0.1352  mix_decode.d8.loss_mask: 0.4929  mix_decode.d8.loss_dice: 0.7820
2025/03/28 11:28:59 - mmengine - INFO - Iter(train) [ 7200/20000]  base_lr: 6.6924e-05 lr: 6.6924e-05  eta: 2:42:26  time: 1.0773  data_time: 0.0237  memory: 10774  loss: 33.2471  decode.loss_cls: 0.0199  decode.loss_mask: 1.0031  decode.loss_dice: 1.0219  decode.d0.loss_cls: 0.0652  decode.d0.loss_mask: 1.0306  decode.d0.loss_dice: 1.0479  decode.d1.loss_cls: 0.0284  decode.d1.loss_mask: 1.0046  decode.d1.loss_dice: 1.0428  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 1.0038  decode.d2.loss_dice: 1.0259  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 1.0052  decode.d3.loss_dice: 1.0229  decode.d4.loss_cls: 0.0171  decode.d4.loss_mask: 1.0040  decode.d4.loss_dice: 1.0243  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 1.0058  decode.d5.loss_dice: 1.0346  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.9981  decode.d6.loss_dice: 1.0325  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.9981  decode.d7.loss_dice: 1.0410  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.9987  decode.d8.loss_dice: 1.0337  mix_decode.loss_cls: 0.0682  mix_decode.loss_mask: 0.5247  mix_decode.loss_dice: 0.6517  mix_decode.d0.loss_cls: 0.0781  mix_decode.d0.loss_mask: 0.5157  mix_decode.d0.loss_dice: 0.6812  mix_decode.d1.loss_cls: 0.0876  mix_decode.d1.loss_mask: 0.5107  mix_decode.d1.loss_dice: 0.6606  mix_decode.d2.loss_cls: 0.1243  mix_decode.d2.loss_mask: 0.5159  mix_decode.d2.loss_dice: 0.6422  mix_decode.d3.loss_cls: 0.1200  mix_decode.d3.loss_mask: 0.5189  mix_decode.d3.loss_dice: 0.6411  mix_decode.d4.loss_cls: 0.0786  mix_decode.d4.loss_mask: 0.5134  mix_decode.d4.loss_dice: 0.6619  mix_decode.d5.loss_cls: 0.0988  mix_decode.d5.loss_mask: 0.5122  mix_decode.d5.loss_dice: 0.6441  mix_decode.d6.loss_cls: 0.0947  mix_decode.d6.loss_mask: 0.5264  mix_decode.d6.loss_dice: 0.6551  mix_decode.d7.loss_cls: 0.0779  mix_decode.d7.loss_mask: 0.5155  mix_decode.d7.loss_dice: 0.6590  mix_decode.d8.loss_cls: 0.0706  mix_decode.d8.loss_mask: 0.5141  mix_decode.d8.loss_dice: 0.6565
2025/03/28 11:29:53 - mmengine - INFO - Iter(train) [ 7250/20000]  base_lr: 6.6689e-05 lr: 6.6689e-05  eta: 2:42:16  time: 1.0779  data_time: 0.0232  memory: 10777  loss: 37.6746  decode.loss_cls: 0.0264  decode.loss_mask: 1.2678  decode.loss_dice: 1.0756  decode.d0.loss_cls: 0.1159  decode.d0.loss_mask: 1.2683  decode.d0.loss_dice: 1.0727  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 1.2681  decode.d1.loss_dice: 1.0804  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 1.2709  decode.d2.loss_dice: 1.0789  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 1.2619  decode.d3.loss_dice: 1.0791  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 1.2621  decode.d4.loss_dice: 1.0796  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 1.2556  decode.d5.loss_dice: 1.0919  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 1.2641  decode.d6.loss_dice: 1.0770  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 1.2644  decode.d7.loss_dice: 1.0841  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 1.2669  decode.d8.loss_dice: 1.0998  mix_decode.loss_cls: 0.1988  mix_decode.loss_mask: 0.5563  mix_decode.loss_dice: 0.6607  mix_decode.d0.loss_cls: 0.1144  mix_decode.d0.loss_mask: 0.5556  mix_decode.d0.loss_dice: 0.7143  mix_decode.d1.loss_cls: 0.1798  mix_decode.d1.loss_mask: 0.5733  mix_decode.d1.loss_dice: 0.6572  mix_decode.d2.loss_cls: 0.1700  mix_decode.d2.loss_mask: 0.5812  mix_decode.d2.loss_dice: 0.6467  mix_decode.d3.loss_cls: 0.1601  mix_decode.d3.loss_mask: 0.5449  mix_decode.d3.loss_dice: 0.6512  mix_decode.d4.loss_cls: 0.1640  mix_decode.d4.loss_mask: 0.5581  mix_decode.d4.loss_dice: 0.6531  mix_decode.d5.loss_cls: 0.1485  mix_decode.d5.loss_mask: 0.5796  mix_decode.d5.loss_dice: 0.6729  mix_decode.d6.loss_cls: 0.1704  mix_decode.d6.loss_mask: 0.5577  mix_decode.d6.loss_dice: 0.6618  mix_decode.d7.loss_cls: 0.1635  mix_decode.d7.loss_mask: 0.5707  mix_decode.d7.loss_dice: 0.6591  mix_decode.d8.loss_cls: 0.1395  mix_decode.d8.loss_mask: 0.5732  mix_decode.d8.loss_dice: 0.6579
2025/03/28 11:30:47 - mmengine - INFO - Iter(train) [ 7300/20000]  base_lr: 6.6453e-05 lr: 6.6453e-05  eta: 2:42:05  time: 1.0758  data_time: 0.0224  memory: 10776  loss: 33.1348  decode.loss_cls: 0.0303  decode.loss_mask: 1.0015  decode.loss_dice: 1.0539  decode.d0.loss_cls: 0.1089  decode.d0.loss_mask: 1.0175  decode.d0.loss_dice: 1.0736  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 1.0132  decode.d1.loss_dice: 1.0510  decode.d2.loss_cls: 0.0354  decode.d2.loss_mask: 1.0122  decode.d2.loss_dice: 1.0630  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 1.0122  decode.d3.loss_dice: 1.0702  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 1.0058  decode.d4.loss_dice: 1.0577  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 1.0172  decode.d5.loss_dice: 1.0837  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 1.0128  decode.d6.loss_dice: 1.0460  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 1.0133  decode.d7.loss_dice: 1.0618  decode.d8.loss_cls: 0.0332  decode.d8.loss_mask: 1.0084  decode.d8.loss_dice: 1.0756  mix_decode.loss_cls: 0.1312  mix_decode.loss_mask: 0.4719  mix_decode.loss_dice: 0.5865  mix_decode.d0.loss_cls: 0.0916  mix_decode.d0.loss_mask: 0.4908  mix_decode.d0.loss_dice: 0.6143  mix_decode.d1.loss_cls: 0.0990  mix_decode.d1.loss_mask: 0.4817  mix_decode.d1.loss_dice: 0.6039  mix_decode.d2.loss_cls: 0.1354  mix_decode.d2.loss_mask: 0.4716  mix_decode.d2.loss_dice: 0.5959  mix_decode.d3.loss_cls: 0.1002  mix_decode.d3.loss_mask: 0.4828  mix_decode.d3.loss_dice: 0.5960  mix_decode.d4.loss_cls: 0.0819  mix_decode.d4.loss_mask: 0.4826  mix_decode.d4.loss_dice: 0.6188  mix_decode.d5.loss_cls: 0.0767  mix_decode.d5.loss_mask: 0.4803  mix_decode.d5.loss_dice: 0.6257  mix_decode.d6.loss_cls: 0.1050  mix_decode.d6.loss_mask: 0.4836  mix_decode.d6.loss_dice: 0.6048  mix_decode.d7.loss_cls: 0.1078  mix_decode.d7.loss_mask: 0.4812  mix_decode.d7.loss_dice: 0.6023  mix_decode.d8.loss_cls: 0.1043  mix_decode.d8.loss_mask: 0.4810  mix_decode.d8.loss_dice: 0.5968
2025/03/28 11:31:41 - mmengine - INFO - Iter(train) [ 7350/20000]  base_lr: 6.6218e-05 lr: 6.6218e-05  eta: 2:41:53  time: 1.0680  data_time: 0.0222  memory: 10769  loss: 35.8357  decode.loss_cls: 0.0366  decode.loss_mask: 1.0781  decode.loss_dice: 1.0666  decode.d0.loss_cls: 0.1108  decode.d0.loss_mask: 1.0736  decode.d0.loss_dice: 1.0720  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 1.0800  decode.d1.loss_dice: 1.0761  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 1.0762  decode.d2.loss_dice: 1.0666  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 1.0828  decode.d3.loss_dice: 1.0630  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 1.0758  decode.d4.loss_dice: 1.0489  decode.d5.loss_cls: 0.0397  decode.d5.loss_mask: 1.0777  decode.d5.loss_dice: 1.0559  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 1.0730  decode.d6.loss_dice: 1.0736  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 1.0774  decode.d7.loss_dice: 1.0720  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 1.0779  decode.d8.loss_dice: 1.0776  mix_decode.loss_cls: 0.1594  mix_decode.loss_mask: 0.5407  mix_decode.loss_dice: 0.6799  mix_decode.d0.loss_cls: 0.1626  mix_decode.d0.loss_mask: 0.5173  mix_decode.d0.loss_dice: 0.7387  mix_decode.d1.loss_cls: 0.2104  mix_decode.d1.loss_mask: 0.4991  mix_decode.d1.loss_dice: 0.6715  mix_decode.d2.loss_cls: 0.1984  mix_decode.d2.loss_mask: 0.5070  mix_decode.d2.loss_dice: 0.6632  mix_decode.d3.loss_cls: 0.1944  mix_decode.d3.loss_mask: 0.5145  mix_decode.d3.loss_dice: 0.6627  mix_decode.d4.loss_cls: 0.1416  mix_decode.d4.loss_mask: 0.5163  mix_decode.d4.loss_dice: 0.6971  mix_decode.d5.loss_cls: 0.1461  mix_decode.d5.loss_mask: 0.5371  mix_decode.d5.loss_dice: 0.6995  mix_decode.d6.loss_cls: 0.1576  mix_decode.d6.loss_mask: 0.5323  mix_decode.d6.loss_dice: 0.7095  mix_decode.d7.loss_cls: 0.1878  mix_decode.d7.loss_mask: 0.5253  mix_decode.d7.loss_dice: 0.6805  mix_decode.d8.loss_cls: 0.1695  mix_decode.d8.loss_mask: 0.5381  mix_decode.d8.loss_dice: 0.6812
2025/03/28 11:32:34 - mmengine - INFO - Iter(train) [ 7400/20000]  base_lr: 6.5982e-05 lr: 6.5982e-05  eta: 2:41:40  time: 1.0812  data_time: 0.0218  memory: 10774  loss: 31.0716  decode.loss_cls: 0.0192  decode.loss_mask: 1.0211  decode.loss_dice: 0.9525  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 1.0215  decode.d0.loss_dice: 0.9484  decode.d1.loss_cls: 0.0363  decode.d1.loss_mask: 1.0268  decode.d1.loss_dice: 0.9342  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 1.0240  decode.d2.loss_dice: 0.9429  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 1.0285  decode.d3.loss_dice: 0.9502  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 1.0224  decode.d4.loss_dice: 0.9453  decode.d5.loss_cls: 0.0247  decode.d5.loss_mask: 1.0155  decode.d5.loss_dice: 0.9569  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 1.0175  decode.d6.loss_dice: 0.9484  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 1.0180  decode.d7.loss_dice: 0.9478  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 1.0190  decode.d8.loss_dice: 0.9529  mix_decode.loss_cls: 0.0837  mix_decode.loss_mask: 0.4574  mix_decode.loss_dice: 0.5646  mix_decode.d0.loss_cls: 0.0937  mix_decode.d0.loss_mask: 0.4578  mix_decode.d0.loss_dice: 0.5780  mix_decode.d1.loss_cls: 0.1257  mix_decode.d1.loss_mask: 0.4623  mix_decode.d1.loss_dice: 0.5498  mix_decode.d2.loss_cls: 0.0575  mix_decode.d2.loss_mask: 0.4723  mix_decode.d2.loss_dice: 0.5638  mix_decode.d3.loss_cls: 0.1161  mix_decode.d3.loss_mask: 0.4552  mix_decode.d3.loss_dice: 0.5333  mix_decode.d4.loss_cls: 0.1176  mix_decode.d4.loss_mask: 0.4566  mix_decode.d4.loss_dice: 0.5313  mix_decode.d5.loss_cls: 0.0575  mix_decode.d5.loss_mask: 0.4650  mix_decode.d5.loss_dice: 0.5757  mix_decode.d6.loss_cls: 0.0925  mix_decode.d6.loss_mask: 0.4510  mix_decode.d6.loss_dice: 0.5596  mix_decode.d7.loss_cls: 0.0638  mix_decode.d7.loss_mask: 0.4673  mix_decode.d7.loss_dice: 0.5676  mix_decode.d8.loss_cls: 0.0998  mix_decode.d8.loss_mask: 0.4554  mix_decode.d8.loss_dice: 0.5516
2025/03/28 11:33:28 - mmengine - INFO - Iter(train) [ 7450/20000]  base_lr: 6.5746e-05 lr: 6.5746e-05  eta: 2:41:27  time: 1.0745  data_time: 0.0222  memory: 10780  loss: 37.2436  decode.loss_cls: 0.0121  decode.loss_mask: 1.0413  decode.loss_dice: 1.0681  decode.d0.loss_cls: 0.0648  decode.d0.loss_mask: 1.0581  decode.d0.loss_dice: 1.0864  decode.d1.loss_cls: 0.0162  decode.d1.loss_mask: 1.0542  decode.d1.loss_dice: 1.0738  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 1.0497  decode.d2.loss_dice: 1.0723  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 1.0464  decode.d3.loss_dice: 1.0593  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 1.0494  decode.d4.loss_dice: 1.0620  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 1.0503  decode.d5.loss_dice: 1.0586  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 1.0490  decode.d6.loss_dice: 1.0566  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 1.0480  decode.d7.loss_dice: 1.0691  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 1.0431  decode.d8.loss_dice: 1.0754  mix_decode.loss_cls: 0.1437  mix_decode.loss_mask: 0.6796  mix_decode.loss_dice: 0.7379  mix_decode.d0.loss_cls: 0.1865  mix_decode.d0.loss_mask: 0.6737  mix_decode.d0.loss_dice: 0.7528  mix_decode.d1.loss_cls: 0.1947  mix_decode.d1.loss_mask: 0.6609  mix_decode.d1.loss_dice: 0.7381  mix_decode.d2.loss_cls: 0.1646  mix_decode.d2.loss_mask: 0.6713  mix_decode.d2.loss_dice: 0.7310  mix_decode.d3.loss_cls: 0.1534  mix_decode.d3.loss_mask: 0.6837  mix_decode.d3.loss_dice: 0.7184  mix_decode.d4.loss_cls: 0.2070  mix_decode.d4.loss_mask: 0.6780  mix_decode.d4.loss_dice: 0.7045  mix_decode.d5.loss_cls: 0.1628  mix_decode.d5.loss_mask: 0.6839  mix_decode.d5.loss_dice: 0.7146  mix_decode.d6.loss_cls: 0.1970  mix_decode.d6.loss_mask: 0.6703  mix_decode.d6.loss_dice: 0.7303  mix_decode.d7.loss_cls: 0.2349  mix_decode.d7.loss_mask: 0.6648  mix_decode.d7.loss_dice: 0.7232  mix_decode.d8.loss_cls: 0.2284  mix_decode.d8.loss_mask: 0.6516  mix_decode.d8.loss_dice: 0.7293
2025/03/28 11:34:22 - mmengine - INFO - Iter(train) [ 7500/20000]  base_lr: 6.5511e-05 lr: 6.5511e-05  eta: 2:41:14  time: 1.0749  data_time: 0.0226  memory: 10770  loss: 32.4649  decode.loss_cls: 0.0790  decode.loss_mask: 0.9515  decode.loss_dice: 0.9890  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.9522  decode.d0.loss_dice: 1.0088  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 0.9539  decode.d1.loss_dice: 1.0077  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.9622  decode.d2.loss_dice: 1.0027  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.9553  decode.d3.loss_dice: 1.0013  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.9554  decode.d4.loss_dice: 0.9972  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.9559  decode.d5.loss_dice: 0.9841  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.9528  decode.d6.loss_dice: 0.9933  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.9596  decode.d7.loss_dice: 0.9971  decode.d8.loss_cls: 0.0749  decode.d8.loss_mask: 0.9602  decode.d8.loss_dice: 0.9777  mix_decode.loss_cls: 0.0737  mix_decode.loss_mask: 0.4762  mix_decode.loss_dice: 0.6608  mix_decode.d0.loss_cls: 0.0746  mix_decode.d0.loss_mask: 0.4630  mix_decode.d0.loss_dice: 0.6674  mix_decode.d1.loss_cls: 0.1241  mix_decode.d1.loss_mask: 0.4638  mix_decode.d1.loss_dice: 0.6494  mix_decode.d2.loss_cls: 0.1580  mix_decode.d2.loss_mask: 0.4816  mix_decode.d2.loss_dice: 0.6409  mix_decode.d3.loss_cls: 0.1628  mix_decode.d3.loss_mask: 0.4511  mix_decode.d3.loss_dice: 0.6307  mix_decode.d4.loss_cls: 0.1164  mix_decode.d4.loss_mask: 0.4479  mix_decode.d4.loss_dice: 0.6373  mix_decode.d5.loss_cls: 0.0798  mix_decode.d5.loss_mask: 0.4821  mix_decode.d5.loss_dice: 0.6577  mix_decode.d6.loss_cls: 0.1108  mix_decode.d6.loss_mask: 0.4828  mix_decode.d6.loss_dice: 0.6423  mix_decode.d7.loss_cls: 0.1200  mix_decode.d7.loss_mask: 0.4605  mix_decode.d7.loss_dice: 0.6615  mix_decode.d8.loss_cls: 0.1081  mix_decode.d8.loss_mask: 0.4483  mix_decode.d8.loss_dice: 0.6561
2025/03/28 11:35:16 - mmengine - INFO - Iter(train) [ 7550/20000]  base_lr: 6.5275e-05 lr: 6.5275e-05  eta: 2:41:01  time: 1.0719  data_time: 0.0223  memory: 10775  loss: 29.7448  decode.loss_cls: 0.0321  decode.loss_mask: 0.8986  decode.loss_dice: 0.8860  decode.d0.loss_cls: 0.1083  decode.d0.loss_mask: 0.8832  decode.d0.loss_dice: 0.9084  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.9005  decode.d1.loss_dice: 0.8725  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.8963  decode.d2.loss_dice: 0.8679  decode.d3.loss_cls: 0.0314  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 0.8680  decode.d4.loss_cls: 0.0340  decode.d4.loss_mask: 0.8929  decode.d4.loss_dice: 0.8801  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.8946  decode.d5.loss_dice: 0.8713  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.8981  decode.d6.loss_dice: 0.8729  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 0.8744  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.9046  decode.d8.loss_dice: 0.8642  mix_decode.loss_cls: 0.0845  mix_decode.loss_mask: 0.4533  mix_decode.loss_dice: 0.6301  mix_decode.d0.loss_cls: 0.1145  mix_decode.d0.loss_mask: 0.4476  mix_decode.d0.loss_dice: 0.6375  mix_decode.d1.loss_cls: 0.0942  mix_decode.d1.loss_mask: 0.4556  mix_decode.d1.loss_dice: 0.6211  mix_decode.d2.loss_cls: 0.0904  mix_decode.d2.loss_mask: 0.4559  mix_decode.d2.loss_dice: 0.6127  mix_decode.d3.loss_cls: 0.0615  mix_decode.d3.loss_mask: 0.4580  mix_decode.d3.loss_dice: 0.6210  mix_decode.d4.loss_cls: 0.0765  mix_decode.d4.loss_mask: 0.4543  mix_decode.d4.loss_dice: 0.6101  mix_decode.d5.loss_cls: 0.0682  mix_decode.d5.loss_mask: 0.4552  mix_decode.d5.loss_dice: 0.6251  mix_decode.d6.loss_cls: 0.0469  mix_decode.d6.loss_mask: 0.4505  mix_decode.d6.loss_dice: 0.6275  mix_decode.d7.loss_cls: 0.0706  mix_decode.d7.loss_mask: 0.4614  mix_decode.d7.loss_dice: 0.6168  mix_decode.d8.loss_cls: 0.0872  mix_decode.d8.loss_mask: 0.4568  mix_decode.d8.loss_dice: 0.6148
2025/03/28 11:36:09 - mmengine - INFO - Iter(train) [ 7600/20000]  base_lr: 6.5039e-05 lr: 6.5039e-05  eta: 2:40:46  time: 1.0752  data_time: 0.0235  memory: 10766  loss: 30.1859  decode.loss_cls: 0.0184  decode.loss_mask: 0.9383  decode.loss_dice: 0.9221  decode.d0.loss_cls: 0.0879  decode.d0.loss_mask: 0.9518  decode.d0.loss_dice: 0.9029  decode.d1.loss_cls: 0.0260  decode.d1.loss_mask: 0.9396  decode.d1.loss_dice: 0.9143  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.9494  decode.d2.loss_dice: 0.9302  decode.d3.loss_cls: 0.0283  decode.d3.loss_mask: 0.9430  decode.d3.loss_dice: 0.9142  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 0.9506  decode.d4.loss_dice: 0.9169  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.9397  decode.d5.loss_dice: 0.8991  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.9391  decode.d6.loss_dice: 0.9085  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.9400  decode.d7.loss_dice: 0.9127  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.9376  decode.d8.loss_dice: 0.9272  mix_decode.loss_cls: 0.0492  mix_decode.loss_mask: 0.4214  mix_decode.loss_dice: 0.6391  mix_decode.d0.loss_cls: 0.0789  mix_decode.d0.loss_mask: 0.4289  mix_decode.d0.loss_dice: 0.6716  mix_decode.d1.loss_cls: 0.0822  mix_decode.d1.loss_mask: 0.4194  mix_decode.d1.loss_dice: 0.6219  mix_decode.d2.loss_cls: 0.0830  mix_decode.d2.loss_mask: 0.4175  mix_decode.d2.loss_dice: 0.6119  mix_decode.d3.loss_cls: 0.0836  mix_decode.d3.loss_mask: 0.4158  mix_decode.d3.loss_dice: 0.6162  mix_decode.d4.loss_cls: 0.0879  mix_decode.d4.loss_mask: 0.4172  mix_decode.d4.loss_dice: 0.6086  mix_decode.d5.loss_cls: 0.0978  mix_decode.d5.loss_mask: 0.4137  mix_decode.d5.loss_dice: 0.6042  mix_decode.d6.loss_cls: 0.0992  mix_decode.d6.loss_mask: 0.4150  mix_decode.d6.loss_dice: 0.6099  mix_decode.d7.loss_cls: 0.1062  mix_decode.d7.loss_mask: 0.4208  mix_decode.d7.loss_dice: 0.6034  mix_decode.d8.loss_cls: 0.0889  mix_decode.d8.loss_mask: 0.4211  mix_decode.d8.loss_dice: 0.6182
2025/03/28 11:37:03 - mmengine - INFO - Iter(train) [ 7650/20000]  base_lr: 6.4803e-05 lr: 6.4803e-05  eta: 2:40:31  time: 1.0731  data_time: 0.0221  memory: 10771  loss: 36.5452  decode.loss_cls: 0.0891  decode.loss_mask: 0.9856  decode.loss_dice: 1.0574  decode.d0.loss_cls: 0.1314  decode.d0.loss_mask: 1.0030  decode.d0.loss_dice: 1.0471  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.9914  decode.d1.loss_dice: 1.0514  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.9906  decode.d2.loss_dice: 1.0831  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.9938  decode.d3.loss_dice: 1.0359  decode.d4.loss_cls: 0.0611  decode.d4.loss_mask: 0.9910  decode.d4.loss_dice: 1.0407  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.9848  decode.d5.loss_dice: 1.0626  decode.d6.loss_cls: 0.1032  decode.d6.loss_mask: 0.9904  decode.d6.loss_dice: 1.0614  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.9872  decode.d7.loss_dice: 1.0540  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.9833  decode.d8.loss_dice: 1.0583  mix_decode.loss_cls: 0.0925  mix_decode.loss_mask: 0.6575  mix_decode.loss_dice: 0.7863  mix_decode.d0.loss_cls: 0.1766  mix_decode.d0.loss_mask: 0.6354  mix_decode.d0.loss_dice: 0.7839  mix_decode.d1.loss_cls: 0.1094  mix_decode.d1.loss_mask: 0.6383  mix_decode.d1.loss_dice: 0.7895  mix_decode.d2.loss_cls: 0.0780  mix_decode.d2.loss_mask: 0.6367  mix_decode.d2.loss_dice: 0.7803  mix_decode.d3.loss_cls: 0.0931  mix_decode.d3.loss_mask: 0.6471  mix_decode.d3.loss_dice: 0.7764  mix_decode.d4.loss_cls: 0.1320  mix_decode.d4.loss_mask: 0.6280  mix_decode.d4.loss_dice: 0.7527  mix_decode.d5.loss_cls: 0.1016  mix_decode.d5.loss_mask: 0.6366  mix_decode.d5.loss_dice: 0.7829  mix_decode.d6.loss_cls: 0.1137  mix_decode.d6.loss_mask: 0.6361  mix_decode.d6.loss_dice: 0.7744  mix_decode.d7.loss_cls: 0.0818  mix_decode.d7.loss_mask: 0.6565  mix_decode.d7.loss_dice: 0.7944  mix_decode.d8.loss_cls: 0.0739  mix_decode.d8.loss_mask: 0.6572  mix_decode.d8.loss_dice: 0.7947
2025/03/28 11:37:57 - mmengine - INFO - Iter(train) [ 7700/20000]  base_lr: 6.4566e-05 lr: 6.4566e-05  eta: 2:40:15  time: 1.0739  data_time: 0.0224  memory: 10766  loss: 37.0341  decode.loss_cls: 0.0178  decode.loss_mask: 1.3237  decode.loss_dice: 1.0617  decode.d0.loss_cls: 0.1310  decode.d0.loss_mask: 1.3097  decode.d0.loss_dice: 1.0236  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 1.2852  decode.d1.loss_dice: 1.0484  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 1.3168  decode.d2.loss_dice: 1.0583  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 1.2912  decode.d3.loss_dice: 1.0383  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 1.3162  decode.d4.loss_dice: 1.0478  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 1.2833  decode.d5.loss_dice: 1.0408  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 1.2850  decode.d6.loss_dice: 1.0307  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 1.2899  decode.d7.loss_dice: 1.0420  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 1.2895  decode.d8.loss_dice: 1.0332  mix_decode.loss_cls: 0.0521  mix_decode.loss_mask: 0.6287  mix_decode.loss_dice: 0.6134  mix_decode.d0.loss_cls: 0.0824  mix_decode.d0.loss_mask: 0.6291  mix_decode.d0.loss_dice: 0.6283  mix_decode.d1.loss_cls: 0.0833  mix_decode.d1.loss_mask: 0.6342  mix_decode.d1.loss_dice: 0.6271  mix_decode.d2.loss_cls: 0.0743  mix_decode.d2.loss_mask: 0.6247  mix_decode.d2.loss_dice: 0.6103  mix_decode.d3.loss_cls: 0.0957  mix_decode.d3.loss_mask: 0.6054  mix_decode.d3.loss_dice: 0.6004  mix_decode.d4.loss_cls: 0.0794  mix_decode.d4.loss_mask: 0.6280  mix_decode.d4.loss_dice: 0.6123  mix_decode.d5.loss_cls: 0.0705  mix_decode.d5.loss_mask: 0.6235  mix_decode.d5.loss_dice: 0.6083  mix_decode.d6.loss_cls: 0.0492  mix_decode.d6.loss_mask: 0.6222  mix_decode.d6.loss_dice: 0.6168  mix_decode.d7.loss_cls: 0.0512  mix_decode.d7.loss_mask: 0.6268  mix_decode.d7.loss_dice: 0.6114  mix_decode.d8.loss_cls: 0.0442  mix_decode.d8.loss_mask: 0.6269  mix_decode.d8.loss_dice: 0.6178
2025/03/28 11:38:51 - mmengine - INFO - Iter(train) [ 7750/20000]  base_lr: 6.4330e-05 lr: 6.4330e-05  eta: 2:40:00  time: 1.0806  data_time: 0.0261  memory: 10778  loss: 33.0400  decode.loss_cls: 0.0494  decode.loss_mask: 1.0231  decode.loss_dice: 1.0661  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 1.0349  decode.d0.loss_dice: 1.1044  decode.d1.loss_cls: 0.0301  decode.d1.loss_mask: 1.0187  decode.d1.loss_dice: 1.0679  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 1.0207  decode.d2.loss_dice: 1.0627  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 1.0190  decode.d3.loss_dice: 1.0530  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 1.0279  decode.d4.loss_dice: 1.0621  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 1.0213  decode.d5.loss_dice: 1.0557  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 1.0229  decode.d6.loss_dice: 1.0352  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 1.0241  decode.d7.loss_dice: 1.0666  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 1.0195  decode.d8.loss_dice: 1.0472  mix_decode.loss_cls: 0.0525  mix_decode.loss_mask: 0.5158  mix_decode.loss_dice: 0.5860  mix_decode.d0.loss_cls: 0.0641  mix_decode.d0.loss_mask: 0.5018  mix_decode.d0.loss_dice: 0.6070  mix_decode.d1.loss_cls: 0.0928  mix_decode.d1.loss_mask: 0.5104  mix_decode.d1.loss_dice: 0.5842  mix_decode.d2.loss_cls: 0.1021  mix_decode.d2.loss_mask: 0.5226  mix_decode.d2.loss_dice: 0.5688  mix_decode.d3.loss_cls: 0.1130  mix_decode.d3.loss_mask: 0.5072  mix_decode.d3.loss_dice: 0.5657  mix_decode.d4.loss_cls: 0.0586  mix_decode.d4.loss_mask: 0.5173  mix_decode.d4.loss_dice: 0.5797  mix_decode.d5.loss_cls: 0.0945  mix_decode.d5.loss_mask: 0.5086  mix_decode.d5.loss_dice: 0.5740  mix_decode.d6.loss_cls: 0.0606  mix_decode.d6.loss_mask: 0.5128  mix_decode.d6.loss_dice: 0.5892  mix_decode.d7.loss_cls: 0.0593  mix_decode.d7.loss_mask: 0.5102  mix_decode.d7.loss_dice: 0.5832  mix_decode.d8.loss_cls: 0.0637  mix_decode.d8.loss_mask: 0.5088  mix_decode.d8.loss_dice: 0.5820
2025/03/28 11:39:44 - mmengine - INFO - Iter(train) [ 7800/20000]  base_lr: 6.4094e-05 lr: 6.4094e-05  eta: 2:39:43  time: 1.0748  data_time: 0.0226  memory: 10770  loss: 33.4856  decode.loss_cls: 0.0210  decode.loss_mask: 0.9970  decode.loss_dice: 0.9721  decode.d0.loss_cls: 0.0631  decode.d0.loss_mask: 1.0159  decode.d0.loss_dice: 0.9956  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 1.0040  decode.d1.loss_dice: 0.9998  decode.d2.loss_cls: 0.0288  decode.d2.loss_mask: 1.0003  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.0254  decode.d3.loss_mask: 1.0076  decode.d3.loss_dice: 0.9789  decode.d4.loss_cls: 0.0264  decode.d4.loss_mask: 0.9957  decode.d4.loss_dice: 0.9863  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.9992  decode.d5.loss_dice: 0.9970  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 1.0031  decode.d6.loss_dice: 0.9913  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 1.0048  decode.d7.loss_dice: 0.9952  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.9969  decode.d8.loss_dice: 0.9775  mix_decode.loss_cls: 0.0938  mix_decode.loss_mask: 0.5960  mix_decode.loss_dice: 0.6528  mix_decode.d0.loss_cls: 0.0988  mix_decode.d0.loss_mask: 0.5848  mix_decode.d0.loss_dice: 0.6799  mix_decode.d1.loss_cls: 0.1177  mix_decode.d1.loss_mask: 0.5907  mix_decode.d1.loss_dice: 0.6504  mix_decode.d2.loss_cls: 0.1126  mix_decode.d2.loss_mask: 0.5977  mix_decode.d2.loss_dice: 0.6374  mix_decode.d3.loss_cls: 0.0867  mix_decode.d3.loss_mask: 0.5982  mix_decode.d3.loss_dice: 0.6431  mix_decode.d4.loss_cls: 0.1252  mix_decode.d4.loss_mask: 0.5493  mix_decode.d4.loss_dice: 0.6256  mix_decode.d5.loss_cls: 0.1335  mix_decode.d5.loss_mask: 0.5563  mix_decode.d5.loss_dice: 0.6400  mix_decode.d6.loss_cls: 0.1059  mix_decode.d6.loss_mask: 0.5614  mix_decode.d6.loss_dice: 0.6330  mix_decode.d7.loss_cls: 0.0951  mix_decode.d7.loss_mask: 0.5800  mix_decode.d7.loss_dice: 0.6446  mix_decode.d8.loss_cls: 0.1165  mix_decode.d8.loss_mask: 0.5609  mix_decode.d8.loss_dice: 0.6367
2025/03/28 11:40:38 - mmengine - INFO - Iter(train) [ 7850/20000]  base_lr: 6.3857e-05 lr: 6.3857e-05  eta: 2:39:27  time: 1.0787  data_time: 0.0232  memory: 10770  loss: 31.8613  decode.loss_cls: 0.0181  decode.loss_mask: 0.9508  decode.loss_dice: 0.8522  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.9732  decode.d0.loss_dice: 0.8506  decode.d1.loss_cls: 0.0179  decode.d1.loss_mask: 0.9611  decode.d1.loss_dice: 0.8532  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.9556  decode.d2.loss_dice: 0.8509  decode.d3.loss_cls: 0.0467  decode.d3.loss_mask: 0.9456  decode.d3.loss_dice: 0.8413  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.9416  decode.d4.loss_dice: 0.8505  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.9402  decode.d5.loss_dice: 0.8447  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.9517  decode.d6.loss_dice: 0.8428  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.9464  decode.d7.loss_dice: 0.8498  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 0.9568  decode.d8.loss_dice: 0.8555  mix_decode.loss_cls: 0.0879  mix_decode.loss_mask: 0.5782  mix_decode.loss_dice: 0.6798  mix_decode.d0.loss_cls: 0.1475  mix_decode.d0.loss_mask: 0.5641  mix_decode.d0.loss_dice: 0.6811  mix_decode.d1.loss_cls: 0.0939  mix_decode.d1.loss_mask: 0.5797  mix_decode.d1.loss_dice: 0.6810  mix_decode.d2.loss_cls: 0.0870  mix_decode.d2.loss_mask: 0.5720  mix_decode.d2.loss_dice: 0.6855  mix_decode.d3.loss_cls: 0.1146  mix_decode.d3.loss_mask: 0.5684  mix_decode.d3.loss_dice: 0.6666  mix_decode.d4.loss_cls: 0.1112  mix_decode.d4.loss_mask: 0.5627  mix_decode.d4.loss_dice: 0.6898  mix_decode.d5.loss_cls: 0.1097  mix_decode.d5.loss_mask: 0.5611  mix_decode.d5.loss_dice: 0.6744  mix_decode.d6.loss_cls: 0.1102  mix_decode.d6.loss_mask: 0.5677  mix_decode.d6.loss_dice: 0.6833  mix_decode.d7.loss_cls: 0.1112  mix_decode.d7.loss_mask: 0.5635  mix_decode.d7.loss_dice: 0.6832  mix_decode.d8.loss_cls: 0.1144  mix_decode.d8.loss_mask: 0.5667  mix_decode.d8.loss_dice: 0.6813
2025/03/28 11:41:32 - mmengine - INFO - Iter(train) [ 7900/20000]  base_lr: 6.3621e-05 lr: 6.3621e-05  eta: 2:39:10  time: 1.0799  data_time: 0.0227  memory: 10769  loss: 32.2057  decode.loss_cls: 0.0215  decode.loss_mask: 1.0033  decode.loss_dice: 1.0173  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 1.0149  decode.d0.loss_dice: 1.0127  decode.d1.loss_cls: 0.0249  decode.d1.loss_mask: 1.0024  decode.d1.loss_dice: 1.0128  decode.d2.loss_cls: 0.0228  decode.d2.loss_mask: 1.0029  decode.d2.loss_dice: 1.0055  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 1.0077  decode.d3.loss_dice: 1.0159  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 1.0059  decode.d4.loss_dice: 1.0100  decode.d5.loss_cls: 0.0258  decode.d5.loss_mask: 1.0058  decode.d5.loss_dice: 1.0264  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 1.0035  decode.d6.loss_dice: 1.0131  decode.d7.loss_cls: 0.0237  decode.d7.loss_mask: 1.0109  decode.d7.loss_dice: 1.0197  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 1.0052  decode.d8.loss_dice: 1.0172  mix_decode.loss_cls: 0.0720  mix_decode.loss_mask: 0.5073  mix_decode.loss_dice: 0.5839  mix_decode.d0.loss_cls: 0.1163  mix_decode.d0.loss_mask: 0.5285  mix_decode.d0.loss_dice: 0.5927  mix_decode.d1.loss_cls: 0.0702  mix_decode.d1.loss_mask: 0.5239  mix_decode.d1.loss_dice: 0.5664  mix_decode.d2.loss_cls: 0.0634  mix_decode.d2.loss_mask: 0.5218  mix_decode.d2.loss_dice: 0.5836  mix_decode.d3.loss_cls: 0.0645  mix_decode.d3.loss_mask: 0.5222  mix_decode.d3.loss_dice: 0.5812  mix_decode.d4.loss_cls: 0.0791  mix_decode.d4.loss_mask: 0.5152  mix_decode.d4.loss_dice: 0.5761  mix_decode.d5.loss_cls: 0.0606  mix_decode.d5.loss_mask: 0.5178  mix_decode.d5.loss_dice: 0.5729  mix_decode.d6.loss_cls: 0.0586  mix_decode.d6.loss_mask: 0.5143  mix_decode.d6.loss_dice: 0.5692  mix_decode.d7.loss_cls: 0.0534  mix_decode.d7.loss_mask: 0.5152  mix_decode.d7.loss_dice: 0.5935  mix_decode.d8.loss_cls: 0.0433  mix_decode.d8.loss_mask: 0.5181  mix_decode.d8.loss_dice: 0.6051
2025/03/28 11:42:26 - mmengine - INFO - Iter(train) [ 7950/20000]  base_lr: 6.3384e-05 lr: 6.3384e-05  eta: 2:38:52  time: 1.0754  data_time: 0.0229  memory: 10784  loss: 34.6357  decode.loss_cls: 0.0390  decode.loss_mask: 1.0515  decode.loss_dice: 0.9274  decode.d0.loss_cls: 0.1685  decode.d0.loss_mask: 1.0566  decode.d0.loss_dice: 0.9115  decode.d1.loss_cls: 0.0355  decode.d1.loss_mask: 1.0451  decode.d1.loss_dice: 0.9117  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 1.0379  decode.d2.loss_dice: 0.9037  decode.d3.loss_cls: 0.0334  decode.d3.loss_mask: 1.0402  decode.d3.loss_dice: 0.9029  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 1.0333  decode.d4.loss_dice: 0.9114  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 1.0350  decode.d5.loss_dice: 0.9294  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 1.0478  decode.d6.loss_dice: 0.9129  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 1.0475  decode.d7.loss_dice: 0.9136  decode.d8.loss_cls: 0.0390  decode.d8.loss_mask: 1.0505  decode.d8.loss_dice: 0.9214  mix_decode.loss_cls: 0.1359  mix_decode.loss_mask: 0.6238  mix_decode.loss_dice: 0.6833  mix_decode.d0.loss_cls: 0.1441  mix_decode.d0.loss_mask: 0.6043  mix_decode.d0.loss_dice: 0.7344  mix_decode.d1.loss_cls: 0.1228  mix_decode.d1.loss_mask: 0.6438  mix_decode.d1.loss_dice: 0.7146  mix_decode.d2.loss_cls: 0.1271  mix_decode.d2.loss_mask: 0.6276  mix_decode.d2.loss_dice: 0.6933  mix_decode.d3.loss_cls: 0.0925  mix_decode.d3.loss_mask: 0.6319  mix_decode.d3.loss_dice: 0.7136  mix_decode.d4.loss_cls: 0.1404  mix_decode.d4.loss_mask: 0.6290  mix_decode.d4.loss_dice: 0.7139  mix_decode.d5.loss_cls: 0.1051  mix_decode.d5.loss_mask: 0.6207  mix_decode.d5.loss_dice: 0.7265  mix_decode.d6.loss_cls: 0.1117  mix_decode.d6.loss_mask: 0.6169  mix_decode.d6.loss_dice: 0.7236  mix_decode.d7.loss_cls: 0.1349  mix_decode.d7.loss_mask: 0.6132  mix_decode.d7.loss_dice: 0.6961  mix_decode.d8.loss_cls: 0.1329  mix_decode.d8.loss_mask: 0.6165  mix_decode.d8.loss_dice: 0.6905
2025/03/28 11:43:20 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 11:43:20 - mmengine - INFO - Iter(train) [ 8000/20000]  base_lr: 6.3147e-05 lr: 6.3147e-05  eta: 2:38:34  time: 1.0741  data_time: 0.0228  memory: 10773  loss: 33.9334  decode.loss_cls: 0.0607  decode.loss_mask: 1.0773  decode.loss_dice: 0.9795  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 1.0830  decode.d0.loss_dice: 0.9784  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 1.0740  decode.d1.loss_dice: 0.9828  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 1.0755  decode.d2.loss_dice: 0.9922  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 1.0706  decode.d3.loss_dice: 0.9776  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 1.0730  decode.d4.loss_dice: 0.9972  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 1.0737  decode.d5.loss_dice: 1.0014  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 1.0634  decode.d6.loss_dice: 0.9843  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 1.0717  decode.d7.loss_dice: 0.9911  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 1.0702  decode.d8.loss_dice: 0.9974  mix_decode.loss_cls: 0.0597  mix_decode.loss_mask: 0.6097  mix_decode.loss_dice: 0.5804  mix_decode.d0.loss_cls: 0.1127  mix_decode.d0.loss_mask: 0.5959  mix_decode.d0.loss_dice: 0.5831  mix_decode.d1.loss_cls: 0.1059  mix_decode.d1.loss_mask: 0.5877  mix_decode.d1.loss_dice: 0.5780  mix_decode.d2.loss_cls: 0.0928  mix_decode.d2.loss_mask: 0.5919  mix_decode.d2.loss_dice: 0.5692  mix_decode.d3.loss_cls: 0.0899  mix_decode.d3.loss_mask: 0.5967  mix_decode.d3.loss_dice: 0.5617  mix_decode.d4.loss_cls: 0.0754  mix_decode.d4.loss_mask: 0.5891  mix_decode.d4.loss_dice: 0.5856  mix_decode.d5.loss_cls: 0.1256  mix_decode.d5.loss_mask: 0.5902  mix_decode.d5.loss_dice: 0.5627  mix_decode.d6.loss_cls: 0.0936  mix_decode.d6.loss_mask: 0.5908  mix_decode.d6.loss_dice: 0.5861  mix_decode.d7.loss_cls: 0.0617  mix_decode.d7.loss_mask: 0.6060  mix_decode.d7.loss_dice: 0.5865  mix_decode.d8.loss_cls: 0.0599  mix_decode.d8.loss_mask: 0.6013  mix_decode.d8.loss_dice: 0.5937
2025/03/28 11:43:20 - mmengine - INFO - Saving checkpoint at 8000 iterations
2025/03/28 11:43:26 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0849  data_time: 0.0019  memory: 3068  
2025/03/28 11:43:30 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:43  time: 0.0851  data_time: 0.0018  memory: 3068  
2025/03/28 11:43:34 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:38  time: 0.0851  data_time: 0.0019  memory: 3068  
2025/03/28 11:43:38 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:34  time: 0.0851  data_time: 0.0019  memory: 3068  
2025/03/28 11:43:43 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0850  data_time: 0.0019  memory: 3068  
2025/03/28 11:43:47 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:26  time: 0.0851  data_time: 0.0019  memory: 3068  
2025/03/28 11:43:51 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:22  time: 0.0882  data_time: 0.0019  memory: 3068  
2025/03/28 11:43:55 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:17  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:00 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:04 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:09  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 11:44:08 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:05  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 11:44:13 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:00  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:17 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:21 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:52  time: 0.0851  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:25 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:47  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:44:30 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:43  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:34 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0851  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:38 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 11:44:43 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:30  time: 0.0884  data_time: 0.0019  memory: 3068  
2025/03/28 11:44:47 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 11:44:51 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 11:44:55 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0854  data_time: 0.0020  memory: 3068  
2025/03/28 11:45:00 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:13  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:04 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:08 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:12 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:17 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 11:45:21 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0855  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:25 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0877  data_time: 0.0021  memory: 3068  
2025/03/28 11:45:30 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:34 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 11:45:38 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:42 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 11:45:47 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:26  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:51 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 11:45:55 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0854  data_time: 0.0017  memory: 3068  
2025/03/28 11:46:00 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0855  data_time: 0.0018  memory: 3068  
2025/03/28 11:46:04 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 11:46:08 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 11:46:12 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 11:46:14 - mmengine - INFO - per class results:
2025/03/28 11:46:14 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 74.83 |  92.2 |
|      building      | 89.06 | 94.85 |
|   low_vegetation   | 64.47 |  89.9 |
|        tree        | 47.01 | 49.69 |
|        car         | 76.83 |  89.0 |
|      clutter       | 11.45 | 12.18 |
+--------------------+-------+-------+
2025/03/28 11:46:14 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 81.2900  mIoU: 60.6100  mAcc: 71.3000  data_time: 0.0019  time: 0.0854
2025/03/28 11:47:08 - mmengine - INFO - Iter(train) [ 8050/20000]  base_lr: 6.2911e-05 lr: 6.2911e-05  eta: 2:38:16  time: 1.0745  data_time: 0.0232  memory: 10774  loss: 33.2621  decode.loss_cls: 0.0775  decode.loss_mask: 1.0313  decode.loss_dice: 0.9584  decode.d0.loss_cls: 0.1306  decode.d0.loss_mask: 1.0381  decode.d0.loss_dice: 0.9381  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 1.0436  decode.d1.loss_dice: 0.9526  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 1.0417  decode.d2.loss_dice: 0.9681  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 1.0774  decode.d3.loss_dice: 0.9638  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 1.0869  decode.d4.loss_dice: 0.9661  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 1.0828  decode.d5.loss_dice: 0.9552  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 1.0363  decode.d6.loss_dice: 0.9556  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 1.0705  decode.d7.loss_dice: 0.9616  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 1.0745  decode.d8.loss_dice: 0.9665  mix_decode.loss_cls: 0.0670  mix_decode.loss_mask: 0.5427  mix_decode.loss_dice: 0.6533  mix_decode.d0.loss_cls: 0.0920  mix_decode.d0.loss_mask: 0.5411  mix_decode.d0.loss_dice: 0.6676  mix_decode.d1.loss_cls: 0.1120  mix_decode.d1.loss_mask: 0.5366  mix_decode.d1.loss_dice: 0.6391  mix_decode.d2.loss_cls: 0.1003  mix_decode.d2.loss_mask: 0.5236  mix_decode.d2.loss_dice: 0.6228  mix_decode.d3.loss_cls: 0.0766  mix_decode.d3.loss_mask: 0.5375  mix_decode.d3.loss_dice: 0.6165  mix_decode.d4.loss_cls: 0.1081  mix_decode.d4.loss_mask: 0.5283  mix_decode.d4.loss_dice: 0.6257  mix_decode.d5.loss_cls: 0.0832  mix_decode.d5.loss_mask: 0.5394  mix_decode.d5.loss_dice: 0.6209  mix_decode.d6.loss_cls: 0.0841  mix_decode.d6.loss_mask: 0.5433  mix_decode.d6.loss_dice: 0.6311  mix_decode.d7.loss_cls: 0.0818  mix_decode.d7.loss_mask: 0.5456  mix_decode.d7.loss_dice: 0.6400  mix_decode.d8.loss_cls: 0.0885  mix_decode.d8.loss_mask: 0.5380  mix_decode.d8.loss_dice: 0.6343
2025/03/28 11:48:02 - mmengine - INFO - Iter(train) [ 8100/20000]  base_lr: 6.2674e-05 lr: 6.2674e-05  eta: 2:37:57  time: 1.0842  data_time: 0.0238  memory: 10777  loss: 35.2586  decode.loss_cls: 0.0908  decode.loss_mask: 1.1180  decode.loss_dice: 1.0330  decode.d0.loss_cls: 0.0955  decode.d0.loss_mask: 1.1116  decode.d0.loss_dice: 1.0171  decode.d1.loss_cls: 0.1178  decode.d1.loss_mask: 1.1041  decode.d1.loss_dice: 1.0011  decode.d2.loss_cls: 0.0894  decode.d2.loss_mask: 1.1128  decode.d2.loss_dice: 0.9911  decode.d3.loss_cls: 0.1272  decode.d3.loss_mask: 1.1172  decode.d3.loss_dice: 1.0117  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 1.1136  decode.d4.loss_dice: 0.9978  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 1.1076  decode.d5.loss_dice: 1.0178  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 1.1125  decode.d6.loss_dice: 1.0217  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 1.1129  decode.d7.loss_dice: 1.0360  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 1.1198  decode.d8.loss_dice: 1.0374  mix_decode.loss_cls: 0.1315  mix_decode.loss_mask: 0.5073  mix_decode.loss_dice: 0.6372  mix_decode.d0.loss_cls: 0.1150  mix_decode.d0.loss_mask: 0.5064  mix_decode.d0.loss_dice: 0.6819  mix_decode.d1.loss_cls: 0.1593  mix_decode.d1.loss_mask: 0.5103  mix_decode.d1.loss_dice: 0.6431  mix_decode.d2.loss_cls: 0.1482  mix_decode.d2.loss_mask: 0.4971  mix_decode.d2.loss_dice: 0.6488  mix_decode.d3.loss_cls: 0.1375  mix_decode.d3.loss_mask: 0.4994  mix_decode.d3.loss_dice: 0.6455  mix_decode.d4.loss_cls: 0.1235  mix_decode.d4.loss_mask: 0.5069  mix_decode.d4.loss_dice: 0.6590  mix_decode.d5.loss_cls: 0.1298  mix_decode.d5.loss_mask: 0.5093  mix_decode.d5.loss_dice: 0.6665  mix_decode.d6.loss_cls: 0.1851  mix_decode.d6.loss_mask: 0.5004  mix_decode.d6.loss_dice: 0.6455  mix_decode.d7.loss_cls: 0.1553  mix_decode.d7.loss_mask: 0.5078  mix_decode.d7.loss_dice: 0.6609  mix_decode.d8.loss_cls: 0.1441  mix_decode.d8.loss_mask: 0.5076  mix_decode.d8.loss_dice: 0.6506
2025/03/28 11:48:56 - mmengine - INFO - Iter(train) [ 8150/20000]  base_lr: 6.2437e-05 lr: 6.2437e-05  eta: 2:37:38  time: 1.0743  data_time: 0.0225  memory: 10768  loss: 29.5535  decode.loss_cls: 0.0088  decode.loss_mask: 0.9280  decode.loss_dice: 0.8779  decode.d0.loss_cls: 0.0640  decode.d0.loss_mask: 0.9395  decode.d0.loss_dice: 0.8521  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.9251  decode.d1.loss_dice: 0.8803  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.9273  decode.d2.loss_dice: 0.8695  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.9275  decode.d3.loss_dice: 0.8721  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.9359  decode.d4.loss_dice: 0.8695  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.9363  decode.d5.loss_dice: 0.8567  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.9341  decode.d6.loss_dice: 0.8643  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.9337  decode.d7.loss_dice: 0.8717  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.9339  decode.d8.loss_dice: 0.8696  mix_decode.loss_cls: 0.0717  mix_decode.loss_mask: 0.5051  mix_decode.loss_dice: 0.5479  mix_decode.d0.loss_cls: 0.1152  mix_decode.d0.loss_mask: 0.5096  mix_decode.d0.loss_dice: 0.5712  mix_decode.d1.loss_cls: 0.0860  mix_decode.d1.loss_mask: 0.5007  mix_decode.d1.loss_dice: 0.5514  mix_decode.d2.loss_cls: 0.1033  mix_decode.d2.loss_mask: 0.5049  mix_decode.d2.loss_dice: 0.5451  mix_decode.d3.loss_cls: 0.0834  mix_decode.d3.loss_mask: 0.5068  mix_decode.d3.loss_dice: 0.5490  mix_decode.d4.loss_cls: 0.0727  mix_decode.d4.loss_mask: 0.5107  mix_decode.d4.loss_dice: 0.5454  mix_decode.d5.loss_cls: 0.0738  mix_decode.d5.loss_mask: 0.5104  mix_decode.d5.loss_dice: 0.5478  mix_decode.d6.loss_cls: 0.0657  mix_decode.d6.loss_mask: 0.5227  mix_decode.d6.loss_dice: 0.5469  mix_decode.d7.loss_cls: 0.0755  mix_decode.d7.loss_mask: 0.5089  mix_decode.d7.loss_dice: 0.5322  mix_decode.d8.loss_cls: 0.0685  mix_decode.d8.loss_mask: 0.5074  mix_decode.d8.loss_dice: 0.5633
2025/03/28 11:49:50 - mmengine - INFO - Iter(train) [ 8200/20000]  base_lr: 6.2199e-05 lr: 6.2199e-05  eta: 2:37:18  time: 1.0763  data_time: 0.0231  memory: 10771  loss: 34.5858  decode.loss_cls: 0.0075  decode.loss_mask: 1.1728  decode.loss_dice: 0.9913  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 1.1878  decode.d0.loss_dice: 0.9566  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 1.1620  decode.d1.loss_dice: 0.9947  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 1.1696  decode.d2.loss_dice: 0.9924  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 1.1705  decode.d3.loss_dice: 0.9881  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 1.1632  decode.d4.loss_dice: 0.9921  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 1.1666  decode.d5.loss_dice: 0.9993  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 1.1667  decode.d6.loss_dice: 0.9993  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 1.1682  decode.d7.loss_dice: 0.9920  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 1.1681  decode.d8.loss_dice: 0.9985  mix_decode.loss_cls: 0.0858  mix_decode.loss_mask: 0.5927  mix_decode.loss_dice: 0.5985  mix_decode.d0.loss_cls: 0.0849  mix_decode.d0.loss_mask: 0.5938  mix_decode.d0.loss_dice: 0.6267  mix_decode.d1.loss_cls: 0.0723  mix_decode.d1.loss_mask: 0.5924  mix_decode.d1.loss_dice: 0.6155  mix_decode.d2.loss_cls: 0.0958  mix_decode.d2.loss_mask: 0.5883  mix_decode.d2.loss_dice: 0.6090  mix_decode.d3.loss_cls: 0.0808  mix_decode.d3.loss_mask: 0.5904  mix_decode.d3.loss_dice: 0.5967  mix_decode.d4.loss_cls: 0.0950  mix_decode.d4.loss_mask: 0.5976  mix_decode.d4.loss_dice: 0.6027  mix_decode.d5.loss_cls: 0.0955  mix_decode.d5.loss_mask: 0.5920  mix_decode.d5.loss_dice: 0.6041  mix_decode.d6.loss_cls: 0.0849  mix_decode.d6.loss_mask: 0.5937  mix_decode.d6.loss_dice: 0.5991  mix_decode.d7.loss_cls: 0.0765  mix_decode.d7.loss_mask: 0.5922  mix_decode.d7.loss_dice: 0.6079  mix_decode.d8.loss_cls: 0.0754  mix_decode.d8.loss_mask: 0.5927  mix_decode.d8.loss_dice: 0.6143
2025/03/28 11:50:43 - mmengine - INFO - Iter(train) [ 8250/20000]  base_lr: 6.1962e-05 lr: 6.1962e-05  eta: 2:36:58  time: 1.0717  data_time: 0.0225  memory: 10764  loss: 34.4479  decode.loss_cls: 0.0184  decode.loss_mask: 1.1761  decode.loss_dice: 1.0345  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 1.2038  decode.d0.loss_dice: 1.0220  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 1.1818  decode.d1.loss_dice: 1.0432  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 1.1796  decode.d2.loss_dice: 1.0390  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 1.1758  decode.d3.loss_dice: 1.0409  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 1.1719  decode.d4.loss_dice: 1.0402  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 1.1738  decode.d5.loss_dice: 1.0352  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 1.1759  decode.d6.loss_dice: 1.0452  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 1.1787  decode.d7.loss_dice: 1.0409  decode.d8.loss_cls: 0.0241  decode.d8.loss_mask: 1.1775  decode.d8.loss_dice: 1.0367  mix_decode.loss_cls: 0.0514  mix_decode.loss_mask: 0.4797  mix_decode.loss_dice: 0.6533  mix_decode.d0.loss_cls: 0.0631  mix_decode.d0.loss_mask: 0.4850  mix_decode.d0.loss_dice: 0.6665  mix_decode.d1.loss_cls: 0.0703  mix_decode.d1.loss_mask: 0.4776  mix_decode.d1.loss_dice: 0.6525  mix_decode.d2.loss_cls: 0.0869  mix_decode.d2.loss_mask: 0.4771  mix_decode.d2.loss_dice: 0.6355  mix_decode.d3.loss_cls: 0.0719  mix_decode.d3.loss_mask: 0.4794  mix_decode.d3.loss_dice: 0.6325  mix_decode.d4.loss_cls: 0.0909  mix_decode.d4.loss_mask: 0.4783  mix_decode.d4.loss_dice: 0.6317  mix_decode.d5.loss_cls: 0.0780  mix_decode.d5.loss_mask: 0.4799  mix_decode.d5.loss_dice: 0.6435  mix_decode.d6.loss_cls: 0.0805  mix_decode.d6.loss_mask: 0.4722  mix_decode.d6.loss_dice: 0.6355  mix_decode.d7.loss_cls: 0.0820  mix_decode.d7.loss_mask: 0.4781  mix_decode.d7.loss_dice: 0.6447  mix_decode.d8.loss_cls: 0.0555  mix_decode.d8.loss_mask: 0.4813  mix_decode.d8.loss_dice: 0.6536
2025/03/28 11:51:37 - mmengine - INFO - Iter(train) [ 8300/20000]  base_lr: 6.1725e-05 lr: 6.1725e-05  eta: 2:36:37  time: 1.0684  data_time: 0.0224  memory: 10774  loss: 31.6455  decode.loss_cls: 0.0801  decode.loss_mask: 0.9779  decode.loss_dice: 0.9853  decode.d0.loss_cls: 0.1123  decode.d0.loss_mask: 0.9729  decode.d0.loss_dice: 0.9474  decode.d1.loss_cls: 0.0827  decode.d1.loss_mask: 0.9706  decode.d1.loss_dice: 0.9557  decode.d2.loss_cls: 0.1074  decode.d2.loss_mask: 0.9738  decode.d2.loss_dice: 0.9400  decode.d3.loss_cls: 0.0681  decode.d3.loss_mask: 0.9802  decode.d3.loss_dice: 0.9591  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.9761  decode.d4.loss_dice: 0.9701  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.9796  decode.d5.loss_dice: 0.9625  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.9815  decode.d6.loss_dice: 0.9699  decode.d7.loss_cls: 0.1135  decode.d7.loss_mask: 0.9806  decode.d7.loss_dice: 0.9602  decode.d8.loss_cls: 0.1299  decode.d8.loss_mask: 0.9792  decode.d8.loss_dice: 0.9870  mix_decode.loss_cls: 0.0297  mix_decode.loss_mask: 0.4915  mix_decode.loss_dice: 0.5900  mix_decode.d0.loss_cls: 0.1162  mix_decode.d0.loss_mask: 0.4870  mix_decode.d0.loss_dice: 0.5852  mix_decode.d1.loss_cls: 0.0951  mix_decode.d1.loss_mask: 0.4904  mix_decode.d1.loss_dice: 0.5719  mix_decode.d2.loss_cls: 0.0781  mix_decode.d2.loss_mask: 0.4891  mix_decode.d2.loss_dice: 0.5774  mix_decode.d3.loss_cls: 0.0535  mix_decode.d3.loss_mask: 0.4886  mix_decode.d3.loss_dice: 0.5750  mix_decode.d4.loss_cls: 0.0479  mix_decode.d4.loss_mask: 0.4891  mix_decode.d4.loss_dice: 0.5815  mix_decode.d5.loss_cls: 0.0838  mix_decode.d5.loss_mask: 0.4866  mix_decode.d5.loss_dice: 0.5675  mix_decode.d6.loss_cls: 0.0358  mix_decode.d6.loss_mask: 0.4897  mix_decode.d6.loss_dice: 0.5810  mix_decode.d7.loss_cls: 0.0425  mix_decode.d7.loss_mask: 0.4918  mix_decode.d7.loss_dice: 0.5834  mix_decode.d8.loss_cls: 0.0349  mix_decode.d8.loss_mask: 0.4950  mix_decode.d8.loss_dice: 0.5918
2025/03/28 11:52:31 - mmengine - INFO - Iter(train) [ 8350/20000]  base_lr: 6.1487e-05 lr: 6.1487e-05  eta: 2:36:15  time: 1.0699  data_time: 0.0223  memory: 10780  loss: 33.7479  decode.loss_cls: 0.1231  decode.loss_mask: 0.9885  decode.loss_dice: 1.0183  decode.d0.loss_cls: 0.1377  decode.d0.loss_mask: 1.0066  decode.d0.loss_dice: 1.0972  decode.d1.loss_cls: 0.1849  decode.d1.loss_mask: 0.9971  decode.d1.loss_dice: 1.0485  decode.d2.loss_cls: 0.1821  decode.d2.loss_mask: 0.9916  decode.d2.loss_dice: 1.0297  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 0.9908  decode.d3.loss_dice: 1.0509  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.9918  decode.d4.loss_dice: 1.0506  decode.d5.loss_cls: 0.1189  decode.d5.loss_mask: 0.9805  decode.d5.loss_dice: 1.0169  decode.d6.loss_cls: 0.1544  decode.d6.loss_mask: 0.9813  decode.d6.loss_dice: 1.0179  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.9872  decode.d7.loss_dice: 1.0189  decode.d8.loss_cls: 0.1162  decode.d8.loss_mask: 0.9899  decode.d8.loss_dice: 1.0378  mix_decode.loss_cls: 0.0878  mix_decode.loss_mask: 0.4450  mix_decode.loss_dice: 0.6704  mix_decode.d0.loss_cls: 0.0895  mix_decode.d0.loss_mask: 0.4548  mix_decode.d0.loss_dice: 0.6978  mix_decode.d1.loss_cls: 0.1159  mix_decode.d1.loss_mask: 0.4519  mix_decode.d1.loss_dice: 0.6608  mix_decode.d2.loss_cls: 0.1124  mix_decode.d2.loss_mask: 0.4484  mix_decode.d2.loss_dice: 0.6369  mix_decode.d3.loss_cls: 0.1418  mix_decode.d3.loss_mask: 0.4454  mix_decode.d3.loss_dice: 0.6588  mix_decode.d4.loss_cls: 0.1082  mix_decode.d4.loss_mask: 0.4452  mix_decode.d4.loss_dice: 0.6635  mix_decode.d5.loss_cls: 0.1312  mix_decode.d5.loss_mask: 0.4447  mix_decode.d5.loss_dice: 0.6620  mix_decode.d6.loss_cls: 0.0878  mix_decode.d6.loss_mask: 0.4488  mix_decode.d6.loss_dice: 0.6696  mix_decode.d7.loss_cls: 0.0797  mix_decode.d7.loss_mask: 0.4475  mix_decode.d7.loss_dice: 0.6632  mix_decode.d8.loss_cls: 0.1085  mix_decode.d8.loss_mask: 0.4431  mix_decode.d8.loss_dice: 0.6539
2025/03/28 11:53:24 - mmengine - INFO - Iter(train) [ 8400/20000]  base_lr: 6.1250e-05 lr: 6.1250e-05  eta: 2:35:54  time: 1.0748  data_time: 0.0226  memory: 10781  loss: 32.0586  decode.loss_cls: 0.0265  decode.loss_mask: 1.0294  decode.loss_dice: 0.9813  decode.d0.loss_cls: 0.1034  decode.d0.loss_mask: 1.0386  decode.d0.loss_dice: 0.9641  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 1.0308  decode.d1.loss_dice: 0.9857  decode.d2.loss_cls: 0.0385  decode.d2.loss_mask: 1.0308  decode.d2.loss_dice: 0.9846  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 1.0211  decode.d3.loss_dice: 0.9726  decode.d4.loss_cls: 0.0278  decode.d4.loss_mask: 1.0332  decode.d4.loss_dice: 0.9838  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 1.0289  decode.d5.loss_dice: 0.9775  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 1.0317  decode.d6.loss_dice: 0.9831  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 1.0340  decode.d7.loss_dice: 0.9860  decode.d8.loss_cls: 0.0314  decode.d8.loss_mask: 1.0275  decode.d8.loss_dice: 0.9939  mix_decode.loss_cls: 0.0466  mix_decode.loss_mask: 0.4545  mix_decode.loss_dice: 0.6242  mix_decode.d0.loss_cls: 0.0643  mix_decode.d0.loss_mask: 0.5044  mix_decode.d0.loss_dice: 0.6435  mix_decode.d1.loss_cls: 0.0791  mix_decode.d1.loss_mask: 0.4746  mix_decode.d1.loss_dice: 0.6368  mix_decode.d2.loss_cls: 0.0626  mix_decode.d2.loss_mask: 0.4577  mix_decode.d2.loss_dice: 0.6193  mix_decode.d3.loss_cls: 0.0715  mix_decode.d3.loss_mask: 0.4581  mix_decode.d3.loss_dice: 0.6106  mix_decode.d4.loss_cls: 0.0557  mix_decode.d4.loss_mask: 0.4621  mix_decode.d4.loss_dice: 0.6255  mix_decode.d5.loss_cls: 0.0772  mix_decode.d5.loss_mask: 0.4506  mix_decode.d5.loss_dice: 0.6216  mix_decode.d6.loss_cls: 0.0496  mix_decode.d6.loss_mask: 0.4547  mix_decode.d6.loss_dice: 0.6288  mix_decode.d7.loss_cls: 0.0546  mix_decode.d7.loss_mask: 0.4616  mix_decode.d7.loss_dice: 0.6304  mix_decode.d8.loss_cls: 0.0710  mix_decode.d8.loss_mask: 0.4598  mix_decode.d8.loss_dice: 0.6268
2025/03/28 11:54:18 - mmengine - INFO - Iter(train) [ 8450/20000]  base_lr: 6.1012e-05 lr: 6.1012e-05  eta: 2:35:32  time: 1.0769  data_time: 0.0230  memory: 10776  loss: 33.2424  decode.loss_cls: 0.0282  decode.loss_mask: 1.0390  decode.loss_dice: 0.9335  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 1.0467  decode.d0.loss_dice: 0.9024  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 1.0386  decode.d1.loss_dice: 0.9352  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 1.0376  decode.d2.loss_dice: 0.9313  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 1.0287  decode.d3.loss_dice: 0.9354  decode.d4.loss_cls: 0.0282  decode.d4.loss_mask: 1.0273  decode.d4.loss_dice: 0.9488  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 1.0321  decode.d5.loss_dice: 0.9234  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 1.0315  decode.d6.loss_dice: 0.9462  decode.d7.loss_cls: 0.0267  decode.d7.loss_mask: 1.0384  decode.d7.loss_dice: 0.9444  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 1.0314  decode.d8.loss_dice: 0.9389  mix_decode.loss_cls: 0.0815  mix_decode.loss_mask: 0.5127  mix_decode.loss_dice: 0.6941  mix_decode.d0.loss_cls: 0.0973  mix_decode.d0.loss_mask: 0.5238  mix_decode.d0.loss_dice: 0.7271  mix_decode.d1.loss_cls: 0.0994  mix_decode.d1.loss_mask: 0.5103  mix_decode.d1.loss_dice: 0.7090  mix_decode.d2.loss_cls: 0.1165  mix_decode.d2.loss_mask: 0.5117  mix_decode.d2.loss_dice: 0.6996  mix_decode.d3.loss_cls: 0.1101  mix_decode.d3.loss_mask: 0.5119  mix_decode.d3.loss_dice: 0.6979  mix_decode.d4.loss_cls: 0.1243  mix_decode.d4.loss_mask: 0.5082  mix_decode.d4.loss_dice: 0.6941  mix_decode.d5.loss_cls: 0.1239  mix_decode.d5.loss_mask: 0.5078  mix_decode.d5.loss_dice: 0.7028  mix_decode.d6.loss_cls: 0.1125  mix_decode.d6.loss_mask: 0.5025  mix_decode.d6.loss_dice: 0.7108  mix_decode.d7.loss_cls: 0.1072  mix_decode.d7.loss_mask: 0.5078  mix_decode.d7.loss_dice: 0.6915  mix_decode.d8.loss_cls: 0.0825  mix_decode.d8.loss_mask: 0.5087  mix_decode.d8.loss_dice: 0.7145
2025/03/28 11:55:12 - mmengine - INFO - Iter(train) [ 8500/20000]  base_lr: 6.0774e-05 lr: 6.0774e-05  eta: 2:35:09  time: 1.0747  data_time: 0.0222  memory: 10773  loss: 34.2303  decode.loss_cls: 0.0611  decode.loss_mask: 1.0512  decode.loss_dice: 0.9951  decode.d0.loss_cls: 0.1466  decode.d0.loss_mask: 1.0071  decode.d0.loss_dice: 0.9819  decode.d1.loss_cls: 0.2199  decode.d1.loss_mask: 0.9981  decode.d1.loss_dice: 0.9879  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.9934  decode.d2.loss_dice: 1.0012  decode.d3.loss_cls: 0.0334  decode.d3.loss_mask: 1.0265  decode.d3.loss_dice: 1.0046  decode.d4.loss_cls: 0.1066  decode.d4.loss_mask: 0.9902  decode.d4.loss_dice: 0.9823  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.9845  decode.d5.loss_dice: 0.9730  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 1.0212  decode.d6.loss_dice: 0.9937  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 1.0290  decode.d7.loss_dice: 0.9880  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 1.0437  decode.d8.loss_dice: 1.0189  mix_decode.loss_cls: 0.1280  mix_decode.loss_mask: 0.5689  mix_decode.loss_dice: 0.6267  mix_decode.d0.loss_cls: 0.1847  mix_decode.d0.loss_mask: 0.5212  mix_decode.d0.loss_dice: 0.6321  mix_decode.d1.loss_cls: 0.1666  mix_decode.d1.loss_mask: 0.5530  mix_decode.d1.loss_dice: 0.6305  mix_decode.d2.loss_cls: 0.1323  mix_decode.d2.loss_mask: 0.5447  mix_decode.d2.loss_dice: 0.6115  mix_decode.d3.loss_cls: 0.1559  mix_decode.d3.loss_mask: 0.5372  mix_decode.d3.loss_dice: 0.6146  mix_decode.d4.loss_cls: 0.1422  mix_decode.d4.loss_mask: 0.5346  mix_decode.d4.loss_dice: 0.6065  mix_decode.d5.loss_cls: 0.1492  mix_decode.d5.loss_mask: 0.5395  mix_decode.d5.loss_dice: 0.6027  mix_decode.d6.loss_cls: 0.1329  mix_decode.d6.loss_mask: 0.5548  mix_decode.d6.loss_dice: 0.6210  mix_decode.d7.loss_cls: 0.1830  mix_decode.d7.loss_mask: 0.5458  mix_decode.d7.loss_dice: 0.6279  mix_decode.d8.loss_cls: 0.1477  mix_decode.d8.loss_mask: 0.5452  mix_decode.d8.loss_dice: 0.6241
2025/03/28 11:56:05 - mmengine - INFO - Iter(train) [ 8550/20000]  base_lr: 6.0537e-05 lr: 6.0537e-05  eta: 2:34:47  time: 1.0756  data_time: 0.0225  memory: 10771  loss: 33.8775  decode.loss_cls: 0.0180  decode.loss_mask: 1.0839  decode.loss_dice: 1.0594  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 1.0903  decode.d0.loss_dice: 1.0627  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 1.0900  decode.d1.loss_dice: 1.0438  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 1.0814  decode.d2.loss_dice: 1.0544  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 1.0755  decode.d3.loss_dice: 1.0543  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 1.0738  decode.d4.loss_dice: 1.0622  decode.d5.loss_cls: 0.0227  decode.d5.loss_mask: 1.0663  decode.d5.loss_dice: 1.0512  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 1.0769  decode.d6.loss_dice: 1.0469  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 1.0779  decode.d7.loss_dice: 1.0578  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 1.0857  decode.d8.loss_dice: 1.0554  mix_decode.loss_cls: 0.0511  mix_decode.loss_mask: 0.5265  mix_decode.loss_dice: 0.6475  mix_decode.d0.loss_cls: 0.0735  mix_decode.d0.loss_mask: 0.5329  mix_decode.d0.loss_dice: 0.6465  mix_decode.d1.loss_cls: 0.0666  mix_decode.d1.loss_mask: 0.5199  mix_decode.d1.loss_dice: 0.6313  mix_decode.d2.loss_cls: 0.0653  mix_decode.d2.loss_mask: 0.5198  mix_decode.d2.loss_dice: 0.6339  mix_decode.d3.loss_cls: 0.0646  mix_decode.d3.loss_mask: 0.5194  mix_decode.d3.loss_dice: 0.6330  mix_decode.d4.loss_cls: 0.0647  mix_decode.d4.loss_mask: 0.5255  mix_decode.d4.loss_dice: 0.6408  mix_decode.d5.loss_cls: 0.0716  mix_decode.d5.loss_mask: 0.5181  mix_decode.d5.loss_dice: 0.6305  mix_decode.d6.loss_cls: 0.0458  mix_decode.d6.loss_mask: 0.5230  mix_decode.d6.loss_dice: 0.6407  mix_decode.d7.loss_cls: 0.0719  mix_decode.d7.loss_mask: 0.5252  mix_decode.d7.loss_dice: 0.6337  mix_decode.d8.loss_cls: 0.0502  mix_decode.d8.loss_mask: 0.5219  mix_decode.d8.loss_dice: 0.6467
2025/03/28 11:56:59 - mmengine - INFO - Iter(train) [ 8600/20000]  base_lr: 6.0299e-05 lr: 6.0299e-05  eta: 2:34:23  time: 1.0747  data_time: 0.0222  memory: 10774  loss: 32.8031  decode.loss_cls: 0.0265  decode.loss_mask: 1.0008  decode.loss_dice: 1.0222  decode.d0.loss_cls: 0.0694  decode.d0.loss_mask: 1.0136  decode.d0.loss_dice: 0.9956  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 1.0061  decode.d1.loss_dice: 1.0477  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 1.0027  decode.d2.loss_dice: 1.0206  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 1.0070  decode.d3.loss_dice: 1.0186  decode.d4.loss_cls: 0.0211  decode.d4.loss_mask: 0.9996  decode.d4.loss_dice: 1.0180  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 1.0039  decode.d5.loss_dice: 1.0376  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 1.0042  decode.d6.loss_dice: 1.0252  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.9993  decode.d7.loss_dice: 1.0563  decode.d8.loss_cls: 0.0287  decode.d8.loss_mask: 1.0075  decode.d8.loss_dice: 1.0529  mix_decode.loss_cls: 0.1296  mix_decode.loss_mask: 0.4691  mix_decode.loss_dice: 0.6037  mix_decode.d0.loss_cls: 0.1501  mix_decode.d0.loss_mask: 0.4193  mix_decode.d0.loss_dice: 0.6455  mix_decode.d1.loss_cls: 0.1924  mix_decode.d1.loss_mask: 0.4140  mix_decode.d1.loss_dice: 0.5950  mix_decode.d2.loss_cls: 0.2113  mix_decode.d2.loss_mask: 0.4396  mix_decode.d2.loss_dice: 0.5859  mix_decode.d3.loss_cls: 0.1442  mix_decode.d3.loss_mask: 0.4440  mix_decode.d3.loss_dice: 0.6091  mix_decode.d4.loss_cls: 0.1258  mix_decode.d4.loss_mask: 0.4498  mix_decode.d4.loss_dice: 0.6065  mix_decode.d5.loss_cls: 0.1402  mix_decode.d5.loss_mask: 0.4540  mix_decode.d5.loss_dice: 0.6038  mix_decode.d6.loss_cls: 0.1450  mix_decode.d6.loss_mask: 0.4528  mix_decode.d6.loss_dice: 0.6109  mix_decode.d7.loss_cls: 0.1344  mix_decode.d7.loss_mask: 0.4698  mix_decode.d7.loss_dice: 0.6202  mix_decode.d8.loss_cls: 0.1344  mix_decode.d8.loss_mask: 0.4740  mix_decode.d8.loss_dice: 0.6180
2025/03/28 11:57:53 - mmengine - INFO - Iter(train) [ 8650/20000]  base_lr: 6.0060e-05 lr: 6.0060e-05  eta: 2:34:00  time: 1.0811  data_time: 0.0227  memory: 10769  loss: 33.9785  decode.loss_cls: 0.0120  decode.loss_mask: 1.0183  decode.loss_dice: 0.9410  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 1.0396  decode.d0.loss_dice: 0.9258  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 1.0238  decode.d1.loss_dice: 0.9610  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 1.0254  decode.d2.loss_dice: 0.9570  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 1.0186  decode.d3.loss_dice: 0.9511  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 1.0208  decode.d4.loss_dice: 0.9514  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 1.0175  decode.d5.loss_dice: 0.9604  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 1.0219  decode.d6.loss_dice: 0.9449  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 1.0183  decode.d7.loss_dice: 0.9543  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 1.0207  decode.d8.loss_dice: 0.9615  mix_decode.loss_cls: 0.1607  mix_decode.loss_mask: 0.6098  mix_decode.loss_dice: 0.6810  mix_decode.d0.loss_cls: 0.1845  mix_decode.d0.loss_mask: 0.6122  mix_decode.d0.loss_dice: 0.6882  mix_decode.d1.loss_cls: 0.0965  mix_decode.d1.loss_mask: 0.6087  mix_decode.d1.loss_dice: 0.6820  mix_decode.d2.loss_cls: 0.1119  mix_decode.d2.loss_mask: 0.6040  mix_decode.d2.loss_dice: 0.6785  mix_decode.d3.loss_cls: 0.0956  mix_decode.d3.loss_mask: 0.6040  mix_decode.d3.loss_dice: 0.6767  mix_decode.d4.loss_cls: 0.1130  mix_decode.d4.loss_mask: 0.6007  mix_decode.d4.loss_dice: 0.6780  mix_decode.d5.loss_cls: 0.1003  mix_decode.d5.loss_mask: 0.6058  mix_decode.d5.loss_dice: 0.6753  mix_decode.d6.loss_cls: 0.0956  mix_decode.d6.loss_mask: 0.6124  mix_decode.d6.loss_dice: 0.6790  mix_decode.d7.loss_cls: 0.1154  mix_decode.d7.loss_mask: 0.6098  mix_decode.d7.loss_dice: 0.6847  mix_decode.d8.loss_cls: 0.1001  mix_decode.d8.loss_mask: 0.6093  mix_decode.d8.loss_dice: 0.6711
2025/03/28 11:58:47 - mmengine - INFO - Iter(train) [ 8700/20000]  base_lr: 5.9822e-05 lr: 5.9822e-05  eta: 2:33:36  time: 1.0814  data_time: 0.0237  memory: 10770  loss: 34.8092  decode.loss_cls: 0.0090  decode.loss_mask: 1.1097  decode.loss_dice: 1.0339  decode.d0.loss_cls: 0.0649  decode.d0.loss_mask: 1.1231  decode.d0.loss_dice: 1.0146  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 1.1091  decode.d1.loss_dice: 1.0355  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 1.1099  decode.d2.loss_dice: 1.0310  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 1.1044  decode.d3.loss_dice: 1.0318  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 1.0998  decode.d4.loss_dice: 1.0294  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 1.1067  decode.d5.loss_dice: 1.0164  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 1.1177  decode.d6.loss_dice: 1.0273  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 1.1059  decode.d7.loss_dice: 1.0199  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 1.1138  decode.d8.loss_dice: 1.0332  mix_decode.loss_cls: 0.0438  mix_decode.loss_mask: 0.5815  mix_decode.loss_dice: 0.6870  mix_decode.d0.loss_cls: 0.0750  mix_decode.d0.loss_mask: 0.5787  mix_decode.d0.loss_dice: 0.7020  mix_decode.d1.loss_cls: 0.1166  mix_decode.d1.loss_mask: 0.5685  mix_decode.d1.loss_dice: 0.6784  mix_decode.d2.loss_cls: 0.1058  mix_decode.d2.loss_mask: 0.5656  mix_decode.d2.loss_dice: 0.6753  mix_decode.d3.loss_cls: 0.0477  mix_decode.d3.loss_mask: 0.5758  mix_decode.d3.loss_dice: 0.6888  mix_decode.d4.loss_cls: 0.0413  mix_decode.d4.loss_mask: 0.5767  mix_decode.d4.loss_dice: 0.6836  mix_decode.d5.loss_cls: 0.0336  mix_decode.d5.loss_mask: 0.5881  mix_decode.d5.loss_dice: 0.6994  mix_decode.d6.loss_cls: 0.0344  mix_decode.d6.loss_mask: 0.5981  mix_decode.d6.loss_dice: 0.6936  mix_decode.d7.loss_cls: 0.0633  mix_decode.d7.loss_mask: 0.5872  mix_decode.d7.loss_dice: 0.6861  mix_decode.d8.loss_cls: 0.0404  mix_decode.d8.loss_mask: 0.5799  mix_decode.d8.loss_dice: 0.6775
2025/03/28 11:59:41 - mmengine - INFO - Iter(train) [ 8750/20000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 2:33:13  time: 1.0755  data_time: 0.0229  memory: 10770  loss: 34.7578  decode.loss_cls: 0.0849  decode.loss_mask: 0.9938  decode.loss_dice: 0.9908  decode.d0.loss_cls: 0.1547  decode.d0.loss_mask: 1.0220  decode.d0.loss_dice: 1.0107  decode.d1.loss_cls: 0.1078  decode.d1.loss_mask: 1.0001  decode.d1.loss_dice: 0.9895  decode.d2.loss_cls: 0.1152  decode.d2.loss_mask: 1.0015  decode.d2.loss_dice: 0.9710  decode.d3.loss_cls: 0.1050  decode.d3.loss_mask: 0.9950  decode.d3.loss_dice: 0.9935  decode.d4.loss_cls: 0.1120  decode.d4.loss_mask: 0.9993  decode.d4.loss_dice: 0.9986  decode.d5.loss_cls: 0.0992  decode.d5.loss_mask: 0.9991  decode.d5.loss_dice: 0.9895  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 1.0021  decode.d6.loss_dice: 1.0021  decode.d7.loss_cls: 0.0864  decode.d7.loss_mask: 0.9989  decode.d7.loss_dice: 1.0022  decode.d8.loss_cls: 0.0882  decode.d8.loss_mask: 0.9994  decode.d8.loss_dice: 0.9986  mix_decode.loss_cls: 0.0828  mix_decode.loss_mask: 0.5287  mix_decode.loss_dice: 0.7552  mix_decode.d0.loss_cls: 0.1469  mix_decode.d0.loss_mask: 0.4898  mix_decode.d0.loss_dice: 0.7608  mix_decode.d1.loss_cls: 0.1892  mix_decode.d1.loss_mask: 0.4835  mix_decode.d1.loss_dice: 0.7299  mix_decode.d2.loss_cls: 0.1710  mix_decode.d2.loss_mask: 0.4785  mix_decode.d2.loss_dice: 0.7330  mix_decode.d3.loss_cls: 0.1121  mix_decode.d3.loss_mask: 0.4805  mix_decode.d3.loss_dice: 0.7466  mix_decode.d4.loss_cls: 0.1341  mix_decode.d4.loss_mask: 0.4809  mix_decode.d4.loss_dice: 0.7373  mix_decode.d5.loss_cls: 0.1013  mix_decode.d5.loss_mask: 0.5075  mix_decode.d5.loss_dice: 0.7587  mix_decode.d6.loss_cls: 0.1408  mix_decode.d6.loss_mask: 0.4961  mix_decode.d6.loss_dice: 0.7492  mix_decode.d7.loss_cls: 0.1145  mix_decode.d7.loss_mask: 0.5192  mix_decode.d7.loss_dice: 0.7541  mix_decode.d8.loss_cls: 0.1319  mix_decode.d8.loss_mask: 0.5219  mix_decode.d8.loss_dice: 0.7378
2025/03/28 12:00:35 - mmengine - INFO - Iter(train) [ 8800/20000]  base_lr: 5.9346e-05 lr: 5.9346e-05  eta: 2:32:48  time: 1.0746  data_time: 0.0228  memory: 10779  loss: 33.6902  decode.loss_cls: 0.0468  decode.loss_mask: 1.0707  decode.loss_dice: 1.0507  decode.d0.loss_cls: 0.1071  decode.d0.loss_mask: 1.0714  decode.d0.loss_dice: 1.0682  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 1.0527  decode.d1.loss_dice: 1.0481  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 1.0639  decode.d2.loss_dice: 1.0466  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 1.0216  decode.d3.loss_dice: 1.0415  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 1.0381  decode.d4.loss_dice: 1.0285  decode.d5.loss_cls: 0.0618  decode.d5.loss_mask: 1.0434  decode.d5.loss_dice: 1.0366  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 1.0511  decode.d6.loss_dice: 1.0477  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 1.0851  decode.d7.loss_dice: 1.0458  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 1.0611  decode.d8.loss_dice: 1.0546  mix_decode.loss_cls: 0.0743  mix_decode.loss_mask: 0.4706  mix_decode.loss_dice: 0.6539  mix_decode.d0.loss_cls: 0.1512  mix_decode.d0.loss_mask: 0.4430  mix_decode.d0.loss_dice: 0.6457  mix_decode.d1.loss_cls: 0.1057  mix_decode.d1.loss_mask: 0.4361  mix_decode.d1.loss_dice: 0.6322  mix_decode.d2.loss_cls: 0.0759  mix_decode.d2.loss_mask: 0.4571  mix_decode.d2.loss_dice: 0.6589  mix_decode.d3.loss_cls: 0.0828  mix_decode.d3.loss_mask: 0.4456  mix_decode.d3.loss_dice: 0.6431  mix_decode.d4.loss_cls: 0.0886  mix_decode.d4.loss_mask: 0.4509  mix_decode.d4.loss_dice: 0.6511  mix_decode.d5.loss_cls: 0.0961  mix_decode.d5.loss_mask: 0.4440  mix_decode.d5.loss_dice: 0.6562  mix_decode.d6.loss_cls: 0.1122  mix_decode.d6.loss_mask: 0.4675  mix_decode.d6.loss_dice: 0.6566  mix_decode.d7.loss_cls: 0.0892  mix_decode.d7.loss_mask: 0.4662  mix_decode.d7.loss_dice: 0.6488  mix_decode.d8.loss_cls: 0.0781  mix_decode.d8.loss_mask: 0.4721  mix_decode.d8.loss_dice: 0.6556
2025/03/28 12:01:29 - mmengine - INFO - Iter(train) [ 8850/20000]  base_lr: 5.9107e-05 lr: 5.9107e-05  eta: 2:32:24  time: 1.0805  data_time: 0.0227  memory: 10779  loss: 31.0138  decode.loss_cls: 0.0468  decode.loss_mask: 0.9380  decode.loss_dice: 0.8750  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.9453  decode.d0.loss_dice: 0.9092  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.9422  decode.d1.loss_dice: 0.9050  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.9426  decode.d2.loss_dice: 0.8923  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.9390  decode.d3.loss_dice: 0.9044  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.9406  decode.d4.loss_dice: 0.8880  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.9384  decode.d5.loss_dice: 0.8765  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.9372  decode.d6.loss_dice: 0.8807  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.9393  decode.d7.loss_dice: 0.8902  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.9382  decode.d8.loss_dice: 0.8780  mix_decode.loss_cls: 0.1053  mix_decode.loss_mask: 0.4985  mix_decode.loss_dice: 0.6214  mix_decode.d0.loss_cls: 0.1295  mix_decode.d0.loss_mask: 0.4933  mix_decode.d0.loss_dice: 0.6445  mix_decode.d1.loss_cls: 0.1129  mix_decode.d1.loss_mask: 0.4907  mix_decode.d1.loss_dice: 0.6211  mix_decode.d2.loss_cls: 0.1328  mix_decode.d2.loss_mask: 0.4874  mix_decode.d2.loss_dice: 0.6090  mix_decode.d3.loss_cls: 0.1041  mix_decode.d3.loss_mask: 0.4862  mix_decode.d3.loss_dice: 0.6050  mix_decode.d4.loss_cls: 0.1245  mix_decode.d4.loss_mask: 0.4904  mix_decode.d4.loss_dice: 0.6208  mix_decode.d5.loss_cls: 0.1120  mix_decode.d5.loss_mask: 0.4859  mix_decode.d5.loss_dice: 0.6102  mix_decode.d6.loss_cls: 0.1125  mix_decode.d6.loss_mask: 0.4965  mix_decode.d6.loss_dice: 0.6044  mix_decode.d7.loss_cls: 0.1308  mix_decode.d7.loss_mask: 0.4858  mix_decode.d7.loss_dice: 0.6146  mix_decode.d8.loss_cls: 0.1301  mix_decode.d8.loss_mask: 0.4911  mix_decode.d8.loss_dice: 0.6117
2025/03/28 12:02:23 - mmengine - INFO - Iter(train) [ 8900/20000]  base_lr: 5.8869e-05 lr: 5.8869e-05  eta: 2:31:59  time: 1.0775  data_time: 0.0227  memory: 10773  loss: 31.4811  decode.loss_cls: 0.0797  decode.loss_mask: 1.0534  decode.loss_dice: 0.9046  decode.d0.loss_cls: 0.1399  decode.d0.loss_mask: 1.0776  decode.d0.loss_dice: 0.9149  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 1.0519  decode.d1.loss_dice: 0.8884  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 1.0526  decode.d2.loss_dice: 0.8896  decode.d3.loss_cls: 0.0979  decode.d3.loss_mask: 1.0515  decode.d3.loss_dice: 0.8922  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 1.0535  decode.d4.loss_dice: 0.8911  decode.d5.loss_cls: 0.0802  decode.d5.loss_mask: 1.0536  decode.d5.loss_dice: 0.8856  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 1.0532  decode.d6.loss_dice: 0.8878  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 1.0530  decode.d7.loss_dice: 0.8965  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 1.0586  decode.d8.loss_dice: 0.9104  mix_decode.loss_cls: 0.0926  mix_decode.loss_mask: 0.4917  mix_decode.loss_dice: 0.5337  mix_decode.d0.loss_cls: 0.0751  mix_decode.d0.loss_mask: 0.4979  mix_decode.d0.loss_dice: 0.5500  mix_decode.d1.loss_cls: 0.0880  mix_decode.d1.loss_mask: 0.4917  mix_decode.d1.loss_dice: 0.5326  mix_decode.d2.loss_cls: 0.0743  mix_decode.d2.loss_mask: 0.4915  mix_decode.d2.loss_dice: 0.5258  mix_decode.d3.loss_cls: 0.0785  mix_decode.d3.loss_mask: 0.4898  mix_decode.d3.loss_dice: 0.5259  mix_decode.d4.loss_cls: 0.0819  mix_decode.d4.loss_mask: 0.4888  mix_decode.d4.loss_dice: 0.5302  mix_decode.d5.loss_cls: 0.0965  mix_decode.d5.loss_mask: 0.4916  mix_decode.d5.loss_dice: 0.5268  mix_decode.d6.loss_cls: 0.0638  mix_decode.d6.loss_mask: 0.4897  mix_decode.d6.loss_dice: 0.5395  mix_decode.d7.loss_cls: 0.1134  mix_decode.d7.loss_mask: 0.4930  mix_decode.d7.loss_dice: 0.5314  mix_decode.d8.loss_cls: 0.0901  mix_decode.d8.loss_mask: 0.4878  mix_decode.d8.loss_dice: 0.5255
2025/03/28 12:03:16 - mmengine - INFO - Iter(train) [ 8950/20000]  base_lr: 5.8630e-05 lr: 5.8630e-05  eta: 2:31:34  time: 1.0751  data_time: 0.0224  memory: 10770  loss: 30.6290  decode.loss_cls: 0.0065  decode.loss_mask: 0.9878  decode.loss_dice: 0.9434  decode.d0.loss_cls: 0.0587  decode.d0.loss_mask: 0.9975  decode.d0.loss_dice: 0.9187  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.9950  decode.d1.loss_dice: 0.9364  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.9930  decode.d2.loss_dice: 0.9437  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.9909  decode.d3.loss_dice: 0.9469  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.9951  decode.d4.loss_dice: 0.9481  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.9949  decode.d5.loss_dice: 0.9362  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.9896  decode.d6.loss_dice: 0.9417  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.9879  decode.d7.loss_dice: 0.9366  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.9902  decode.d8.loss_dice: 0.9393  mix_decode.loss_cls: 0.0412  mix_decode.loss_mask: 0.4931  mix_decode.loss_dice: 0.5781  mix_decode.d0.loss_cls: 0.0755  mix_decode.d0.loss_mask: 0.4936  mix_decode.d0.loss_dice: 0.5847  mix_decode.d1.loss_cls: 0.0393  mix_decode.d1.loss_mask: 0.4974  mix_decode.d1.loss_dice: 0.5904  mix_decode.d2.loss_cls: 0.0397  mix_decode.d2.loss_mask: 0.4995  mix_decode.d2.loss_dice: 0.5754  mix_decode.d3.loss_cls: 0.0464  mix_decode.d3.loss_mask: 0.4935  mix_decode.d3.loss_dice: 0.5720  mix_decode.d4.loss_cls: 0.0320  mix_decode.d4.loss_mask: 0.4992  mix_decode.d4.loss_dice: 0.5836  mix_decode.d5.loss_cls: 0.0413  mix_decode.d5.loss_mask: 0.4970  mix_decode.d5.loss_dice: 0.5796  mix_decode.d6.loss_cls: 0.0465  mix_decode.d6.loss_mask: 0.4989  mix_decode.d6.loss_dice: 0.5762  mix_decode.d7.loss_cls: 0.0414  mix_decode.d7.loss_mask: 0.4960  mix_decode.d7.loss_dice: 0.5864  mix_decode.d8.loss_cls: 0.0396  mix_decode.d8.loss_mask: 0.4945  mix_decode.d8.loss_dice: 0.5752
2025/03/28 12:04:10 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 12:04:10 - mmengine - INFO - Iter(train) [ 9000/20000]  base_lr: 5.8391e-05 lr: 5.8391e-05  eta: 2:31:08  time: 1.0714  data_time: 0.0222  memory: 10772  loss: 32.0673  decode.loss_cls: 0.0443  decode.loss_mask: 0.8478  decode.loss_dice: 1.0202  decode.d0.loss_cls: 0.0730  decode.d0.loss_mask: 0.8515  decode.d0.loss_dice: 1.0367  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.8399  decode.d1.loss_dice: 1.0147  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.8496  decode.d2.loss_dice: 0.9969  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.8494  decode.d3.loss_dice: 0.9907  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.8403  decode.d4.loss_dice: 0.9994  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.8468  decode.d5.loss_dice: 1.0054  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.8438  decode.d6.loss_dice: 1.0144  decode.d7.loss_cls: 0.0356  decode.d7.loss_mask: 0.8396  decode.d7.loss_dice: 1.0292  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.8491  decode.d8.loss_dice: 1.0355  mix_decode.loss_cls: 0.0933  mix_decode.loss_mask: 0.4920  mix_decode.loss_dice: 0.7047  mix_decode.d0.loss_cls: 0.0995  mix_decode.d0.loss_mask: 0.4914  mix_decode.d0.loss_dice: 0.7308  mix_decode.d1.loss_cls: 0.1268  mix_decode.d1.loss_mask: 0.4802  mix_decode.d1.loss_dice: 0.6810  mix_decode.d2.loss_cls: 0.1353  mix_decode.d2.loss_mask: 0.4821  mix_decode.d2.loss_dice: 0.6803  mix_decode.d3.loss_cls: 0.1262  mix_decode.d3.loss_mask: 0.4851  mix_decode.d3.loss_dice: 0.6841  mix_decode.d4.loss_cls: 0.1181  mix_decode.d4.loss_mask: 0.4829  mix_decode.d4.loss_dice: 0.6712  mix_decode.d5.loss_cls: 0.1375  mix_decode.d5.loss_mask: 0.4786  mix_decode.d5.loss_dice: 0.6683  mix_decode.d6.loss_cls: 0.1119  mix_decode.d6.loss_mask: 0.4868  mix_decode.d6.loss_dice: 0.6773  mix_decode.d7.loss_cls: 0.0866  mix_decode.d7.loss_mask: 0.4881  mix_decode.d7.loss_dice: 0.7091  mix_decode.d8.loss_cls: 0.0823  mix_decode.d8.loss_mask: 0.4875  mix_decode.d8.loss_dice: 0.6956
2025/03/28 12:05:05 - mmengine - INFO - Iter(train) [ 9050/20000]  base_lr: 5.8152e-05 lr: 5.8152e-05  eta: 2:30:43  time: 1.0764  data_time: 0.0233  memory: 10777  loss: 34.2741  decode.loss_cls: 0.0082  decode.loss_mask: 1.0190  decode.loss_dice: 1.0778  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 1.0183  decode.d0.loss_dice: 1.0687  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 1.0246  decode.d1.loss_dice: 1.0791  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 1.0153  decode.d2.loss_dice: 1.0825  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 1.0204  decode.d3.loss_dice: 1.0838  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 1.0193  decode.d4.loss_dice: 1.0769  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 1.0212  decode.d5.loss_dice: 1.0750  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 1.0168  decode.d6.loss_dice: 1.0758  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 1.0238  decode.d7.loss_dice: 1.0809  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 1.0294  decode.d8.loss_dice: 1.0842  mix_decode.loss_cls: 0.1196  mix_decode.loss_mask: 0.5051  mix_decode.loss_dice: 0.6941  mix_decode.d0.loss_cls: 0.1157  mix_decode.d0.loss_mask: 0.5093  mix_decode.d0.loss_dice: 0.7123  mix_decode.d1.loss_cls: 0.1125  mix_decode.d1.loss_mask: 0.5015  mix_decode.d1.loss_dice: 0.6993  mix_decode.d2.loss_cls: 0.1093  mix_decode.d2.loss_mask: 0.5036  mix_decode.d2.loss_dice: 0.6913  mix_decode.d3.loss_cls: 0.0929  mix_decode.d3.loss_mask: 0.4973  mix_decode.d3.loss_dice: 0.7023  mix_decode.d4.loss_cls: 0.0837  mix_decode.d4.loss_mask: 0.5089  mix_decode.d4.loss_dice: 0.7086  mix_decode.d5.loss_cls: 0.0859  mix_decode.d5.loss_mask: 0.5116  mix_decode.d5.loss_dice: 0.7024  mix_decode.d6.loss_cls: 0.1069  mix_decode.d6.loss_mask: 0.5057  mix_decode.d6.loss_dice: 0.6958  mix_decode.d7.loss_cls: 0.1266  mix_decode.d7.loss_mask: 0.5038  mix_decode.d7.loss_dice: 0.6979  mix_decode.d8.loss_cls: 0.1022  mix_decode.d8.loss_mask: 0.5099  mix_decode.d8.loss_dice: 0.7089
2025/03/28 12:05:59 - mmengine - INFO - Iter(train) [ 9100/20000]  base_lr: 5.7913e-05 lr: 5.7913e-05  eta: 2:30:17  time: 1.0739  data_time: 0.0225  memory: 10776  loss: 34.8648  decode.loss_cls: 0.0648  decode.loss_mask: 1.0510  decode.loss_dice: 0.9649  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 1.0682  decode.d0.loss_dice: 0.9986  decode.d1.loss_cls: 0.1278  decode.d1.loss_mask: 1.0473  decode.d1.loss_dice: 0.9517  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 1.0448  decode.d2.loss_dice: 0.9597  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 1.0456  decode.d3.loss_dice: 0.9472  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 1.0498  decode.d4.loss_dice: 0.9436  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 1.0558  decode.d5.loss_dice: 0.9509  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 1.0491  decode.d6.loss_dice: 0.9583  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 1.0528  decode.d7.loss_dice: 0.9503  decode.d8.loss_cls: 0.1105  decode.d8.loss_mask: 1.0503  decode.d8.loss_dice: 0.9600  mix_decode.loss_cls: 0.1016  mix_decode.loss_mask: 0.5653  mix_decode.loss_dice: 0.7109  mix_decode.d0.loss_cls: 0.1226  mix_decode.d0.loss_mask: 0.5723  mix_decode.d0.loss_dice: 0.7188  mix_decode.d1.loss_cls: 0.0929  mix_decode.d1.loss_mask: 0.5739  mix_decode.d1.loss_dice: 0.7101  mix_decode.d2.loss_cls: 0.1136  mix_decode.d2.loss_mask: 0.5700  mix_decode.d2.loss_dice: 0.7042  mix_decode.d3.loss_cls: 0.1148  mix_decode.d3.loss_mask: 0.5686  mix_decode.d3.loss_dice: 0.7049  mix_decode.d4.loss_cls: 0.0951  mix_decode.d4.loss_mask: 0.5785  mix_decode.d4.loss_dice: 0.6970  mix_decode.d5.loss_cls: 0.1059  mix_decode.d5.loss_mask: 0.5655  mix_decode.d5.loss_dice: 0.7038  mix_decode.d6.loss_cls: 0.0715  mix_decode.d6.loss_mask: 0.5703  mix_decode.d6.loss_dice: 0.7257  mix_decode.d7.loss_cls: 0.1201  mix_decode.d7.loss_mask: 0.5691  mix_decode.d7.loss_dice: 0.7089  mix_decode.d8.loss_cls: 0.1054  mix_decode.d8.loss_mask: 0.5692  mix_decode.d8.loss_dice: 0.7071
2025/03/28 12:06:53 - mmengine - INFO - Iter(train) [ 9150/20000]  base_lr: 5.7674e-05 lr: 5.7674e-05  eta: 2:29:50  time: 1.0770  data_time: 0.0224  memory: 10772  loss: 31.1768  decode.loss_cls: 0.0846  decode.loss_mask: 0.9441  decode.loss_dice: 0.9034  decode.d0.loss_cls: 0.1044  decode.d0.loss_mask: 0.9649  decode.d0.loss_dice: 0.9071  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.9434  decode.d1.loss_dice: 0.9283  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.9456  decode.d2.loss_dice: 0.9092  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.9470  decode.d3.loss_dice: 0.9125  decode.d4.loss_cls: 0.0623  decode.d4.loss_mask: 0.9471  decode.d4.loss_dice: 0.9264  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.9425  decode.d5.loss_dice: 0.8995  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.9464  decode.d6.loss_dice: 0.9025  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.9380  decode.d7.loss_dice: 0.9019  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 0.9405  decode.d8.loss_dice: 0.9053  mix_decode.loss_cls: 0.0901  mix_decode.loss_mask: 0.4977  mix_decode.loss_dice: 0.5878  mix_decode.d0.loss_cls: 0.1052  mix_decode.d0.loss_mask: 0.5191  mix_decode.d0.loss_dice: 0.5986  mix_decode.d1.loss_cls: 0.1039  mix_decode.d1.loss_mask: 0.5176  mix_decode.d1.loss_dice: 0.5991  mix_decode.d2.loss_cls: 0.0785  mix_decode.d2.loss_mask: 0.5152  mix_decode.d2.loss_dice: 0.6100  mix_decode.d3.loss_cls: 0.1009  mix_decode.d3.loss_mask: 0.4948  mix_decode.d3.loss_dice: 0.5812  mix_decode.d4.loss_cls: 0.0626  mix_decode.d4.loss_mask: 0.5046  mix_decode.d4.loss_dice: 0.6006  mix_decode.d5.loss_cls: 0.0997  mix_decode.d5.loss_mask: 0.4954  mix_decode.d5.loss_dice: 0.5828  mix_decode.d6.loss_cls: 0.1019  mix_decode.d6.loss_mask: 0.4984  mix_decode.d6.loss_dice: 0.5862  mix_decode.d7.loss_cls: 0.0680  mix_decode.d7.loss_mask: 0.5076  mix_decode.d7.loss_dice: 0.6010  mix_decode.d8.loss_cls: 0.0590  mix_decode.d8.loss_mask: 0.5139  mix_decode.d8.loss_dice: 0.6060
2025/03/28 12:07:46 - mmengine - INFO - Iter(train) [ 9200/20000]  base_lr: 5.7435e-05 lr: 5.7435e-05  eta: 2:29:23  time: 1.0802  data_time: 0.0233  memory: 10771  loss: 31.6872  decode.loss_cls: 0.0158  decode.loss_mask: 1.0396  decode.loss_dice: 1.0100  decode.d0.loss_cls: 0.0798  decode.d0.loss_mask: 1.0575  decode.d0.loss_dice: 1.0005  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 1.0436  decode.d1.loss_dice: 1.0141  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 1.0438  decode.d2.loss_dice: 1.0074  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 1.0408  decode.d3.loss_dice: 1.0237  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 1.0352  decode.d4.loss_dice: 1.0115  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 1.0349  decode.d5.loss_dice: 1.0109  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 1.0376  decode.d6.loss_dice: 1.0160  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 1.0383  decode.d7.loss_dice: 1.0105  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 1.0339  decode.d8.loss_dice: 1.0082  mix_decode.loss_cls: 0.0691  mix_decode.loss_mask: 0.4472  mix_decode.loss_dice: 0.5401  mix_decode.d0.loss_cls: 0.1579  mix_decode.d0.loss_mask: 0.4637  mix_decode.d0.loss_dice: 0.5525  mix_decode.d1.loss_cls: 0.0838  mix_decode.d1.loss_mask: 0.4500  mix_decode.d1.loss_dice: 0.5548  mix_decode.d2.loss_cls: 0.0923  mix_decode.d2.loss_mask: 0.4528  mix_decode.d2.loss_dice: 0.5458  mix_decode.d3.loss_cls: 0.0776  mix_decode.d3.loss_mask: 0.4517  mix_decode.d3.loss_dice: 0.5665  mix_decode.d4.loss_cls: 0.0718  mix_decode.d4.loss_mask: 0.4549  mix_decode.d4.loss_dice: 0.5615  mix_decode.d5.loss_cls: 0.0715  mix_decode.d5.loss_mask: 0.4573  mix_decode.d5.loss_dice: 0.5651  mix_decode.d6.loss_cls: 0.0731  mix_decode.d6.loss_mask: 0.4500  mix_decode.d6.loss_dice: 0.5617  mix_decode.d7.loss_cls: 0.0985  mix_decode.d7.loss_mask: 0.4502  mix_decode.d7.loss_dice: 0.5483  mix_decode.d8.loss_cls: 0.0705  mix_decode.d8.loss_mask: 0.4475  mix_decode.d8.loss_dice: 0.5521
2025/03/28 12:08:40 - mmengine - INFO - Iter(train) [ 9250/20000]  base_lr: 5.7195e-05 lr: 5.7195e-05  eta: 2:28:56  time: 1.0718  data_time: 0.0224  memory: 10772  loss: 32.8155  decode.loss_cls: 0.0669  decode.loss_mask: 1.0031  decode.loss_dice: 0.9365  decode.d0.loss_cls: 0.1140  decode.d0.loss_mask: 1.0087  decode.d0.loss_dice: 0.9173  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 1.0048  decode.d1.loss_dice: 0.9295  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 1.0028  decode.d2.loss_dice: 0.9118  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 1.0051  decode.d3.loss_dice: 0.9251  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 1.0016  decode.d4.loss_dice: 0.9164  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 1.0035  decode.d5.loss_dice: 0.9235  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 1.0074  decode.d6.loss_dice: 0.9250  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 1.0038  decode.d7.loss_dice: 0.9411  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 1.0038  decode.d8.loss_dice: 0.9368  mix_decode.loss_cls: 0.1745  mix_decode.loss_mask: 0.4353  mix_decode.loss_dice: 0.6528  mix_decode.d0.loss_cls: 0.1675  mix_decode.d0.loss_mask: 0.4383  mix_decode.d0.loss_dice: 0.7022  mix_decode.d1.loss_cls: 0.1981  mix_decode.d1.loss_mask: 0.4360  mix_decode.d1.loss_dice: 0.6613  mix_decode.d2.loss_cls: 0.1607  mix_decode.d2.loss_mask: 0.4395  mix_decode.d2.loss_dice: 0.6757  mix_decode.d3.loss_cls: 0.1468  mix_decode.d3.loss_mask: 0.4402  mix_decode.d3.loss_dice: 0.6705  mix_decode.d4.loss_cls: 0.1791  mix_decode.d4.loss_mask: 0.4375  mix_decode.d4.loss_dice: 0.6540  mix_decode.d5.loss_cls: 0.1577  mix_decode.d5.loss_mask: 0.4451  mix_decode.d5.loss_dice: 0.6798  mix_decode.d6.loss_cls: 0.1358  mix_decode.d6.loss_mask: 0.4507  mix_decode.d6.loss_dice: 0.6859  mix_decode.d7.loss_cls: 0.1398  mix_decode.d7.loss_mask: 0.4455  mix_decode.d7.loss_dice: 0.6903  mix_decode.d8.loss_cls: 0.1563  mix_decode.d8.loss_mask: 0.4352  mix_decode.d8.loss_dice: 0.6786
2025/03/28 12:09:34 - mmengine - INFO - Iter(train) [ 9300/20000]  base_lr: 5.6956e-05 lr: 5.6956e-05  eta: 2:28:29  time: 1.0751  data_time: 0.0224  memory: 10778  loss: 33.5832  decode.loss_cls: 0.0381  decode.loss_mask: 0.9948  decode.loss_dice: 0.9587  decode.d0.loss_cls: 0.1077  decode.d0.loss_mask: 0.9965  decode.d0.loss_dice: 0.9818  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.9928  decode.d1.loss_dice: 0.9575  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.9879  decode.d2.loss_dice: 0.9543  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.9875  decode.d3.loss_dice: 0.9499  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.9854  decode.d4.loss_dice: 0.9474  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.9907  decode.d5.loss_dice: 0.9550  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 1.0003  decode.d6.loss_dice: 0.9399  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.9985  decode.d7.loss_dice: 0.9844  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.9939  decode.d8.loss_dice: 0.9505  mix_decode.loss_cls: 0.1044  mix_decode.loss_mask: 0.5355  mix_decode.loss_dice: 0.7091  mix_decode.d0.loss_cls: 0.1499  mix_decode.d0.loss_mask: 0.5487  mix_decode.d0.loss_dice: 0.7387  mix_decode.d1.loss_cls: 0.1317  mix_decode.d1.loss_mask: 0.5382  mix_decode.d1.loss_dice: 0.6969  mix_decode.d2.loss_cls: 0.0998  mix_decode.d2.loss_mask: 0.5396  mix_decode.d2.loss_dice: 0.6985  mix_decode.d3.loss_cls: 0.1051  mix_decode.d3.loss_mask: 0.5505  mix_decode.d3.loss_dice: 0.7012  mix_decode.d4.loss_cls: 0.0886  mix_decode.d4.loss_mask: 0.5556  mix_decode.d4.loss_dice: 0.6892  mix_decode.d5.loss_cls: 0.1491  mix_decode.d5.loss_mask: 0.5409  mix_decode.d5.loss_dice: 0.6742  mix_decode.d6.loss_cls: 0.1377  mix_decode.d6.loss_mask: 0.5457  mix_decode.d6.loss_dice: 0.6934  mix_decode.d7.loss_cls: 0.1574  mix_decode.d7.loss_mask: 0.5520  mix_decode.d7.loss_dice: 0.7005  mix_decode.d8.loss_cls: 0.1123  mix_decode.d8.loss_mask: 0.5382  mix_decode.d8.loss_dice: 0.7178
2025/03/28 12:10:28 - mmengine - INFO - Iter(train) [ 9350/20000]  base_lr: 5.6716e-05 lr: 5.6716e-05  eta: 2:28:01  time: 1.0769  data_time: 0.0227  memory: 10783  loss: 28.9799  decode.loss_cls: 0.0249  decode.loss_mask: 0.8061  decode.loss_dice: 0.8721  decode.d0.loss_cls: 0.1099  decode.d0.loss_mask: 0.8189  decode.d0.loss_dice: 0.8800  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.8104  decode.d1.loss_dice: 0.8785  decode.d2.loss_cls: 0.0300  decode.d2.loss_mask: 0.8084  decode.d2.loss_dice: 0.8727  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.8090  decode.d3.loss_dice: 0.8709  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.8043  decode.d4.loss_dice: 0.8661  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.8031  decode.d5.loss_dice: 0.8689  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.8103  decode.d6.loss_dice: 0.8673  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.8109  decode.d7.loss_dice: 0.8839  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.8055  decode.d8.loss_dice: 0.8769  mix_decode.loss_cls: 0.0643  mix_decode.loss_mask: 0.4883  mix_decode.loss_dice: 0.6270  mix_decode.d0.loss_cls: 0.0636  mix_decode.d0.loss_mask: 0.5019  mix_decode.d0.loss_dice: 0.6555  mix_decode.d1.loss_cls: 0.0866  mix_decode.d1.loss_mask: 0.4812  mix_decode.d1.loss_dice: 0.6286  mix_decode.d2.loss_cls: 0.0572  mix_decode.d2.loss_mask: 0.4836  mix_decode.d2.loss_dice: 0.6125  mix_decode.d3.loss_cls: 0.0762  mix_decode.d3.loss_mask: 0.4821  mix_decode.d3.loss_dice: 0.6141  mix_decode.d4.loss_cls: 0.0457  mix_decode.d4.loss_mask: 0.4871  mix_decode.d4.loss_dice: 0.6271  mix_decode.d5.loss_cls: 0.0486  mix_decode.d5.loss_mask: 0.4849  mix_decode.d5.loss_dice: 0.6202  mix_decode.d6.loss_cls: 0.0576  mix_decode.d6.loss_mask: 0.4902  mix_decode.d6.loss_dice: 0.6047  mix_decode.d7.loss_cls: 0.0705  mix_decode.d7.loss_mask: 0.4859  mix_decode.d7.loss_dice: 0.6096  mix_decode.d8.loss_cls: 0.0689  mix_decode.d8.loss_mask: 0.4851  mix_decode.d8.loss_dice: 0.6308
2025/03/28 12:11:22 - mmengine - INFO - Iter(train) [ 9400/20000]  base_lr: 5.6477e-05 lr: 5.6477e-05  eta: 2:27:33  time: 1.0880  data_time: 0.0241  memory: 10773  loss: 31.5292  decode.loss_cls: 0.0144  decode.loss_mask: 0.9938  decode.loss_dice: 0.9679  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.9813  decode.d0.loss_dice: 0.9651  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.9799  decode.d1.loss_dice: 0.9643  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.9910  decode.d2.loss_dice: 0.9550  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.9987  decode.d3.loss_dice: 0.9544  decode.d4.loss_cls: 0.0177  decode.d4.loss_mask: 0.9969  decode.d4.loss_dice: 0.9712  decode.d5.loss_cls: 0.0178  decode.d5.loss_mask: 0.9924  decode.d5.loss_dice: 0.9674  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.9899  decode.d6.loss_dice: 0.9555  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.9978  decode.d7.loss_dice: 0.9583  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.9977  decode.d8.loss_dice: 0.9648  mix_decode.loss_cls: 0.0796  mix_decode.loss_mask: 0.5037  mix_decode.loss_dice: 0.5926  mix_decode.d0.loss_cls: 0.1453  mix_decode.d0.loss_mask: 0.4793  mix_decode.d0.loss_dice: 0.5981  mix_decode.d1.loss_cls: 0.1095  mix_decode.d1.loss_mask: 0.4827  mix_decode.d1.loss_dice: 0.5724  mix_decode.d2.loss_cls: 0.0695  mix_decode.d2.loss_mask: 0.5094  mix_decode.d2.loss_dice: 0.5830  mix_decode.d3.loss_cls: 0.0711  mix_decode.d3.loss_mask: 0.5098  mix_decode.d3.loss_dice: 0.5755  mix_decode.d4.loss_cls: 0.0652  mix_decode.d4.loss_mask: 0.5055  mix_decode.d4.loss_dice: 0.5939  mix_decode.d5.loss_cls: 0.0911  mix_decode.d5.loss_mask: 0.4910  mix_decode.d5.loss_dice: 0.5935  mix_decode.d6.loss_cls: 0.0598  mix_decode.d6.loss_mask: 0.5068  mix_decode.d6.loss_dice: 0.6015  mix_decode.d7.loss_cls: 0.0827  mix_decode.d7.loss_mask: 0.4838  mix_decode.d7.loss_dice: 0.5998  mix_decode.d8.loss_cls: 0.0867  mix_decode.d8.loss_mask: 0.4888  mix_decode.d8.loss_dice: 0.6045
2025/03/28 12:12:16 - mmengine - INFO - Iter(train) [ 9450/20000]  base_lr: 5.6237e-05 lr: 5.6237e-05  eta: 2:27:05  time: 1.0831  data_time: 0.0235  memory: 10773  loss: 30.3692  decode.loss_cls: 0.0741  decode.loss_mask: 0.8475  decode.loss_dice: 0.9067  decode.d0.loss_cls: 0.1249  decode.d0.loss_mask: 0.8575  decode.d0.loss_dice: 0.9410  decode.d1.loss_cls: 0.0983  decode.d1.loss_mask: 0.8462  decode.d1.loss_dice: 0.8815  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.8503  decode.d2.loss_dice: 0.8909  decode.d3.loss_cls: 0.0722  decode.d3.loss_mask: 0.8517  decode.d3.loss_dice: 0.9183  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.8544  decode.d4.loss_dice: 0.8932  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.8459  decode.d5.loss_dice: 0.8732  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.8581  decode.d6.loss_dice: 0.9072  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.8566  decode.d7.loss_dice: 0.8681  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.8606  decode.d8.loss_dice: 0.9087  mix_decode.loss_cls: 0.0609  mix_decode.loss_mask: 0.4570  mix_decode.loss_dice: 0.6749  mix_decode.d0.loss_cls: 0.0847  mix_decode.d0.loss_mask: 0.4569  mix_decode.d0.loss_dice: 0.6967  mix_decode.d1.loss_cls: 0.0765  mix_decode.d1.loss_mask: 0.4587  mix_decode.d1.loss_dice: 0.6581  mix_decode.d2.loss_cls: 0.0788  mix_decode.d2.loss_mask: 0.4582  mix_decode.d2.loss_dice: 0.6499  mix_decode.d3.loss_cls: 0.0622  mix_decode.d3.loss_mask: 0.4639  mix_decode.d3.loss_dice: 0.6733  mix_decode.d4.loss_cls: 0.0652  mix_decode.d4.loss_mask: 0.4620  mix_decode.d4.loss_dice: 0.6646  mix_decode.d5.loss_cls: 0.0868  mix_decode.d5.loss_mask: 0.4638  mix_decode.d5.loss_dice: 0.6587  mix_decode.d6.loss_cls: 0.0925  mix_decode.d6.loss_mask: 0.4582  mix_decode.d6.loss_dice: 0.6721  mix_decode.d7.loss_cls: 0.0694  mix_decode.d7.loss_mask: 0.4574  mix_decode.d7.loss_dice: 0.6731  mix_decode.d8.loss_cls: 0.0778  mix_decode.d8.loss_mask: 0.4560  mix_decode.d8.loss_dice: 0.6705
2025/03/28 12:13:10 - mmengine - INFO - Iter(train) [ 9500/20000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 2:26:37  time: 1.0963  data_time: 0.0245  memory: 10781  loss: 33.7783  decode.loss_cls: 0.0153  decode.loss_mask: 0.9743  decode.loss_dice: 0.8781  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.9915  decode.d0.loss_dice: 0.9068  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.9735  decode.d1.loss_dice: 0.8978  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.9709  decode.d2.loss_dice: 0.8893  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.9717  decode.d3.loss_dice: 0.8894  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.9773  decode.d4.loss_dice: 0.8803  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.9733  decode.d5.loss_dice: 0.8800  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.9734  decode.d6.loss_dice: 0.8823  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.9760  decode.d7.loss_dice: 0.8769  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.9757  decode.d8.loss_dice: 0.8754  mix_decode.loss_cls: 0.1191  mix_decode.loss_mask: 0.6577  mix_decode.loss_dice: 0.7272  mix_decode.d0.loss_cls: 0.1443  mix_decode.d0.loss_mask: 0.6321  mix_decode.d0.loss_dice: 0.7354  mix_decode.d1.loss_cls: 0.1131  mix_decode.d1.loss_mask: 0.6499  mix_decode.d1.loss_dice: 0.7401  mix_decode.d2.loss_cls: 0.1566  mix_decode.d2.loss_mask: 0.6464  mix_decode.d2.loss_dice: 0.7133  mix_decode.d3.loss_cls: 0.1090  mix_decode.d3.loss_mask: 0.6446  mix_decode.d3.loss_dice: 0.7330  mix_decode.d4.loss_cls: 0.1170  mix_decode.d4.loss_mask: 0.6510  mix_decode.d4.loss_dice: 0.7185  mix_decode.d5.loss_cls: 0.1312  mix_decode.d5.loss_mask: 0.6484  mix_decode.d5.loss_dice: 0.7166  mix_decode.d6.loss_cls: 0.1079  mix_decode.d6.loss_mask: 0.6520  mix_decode.d6.loss_dice: 0.7352  mix_decode.d7.loss_cls: 0.0991  mix_decode.d7.loss_mask: 0.6461  mix_decode.d7.loss_dice: 0.7453  mix_decode.d8.loss_cls: 0.0927  mix_decode.d8.loss_mask: 0.6579  mix_decode.d8.loss_dice: 0.7394
2025/03/28 12:14:04 - mmengine - INFO - Iter(train) [ 9550/20000]  base_lr: 5.5757e-05 lr: 5.5757e-05  eta: 2:26:09  time: 1.0737  data_time: 0.0224  memory: 10769  loss: 32.5439  decode.loss_cls: 0.0055  decode.loss_mask: 1.0500  decode.loss_dice: 0.9845  decode.d0.loss_cls: 0.0592  decode.d0.loss_mask: 1.0579  decode.d0.loss_dice: 0.9544  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 1.0529  decode.d1.loss_dice: 0.9965  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 1.0489  decode.d2.loss_dice: 0.9803  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 1.0535  decode.d3.loss_dice: 0.9899  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 1.0509  decode.d4.loss_dice: 0.9841  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 1.0554  decode.d5.loss_dice: 0.9789  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 1.0509  decode.d6.loss_dice: 0.9736  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 1.0496  decode.d7.loss_dice: 0.9779  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 1.0525  decode.d8.loss_dice: 0.9849  mix_decode.loss_cls: 0.0367  mix_decode.loss_mask: 0.5193  mix_decode.loss_dice: 0.6305  mix_decode.d0.loss_cls: 0.1007  mix_decode.d0.loss_mask: 0.5021  mix_decode.d0.loss_dice: 0.6403  mix_decode.d1.loss_cls: 0.0744  mix_decode.d1.loss_mask: 0.5183  mix_decode.d1.loss_dice: 0.6322  mix_decode.d2.loss_cls: 0.0636  mix_decode.d2.loss_mask: 0.5073  mix_decode.d2.loss_dice: 0.6299  mix_decode.d3.loss_cls: 0.0760  mix_decode.d3.loss_mask: 0.5073  mix_decode.d3.loss_dice: 0.6203  mix_decode.d4.loss_cls: 0.0780  mix_decode.d4.loss_mask: 0.5133  mix_decode.d4.loss_dice: 0.6227  mix_decode.d5.loss_cls: 0.0736  mix_decode.d5.loss_mask: 0.5127  mix_decode.d5.loss_dice: 0.6236  mix_decode.d6.loss_cls: 0.0773  mix_decode.d6.loss_mask: 0.5137  mix_decode.d6.loss_dice: 0.6292  mix_decode.d7.loss_cls: 0.0594  mix_decode.d7.loss_mask: 0.5190  mix_decode.d7.loss_dice: 0.6283  mix_decode.d8.loss_cls: 0.0365  mix_decode.d8.loss_mask: 0.5202  mix_decode.d8.loss_dice: 0.6347
2025/03/28 12:14:58 - mmengine - INFO - Iter(train) [ 9600/20000]  base_lr: 5.5517e-05 lr: 5.5517e-05  eta: 2:25:40  time: 1.1002  data_time: 0.0245  memory: 10769  loss: 34.7619  decode.loss_cls: 0.0714  decode.loss_mask: 1.0756  decode.loss_dice: 1.0816  decode.d0.loss_cls: 0.1041  decode.d0.loss_mask: 1.0858  decode.d0.loss_dice: 1.0969  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 1.0870  decode.d1.loss_dice: 1.1088  decode.d2.loss_cls: 0.1124  decode.d2.loss_mask: 1.0839  decode.d2.loss_dice: 1.0903  decode.d3.loss_cls: 0.0973  decode.d3.loss_mask: 1.0758  decode.d3.loss_dice: 1.0814  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 1.0850  decode.d4.loss_dice: 1.0976  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 1.0736  decode.d5.loss_dice: 1.0765  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 1.0747  decode.d6.loss_dice: 1.0706  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 1.0739  decode.d7.loss_dice: 1.0837  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 1.0775  decode.d8.loss_dice: 1.0820  mix_decode.loss_cls: 0.0759  mix_decode.loss_mask: 0.5094  mix_decode.loss_dice: 0.6171  mix_decode.d0.loss_cls: 0.1095  mix_decode.d0.loss_mask: 0.5076  mix_decode.d0.loss_dice: 0.6352  mix_decode.d1.loss_cls: 0.1048  mix_decode.d1.loss_mask: 0.5136  mix_decode.d1.loss_dice: 0.6294  mix_decode.d2.loss_cls: 0.1067  mix_decode.d2.loss_mask: 0.5164  mix_decode.d2.loss_dice: 0.6182  mix_decode.d3.loss_cls: 0.1104  mix_decode.d3.loss_mask: 0.5121  mix_decode.d3.loss_dice: 0.6097  mix_decode.d4.loss_cls: 0.1043  mix_decode.d4.loss_mask: 0.5052  mix_decode.d4.loss_dice: 0.6274  mix_decode.d5.loss_cls: 0.0951  mix_decode.d5.loss_mask: 0.5099  mix_decode.d5.loss_dice: 0.6213  mix_decode.d6.loss_cls: 0.1075  mix_decode.d6.loss_mask: 0.5049  mix_decode.d6.loss_dice: 0.6113  mix_decode.d7.loss_cls: 0.0777  mix_decode.d7.loss_mask: 0.5128  mix_decode.d7.loss_dice: 0.6370  mix_decode.d8.loss_cls: 0.0891  mix_decode.d8.loss_mask: 0.5153  mix_decode.d8.loss_dice: 0.6210
2025/03/28 12:15:53 - mmengine - INFO - Iter(train) [ 9650/20000]  base_lr: 5.5276e-05 lr: 5.5276e-05  eta: 2:25:11  time: 1.0968  data_time: 0.0242  memory: 10770  loss: 28.6006  decode.loss_cls: 0.0902  decode.loss_mask: 0.8331  decode.loss_dice: 0.8093  decode.d0.loss_cls: 0.1122  decode.d0.loss_mask: 0.8323  decode.d0.loss_dice: 0.7980  decode.d1.loss_cls: 0.1077  decode.d1.loss_mask: 0.8315  decode.d1.loss_dice: 0.7799  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.8375  decode.d2.loss_dice: 0.8143  decode.d3.loss_cls: 0.0591  decode.d3.loss_mask: 0.8322  decode.d3.loss_dice: 0.7939  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.8328  decode.d4.loss_dice: 0.7870  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.8340  decode.d5.loss_dice: 0.8047  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.8314  decode.d6.loss_dice: 0.8067  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.8350  decode.d7.loss_dice: 0.7934  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.8320  decode.d8.loss_dice: 0.7956  mix_decode.loss_cls: 0.0614  mix_decode.loss_mask: 0.4828  mix_decode.loss_dice: 0.6205  mix_decode.d0.loss_cls: 0.0854  mix_decode.d0.loss_mask: 0.4632  mix_decode.d0.loss_dice: 0.6254  mix_decode.d1.loss_cls: 0.0807  mix_decode.d1.loss_mask: 0.4613  mix_decode.d1.loss_dice: 0.6202  mix_decode.d2.loss_cls: 0.0732  mix_decode.d2.loss_mask: 0.4584  mix_decode.d2.loss_dice: 0.6170  mix_decode.d3.loss_cls: 0.1047  mix_decode.d3.loss_mask: 0.4532  mix_decode.d3.loss_dice: 0.5908  mix_decode.d4.loss_cls: 0.0913  mix_decode.d4.loss_mask: 0.4561  mix_decode.d4.loss_dice: 0.6074  mix_decode.d5.loss_cls: 0.0710  mix_decode.d5.loss_mask: 0.4619  mix_decode.d5.loss_dice: 0.6266  mix_decode.d6.loss_cls: 0.0771  mix_decode.d6.loss_mask: 0.4596  mix_decode.d6.loss_dice: 0.6164  mix_decode.d7.loss_cls: 0.0596  mix_decode.d7.loss_mask: 0.4601  mix_decode.d7.loss_dice: 0.6073  mix_decode.d8.loss_cls: 0.0945  mix_decode.d8.loss_mask: 0.4623  mix_decode.d8.loss_dice: 0.6026
2025/03/28 12:16:47 - mmengine - INFO - Iter(train) [ 9700/20000]  base_lr: 5.5036e-05 lr: 5.5036e-05  eta: 2:24:42  time: 1.0797  data_time: 0.0228  memory: 10770  loss: 33.3248  decode.loss_cls: 0.0438  decode.loss_mask: 0.9604  decode.loss_dice: 1.0352  decode.d0.loss_cls: 0.1064  decode.d0.loss_mask: 0.9548  decode.d0.loss_dice: 1.0566  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.9545  decode.d1.loss_dice: 1.0375  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.9575  decode.d2.loss_dice: 1.0278  decode.d3.loss_cls: 0.0946  decode.d3.loss_mask: 0.9553  decode.d3.loss_dice: 1.0269  decode.d4.loss_cls: 0.0825  decode.d4.loss_mask: 0.9549  decode.d4.loss_dice: 1.0196  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.9570  decode.d5.loss_dice: 1.0267  decode.d6.loss_cls: 0.0461  decode.d6.loss_mask: 0.9580  decode.d6.loss_dice: 1.0237  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.9553  decode.d7.loss_dice: 1.0462  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.9547  decode.d8.loss_dice: 1.0301  mix_decode.loss_cls: 0.1534  mix_decode.loss_mask: 0.4304  mix_decode.loss_dice: 0.6900  mix_decode.d0.loss_cls: 0.1859  mix_decode.d0.loss_mask: 0.4110  mix_decode.d0.loss_dice: 0.7280  mix_decode.d1.loss_cls: 0.1712  mix_decode.d1.loss_mask: 0.4227  mix_decode.d1.loss_dice: 0.6780  mix_decode.d2.loss_cls: 0.1623  mix_decode.d2.loss_mask: 0.4275  mix_decode.d2.loss_dice: 0.6813  mix_decode.d3.loss_cls: 0.1565  mix_decode.d3.loss_mask: 0.4255  mix_decode.d3.loss_dice: 0.6732  mix_decode.d4.loss_cls: 0.1542  mix_decode.d4.loss_mask: 0.4262  mix_decode.d4.loss_dice: 0.6748  mix_decode.d5.loss_cls: 0.1433  mix_decode.d5.loss_mask: 0.4382  mix_decode.d5.loss_dice: 0.6854  mix_decode.d6.loss_cls: 0.1563  mix_decode.d6.loss_mask: 0.4135  mix_decode.d6.loss_dice: 0.6668  mix_decode.d7.loss_cls: 0.1598  mix_decode.d7.loss_mask: 0.4250  mix_decode.d7.loss_dice: 0.7009  mix_decode.d8.loss_cls: 0.1648  mix_decode.d8.loss_mask: 0.4241  mix_decode.d8.loss_dice: 0.6917
2025/03/28 12:17:41 - mmengine - INFO - Iter(train) [ 9750/20000]  base_lr: 5.4795e-05 lr: 5.4795e-05  eta: 2:24:12  time: 1.0792  data_time: 0.0235  memory: 10766  loss: 32.8591  decode.loss_cls: 0.0107  decode.loss_mask: 1.0906  decode.loss_dice: 0.9629  decode.d0.loss_cls: 0.0749  decode.d0.loss_mask: 1.1001  decode.d0.loss_dice: 0.9638  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 1.0952  decode.d1.loss_dice: 0.9607  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 1.0918  decode.d2.loss_dice: 0.9590  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 1.0916  decode.d3.loss_dice: 0.9682  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 1.0929  decode.d4.loss_dice: 0.9535  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 1.0857  decode.d5.loss_dice: 0.9631  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 1.0879  decode.d6.loss_dice: 0.9545  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 1.0936  decode.d7.loss_dice: 0.9454  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 1.0916  decode.d8.loss_dice: 0.9595  mix_decode.loss_cls: 0.1172  mix_decode.loss_mask: 0.4751  mix_decode.loss_dice: 0.6305  mix_decode.d0.loss_cls: 0.1267  mix_decode.d0.loss_mask: 0.4567  mix_decode.d0.loss_dice: 0.6670  mix_decode.d1.loss_cls: 0.1367  mix_decode.d1.loss_mask: 0.4668  mix_decode.d1.loss_dice: 0.6148  mix_decode.d2.loss_cls: 0.1070  mix_decode.d2.loss_mask: 0.4650  mix_decode.d2.loss_dice: 0.6432  mix_decode.d3.loss_cls: 0.1085  mix_decode.d3.loss_mask: 0.4641  mix_decode.d3.loss_dice: 0.6338  mix_decode.d4.loss_cls: 0.1017  mix_decode.d4.loss_mask: 0.4674  mix_decode.d4.loss_dice: 0.6159  mix_decode.d5.loss_cls: 0.1339  mix_decode.d5.loss_mask: 0.4586  mix_decode.d5.loss_dice: 0.6343  mix_decode.d6.loss_cls: 0.1240  mix_decode.d6.loss_mask: 0.4624  mix_decode.d6.loss_dice: 0.6379  mix_decode.d7.loss_cls: 0.0809  mix_decode.d7.loss_mask: 0.4732  mix_decode.d7.loss_dice: 0.6426  mix_decode.d8.loss_cls: 0.1034  mix_decode.d8.loss_mask: 0.4753  mix_decode.d8.loss_dice: 0.6355
2025/03/28 12:18:35 - mmengine - INFO - Iter(train) [ 9800/20000]  base_lr: 5.4555e-05 lr: 5.4555e-05  eta: 2:23:42  time: 1.0889  data_time: 0.0239  memory: 10779  loss: 32.5921  decode.loss_cls: 0.0394  decode.loss_mask: 0.9748  decode.loss_dice: 1.0391  decode.d0.loss_cls: 0.0980  decode.d0.loss_mask: 1.0236  decode.d0.loss_dice: 0.9942  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.9916  decode.d1.loss_dice: 1.0131  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.9891  decode.d2.loss_dice: 1.0103  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.9886  decode.d3.loss_dice: 1.0192  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.9877  decode.d4.loss_dice: 1.0087  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.9886  decode.d5.loss_dice: 1.0372  decode.d6.loss_cls: 0.0480  decode.d6.loss_mask: 0.9827  decode.d6.loss_dice: 1.0401  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.9844  decode.d7.loss_dice: 1.0313  decode.d8.loss_cls: 0.0483  decode.d8.loss_mask: 0.9778  decode.d8.loss_dice: 1.0199  mix_decode.loss_cls: 0.0494  mix_decode.loss_mask: 0.4812  mix_decode.loss_dice: 0.6306  mix_decode.d0.loss_cls: 0.0877  mix_decode.d0.loss_mask: 0.4991  mix_decode.d0.loss_dice: 0.6494  mix_decode.d1.loss_cls: 0.1013  mix_decode.d1.loss_mask: 0.4867  mix_decode.d1.loss_dice: 0.6277  mix_decode.d2.loss_cls: 0.0866  mix_decode.d2.loss_mask: 0.4896  mix_decode.d2.loss_dice: 0.6130  mix_decode.d3.loss_cls: 0.0830  mix_decode.d3.loss_mask: 0.4904  mix_decode.d3.loss_dice: 0.6233  mix_decode.d4.loss_cls: 0.0586  mix_decode.d4.loss_mask: 0.4865  mix_decode.d4.loss_dice: 0.6300  mix_decode.d5.loss_cls: 0.0731  mix_decode.d5.loss_mask: 0.4841  mix_decode.d5.loss_dice: 0.6263  mix_decode.d6.loss_cls: 0.0598  mix_decode.d6.loss_mask: 0.4863  mix_decode.d6.loss_dice: 0.6527  mix_decode.d7.loss_cls: 0.0546  mix_decode.d7.loss_mask: 0.4888  mix_decode.d7.loss_dice: 0.6356  mix_decode.d8.loss_cls: 0.0610  mix_decode.d8.loss_mask: 0.4828  mix_decode.d8.loss_dice: 0.6398
2025/03/28 12:19:29 - mmengine - INFO - Iter(train) [ 9850/20000]  base_lr: 5.4314e-05 lr: 5.4314e-05  eta: 2:23:12  time: 1.0799  data_time: 0.0229  memory: 10785  loss: 31.1415  decode.loss_cls: 0.0113  decode.loss_mask: 0.8997  decode.loss_dice: 1.0144  decode.d0.loss_cls: 0.0678  decode.d0.loss_mask: 0.8996  decode.d0.loss_dice: 0.9906  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.9035  decode.d1.loss_dice: 0.9703  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.9033  decode.d2.loss_dice: 0.9970  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.9072  decode.d3.loss_dice: 0.9948  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.9010  decode.d4.loss_dice: 0.9676  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 0.9019  decode.d5.loss_dice: 0.9897  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.8942  decode.d6.loss_dice: 0.9882  decode.d7.loss_cls: 0.0888  decode.d7.loss_mask: 0.8998  decode.d7.loss_dice: 0.9962  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.8976  decode.d8.loss_dice: 0.9784  mix_decode.loss_cls: 0.1043  mix_decode.loss_mask: 0.4015  mix_decode.loss_dice: 0.6671  mix_decode.d0.loss_cls: 0.1032  mix_decode.d0.loss_mask: 0.4139  mix_decode.d0.loss_dice: 0.6776  mix_decode.d1.loss_cls: 0.1220  mix_decode.d1.loss_mask: 0.4156  mix_decode.d1.loss_dice: 0.6390  mix_decode.d2.loss_cls: 0.0917  mix_decode.d2.loss_mask: 0.4081  mix_decode.d2.loss_dice: 0.6636  mix_decode.d3.loss_cls: 0.0819  mix_decode.d3.loss_mask: 0.4072  mix_decode.d3.loss_dice: 0.6495  mix_decode.d4.loss_cls: 0.1016  mix_decode.d4.loss_mask: 0.4063  mix_decode.d4.loss_dice: 0.6407  mix_decode.d5.loss_cls: 0.0764  mix_decode.d5.loss_mask: 0.4092  mix_decode.d5.loss_dice: 0.6695  mix_decode.d6.loss_cls: 0.1061  mix_decode.d6.loss_mask: 0.4075  mix_decode.d6.loss_dice: 0.6696  mix_decode.d7.loss_cls: 0.0963  mix_decode.d7.loss_mask: 0.4091  mix_decode.d7.loss_dice: 0.6541  mix_decode.d8.loss_cls: 0.1118  mix_decode.d8.loss_mask: 0.4056  mix_decode.d8.loss_dice: 0.6713
2025/03/28 12:20:23 - mmengine - INFO - Iter(train) [ 9900/20000]  base_lr: 5.4073e-05 lr: 5.4073e-05  eta: 2:22:42  time: 1.0777  data_time: 0.0224  memory: 10780  loss: 28.6218  decode.loss_cls: 0.0565  decode.loss_mask: 0.7775  decode.loss_dice: 0.7823  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.7829  decode.d0.loss_dice: 0.7952  decode.d1.loss_cls: 0.0478  decode.d1.loss_mask: 0.7746  decode.d1.loss_dice: 0.7819  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.7814  decode.d2.loss_dice: 0.7878  decode.d3.loss_cls: 0.0489  decode.d3.loss_mask: 0.7816  decode.d3.loss_dice: 0.7785  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.7813  decode.d4.loss_dice: 0.7816  decode.d5.loss_cls: 0.0618  decode.d5.loss_mask: 0.7827  decode.d5.loss_dice: 0.7874  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.7829  decode.d6.loss_dice: 0.7812  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.7765  decode.d7.loss_dice: 0.7858  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.7780  decode.d8.loss_dice: 0.7837  mix_decode.loss_cls: 0.1102  mix_decode.loss_mask: 0.4817  mix_decode.loss_dice: 0.6388  mix_decode.d0.loss_cls: 0.1338  mix_decode.d0.loss_mask: 0.4793  mix_decode.d0.loss_dice: 0.6675  mix_decode.d1.loss_cls: 0.1562  mix_decode.d1.loss_mask: 0.4868  mix_decode.d1.loss_dice: 0.6326  mix_decode.d2.loss_cls: 0.1239  mix_decode.d2.loss_mask: 0.4879  mix_decode.d2.loss_dice: 0.6145  mix_decode.d3.loss_cls: 0.1268  mix_decode.d3.loss_mask: 0.4760  mix_decode.d3.loss_dice: 0.6091  mix_decode.d4.loss_cls: 0.1017  mix_decode.d4.loss_mask: 0.4835  mix_decode.d4.loss_dice: 0.6299  mix_decode.d5.loss_cls: 0.1378  mix_decode.d5.loss_mask: 0.4759  mix_decode.d5.loss_dice: 0.6153  mix_decode.d6.loss_cls: 0.1292  mix_decode.d6.loss_mask: 0.4801  mix_decode.d6.loss_dice: 0.6231  mix_decode.d7.loss_cls: 0.0490  mix_decode.d7.loss_mask: 0.5349  mix_decode.d7.loss_dice: 0.6455  mix_decode.d8.loss_cls: 0.0700  mix_decode.d8.loss_mask: 0.5262  mix_decode.d8.loss_dice: 0.6427
2025/03/28 12:21:17 - mmengine - INFO - Iter(train) [ 9950/20000]  base_lr: 5.3832e-05 lr: 5.3832e-05  eta: 2:22:11  time: 1.0716  data_time: 0.0227  memory: 10766  loss: 28.8912  decode.loss_cls: 0.0119  decode.loss_mask: 0.9549  decode.loss_dice: 0.8213  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.9739  decode.d0.loss_dice: 0.8085  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.9633  decode.d1.loss_dice: 0.8308  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.9612  decode.d2.loss_dice: 0.8288  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.9581  decode.d3.loss_dice: 0.8282  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.9611  decode.d4.loss_dice: 0.8325  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.9541  decode.d5.loss_dice: 0.8278  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.9530  decode.d6.loss_dice: 0.8222  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.9556  decode.d7.loss_dice: 0.8287  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.9600  decode.d8.loss_dice: 0.8264  mix_decode.loss_cls: 0.0512  mix_decode.loss_mask: 0.4730  mix_decode.loss_dice: 0.5488  mix_decode.d0.loss_cls: 0.0566  mix_decode.d0.loss_mask: 0.4823  mix_decode.d0.loss_dice: 0.5580  mix_decode.d1.loss_cls: 0.0676  mix_decode.d1.loss_mask: 0.4756  mix_decode.d1.loss_dice: 0.5424  mix_decode.d2.loss_cls: 0.0682  mix_decode.d2.loss_mask: 0.4769  mix_decode.d2.loss_dice: 0.5463  mix_decode.d3.loss_cls: 0.0656  mix_decode.d3.loss_mask: 0.4731  mix_decode.d3.loss_dice: 0.5400  mix_decode.d4.loss_cls: 0.0666  mix_decode.d4.loss_mask: 0.4736  mix_decode.d4.loss_dice: 0.5427  mix_decode.d5.loss_cls: 0.0652  mix_decode.d5.loss_mask: 0.4759  mix_decode.d5.loss_dice: 0.5472  mix_decode.d6.loss_cls: 0.0761  mix_decode.d6.loss_mask: 0.4711  mix_decode.d6.loss_dice: 0.5412  mix_decode.d7.loss_cls: 0.0529  mix_decode.d7.loss_mask: 0.4774  mix_decode.d7.loss_dice: 0.5472  mix_decode.d8.loss_cls: 0.0491  mix_decode.d8.loss_mask: 0.4733  mix_decode.d8.loss_dice: 0.5500
2025/03/28 12:22:11 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 12:22:11 - mmengine - INFO - Iter(train) [10000/20000]  base_lr: 5.3591e-05 lr: 5.3591e-05  eta: 2:21:40  time: 1.0727  data_time: 0.0223  memory: 10782  loss: 32.2260  decode.loss_cls: 0.0241  decode.loss_mask: 1.1445  decode.loss_dice: 0.9462  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 1.1628  decode.d0.loss_dice: 0.9477  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 1.1580  decode.d1.loss_dice: 0.9624  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 1.1464  decode.d2.loss_dice: 0.9650  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 1.1446  decode.d3.loss_dice: 0.9620  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 1.1557  decode.d4.loss_dice: 0.9526  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 1.1494  decode.d5.loss_dice: 0.9702  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 1.1525  decode.d6.loss_dice: 0.9572  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 1.1546  decode.d7.loss_dice: 0.9463  decode.d8.loss_cls: 0.0218  decode.d8.loss_mask: 1.1469  decode.d8.loss_dice: 0.9510  mix_decode.loss_cls: 0.0596  mix_decode.loss_mask: 0.4741  mix_decode.loss_dice: 0.5540  mix_decode.d0.loss_cls: 0.0765  mix_decode.d0.loss_mask: 0.4737  mix_decode.d0.loss_dice: 0.5688  mix_decode.d1.loss_cls: 0.0601  mix_decode.d1.loss_mask: 0.4731  mix_decode.d1.loss_dice: 0.5410  mix_decode.d2.loss_cls: 0.0722  mix_decode.d2.loss_mask: 0.4709  mix_decode.d2.loss_dice: 0.5271  mix_decode.d3.loss_cls: 0.0599  mix_decode.d3.loss_mask: 0.4752  mix_decode.d3.loss_dice: 0.5424  mix_decode.d4.loss_cls: 0.0547  mix_decode.d4.loss_mask: 0.4756  mix_decode.d4.loss_dice: 0.5352  mix_decode.d5.loss_cls: 0.0449  mix_decode.d5.loss_mask: 0.4788  mix_decode.d5.loss_dice: 0.5451  mix_decode.d6.loss_cls: 0.0773  mix_decode.d6.loss_mask: 0.4772  mix_decode.d6.loss_dice: 0.5373  mix_decode.d7.loss_cls: 0.0535  mix_decode.d7.loss_mask: 0.4785  mix_decode.d7.loss_dice: 0.5265  mix_decode.d8.loss_cls: 0.0548  mix_decode.d8.loss_mask: 0.4739  mix_decode.d8.loss_dice: 0.5396
2025/03/28 12:22:11 - mmengine - INFO - Saving checkpoint at 10000 iterations
2025/03/28 12:22:16 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0850  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:21 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:43  time: 0.0851  data_time: 0.0020  memory: 3067  
2025/03/28 12:22:25 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:39  time: 0.0850  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:29 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:34  time: 0.0850  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:33 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0852  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:38 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:26  time: 0.0851  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:42 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:22  time: 0.0873  data_time: 0.0020  memory: 3067  
2025/03/28 12:22:46 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:18  time: 0.0854  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:51 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0852  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:55 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:09  time: 0.0852  data_time: 0.0019  memory: 3067  
2025/03/28 12:22:59 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:05  time: 0.0875  data_time: 0.0019  memory: 3067  
2025/03/28 12:23:03 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:01  time: 0.0853  data_time: 0.0017  memory: 3067  
2025/03/28 12:23:08 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0853  data_time: 0.0019  memory: 3067  
2025/03/28 12:23:12 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:52  time: 0.0854  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:16 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:48  time: 0.0854  data_time: 0.0019  memory: 3067  
2025/03/28 12:23:21 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:44  time: 0.0852  data_time: 0.0017  memory: 3067  
2025/03/28 12:23:25 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0854  data_time: 0.0019  memory: 3067  
2025/03/28 12:23:29 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0853  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:33 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:31  time: 0.0854  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:38 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0871  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:42 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0854  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:46 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0855  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:51 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:14  time: 0.0855  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:55 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0853  data_time: 0.0018  memory: 3067  
2025/03/28 12:23:59 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0854  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:03 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0854  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:08 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0853  data_time: 0.0018  memory: 3067  
2025/03/28 12:24:12 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0853  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:16 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0881  data_time: 0.0021  memory: 3067  
2025/03/28 12:24:21 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0855  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:25 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0855  data_time: 0.0018  memory: 3067  
2025/03/28 12:24:29 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0855  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:33 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0889  data_time: 0.0020  memory: 3067  
2025/03/28 12:24:38 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:27  time: 0.0851  data_time: 0.0018  memory: 3067  
2025/03/28 12:24:42 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0853  data_time: 0.0018  memory: 3067  
2025/03/28 12:24:46 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0852  data_time: 0.0018  memory: 3067  
2025/03/28 12:24:51 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0855  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:55 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0854  data_time: 0.0019  memory: 3067  
2025/03/28 12:24:59 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0852  data_time: 0.0019  memory: 3067  
2025/03/28 12:25:03 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0852  data_time: 0.0018  memory: 3067  
2025/03/28 12:25:05 - mmengine - INFO - per class results:
2025/03/28 12:25:05 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 75.31 | 91.18 |
|      building      | 87.53 | 96.12 |
|   low_vegetation   |  64.1 | 90.11 |
|        tree        | 46.45 | 49.41 |
|        car         | 76.05 | 86.71 |
|      clutter       |  7.49 |  7.7  |
+--------------------+-------+-------+
2025/03/28 12:25:05 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 81.0200  mIoU: 59.4900  mAcc: 70.2000  data_time: 0.0019  time: 0.0855
2025/03/28 12:25:59 - mmengine - INFO - Iter(train) [10050/20000]  base_lr: 5.3350e-05 lr: 5.3350e-05  eta: 2:21:09  time: 1.0777  data_time: 0.0226  memory: 10774  loss: 34.1739  decode.loss_cls: 0.1322  decode.loss_mask: 1.0482  decode.loss_dice: 0.9701  decode.d0.loss_cls: 0.1119  decode.d0.loss_mask: 1.0577  decode.d0.loss_dice: 0.9775  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 1.0528  decode.d1.loss_dice: 1.0103  decode.d2.loss_cls: 0.1117  decode.d2.loss_mask: 1.0416  decode.d2.loss_dice: 0.9659  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 1.0447  decode.d3.loss_dice: 0.9460  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 1.0519  decode.d4.loss_dice: 0.9782  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 1.0552  decode.d5.loss_dice: 0.9772  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 1.0503  decode.d6.loss_dice: 0.9530  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 1.0524  decode.d7.loss_dice: 0.9568  decode.d8.loss_cls: 0.0925  decode.d8.loss_mask: 1.0518  decode.d8.loss_dice: 0.9666  mix_decode.loss_cls: 0.1182  mix_decode.loss_mask: 0.5828  mix_decode.loss_dice: 0.6248  mix_decode.d0.loss_cls: 0.1309  mix_decode.d0.loss_mask: 0.5646  mix_decode.d0.loss_dice: 0.6321  mix_decode.d1.loss_cls: 0.1129  mix_decode.d1.loss_mask: 0.5749  mix_decode.d1.loss_dice: 0.6390  mix_decode.d2.loss_cls: 0.1118  mix_decode.d2.loss_mask: 0.5646  mix_decode.d2.loss_dice: 0.6060  mix_decode.d3.loss_cls: 0.1149  mix_decode.d3.loss_mask: 0.5755  mix_decode.d3.loss_dice: 0.6109  mix_decode.d4.loss_cls: 0.0874  mix_decode.d4.loss_mask: 0.5752  mix_decode.d4.loss_dice: 0.6263  mix_decode.d5.loss_cls: 0.0870  mix_decode.d5.loss_mask: 0.5851  mix_decode.d5.loss_dice: 0.6233  mix_decode.d6.loss_cls: 0.0887  mix_decode.d6.loss_mask: 0.5787  mix_decode.d6.loss_dice: 0.6134  mix_decode.d7.loss_cls: 0.1013  mix_decode.d7.loss_mask: 0.5840  mix_decode.d7.loss_dice: 0.6219  mix_decode.d8.loss_cls: 0.1001  mix_decode.d8.loss_mask: 0.5733  mix_decode.d8.loss_dice: 0.6105
2025/03/28 12:26:53 - mmengine - INFO - Iter(train) [10100/20000]  base_lr: 5.3109e-05 lr: 5.3109e-05  eta: 2:20:38  time: 1.0750  data_time: 0.0228  memory: 10765  loss: 31.8830  decode.loss_cls: 0.0143  decode.loss_mask: 0.9915  decode.loss_dice: 0.9440  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.9980  decode.d0.loss_dice: 0.9407  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.9939  decode.d1.loss_dice: 0.9509  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.9998  decode.d2.loss_dice: 0.9578  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.9911  decode.d3.loss_dice: 0.9514  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.9890  decode.d4.loss_dice: 0.9536  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.9915  decode.d5.loss_dice: 0.9508  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.9855  decode.d6.loss_dice: 0.9321  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.9908  decode.d7.loss_dice: 0.9430  decode.d8.loss_cls: 0.0129  decode.d8.loss_mask: 0.9979  decode.d8.loss_dice: 0.9437  mix_decode.loss_cls: 0.0578  mix_decode.loss_mask: 0.4945  mix_decode.loss_dice: 0.6714  mix_decode.d0.loss_cls: 0.1082  mix_decode.d0.loss_mask: 0.4993  mix_decode.d0.loss_dice: 0.6777  mix_decode.d1.loss_cls: 0.0608  mix_decode.d1.loss_mask: 0.4958  mix_decode.d1.loss_dice: 0.6709  mix_decode.d2.loss_cls: 0.0763  mix_decode.d2.loss_mask: 0.4967  mix_decode.d2.loss_dice: 0.6632  mix_decode.d3.loss_cls: 0.0542  mix_decode.d3.loss_mask: 0.4965  mix_decode.d3.loss_dice: 0.6713  mix_decode.d4.loss_cls: 0.0606  mix_decode.d4.loss_mask: 0.4936  mix_decode.d4.loss_dice: 0.6649  mix_decode.d5.loss_cls: 0.0651  mix_decode.d5.loss_mask: 0.4895  mix_decode.d5.loss_dice: 0.6567  mix_decode.d6.loss_cls: 0.0745  mix_decode.d6.loss_mask: 0.4938  mix_decode.d6.loss_dice: 0.6772  mix_decode.d7.loss_cls: 0.0495  mix_decode.d7.loss_mask: 0.4923  mix_decode.d7.loss_dice: 0.6693  mix_decode.d8.loss_cls: 0.0534  mix_decode.d8.loss_mask: 0.4891  mix_decode.d8.loss_dice: 0.6638
2025/03/28 12:27:47 - mmengine - INFO - Iter(train) [10150/20000]  base_lr: 5.2867e-05 lr: 5.2867e-05  eta: 2:20:06  time: 1.0837  data_time: 0.0241  memory: 10780  loss: 34.4489  decode.loss_cls: 0.0996  decode.loss_mask: 1.0457  decode.loss_dice: 1.0244  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 1.0774  decode.d0.loss_dice: 1.0569  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 1.0554  decode.d1.loss_dice: 1.0254  decode.d2.loss_cls: 0.0915  decode.d2.loss_mask: 1.0526  decode.d2.loss_dice: 1.0227  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 1.0480  decode.d3.loss_dice: 1.0288  decode.d4.loss_cls: 0.1036  decode.d4.loss_mask: 1.0518  decode.d4.loss_dice: 1.0216  decode.d5.loss_cls: 0.1109  decode.d5.loss_mask: 1.0520  decode.d5.loss_dice: 1.0222  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 1.0471  decode.d6.loss_dice: 1.0192  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 1.0488  decode.d7.loss_dice: 1.0267  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 1.0467  decode.d8.loss_dice: 1.0187  mix_decode.loss_cls: 0.1039  mix_decode.loss_mask: 0.5525  mix_decode.loss_dice: 0.6048  mix_decode.d0.loss_cls: 0.1496  mix_decode.d0.loss_mask: 0.5233  mix_decode.d0.loss_dice: 0.6298  mix_decode.d1.loss_cls: 0.0938  mix_decode.d1.loss_mask: 0.5460  mix_decode.d1.loss_dice: 0.6154  mix_decode.d2.loss_cls: 0.1226  mix_decode.d2.loss_mask: 0.5283  mix_decode.d2.loss_dice: 0.6067  mix_decode.d3.loss_cls: 0.0921  mix_decode.d3.loss_mask: 0.5396  mix_decode.d3.loss_dice: 0.6096  mix_decode.d4.loss_cls: 0.1068  mix_decode.d4.loss_mask: 0.5468  mix_decode.d4.loss_dice: 0.6142  mix_decode.d5.loss_cls: 0.0900  mix_decode.d5.loss_mask: 0.5447  mix_decode.d5.loss_dice: 0.6126  mix_decode.d6.loss_cls: 0.1000  mix_decode.d6.loss_mask: 0.5558  mix_decode.d6.loss_dice: 0.6235  mix_decode.d7.loss_cls: 0.1137  mix_decode.d7.loss_mask: 0.5574  mix_decode.d7.loss_dice: 0.6123  mix_decode.d8.loss_cls: 0.1199  mix_decode.d8.loss_mask: 0.5505  mix_decode.d8.loss_dice: 0.6105
2025/03/28 12:28:40 - mmengine - INFO - Iter(train) [10200/20000]  base_lr: 5.2625e-05 lr: 5.2625e-05  eta: 2:19:34  time: 1.0767  data_time: 0.0225  memory: 10770  loss: 29.2446  decode.loss_cls: 0.0154  decode.loss_mask: 0.9146  decode.loss_dice: 0.8928  decode.d0.loss_cls: 0.0809  decode.d0.loss_mask: 0.9176  decode.d0.loss_dice: 0.9059  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.9239  decode.d1.loss_dice: 0.9025  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.9175  decode.d2.loss_dice: 0.8914  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.9162  decode.d3.loss_dice: 0.9003  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.9115  decode.d4.loss_dice: 0.9003  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.9148  decode.d5.loss_dice: 0.9031  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.9148  decode.d6.loss_dice: 0.9032  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.9208  decode.d7.loss_dice: 0.8999  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.9134  decode.d8.loss_dice: 0.8916  mix_decode.loss_cls: 0.0910  mix_decode.loss_mask: 0.3845  mix_decode.loss_dice: 0.5677  mix_decode.d0.loss_cls: 0.1527  mix_decode.d0.loss_mask: 0.3880  mix_decode.d0.loss_dice: 0.6368  mix_decode.d1.loss_cls: 0.1222  mix_decode.d1.loss_mask: 0.3835  mix_decode.d1.loss_dice: 0.5789  mix_decode.d2.loss_cls: 0.1504  mix_decode.d2.loss_mask: 0.3833  mix_decode.d2.loss_dice: 0.5708  mix_decode.d3.loss_cls: 0.1551  mix_decode.d3.loss_mask: 0.3821  mix_decode.d3.loss_dice: 0.5591  mix_decode.d4.loss_cls: 0.1266  mix_decode.d4.loss_mask: 0.3831  mix_decode.d4.loss_dice: 0.5724  mix_decode.d5.loss_cls: 0.1041  mix_decode.d5.loss_mask: 0.3868  mix_decode.d5.loss_dice: 0.5961  mix_decode.d6.loss_cls: 0.1350  mix_decode.d6.loss_mask: 0.3816  mix_decode.d6.loss_dice: 0.5738  mix_decode.d7.loss_cls: 0.1174  mix_decode.d7.loss_mask: 0.3839  mix_decode.d7.loss_dice: 0.5718  mix_decode.d8.loss_cls: 0.0931  mix_decode.d8.loss_mask: 0.3835  mix_decode.d8.loss_dice: 0.5918
2025/03/28 12:29:34 - mmengine - INFO - Iter(train) [10250/20000]  base_lr: 5.2384e-05 lr: 5.2384e-05  eta: 2:19:02  time: 1.0672  data_time: 0.0222  memory: 10778  loss: 29.5682  decode.loss_cls: 0.0260  decode.loss_mask: 0.9494  decode.loss_dice: 0.9013  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.9594  decode.d0.loss_dice: 0.8760  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.9513  decode.d1.loss_dice: 0.8730  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.9505  decode.d2.loss_dice: 0.8622  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.9433  decode.d3.loss_dice: 0.8716  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.9465  decode.d4.loss_dice: 0.8709  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.9412  decode.d5.loss_dice: 0.8912  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.9438  decode.d6.loss_dice: 0.8614  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.9430  decode.d7.loss_dice: 0.8646  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.9439  decode.d8.loss_dice: 0.8668  mix_decode.loss_cls: 0.0862  mix_decode.loss_mask: 0.4524  mix_decode.loss_dice: 0.5411  mix_decode.d0.loss_cls: 0.1060  mix_decode.d0.loss_mask: 0.4590  mix_decode.d0.loss_dice: 0.5794  mix_decode.d1.loss_cls: 0.1005  mix_decode.d1.loss_mask: 0.4533  mix_decode.d1.loss_dice: 0.5625  mix_decode.d2.loss_cls: 0.0891  mix_decode.d2.loss_mask: 0.4486  mix_decode.d2.loss_dice: 0.5338  mix_decode.d3.loss_cls: 0.0535  mix_decode.d3.loss_mask: 0.4587  mix_decode.d3.loss_dice: 0.5465  mix_decode.d4.loss_cls: 0.0795  mix_decode.d4.loss_mask: 0.4470  mix_decode.d4.loss_dice: 0.5462  mix_decode.d5.loss_cls: 0.0416  mix_decode.d5.loss_mask: 0.4489  mix_decode.d5.loss_dice: 0.5605  mix_decode.d6.loss_cls: 0.0583  mix_decode.d6.loss_mask: 0.4521  mix_decode.d6.loss_dice: 0.5488  mix_decode.d7.loss_cls: 0.0696  mix_decode.d7.loss_mask: 0.4554  mix_decode.d7.loss_dice: 0.5463  mix_decode.d8.loss_cls: 0.0553  mix_decode.d8.loss_mask: 0.4579  mix_decode.d8.loss_dice: 0.5437
2025/03/28 12:30:28 - mmengine - INFO - Iter(train) [10300/20000]  base_lr: 5.2142e-05 lr: 5.2142e-05  eta: 2:18:29  time: 1.0802  data_time: 0.0231  memory: 10766  loss: 32.0885  decode.loss_cls: 0.0679  decode.loss_mask: 0.9558  decode.loss_dice: 0.9623  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.9685  decode.d0.loss_dice: 0.9629  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.9589  decode.d1.loss_dice: 0.9727  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.9577  decode.d2.loss_dice: 0.9574  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.9546  decode.d3.loss_dice: 0.9503  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.9497  decode.d4.loss_dice: 0.9498  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.9553  decode.d5.loss_dice: 0.9605  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.9508  decode.d6.loss_dice: 0.9609  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.9510  decode.d7.loss_dice: 0.9616  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.9512  decode.d8.loss_dice: 0.9659  mix_decode.loss_cls: 0.0923  mix_decode.loss_mask: 0.5435  mix_decode.loss_dice: 0.5905  mix_decode.d0.loss_cls: 0.1146  mix_decode.d0.loss_mask: 0.5461  mix_decode.d0.loss_dice: 0.6290  mix_decode.d1.loss_cls: 0.1285  mix_decode.d1.loss_mask: 0.5402  mix_decode.d1.loss_dice: 0.5887  mix_decode.d2.loss_cls: 0.1238  mix_decode.d2.loss_mask: 0.5353  mix_decode.d2.loss_dice: 0.5804  mix_decode.d3.loss_cls: 0.0807  mix_decode.d3.loss_mask: 0.5328  mix_decode.d3.loss_dice: 0.5834  mix_decode.d4.loss_cls: 0.0772  mix_decode.d4.loss_mask: 0.5366  mix_decode.d4.loss_dice: 0.5982  mix_decode.d5.loss_cls: 0.0810  mix_decode.d5.loss_mask: 0.5343  mix_decode.d5.loss_dice: 0.5950  mix_decode.d6.loss_cls: 0.0956  mix_decode.d6.loss_mask: 0.5349  mix_decode.d6.loss_dice: 0.6044  mix_decode.d7.loss_cls: 0.0941  mix_decode.d7.loss_mask: 0.5417  mix_decode.d7.loss_dice: 0.5981  mix_decode.d8.loss_cls: 0.0883  mix_decode.d8.loss_mask: 0.5385  mix_decode.d8.loss_dice: 0.5884
2025/03/28 12:31:22 - mmengine - INFO - Iter(train) [10350/20000]  base_lr: 5.1900e-05 lr: 5.1900e-05  eta: 2:17:57  time: 1.0853  data_time: 0.0239  memory: 10775  loss: 27.7538  decode.loss_cls: 0.0090  decode.loss_mask: 0.9243  decode.loss_dice: 0.8274  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.9435  decode.d0.loss_dice: 0.8485  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.9277  decode.d1.loss_dice: 0.8342  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.9334  decode.d2.loss_dice: 0.8379  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.9242  decode.d3.loss_dice: 0.8385  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.9234  decode.d4.loss_dice: 0.8258  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.9288  decode.d5.loss_dice: 0.8390  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.9283  decode.d6.loss_dice: 0.8272  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.9288  decode.d7.loss_dice: 0.8353  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.9289  decode.d8.loss_dice: 0.8367  mix_decode.loss_cls: 0.0647  mix_decode.loss_mask: 0.4339  mix_decode.loss_dice: 0.4981  mix_decode.d0.loss_cls: 0.0977  mix_decode.d0.loss_mask: 0.4332  mix_decode.d0.loss_dice: 0.5192  mix_decode.d1.loss_cls: 0.0619  mix_decode.d1.loss_mask: 0.4319  mix_decode.d1.loss_dice: 0.4929  mix_decode.d2.loss_cls: 0.0668  mix_decode.d2.loss_mask: 0.4333  mix_decode.d2.loss_dice: 0.5090  mix_decode.d3.loss_cls: 0.0661  mix_decode.d3.loss_mask: 0.4275  mix_decode.d3.loss_dice: 0.4878  mix_decode.d4.loss_cls: 0.0642  mix_decode.d4.loss_mask: 0.4271  mix_decode.d4.loss_dice: 0.4852  mix_decode.d5.loss_cls: 0.0735  mix_decode.d5.loss_mask: 0.4287  mix_decode.d5.loss_dice: 0.4934  mix_decode.d6.loss_cls: 0.0686  mix_decode.d6.loss_mask: 0.4288  mix_decode.d6.loss_dice: 0.4760  mix_decode.d7.loss_cls: 0.0739  mix_decode.d7.loss_mask: 0.4303  mix_decode.d7.loss_dice: 0.5027  mix_decode.d8.loss_cls: 0.0518  mix_decode.d8.loss_mask: 0.4337  mix_decode.d8.loss_dice: 0.4937
2025/03/28 12:32:16 - mmengine - INFO - Iter(train) [10400/20000]  base_lr: 5.1658e-05 lr: 5.1658e-05  eta: 2:17:24  time: 1.0710  data_time: 0.0222  memory: 10784  loss: 27.2592  decode.loss_cls: 0.0241  decode.loss_mask: 0.7753  decode.loss_dice: 0.8041  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.7811  decode.d0.loss_dice: 0.8090  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.7823  decode.d1.loss_dice: 0.8121  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.7823  decode.d2.loss_dice: 0.7998  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.7773  decode.d3.loss_dice: 0.7984  decode.d4.loss_cls: 0.0262  decode.d4.loss_mask: 0.7754  decode.d4.loss_dice: 0.8045  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.7785  decode.d5.loss_dice: 0.8018  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.7752  decode.d6.loss_dice: 0.7932  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.7819  decode.d7.loss_dice: 0.7996  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.7757  decode.d8.loss_dice: 0.7979  mix_decode.loss_cls: 0.0940  mix_decode.loss_mask: 0.4381  mix_decode.loss_dice: 0.5741  mix_decode.d0.loss_cls: 0.1243  mix_decode.d0.loss_mask: 0.4500  mix_decode.d0.loss_dice: 0.5962  mix_decode.d1.loss_cls: 0.1001  mix_decode.d1.loss_mask: 0.4415  mix_decode.d1.loss_dice: 0.5543  mix_decode.d2.loss_cls: 0.1146  mix_decode.d2.loss_mask: 0.4316  mix_decode.d2.loss_dice: 0.5586  mix_decode.d3.loss_cls: 0.0961  mix_decode.d3.loss_mask: 0.4327  mix_decode.d3.loss_dice: 0.5552  mix_decode.d4.loss_cls: 0.0845  mix_decode.d4.loss_mask: 0.4375  mix_decode.d4.loss_dice: 0.5864  mix_decode.d5.loss_cls: 0.0926  mix_decode.d5.loss_mask: 0.4377  mix_decode.d5.loss_dice: 0.5862  mix_decode.d6.loss_cls: 0.1059  mix_decode.d6.loss_mask: 0.4289  mix_decode.d6.loss_dice: 0.5777  mix_decode.d7.loss_cls: 0.1024  mix_decode.d7.loss_mask: 0.4174  mix_decode.d7.loss_dice: 0.5675  mix_decode.d8.loss_cls: 0.1166  mix_decode.d8.loss_mask: 0.4251  mix_decode.d8.loss_dice: 0.5637
2025/03/28 12:33:10 - mmengine - INFO - Iter(train) [10450/20000]  base_lr: 5.1416e-05 lr: 5.1416e-05  eta: 2:16:51  time: 1.0720  data_time: 0.0225  memory: 10771  loss: 29.1734  decode.loss_cls: 0.0291  decode.loss_mask: 0.9231  decode.loss_dice: 0.8730  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.9278  decode.d0.loss_dice: 0.8527  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.9192  decode.d1.loss_dice: 0.8915  decode.d2.loss_cls: 0.0247  decode.d2.loss_mask: 0.9225  decode.d2.loss_dice: 0.8720  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.9188  decode.d3.loss_dice: 0.8842  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.9178  decode.d4.loss_dice: 0.8707  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.9224  decode.d5.loss_dice: 0.8725  decode.d6.loss_cls: 0.0388  decode.d6.loss_mask: 0.9182  decode.d6.loss_dice: 0.8556  decode.d7.loss_cls: 0.0348  decode.d7.loss_mask: 0.9147  decode.d7.loss_dice: 0.8665  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.9199  decode.d8.loss_dice: 0.8616  mix_decode.loss_cls: 0.0598  mix_decode.loss_mask: 0.4498  mix_decode.loss_dice: 0.5569  mix_decode.d0.loss_cls: 0.0998  mix_decode.d0.loss_mask: 0.4509  mix_decode.d0.loss_dice: 0.5715  mix_decode.d1.loss_cls: 0.0639  mix_decode.d1.loss_mask: 0.4464  mix_decode.d1.loss_dice: 0.5846  mix_decode.d2.loss_cls: 0.0674  mix_decode.d2.loss_mask: 0.4517  mix_decode.d2.loss_dice: 0.5617  mix_decode.d3.loss_cls: 0.0965  mix_decode.d3.loss_mask: 0.4517  mix_decode.d3.loss_dice: 0.5547  mix_decode.d4.loss_cls: 0.1110  mix_decode.d4.loss_mask: 0.4441  mix_decode.d4.loss_dice: 0.5504  mix_decode.d5.loss_cls: 0.0804  mix_decode.d5.loss_mask: 0.4453  mix_decode.d5.loss_dice: 0.5558  mix_decode.d6.loss_cls: 0.0619  mix_decode.d6.loss_mask: 0.4486  mix_decode.d6.loss_dice: 0.5619  mix_decode.d7.loss_cls: 0.0559  mix_decode.d7.loss_mask: 0.4491  mix_decode.d7.loss_dice: 0.5545  mix_decode.d8.loss_cls: 0.0546  mix_decode.d8.loss_mask: 0.4484  mix_decode.d8.loss_dice: 0.5518
2025/03/28 12:34:04 - mmengine - INFO - Iter(train) [10500/20000]  base_lr: 5.1173e-05 lr: 5.1173e-05  eta: 2:16:18  time: 1.0746  data_time: 0.0227  memory: 10771  loss: 32.5864  decode.loss_cls: 0.0790  decode.loss_mask: 1.0153  decode.loss_dice: 0.9186  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 1.0181  decode.d0.loss_dice: 0.9327  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 1.0031  decode.d1.loss_dice: 0.9534  decode.d2.loss_cls: 0.0917  decode.d2.loss_mask: 1.0126  decode.d2.loss_dice: 0.9253  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 1.0177  decode.d3.loss_dice: 0.9257  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 1.0223  decode.d4.loss_dice: 0.9147  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 1.0190  decode.d5.loss_dice: 0.9369  decode.d6.loss_cls: 0.0809  decode.d6.loss_mask: 1.0102  decode.d6.loss_dice: 0.9113  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 1.0122  decode.d7.loss_dice: 0.9376  decode.d8.loss_cls: 0.0797  decode.d8.loss_mask: 1.0140  decode.d8.loss_dice: 0.9163  mix_decode.loss_cls: 0.0989  mix_decode.loss_mask: 0.4779  mix_decode.loss_dice: 0.6487  mix_decode.d0.loss_cls: 0.2255  mix_decode.d0.loss_mask: 0.4648  mix_decode.d0.loss_dice: 0.6452  mix_decode.d1.loss_cls: 0.1705  mix_decode.d1.loss_mask: 0.4714  mix_decode.d1.loss_dice: 0.6368  mix_decode.d2.loss_cls: 0.1366  mix_decode.d2.loss_mask: 0.4719  mix_decode.d2.loss_dice: 0.6282  mix_decode.d3.loss_cls: 0.1377  mix_decode.d3.loss_mask: 0.4737  mix_decode.d3.loss_dice: 0.6330  mix_decode.d4.loss_cls: 0.1209  mix_decode.d4.loss_mask: 0.4770  mix_decode.d4.loss_dice: 0.6348  mix_decode.d5.loss_cls: 0.1188  mix_decode.d5.loss_mask: 0.4795  mix_decode.d5.loss_dice: 0.6414  mix_decode.d6.loss_cls: 0.1242  mix_decode.d6.loss_mask: 0.4796  mix_decode.d6.loss_dice: 0.6228  mix_decode.d7.loss_cls: 0.1160  mix_decode.d7.loss_mask: 0.4781  mix_decode.d7.loss_dice: 0.6468  mix_decode.d8.loss_cls: 0.1256  mix_decode.d8.loss_mask: 0.4741  mix_decode.d8.loss_dice: 0.6042
2025/03/28 12:34:58 - mmengine - INFO - Iter(train) [10550/20000]  base_lr: 5.0931e-05 lr: 5.0931e-05  eta: 2:15:45  time: 1.0912  data_time: 0.0240  memory: 10774  loss: 29.0191  decode.loss_cls: 0.0230  decode.loss_mask: 0.8632  decode.loss_dice: 0.8819  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.8736  decode.d0.loss_dice: 0.9078  decode.d1.loss_cls: 0.1111  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 0.8904  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.8682  decode.d2.loss_dice: 0.8918  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.8605  decode.d3.loss_dice: 0.8913  decode.d4.loss_cls: 0.0720  decode.d4.loss_mask: 0.8586  decode.d4.loss_dice: 0.8924  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.8522  decode.d5.loss_dice: 0.8975  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.8601  decode.d6.loss_dice: 0.8832  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.8604  decode.d7.loss_dice: 0.8814  decode.d8.loss_cls: 0.0292  decode.d8.loss_mask: 0.8605  decode.d8.loss_dice: 0.8620  mix_decode.loss_cls: 0.0887  mix_decode.loss_mask: 0.3865  mix_decode.loss_dice: 0.5635  mix_decode.d0.loss_cls: 0.1264  mix_decode.d0.loss_mask: 0.3902  mix_decode.d0.loss_dice: 0.6236  mix_decode.d1.loss_cls: 0.1287  mix_decode.d1.loss_mask: 0.3882  mix_decode.d1.loss_dice: 0.5894  mix_decode.d2.loss_cls: 0.1229  mix_decode.d2.loss_mask: 0.3894  mix_decode.d2.loss_dice: 0.6022  mix_decode.d3.loss_cls: 0.1281  mix_decode.d3.loss_mask: 0.3868  mix_decode.d3.loss_dice: 0.5960  mix_decode.d4.loss_cls: 0.1282  mix_decode.d4.loss_mask: 0.3897  mix_decode.d4.loss_dice: 0.5903  mix_decode.d5.loss_cls: 0.1232  mix_decode.d5.loss_mask: 0.3850  mix_decode.d5.loss_dice: 0.5967  mix_decode.d6.loss_cls: 0.1086  mix_decode.d6.loss_mask: 0.3818  mix_decode.d6.loss_dice: 0.6072  mix_decode.d7.loss_cls: 0.1025  mix_decode.d7.loss_mask: 0.3871  mix_decode.d7.loss_dice: 0.5821  mix_decode.d8.loss_cls: 0.1144  mix_decode.d8.loss_mask: 0.3901  mix_decode.d8.loss_dice: 0.5867
2025/03/28 12:35:52 - mmengine - INFO - Iter(train) [10600/20000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 2:15:12  time: 1.0807  data_time: 0.0230  memory: 10768  loss: 32.6075  decode.loss_cls: 0.0259  decode.loss_mask: 0.9678  decode.loss_dice: 0.9370  decode.d0.loss_cls: 0.1019  decode.d0.loss_mask: 0.9746  decode.d0.loss_dice: 0.9555  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.9634  decode.d1.loss_dice: 0.9548  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.9630  decode.d2.loss_dice: 0.9570  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.9668  decode.d3.loss_dice: 0.9430  decode.d4.loss_cls: 0.0212  decode.d4.loss_mask: 0.9766  decode.d4.loss_dice: 0.9490  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.9686  decode.d5.loss_dice: 0.9582  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.9743  decode.d6.loss_dice: 0.9602  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.9698  decode.d7.loss_dice: 0.9512  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.9643  decode.d8.loss_dice: 0.9629  mix_decode.loss_cls: 0.0916  mix_decode.loss_mask: 0.5687  mix_decode.loss_dice: 0.6208  mix_decode.d0.loss_cls: 0.0830  mix_decode.d0.loss_mask: 0.5817  mix_decode.d0.loss_dice: 0.6649  mix_decode.d1.loss_cls: 0.1408  mix_decode.d1.loss_mask: 0.5635  mix_decode.d1.loss_dice: 0.6277  mix_decode.d2.loss_cls: 0.0940  mix_decode.d2.loss_mask: 0.5627  mix_decode.d2.loss_dice: 0.6424  mix_decode.d3.loss_cls: 0.1183  mix_decode.d3.loss_mask: 0.5598  mix_decode.d3.loss_dice: 0.6198  mix_decode.d4.loss_cls: 0.1114  mix_decode.d4.loss_mask: 0.5761  mix_decode.d4.loss_dice: 0.6061  mix_decode.d5.loss_cls: 0.1067  mix_decode.d5.loss_mask: 0.5627  mix_decode.d5.loss_dice: 0.6228  mix_decode.d6.loss_cls: 0.1096  mix_decode.d6.loss_mask: 0.5653  mix_decode.d6.loss_dice: 0.6298  mix_decode.d7.loss_cls: 0.1070  mix_decode.d7.loss_mask: 0.5716  mix_decode.d7.loss_dice: 0.6360  mix_decode.d8.loss_cls: 0.0852  mix_decode.d8.loss_mask: 0.5634  mix_decode.d8.loss_dice: 0.6411
2025/03/28 12:36:46 - mmengine - INFO - Iter(train) [10650/20000]  base_lr: 5.0446e-05 lr: 5.0446e-05  eta: 2:14:38  time: 1.0693  data_time: 0.0227  memory: 10768  loss: 29.5017  decode.loss_cls: 0.0202  decode.loss_mask: 0.9860  decode.loss_dice: 0.9083  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.9973  decode.d0.loss_dice: 0.8647  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 0.9929  decode.d1.loss_dice: 0.9109  decode.d2.loss_cls: 0.0227  decode.d2.loss_mask: 0.9912  decode.d2.loss_dice: 0.8934  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.9895  decode.d3.loss_dice: 0.8939  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.9887  decode.d4.loss_dice: 0.8963  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.9880  decode.d5.loss_dice: 0.9093  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.9947  decode.d6.loss_dice: 0.9015  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.9920  decode.d7.loss_dice: 0.8949  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.9926  decode.d8.loss_dice: 0.9244  mix_decode.loss_cls: 0.1193  mix_decode.loss_mask: 0.4139  mix_decode.loss_dice: 0.4966  mix_decode.d0.loss_cls: 0.0951  mix_decode.d0.loss_mask: 0.4103  mix_decode.d0.loss_dice: 0.5401  mix_decode.d1.loss_cls: 0.1108  mix_decode.d1.loss_mask: 0.4153  mix_decode.d1.loss_dice: 0.4935  mix_decode.d2.loss_cls: 0.1161  mix_decode.d2.loss_mask: 0.4168  mix_decode.d2.loss_dice: 0.4968  mix_decode.d3.loss_cls: 0.0956  mix_decode.d3.loss_mask: 0.4221  mix_decode.d3.loss_dice: 0.5222  mix_decode.d4.loss_cls: 0.1319  mix_decode.d4.loss_mask: 0.4212  mix_decode.d4.loss_dice: 0.5323  mix_decode.d5.loss_cls: 0.1019  mix_decode.d5.loss_mask: 0.4246  mix_decode.d5.loss_dice: 0.4983  mix_decode.d6.loss_cls: 0.0959  mix_decode.d6.loss_mask: 0.4253  mix_decode.d6.loss_dice: 0.4989  mix_decode.d7.loss_cls: 0.0950  mix_decode.d7.loss_mask: 0.4150  mix_decode.d7.loss_dice: 0.4920  mix_decode.d8.loss_cls: 0.1009  mix_decode.d8.loss_mask: 0.4180  mix_decode.d8.loss_dice: 0.5083
2025/03/28 12:37:40 - mmengine - INFO - Iter(train) [10700/20000]  base_lr: 5.0203e-05 lr: 5.0203e-05  eta: 2:14:04  time: 1.0721  data_time: 0.0224  memory: 10770  loss: 31.5755  decode.loss_cls: 0.0096  decode.loss_mask: 0.9280  decode.loss_dice: 0.9352  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.9515  decode.d0.loss_dice: 0.9113  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.9328  decode.d1.loss_dice: 0.9321  decode.d2.loss_cls: 0.0169  decode.d2.loss_mask: 0.9248  decode.d2.loss_dice: 0.9272  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.9203  decode.d3.loss_dice: 0.9330  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.9196  decode.d4.loss_dice: 0.9177  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.9246  decode.d5.loss_dice: 0.9332  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.9275  decode.d6.loss_dice: 0.9363  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.9303  decode.d7.loss_dice: 0.9375  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.9266  decode.d8.loss_dice: 0.9329  mix_decode.loss_cls: 0.1149  mix_decode.loss_mask: 0.5066  mix_decode.loss_dice: 0.6282  mix_decode.d0.loss_cls: 0.1628  mix_decode.d0.loss_mask: 0.5122  mix_decode.d0.loss_dice: 0.6612  mix_decode.d1.loss_cls: 0.1341  mix_decode.d1.loss_mask: 0.5117  mix_decode.d1.loss_dice: 0.6326  mix_decode.d2.loss_cls: 0.1532  mix_decode.d2.loss_mask: 0.5037  mix_decode.d2.loss_dice: 0.6390  mix_decode.d3.loss_cls: 0.1044  mix_decode.d3.loss_mask: 0.4997  mix_decode.d3.loss_dice: 0.6444  mix_decode.d4.loss_cls: 0.1110  mix_decode.d4.loss_mask: 0.5062  mix_decode.d4.loss_dice: 0.6380  mix_decode.d5.loss_cls: 0.1292  mix_decode.d5.loss_mask: 0.5019  mix_decode.d5.loss_dice: 0.6313  mix_decode.d6.loss_cls: 0.1385  mix_decode.d6.loss_mask: 0.5213  mix_decode.d6.loss_dice: 0.6312  mix_decode.d7.loss_cls: 0.1193  mix_decode.d7.loss_mask: 0.5147  mix_decode.d7.loss_dice: 0.6380  mix_decode.d8.loss_cls: 0.1228  mix_decode.d8.loss_mask: 0.5039  mix_decode.d8.loss_dice: 0.6219
2025/03/28 12:38:33 - mmengine - INFO - Iter(train) [10750/20000]  base_lr: 4.9960e-05 lr: 4.9960e-05  eta: 2:13:30  time: 1.0757  data_time: 0.0229  memory: 10771  loss: 31.6587  decode.loss_cls: 0.0250  decode.loss_mask: 0.9461  decode.loss_dice: 0.8593  decode.d0.loss_cls: 0.1188  decode.d0.loss_mask: 0.9485  decode.d0.loss_dice: 0.8389  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.9426  decode.d1.loss_dice: 0.8652  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.9491  decode.d2.loss_dice: 0.8546  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.9420  decode.d3.loss_dice: 0.8496  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.9513  decode.d4.loss_dice: 0.8473  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.9501  decode.d5.loss_dice: 0.8631  decode.d6.loss_cls: 0.0412  decode.d6.loss_mask: 0.9408  decode.d6.loss_dice: 0.8417  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.9403  decode.d7.loss_dice: 0.8565  decode.d8.loss_cls: 0.0211  decode.d8.loss_mask: 0.9425  decode.d8.loss_dice: 0.8602  mix_decode.loss_cls: 0.1047  mix_decode.loss_mask: 0.5425  mix_decode.loss_dice: 0.6611  mix_decode.d0.loss_cls: 0.1692  mix_decode.d0.loss_mask: 0.5369  mix_decode.d0.loss_dice: 0.6805  mix_decode.d1.loss_cls: 0.1459  mix_decode.d1.loss_mask: 0.5301  mix_decode.d1.loss_dice: 0.6312  mix_decode.d2.loss_cls: 0.1474  mix_decode.d2.loss_mask: 0.5307  mix_decode.d2.loss_dice: 0.6486  mix_decode.d3.loss_cls: 0.1891  mix_decode.d3.loss_mask: 0.5317  mix_decode.d3.loss_dice: 0.6362  mix_decode.d4.loss_cls: 0.0967  mix_decode.d4.loss_mask: 0.5267  mix_decode.d4.loss_dice: 0.6827  mix_decode.d5.loss_cls: 0.1458  mix_decode.d5.loss_mask: 0.5221  mix_decode.d5.loss_dice: 0.6397  mix_decode.d6.loss_cls: 0.1141  mix_decode.d6.loss_mask: 0.5398  mix_decode.d6.loss_dice: 0.6439  mix_decode.d7.loss_cls: 0.1400  mix_decode.d7.loss_mask: 0.5260  mix_decode.d7.loss_dice: 0.6401  mix_decode.d8.loss_cls: 0.1631  mix_decode.d8.loss_mask: 0.5295  mix_decode.d8.loss_dice: 0.6410
2025/03/28 12:39:27 - mmengine - INFO - Iter(train) [10800/20000]  base_lr: 4.9717e-05 lr: 4.9717e-05  eta: 2:12:55  time: 1.0758  data_time: 0.0226  memory: 10777  loss: 29.3921  decode.loss_cls: 0.0089  decode.loss_mask: 0.8707  decode.loss_dice: 0.7921  decode.d0.loss_cls: 0.0588  decode.d0.loss_mask: 0.8812  decode.d0.loss_dice: 0.7570  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.8701  decode.d1.loss_dice: 0.7749  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.8750  decode.d2.loss_dice: 0.7775  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.8745  decode.d3.loss_dice: 0.7767  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.8700  decode.d4.loss_dice: 0.7782  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.8684  decode.d5.loss_dice: 0.7883  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.8716  decode.d6.loss_dice: 0.7846  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.8680  decode.d7.loss_dice: 0.7837  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.8690  decode.d8.loss_dice: 0.7829  mix_decode.loss_cls: 0.0624  mix_decode.loss_mask: 0.5193  mix_decode.loss_dice: 0.6643  mix_decode.d0.loss_cls: 0.0923  mix_decode.d0.loss_mask: 0.5227  mix_decode.d0.loss_dice: 0.6659  mix_decode.d1.loss_cls: 0.0754  mix_decode.d1.loss_mask: 0.5269  mix_decode.d1.loss_dice: 0.6595  mix_decode.d2.loss_cls: 0.1223  mix_decode.d2.loss_mask: 0.5298  mix_decode.d2.loss_dice: 0.6375  mix_decode.d3.loss_cls: 0.0772  mix_decode.d3.loss_mask: 0.5306  mix_decode.d3.loss_dice: 0.6647  mix_decode.d4.loss_cls: 0.0439  mix_decode.d4.loss_mask: 0.5407  mix_decode.d4.loss_dice: 0.6800  mix_decode.d5.loss_cls: 0.0991  mix_decode.d5.loss_mask: 0.5271  mix_decode.d5.loss_dice: 0.6632  mix_decode.d6.loss_cls: 0.0509  mix_decode.d6.loss_mask: 0.5406  mix_decode.d6.loss_dice: 0.6796  mix_decode.d7.loss_cls: 0.0513  mix_decode.d7.loss_mask: 0.5425  mix_decode.d7.loss_dice: 0.6787  mix_decode.d8.loss_cls: 0.0916  mix_decode.d8.loss_mask: 0.5260  mix_decode.d8.loss_dice: 0.6599
2025/03/28 12:40:21 - mmengine - INFO - Iter(train) [10850/20000]  base_lr: 4.9473e-05 lr: 4.9473e-05  eta: 2:12:21  time: 1.0696  data_time: 0.0228  memory: 10776  loss: 30.3937  decode.loss_cls: 0.1008  decode.loss_mask: 0.9153  decode.loss_dice: 0.8449  decode.d0.loss_cls: 0.1560  decode.d0.loss_mask: 0.9210  decode.d0.loss_dice: 0.8718  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.9147  decode.d1.loss_dice: 0.8625  decode.d2.loss_cls: 0.0945  decode.d2.loss_mask: 0.9129  decode.d2.loss_dice: 0.8285  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.9173  decode.d3.loss_dice: 0.8315  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.9140  decode.d4.loss_dice: 0.8374  decode.d5.loss_cls: 0.0972  decode.d5.loss_mask: 0.9139  decode.d5.loss_dice: 0.8411  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.9129  decode.d6.loss_dice: 0.8325  decode.d7.loss_cls: 0.0705  decode.d7.loss_mask: 0.9205  decode.d7.loss_dice: 0.8586  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 0.9151  decode.d8.loss_dice: 0.8537  mix_decode.loss_cls: 0.1300  mix_decode.loss_mask: 0.4741  mix_decode.loss_dice: 0.5857  mix_decode.d0.loss_cls: 0.1172  mix_decode.d0.loss_mask: 0.4836  mix_decode.d0.loss_dice: 0.6049  mix_decode.d1.loss_cls: 0.1174  mix_decode.d1.loss_mask: 0.4751  mix_decode.d1.loss_dice: 0.5815  mix_decode.d2.loss_cls: 0.1391  mix_decode.d2.loss_mask: 0.4741  mix_decode.d2.loss_dice: 0.5739  mix_decode.d3.loss_cls: 0.1351  mix_decode.d3.loss_mask: 0.4767  mix_decode.d3.loss_dice: 0.5810  mix_decode.d4.loss_cls: 0.0925  mix_decode.d4.loss_mask: 0.4803  mix_decode.d4.loss_dice: 0.5844  mix_decode.d5.loss_cls: 0.0823  mix_decode.d5.loss_mask: 0.4785  mix_decode.d5.loss_dice: 0.5946  mix_decode.d6.loss_cls: 0.1198  mix_decode.d6.loss_mask: 0.4822  mix_decode.d6.loss_dice: 0.5853  mix_decode.d7.loss_cls: 0.0973  mix_decode.d7.loss_mask: 0.4847  mix_decode.d7.loss_dice: 0.5797  mix_decode.d8.loss_cls: 0.1038  mix_decode.d8.loss_mask: 0.5009  mix_decode.d8.loss_dice: 0.5756
2025/03/28 12:41:15 - mmengine - INFO - Iter(train) [10900/20000]  base_lr: 4.9230e-05 lr: 4.9230e-05  eta: 2:11:46  time: 1.0825  data_time: 0.0238  memory: 10774  loss: 31.2389  decode.loss_cls: 0.0205  decode.loss_mask: 0.9490  decode.loss_dice: 0.8487  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.9508  decode.d0.loss_dice: 0.8687  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 0.9445  decode.d1.loss_dice: 0.8715  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.9495  decode.d2.loss_dice: 0.8585  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.9436  decode.d3.loss_dice: 0.8563  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.9456  decode.d4.loss_dice: 0.8498  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.9475  decode.d5.loss_dice: 0.8545  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.9534  decode.d6.loss_dice: 0.8563  decode.d7.loss_cls: 0.0262  decode.d7.loss_mask: 0.9478  decode.d7.loss_dice: 0.8567  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.9439  decode.d8.loss_dice: 0.8499  mix_decode.loss_cls: 0.0845  mix_decode.loss_mask: 0.5758  mix_decode.loss_dice: 0.6323  mix_decode.d0.loss_cls: 0.1066  mix_decode.d0.loss_mask: 0.5741  mix_decode.d0.loss_dice: 0.6534  mix_decode.d1.loss_cls: 0.0810  mix_decode.d1.loss_mask: 0.5706  mix_decode.d1.loss_dice: 0.6469  mix_decode.d2.loss_cls: 0.0852  mix_decode.d2.loss_mask: 0.5661  mix_decode.d2.loss_dice: 0.6270  mix_decode.d3.loss_cls: 0.0841  mix_decode.d3.loss_mask: 0.5702  mix_decode.d3.loss_dice: 0.6188  mix_decode.d4.loss_cls: 0.0787  mix_decode.d4.loss_mask: 0.5712  mix_decode.d4.loss_dice: 0.6235  mix_decode.d5.loss_cls: 0.0835  mix_decode.d5.loss_mask: 0.5704  mix_decode.d5.loss_dice: 0.6200  mix_decode.d6.loss_cls: 0.0904  mix_decode.d6.loss_mask: 0.5769  mix_decode.d6.loss_dice: 0.6217  mix_decode.d7.loss_cls: 0.1105  mix_decode.d7.loss_mask: 0.5689  mix_decode.d7.loss_dice: 0.6228  mix_decode.d8.loss_cls: 0.1026  mix_decode.d8.loss_mask: 0.5676  mix_decode.d8.loss_dice: 0.6280
2025/03/28 12:42:09 - mmengine - INFO - Iter(train) [10950/20000]  base_lr: 4.8986e-05 lr: 4.8986e-05  eta: 2:11:12  time: 1.0738  data_time: 0.0222  memory: 10782  loss: 26.8078  decode.loss_cls: 0.0723  decode.loss_mask: 0.8174  decode.loss_dice: 0.8407  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.8222  decode.d0.loss_dice: 0.8262  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.8139  decode.d1.loss_dice: 0.8339  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.8150  decode.d2.loss_dice: 0.7924  decode.d3.loss_cls: 0.0869  decode.d3.loss_mask: 0.8193  decode.d3.loss_dice: 0.8087  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.8183  decode.d4.loss_dice: 0.8088  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.8226  decode.d5.loss_dice: 0.7817  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.8188  decode.d6.loss_dice: 0.8232  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.8170  decode.d7.loss_dice: 0.8325  decode.d8.loss_cls: 0.0854  decode.d8.loss_mask: 0.8187  decode.d8.loss_dice: 0.7987  mix_decode.loss_cls: 0.0748  mix_decode.loss_mask: 0.4161  mix_decode.loss_dice: 0.4995  mix_decode.d0.loss_cls: 0.1133  mix_decode.d0.loss_mask: 0.4153  mix_decode.d0.loss_dice: 0.5091  mix_decode.d1.loss_cls: 0.0744  mix_decode.d1.loss_mask: 0.4140  mix_decode.d1.loss_dice: 0.4889  mix_decode.d2.loss_cls: 0.0841  mix_decode.d2.loss_mask: 0.4158  mix_decode.d2.loss_dice: 0.4846  mix_decode.d3.loss_cls: 0.0613  mix_decode.d3.loss_mask: 0.4077  mix_decode.d3.loss_dice: 0.4774  mix_decode.d4.loss_cls: 0.0673  mix_decode.d4.loss_mask: 0.4155  mix_decode.d4.loss_dice: 0.4958  mix_decode.d5.loss_cls: 0.0595  mix_decode.d5.loss_mask: 0.4186  mix_decode.d5.loss_dice: 0.4798  mix_decode.d6.loss_cls: 0.0661  mix_decode.d6.loss_mask: 0.4182  mix_decode.d6.loss_dice: 0.4831  mix_decode.d7.loss_cls: 0.0586  mix_decode.d7.loss_mask: 0.4155  mix_decode.d7.loss_dice: 0.4998  mix_decode.d8.loss_cls: 0.0464  mix_decode.d8.loss_mask: 0.4212  mix_decode.d8.loss_dice: 0.5063
2025/03/28 12:43:03 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 12:43:03 - mmengine - INFO - Iter(train) [11000/20000]  base_lr: 4.8743e-05 lr: 4.8743e-05  eta: 2:10:37  time: 1.0797  data_time: 0.0230  memory: 10781  loss: 30.4051  decode.loss_cls: 0.0131  decode.loss_mask: 1.0280  decode.loss_dice: 0.9103  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 1.0401  decode.d0.loss_dice: 0.8952  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 1.0340  decode.d1.loss_dice: 0.9158  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 1.0339  decode.d2.loss_dice: 0.9135  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 1.0407  decode.d3.loss_dice: 0.9101  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 1.0459  decode.d4.loss_dice: 0.9257  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 1.0393  decode.d5.loss_dice: 0.9191  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 1.0306  decode.d6.loss_dice: 0.9034  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 1.0384  decode.d7.loss_dice: 0.9145  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 1.0335  decode.d8.loss_dice: 0.9091  mix_decode.loss_cls: 0.0936  mix_decode.loss_mask: 0.4121  mix_decode.loss_dice: 0.5393  mix_decode.d0.loss_cls: 0.1200  mix_decode.d0.loss_mask: 0.4284  mix_decode.d0.loss_dice: 0.5557  mix_decode.d1.loss_cls: 0.0926  mix_decode.d1.loss_mask: 0.4220  mix_decode.d1.loss_dice: 0.5410  mix_decode.d2.loss_cls: 0.1289  mix_decode.d2.loss_mask: 0.4116  mix_decode.d2.loss_dice: 0.5210  mix_decode.d3.loss_cls: 0.0951  mix_decode.d3.loss_mask: 0.4285  mix_decode.d3.loss_dice: 0.5575  mix_decode.d4.loss_cls: 0.1044  mix_decode.d4.loss_mask: 0.4299  mix_decode.d4.loss_dice: 0.5386  mix_decode.d5.loss_cls: 0.1077  mix_decode.d5.loss_mask: 0.4389  mix_decode.d5.loss_dice: 0.5204  mix_decode.d6.loss_cls: 0.1432  mix_decode.d6.loss_mask: 0.4049  mix_decode.d6.loss_dice: 0.5278  mix_decode.d7.loss_cls: 0.1164  mix_decode.d7.loss_mask: 0.4170  mix_decode.d7.loss_dice: 0.5320  mix_decode.d8.loss_cls: 0.1094  mix_decode.d8.loss_mask: 0.4120  mix_decode.d8.loss_dice: 0.5411
2025/03/28 12:43:57 - mmengine - INFO - Iter(train) [11050/20000]  base_lr: 4.8499e-05 lr: 4.8499e-05  eta: 2:10:02  time: 1.0744  data_time: 0.0221  memory: 10772  loss: 27.7992  decode.loss_cls: 0.0137  decode.loss_mask: 0.8614  decode.loss_dice: 0.8102  decode.d0.loss_cls: 0.0965  decode.d0.loss_mask: 0.8649  decode.d0.loss_dice: 0.8298  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.8455  decode.d1.loss_dice: 0.8283  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.8532  decode.d2.loss_dice: 0.8087  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.8612  decode.d3.loss_dice: 0.8159  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.8576  decode.d4.loss_dice: 0.8134  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.8522  decode.d5.loss_dice: 0.8108  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.8600  decode.d6.loss_dice: 0.8348  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.8539  decode.d7.loss_dice: 0.8087  decode.d8.loss_cls: 0.0202  decode.d8.loss_mask: 0.8558  decode.d8.loss_dice: 0.8165  mix_decode.loss_cls: 0.1207  mix_decode.loss_mask: 0.4531  mix_decode.loss_dice: 0.5133  mix_decode.d0.loss_cls: 0.1020  mix_decode.d0.loss_mask: 0.4534  mix_decode.d0.loss_dice: 0.5652  mix_decode.d1.loss_cls: 0.1084  mix_decode.d1.loss_mask: 0.4490  mix_decode.d1.loss_dice: 0.5145  mix_decode.d2.loss_cls: 0.1167  mix_decode.d2.loss_mask: 0.4479  mix_decode.d2.loss_dice: 0.5116  mix_decode.d3.loss_cls: 0.1006  mix_decode.d3.loss_mask: 0.4532  mix_decode.d3.loss_dice: 0.5098  mix_decode.d4.loss_cls: 0.1157  mix_decode.d4.loss_mask: 0.4500  mix_decode.d4.loss_dice: 0.5313  mix_decode.d5.loss_cls: 0.1007  mix_decode.d5.loss_mask: 0.4480  mix_decode.d5.loss_dice: 0.5305  mix_decode.d6.loss_cls: 0.1276  mix_decode.d6.loss_mask: 0.4506  mix_decode.d6.loss_dice: 0.5099  mix_decode.d7.loss_cls: 0.1211  mix_decode.d7.loss_mask: 0.4427  mix_decode.d7.loss_dice: 0.5067  mix_decode.d8.loss_cls: 0.1063  mix_decode.d8.loss_mask: 0.4449  mix_decode.d8.loss_dice: 0.5078
2025/03/28 12:44:51 - mmengine - INFO - Iter(train) [11100/20000]  base_lr: 4.8255e-05 lr: 4.8255e-05  eta: 2:09:26  time: 1.0754  data_time: 0.0221  memory: 10772  loss: 28.6442  decode.loss_cls: 0.1007  decode.loss_mask: 0.9008  decode.loss_dice: 0.8028  decode.d0.loss_cls: 0.1227  decode.d0.loss_mask: 0.9087  decode.d0.loss_dice: 0.8652  decode.d1.loss_cls: 0.1259  decode.d1.loss_mask: 0.9029  decode.d1.loss_dice: 0.7878  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.9026  decode.d2.loss_dice: 0.7785  decode.d3.loss_cls: 0.0458  decode.d3.loss_mask: 0.9002  decode.d3.loss_dice: 0.7833  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.9043  decode.d4.loss_dice: 0.8155  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.9051  decode.d5.loss_dice: 0.7929  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.9059  decode.d6.loss_dice: 0.8149  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.9085  decode.d7.loss_dice: 0.8299  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.9037  decode.d8.loss_dice: 0.8021  mix_decode.loss_cls: 0.1123  mix_decode.loss_mask: 0.4174  mix_decode.loss_dice: 0.5537  mix_decode.d0.loss_cls: 0.1942  mix_decode.d0.loss_mask: 0.4096  mix_decode.d0.loss_dice: 0.5778  mix_decode.d1.loss_cls: 0.1018  mix_decode.d1.loss_mask: 0.4119  mix_decode.d1.loss_dice: 0.5541  mix_decode.d2.loss_cls: 0.1198  mix_decode.d2.loss_mask: 0.4072  mix_decode.d2.loss_dice: 0.5542  mix_decode.d3.loss_cls: 0.1182  mix_decode.d3.loss_mask: 0.4055  mix_decode.d3.loss_dice: 0.5367  mix_decode.d4.loss_cls: 0.1097  mix_decode.d4.loss_mask: 0.4054  mix_decode.d4.loss_dice: 0.5496  mix_decode.d5.loss_cls: 0.1148  mix_decode.d5.loss_mask: 0.4177  mix_decode.d5.loss_dice: 0.5500  mix_decode.d6.loss_cls: 0.1271  mix_decode.d6.loss_mask: 0.4188  mix_decode.d6.loss_dice: 0.5758  mix_decode.d7.loss_cls: 0.1291  mix_decode.d7.loss_mask: 0.4073  mix_decode.d7.loss_dice: 0.5539  mix_decode.d8.loss_cls: 0.1280  mix_decode.d8.loss_mask: 0.4173  mix_decode.d8.loss_dice: 0.5601
2025/03/28 12:45:45 - mmengine - INFO - Iter(train) [11150/20000]  base_lr: 4.8011e-05 lr: 4.8011e-05  eta: 2:08:51  time: 1.0843  data_time: 0.0233  memory: 10773  loss: 31.6662  decode.loss_cls: 0.0262  decode.loss_mask: 0.9579  decode.loss_dice: 0.9073  decode.d0.loss_cls: 0.1390  decode.d0.loss_mask: 0.9700  decode.d0.loss_dice: 0.8832  decode.d1.loss_cls: 0.0282  decode.d1.loss_mask: 0.9534  decode.d1.loss_dice: 0.8956  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.9524  decode.d2.loss_dice: 0.9150  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.9508  decode.d3.loss_dice: 0.9159  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.9565  decode.d4.loss_dice: 0.9058  decode.d5.loss_cls: 0.0243  decode.d5.loss_mask: 0.9477  decode.d5.loss_dice: 0.9095  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.9516  decode.d6.loss_dice: 0.9212  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.9584  decode.d7.loss_dice: 0.8938  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.9505  decode.d8.loss_dice: 0.8927  mix_decode.loss_cls: 0.1248  mix_decode.loss_mask: 0.5484  mix_decode.loss_dice: 0.5874  mix_decode.d0.loss_cls: 0.1410  mix_decode.d0.loss_mask: 0.5659  mix_decode.d0.loss_dice: 0.6043  mix_decode.d1.loss_cls: 0.1195  mix_decode.d1.loss_mask: 0.5550  mix_decode.d1.loss_dice: 0.5932  mix_decode.d2.loss_cls: 0.1315  mix_decode.d2.loss_mask: 0.5534  mix_decode.d2.loss_dice: 0.5992  mix_decode.d3.loss_cls: 0.0980  mix_decode.d3.loss_mask: 0.5548  mix_decode.d3.loss_dice: 0.6060  mix_decode.d4.loss_cls: 0.1108  mix_decode.d4.loss_mask: 0.5548  mix_decode.d4.loss_dice: 0.5805  mix_decode.d5.loss_cls: 0.1403  mix_decode.d5.loss_mask: 0.5564  mix_decode.d5.loss_dice: 0.5984  mix_decode.d6.loss_cls: 0.1327  mix_decode.d6.loss_mask: 0.5479  mix_decode.d6.loss_dice: 0.5785  mix_decode.d7.loss_cls: 0.1259  mix_decode.d7.loss_mask: 0.5497  mix_decode.d7.loss_dice: 0.6032  mix_decode.d8.loss_cls: 0.1111  mix_decode.d8.loss_mask: 0.5499  mix_decode.d8.loss_dice: 0.5834
2025/03/28 12:46:39 - mmengine - INFO - Iter(train) [11200/20000]  base_lr: 4.7767e-05 lr: 4.7767e-05  eta: 2:08:16  time: 1.0751  data_time: 0.0229  memory: 10780  loss: 29.2302  decode.loss_cls: 0.0596  decode.loss_mask: 0.8565  decode.loss_dice: 0.8627  decode.d0.loss_cls: 0.0891  decode.d0.loss_mask: 0.8688  decode.d0.loss_dice: 0.8899  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.8582  decode.d1.loss_dice: 0.8608  decode.d2.loss_cls: 0.1007  decode.d2.loss_mask: 0.8540  decode.d2.loss_dice: 0.8520  decode.d3.loss_cls: 0.0665  decode.d3.loss_mask: 0.8592  decode.d3.loss_dice: 0.8534  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.8595  decode.d4.loss_dice: 0.8678  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.8500  decode.d5.loss_dice: 0.8606  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.8566  decode.d6.loss_dice: 0.8558  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.8539  decode.d7.loss_dice: 0.8645  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.8572  decode.d8.loss_dice: 0.8669  mix_decode.loss_cls: 0.1017  mix_decode.loss_mask: 0.4042  mix_decode.loss_dice: 0.6060  mix_decode.d0.loss_cls: 0.1319  mix_decode.d0.loss_mask: 0.4185  mix_decode.d0.loss_dice: 0.6730  mix_decode.d1.loss_cls: 0.1245  mix_decode.d1.loss_mask: 0.4023  mix_decode.d1.loss_dice: 0.6269  mix_decode.d2.loss_cls: 0.1081  mix_decode.d2.loss_mask: 0.3986  mix_decode.d2.loss_dice: 0.6099  mix_decode.d3.loss_cls: 0.1150  mix_decode.d3.loss_mask: 0.3990  mix_decode.d3.loss_dice: 0.5867  mix_decode.d4.loss_cls: 0.0798  mix_decode.d4.loss_mask: 0.4140  mix_decode.d4.loss_dice: 0.6096  mix_decode.d5.loss_cls: 0.1120  mix_decode.d5.loss_mask: 0.4088  mix_decode.d5.loss_dice: 0.6051  mix_decode.d6.loss_cls: 0.0979  mix_decode.d6.loss_mask: 0.4141  mix_decode.d6.loss_dice: 0.5927  mix_decode.d7.loss_cls: 0.1034  mix_decode.d7.loss_mask: 0.4070  mix_decode.d7.loss_dice: 0.6136  mix_decode.d8.loss_cls: 0.0864  mix_decode.d8.loss_mask: 0.4071  mix_decode.d8.loss_dice: 0.6211
2025/03/28 12:47:33 - mmengine - INFO - Iter(train) [11250/20000]  base_lr: 4.7523e-05 lr: 4.7523e-05  eta: 2:07:40  time: 1.0807  data_time: 0.0229  memory: 10773  loss: 28.5795  decode.loss_cls: 0.0188  decode.loss_mask: 0.9581  decode.loss_dice: 0.9237  decode.d0.loss_cls: 0.0749  decode.d0.loss_mask: 0.9773  decode.d0.loss_dice: 0.9412  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.9595  decode.d1.loss_dice: 0.9131  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.9694  decode.d2.loss_dice: 0.9286  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.9602  decode.d3.loss_dice: 0.9154  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.9634  decode.d4.loss_dice: 0.9230  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.9662  decode.d5.loss_dice: 0.9296  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.9598  decode.d6.loss_dice: 0.9240  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.9606  decode.d7.loss_dice: 0.9188  decode.d8.loss_cls: 0.0215  decode.d8.loss_mask: 0.9628  decode.d8.loss_dice: 0.9375  mix_decode.loss_cls: 0.0448  mix_decode.loss_mask: 0.3771  mix_decode.loss_dice: 0.5028  mix_decode.d0.loss_cls: 0.0894  mix_decode.d0.loss_mask: 0.3817  mix_decode.d0.loss_dice: 0.5326  mix_decode.d1.loss_cls: 0.0541  mix_decode.d1.loss_mask: 0.3803  mix_decode.d1.loss_dice: 0.5082  mix_decode.d2.loss_cls: 0.0671  mix_decode.d2.loss_mask: 0.3795  mix_decode.d2.loss_dice: 0.4918  mix_decode.d3.loss_cls: 0.0598  mix_decode.d3.loss_mask: 0.3805  mix_decode.d3.loss_dice: 0.5002  mix_decode.d4.loss_cls: 0.0424  mix_decode.d4.loss_mask: 0.3770  mix_decode.d4.loss_dice: 0.5085  mix_decode.d5.loss_cls: 0.0418  mix_decode.d5.loss_mask: 0.3765  mix_decode.d5.loss_dice: 0.5098  mix_decode.d6.loss_cls: 0.0933  mix_decode.d6.loss_mask: 0.3753  mix_decode.d6.loss_dice: 0.4925  mix_decode.d7.loss_cls: 0.0455  mix_decode.d7.loss_mask: 0.3753  mix_decode.d7.loss_dice: 0.5096  mix_decode.d8.loss_cls: 0.0453  mix_decode.d8.loss_mask: 0.3759  mix_decode.d8.loss_dice: 0.5016
2025/03/28 12:48:28 - mmengine - INFO - Iter(train) [11300/20000]  base_lr: 4.7278e-05 lr: 4.7278e-05  eta: 2:07:04  time: 1.0883  data_time: 0.0243  memory: 10773  loss: 31.0938  decode.loss_cls: 0.0900  decode.loss_mask: 0.9057  decode.loss_dice: 0.8274  decode.d0.loss_cls: 0.1210  decode.d0.loss_mask: 0.9389  decode.d0.loss_dice: 0.8314  decode.d1.loss_cls: 0.0945  decode.d1.loss_mask: 0.9004  decode.d1.loss_dice: 0.8320  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 0.8995  decode.d2.loss_dice: 0.8301  decode.d3.loss_cls: 0.1496  decode.d3.loss_mask: 0.9011  decode.d3.loss_dice: 0.8315  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.9061  decode.d4.loss_dice: 0.8283  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.9416  decode.d5.loss_dice: 0.8572  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.9328  decode.d6.loss_dice: 0.8389  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.9350  decode.d7.loss_dice: 0.8496  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.8973  decode.d8.loss_dice: 0.8308  mix_decode.loss_cls: 0.0919  mix_decode.loss_mask: 0.5071  mix_decode.loss_dice: 0.6616  mix_decode.d0.loss_cls: 0.1065  mix_decode.d0.loss_mask: 0.4896  mix_decode.d0.loss_dice: 0.6810  mix_decode.d1.loss_cls: 0.0865  mix_decode.d1.loss_mask: 0.5268  mix_decode.d1.loss_dice: 0.6587  mix_decode.d2.loss_cls: 0.1423  mix_decode.d2.loss_mask: 0.4935  mix_decode.d2.loss_dice: 0.6332  mix_decode.d3.loss_cls: 0.1183  mix_decode.d3.loss_mask: 0.4986  mix_decode.d3.loss_dice: 0.6393  mix_decode.d4.loss_cls: 0.0974  mix_decode.d4.loss_mask: 0.5009  mix_decode.d4.loss_dice: 0.6642  mix_decode.d5.loss_cls: 0.1003  mix_decode.d5.loss_mask: 0.5177  mix_decode.d5.loss_dice: 0.6606  mix_decode.d6.loss_cls: 0.1389  mix_decode.d6.loss_mask: 0.4931  mix_decode.d6.loss_dice: 0.6488  mix_decode.d7.loss_cls: 0.1056  mix_decode.d7.loss_mask: 0.5001  mix_decode.d7.loss_dice: 0.6688  mix_decode.d8.loss_cls: 0.0970  mix_decode.d8.loss_mask: 0.5154  mix_decode.d8.loss_dice: 0.6664
2025/03/28 12:49:22 - mmengine - INFO - Iter(train) [11350/20000]  base_lr: 4.7033e-05 lr: 4.7033e-05  eta: 2:06:28  time: 1.0763  data_time: 0.0230  memory: 10779  loss: 29.3554  decode.loss_cls: 0.0312  decode.loss_mask: 0.9299  decode.loss_dice: 0.8810  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.9299  decode.d0.loss_dice: 0.9193  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.9220  decode.d1.loss_dice: 0.9059  decode.d2.loss_cls: 0.0235  decode.d2.loss_mask: 0.9236  decode.d2.loss_dice: 0.8950  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.9275  decode.d3.loss_dice: 0.8963  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.9302  decode.d4.loss_dice: 0.9062  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.9329  decode.d5.loss_dice: 0.8915  decode.d6.loss_cls: 0.0365  decode.d6.loss_mask: 0.9352  decode.d6.loss_dice: 0.8840  decode.d7.loss_cls: 0.0442  decode.d7.loss_mask: 0.9278  decode.d7.loss_dice: 0.8853  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 0.9284  decode.d8.loss_dice: 0.8692  mix_decode.loss_cls: 0.0667  mix_decode.loss_mask: 0.4639  mix_decode.loss_dice: 0.5613  mix_decode.d0.loss_cls: 0.0743  mix_decode.d0.loss_mask: 0.4492  mix_decode.d0.loss_dice: 0.5806  mix_decode.d1.loss_cls: 0.0589  mix_decode.d1.loss_mask: 0.4607  mix_decode.d1.loss_dice: 0.5396  mix_decode.d2.loss_cls: 0.0516  mix_decode.d2.loss_mask: 0.4638  mix_decode.d2.loss_dice: 0.5612  mix_decode.d3.loss_cls: 0.0462  mix_decode.d3.loss_mask: 0.4691  mix_decode.d3.loss_dice: 0.5645  mix_decode.d4.loss_cls: 0.0609  mix_decode.d4.loss_mask: 0.4660  mix_decode.d4.loss_dice: 0.5553  mix_decode.d5.loss_cls: 0.0466  mix_decode.d5.loss_mask: 0.4712  mix_decode.d5.loss_dice: 0.5518  mix_decode.d6.loss_cls: 0.0681  mix_decode.d6.loss_mask: 0.4510  mix_decode.d6.loss_dice: 0.5528  mix_decode.d7.loss_cls: 0.0541  mix_decode.d7.loss_mask: 0.4646  mix_decode.d7.loss_dice: 0.5588  mix_decode.d8.loss_cls: 0.0615  mix_decode.d8.loss_mask: 0.4643  mix_decode.d8.loss_dice: 0.5414
2025/03/28 12:50:16 - mmengine - INFO - Iter(train) [11400/20000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 2:05:52  time: 1.0770  data_time: 0.0228  memory: 10772  loss: 30.0095  decode.loss_cls: 0.0099  decode.loss_mask: 0.9625  decode.loss_dice: 0.9443  decode.d0.loss_cls: 0.0589  decode.d0.loss_mask: 0.9721  decode.d0.loss_dice: 0.9465  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.9576  decode.d1.loss_dice: 0.9293  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.9505  decode.d2.loss_dice: 0.9395  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.9596  decode.d3.loss_dice: 0.9464  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.9603  decode.d4.loss_dice: 0.9420  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.9537  decode.d5.loss_dice: 0.9372  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.9580  decode.d6.loss_dice: 0.9375  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.9640  decode.d7.loss_dice: 0.9398  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.9583  decode.d8.loss_dice: 0.9444  mix_decode.loss_cls: 0.0860  mix_decode.loss_mask: 0.4486  mix_decode.loss_dice: 0.5384  mix_decode.d0.loss_cls: 0.1281  mix_decode.d0.loss_mask: 0.4525  mix_decode.d0.loss_dice: 0.5480  mix_decode.d1.loss_cls: 0.1212  mix_decode.d1.loss_mask: 0.4426  mix_decode.d1.loss_dice: 0.5429  mix_decode.d2.loss_cls: 0.0876  mix_decode.d2.loss_mask: 0.4434  mix_decode.d2.loss_dice: 0.5532  mix_decode.d3.loss_cls: 0.0772  mix_decode.d3.loss_mask: 0.4454  mix_decode.d3.loss_dice: 0.5421  mix_decode.d4.loss_cls: 0.0978  mix_decode.d4.loss_mask: 0.4403  mix_decode.d4.loss_dice: 0.5240  mix_decode.d5.loss_cls: 0.0906  mix_decode.d5.loss_mask: 0.4435  mix_decode.d5.loss_dice: 0.5505  mix_decode.d6.loss_cls: 0.1104  mix_decode.d6.loss_mask: 0.4420  mix_decode.d6.loss_dice: 0.5264  mix_decode.d7.loss_cls: 0.0933  mix_decode.d7.loss_mask: 0.4436  mix_decode.d7.loss_dice: 0.5414  mix_decode.d8.loss_cls: 0.0930  mix_decode.d8.loss_mask: 0.4446  mix_decode.d8.loss_dice: 0.5418
2025/03/28 12:51:09 - mmengine - INFO - Iter(train) [11450/20000]  base_lr: 4.6544e-05 lr: 4.6544e-05  eta: 2:05:15  time: 1.0768  data_time: 0.0223  memory: 10778  loss: 30.2268  decode.loss_cls: 0.0680  decode.loss_mask: 0.9210  decode.loss_dice: 0.7939  decode.d0.loss_cls: 0.1613  decode.d0.loss_mask: 0.9074  decode.d0.loss_dice: 0.8036  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.9092  decode.d1.loss_dice: 0.8185  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.9184  decode.d2.loss_dice: 0.8011  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.9115  decode.d3.loss_dice: 0.7965  decode.d4.loss_cls: 0.0804  decode.d4.loss_mask: 0.9098  decode.d4.loss_dice: 0.7797  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.9112  decode.d5.loss_dice: 0.7938  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.9186  decode.d6.loss_dice: 0.7919  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.9165  decode.d7.loss_dice: 0.8098  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.9252  decode.d8.loss_dice: 0.7919  mix_decode.loss_cls: 0.0523  mix_decode.loss_mask: 0.5561  mix_decode.loss_dice: 0.6009  mix_decode.d0.loss_cls: 0.1008  mix_decode.d0.loss_mask: 0.5599  mix_decode.d0.loss_dice: 0.6132  mix_decode.d1.loss_cls: 0.0717  mix_decode.d1.loss_mask: 0.5597  mix_decode.d1.loss_dice: 0.6063  mix_decode.d2.loss_cls: 0.0670  mix_decode.d2.loss_mask: 0.5639  mix_decode.d2.loss_dice: 0.6177  mix_decode.d3.loss_cls: 0.0345  mix_decode.d3.loss_mask: 0.5717  mix_decode.d3.loss_dice: 0.6100  mix_decode.d4.loss_cls: 0.0726  mix_decode.d4.loss_mask: 0.5534  mix_decode.d4.loss_dice: 0.6041  mix_decode.d5.loss_cls: 0.0640  mix_decode.d5.loss_mask: 0.5606  mix_decode.d5.loss_dice: 0.5945  mix_decode.d6.loss_cls: 0.0626  mix_decode.d6.loss_mask: 0.5750  mix_decode.d6.loss_dice: 0.5904  mix_decode.d7.loss_cls: 0.0985  mix_decode.d7.loss_mask: 0.5598  mix_decode.d7.loss_dice: 0.5815  mix_decode.d8.loss_cls: 0.0382  mix_decode.d8.loss_mask: 0.5715  mix_decode.d8.loss_dice: 0.6054
2025/03/28 12:52:04 - mmengine - INFO - Iter(train) [11500/20000]  base_lr: 4.6299e-05 lr: 4.6299e-05  eta: 2:04:39  time: 1.0825  data_time: 0.0233  memory: 10777  loss: 28.4839  decode.loss_cls: 0.0214  decode.loss_mask: 0.9021  decode.loss_dice: 0.8265  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.9249  decode.d0.loss_dice: 0.8402  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 0.9051  decode.d1.loss_dice: 0.8320  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.9100  decode.d2.loss_dice: 0.8088  decode.d3.loss_cls: 0.0314  decode.d3.loss_mask: 0.9154  decode.d3.loss_dice: 0.8040  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.9039  decode.d4.loss_dice: 0.8228  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.9111  decode.d5.loss_dice: 0.8199  decode.d6.loss_cls: 0.0296  decode.d6.loss_mask: 0.9090  decode.d6.loss_dice: 0.7975  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.9089  decode.d7.loss_dice: 0.8023  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.9066  decode.d8.loss_dice: 0.8158  mix_decode.loss_cls: 0.0423  mix_decode.loss_mask: 0.4527  mix_decode.loss_dice: 0.5649  mix_decode.d0.loss_cls: 0.1170  mix_decode.d0.loss_mask: 0.4512  mix_decode.d0.loss_dice: 0.5989  mix_decode.d1.loss_cls: 0.0897  mix_decode.d1.loss_mask: 0.4613  mix_decode.d1.loss_dice: 0.5587  mix_decode.d2.loss_cls: 0.0866  mix_decode.d2.loss_mask: 0.4594  mix_decode.d2.loss_dice: 0.5432  mix_decode.d3.loss_cls: 0.0652  mix_decode.d3.loss_mask: 0.4483  mix_decode.d3.loss_dice: 0.5503  mix_decode.d4.loss_cls: 0.0599  mix_decode.d4.loss_mask: 0.4467  mix_decode.d4.loss_dice: 0.5733  mix_decode.d5.loss_cls: 0.0431  mix_decode.d5.loss_mask: 0.4479  mix_decode.d5.loss_dice: 0.5716  mix_decode.d6.loss_cls: 0.0452  mix_decode.d6.loss_mask: 0.4621  mix_decode.d6.loss_dice: 0.5689  mix_decode.d7.loss_cls: 0.0623  mix_decode.d7.loss_mask: 0.4538  mix_decode.d7.loss_dice: 0.5631  mix_decode.d8.loss_cls: 0.0560  mix_decode.d8.loss_mask: 0.4492  mix_decode.d8.loss_dice: 0.5712
2025/03/28 12:52:57 - mmengine - INFO - Iter(train) [11550/20000]  base_lr: 4.6054e-05 lr: 4.6054e-05  eta: 2:04:02  time: 1.0737  data_time: 0.0223  memory: 10775  loss: 29.4736  decode.loss_cls: 0.0068  decode.loss_mask: 1.0235  decode.loss_dice: 0.8100  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 1.0319  decode.d0.loss_dice: 0.7850  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 1.0274  decode.d1.loss_dice: 0.8148  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 1.0300  decode.d2.loss_dice: 0.8032  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 1.0241  decode.d3.loss_dice: 0.8067  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 1.0306  decode.d4.loss_dice: 0.8144  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 1.0223  decode.d5.loss_dice: 0.8014  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 1.0323  decode.d6.loss_dice: 0.8003  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 1.0253  decode.d7.loss_dice: 0.8053  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 1.0275  decode.d8.loss_dice: 0.7991  mix_decode.loss_cls: 0.0571  mix_decode.loss_mask: 0.4751  mix_decode.loss_dice: 0.5615  mix_decode.d0.loss_cls: 0.1091  mix_decode.d0.loss_mask: 0.4710  mix_decode.d0.loss_dice: 0.5711  mix_decode.d1.loss_cls: 0.0896  mix_decode.d1.loss_mask: 0.4765  mix_decode.d1.loss_dice: 0.5679  mix_decode.d2.loss_cls: 0.0426  mix_decode.d2.loss_mask: 0.4782  mix_decode.d2.loss_dice: 0.5580  mix_decode.d3.loss_cls: 0.0336  mix_decode.d3.loss_mask: 0.4797  mix_decode.d3.loss_dice: 0.5525  mix_decode.d4.loss_cls: 0.0239  mix_decode.d4.loss_mask: 0.4795  mix_decode.d4.loss_dice: 0.5505  mix_decode.d5.loss_cls: 0.0667  mix_decode.d5.loss_mask: 0.4826  mix_decode.d5.loss_dice: 0.5458  mix_decode.d6.loss_cls: 0.1120  mix_decode.d6.loss_mask: 0.4931  mix_decode.d6.loss_dice: 0.5432  mix_decode.d7.loss_cls: 0.0690  mix_decode.d7.loss_mask: 0.4920  mix_decode.d7.loss_dice: 0.5465  mix_decode.d8.loss_cls: 0.0447  mix_decode.d8.loss_mask: 0.4848  mix_decode.d8.loss_dice: 0.5526
2025/03/28 12:53:51 - mmengine - INFO - Iter(train) [11600/20000]  base_lr: 4.5808e-05 lr: 4.5808e-05  eta: 2:03:25  time: 1.0720  data_time: 0.0220  memory: 10769  loss: 26.3958  decode.loss_cls: 0.0332  decode.loss_mask: 0.7806  decode.loss_dice: 0.8040  decode.d0.loss_cls: 0.0841  decode.d0.loss_mask: 0.7835  decode.d0.loss_dice: 0.7730  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.7830  decode.d1.loss_dice: 0.8142  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.7868  decode.d2.loss_dice: 0.7751  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.7857  decode.d3.loss_dice: 0.7911  decode.d4.loss_cls: 0.0191  decode.d4.loss_mask: 0.7834  decode.d4.loss_dice: 0.7902  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.7832  decode.d5.loss_dice: 0.7846  decode.d6.loss_cls: 0.0164  decode.d6.loss_mask: 0.7841  decode.d6.loss_dice: 0.8157  decode.d7.loss_cls: 0.0318  decode.d7.loss_mask: 0.7850  decode.d7.loss_dice: 0.8161  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.7873  decode.d8.loss_dice: 0.8094  mix_decode.loss_cls: 0.0679  mix_decode.loss_mask: 0.3932  mix_decode.loss_dice: 0.5666  mix_decode.d0.loss_cls: 0.0969  mix_decode.d0.loss_mask: 0.3954  mix_decode.d0.loss_dice: 0.5806  mix_decode.d1.loss_cls: 0.0604  mix_decode.d1.loss_mask: 0.3925  mix_decode.d1.loss_dice: 0.5566  mix_decode.d2.loss_cls: 0.0568  mix_decode.d2.loss_mask: 0.3938  mix_decode.d2.loss_dice: 0.5510  mix_decode.d3.loss_cls: 0.0598  mix_decode.d3.loss_mask: 0.3961  mix_decode.d3.loss_dice: 0.5775  mix_decode.d4.loss_cls: 0.0604  mix_decode.d4.loss_mask: 0.3950  mix_decode.d4.loss_dice: 0.5650  mix_decode.d5.loss_cls: 0.0627  mix_decode.d5.loss_mask: 0.3989  mix_decode.d5.loss_dice: 0.5607  mix_decode.d6.loss_cls: 0.0619  mix_decode.d6.loss_mask: 0.3965  mix_decode.d6.loss_dice: 0.5610  mix_decode.d7.loss_cls: 0.0588  mix_decode.d7.loss_mask: 0.3988  mix_decode.d7.loss_dice: 0.5748  mix_decode.d8.loss_cls: 0.0553  mix_decode.d8.loss_mask: 0.3972  mix_decode.d8.loss_dice: 0.5724
2025/03/28 12:54:45 - mmengine - INFO - Iter(train) [11650/20000]  base_lr: 4.5563e-05 lr: 4.5563e-05  eta: 2:02:48  time: 1.0732  data_time: 0.0221  memory: 10774  loss: 30.8921  decode.loss_cls: 0.0128  decode.loss_mask: 0.9128  decode.loss_dice: 0.8517  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.9268  decode.d0.loss_dice: 0.8386  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.9088  decode.d1.loss_dice: 0.8608  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.9110  decode.d2.loss_dice: 0.8429  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.9242  decode.d3.loss_dice: 0.8434  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.9127  decode.d4.loss_dice: 0.8414  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.9121  decode.d5.loss_dice: 0.8469  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.9231  decode.d6.loss_dice: 0.8410  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.9127  decode.d7.loss_dice: 0.8476  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.9028  decode.d8.loss_dice: 0.8446  mix_decode.loss_cls: 0.1604  mix_decode.loss_mask: 0.4968  mix_decode.loss_dice: 0.6250  mix_decode.d0.loss_cls: 0.1668  mix_decode.d0.loss_mask: 0.5160  mix_decode.d0.loss_dice: 0.6679  mix_decode.d1.loss_cls: 0.1691  mix_decode.d1.loss_mask: 0.5027  mix_decode.d1.loss_dice: 0.6405  mix_decode.d2.loss_cls: 0.2031  mix_decode.d2.loss_mask: 0.5001  mix_decode.d2.loss_dice: 0.6354  mix_decode.d3.loss_cls: 0.1788  mix_decode.d3.loss_mask: 0.5049  mix_decode.d3.loss_dice: 0.6201  mix_decode.d4.loss_cls: 0.1574  mix_decode.d4.loss_mask: 0.5011  mix_decode.d4.loss_dice: 0.6297  mix_decode.d5.loss_cls: 0.1711  mix_decode.d5.loss_mask: 0.4975  mix_decode.d5.loss_dice: 0.6318  mix_decode.d6.loss_cls: 0.1580  mix_decode.d6.loss_mask: 0.5032  mix_decode.d6.loss_dice: 0.6301  mix_decode.d7.loss_cls: 0.1408  mix_decode.d7.loss_mask: 0.5194  mix_decode.d7.loss_dice: 0.6577  mix_decode.d8.loss_cls: 0.1740  mix_decode.d8.loss_mask: 0.5081  mix_decode.d8.loss_dice: 0.6274
2025/03/28 12:55:39 - mmengine - INFO - Iter(train) [11700/20000]  base_lr: 4.5317e-05 lr: 4.5317e-05  eta: 2:02:11  time: 1.0740  data_time: 0.0224  memory: 10780  loss: 26.5623  decode.loss_cls: 0.0471  decode.loss_mask: 0.7647  decode.loss_dice: 0.7572  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.7640  decode.d0.loss_dice: 0.7568  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.7683  decode.d1.loss_dice: 0.7794  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.7664  decode.d2.loss_dice: 0.7750  decode.d3.loss_cls: 0.0391  decode.d3.loss_mask: 0.7677  decode.d3.loss_dice: 0.7739  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.7718  decode.d4.loss_dice: 0.7707  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.7702  decode.d5.loss_dice: 0.7937  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.7738  decode.d6.loss_dice: 0.7714  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.7693  decode.d7.loss_dice: 0.7721  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.7690  decode.d8.loss_dice: 0.7879  mix_decode.loss_cls: 0.0776  mix_decode.loss_mask: 0.4349  mix_decode.loss_dice: 0.5552  mix_decode.d0.loss_cls: 0.1155  mix_decode.d0.loss_mask: 0.4325  mix_decode.d0.loss_dice: 0.5665  mix_decode.d1.loss_cls: 0.0644  mix_decode.d1.loss_mask: 0.4273  mix_decode.d1.loss_dice: 0.5489  mix_decode.d2.loss_cls: 0.0754  mix_decode.d2.loss_mask: 0.4292  mix_decode.d2.loss_dice: 0.5437  mix_decode.d3.loss_cls: 0.0490  mix_decode.d3.loss_mask: 0.4450  mix_decode.d3.loss_dice: 0.5518  mix_decode.d4.loss_cls: 0.0452  mix_decode.d4.loss_mask: 0.4411  mix_decode.d4.loss_dice: 0.5626  mix_decode.d5.loss_cls: 0.0652  mix_decode.d5.loss_mask: 0.4385  mix_decode.d5.loss_dice: 0.5596  mix_decode.d6.loss_cls: 0.0922  mix_decode.d6.loss_mask: 0.4395  mix_decode.d6.loss_dice: 0.5547  mix_decode.d7.loss_cls: 0.0960  mix_decode.d7.loss_mask: 0.4481  mix_decode.d7.loss_dice: 0.5596  mix_decode.d8.loss_cls: 0.0623  mix_decode.d8.loss_mask: 0.4423  mix_decode.d8.loss_dice: 0.5789
2025/03/28 12:56:32 - mmengine - INFO - Iter(train) [11750/20000]  base_lr: 4.5071e-05 lr: 4.5071e-05  eta: 2:01:33  time: 1.0870  data_time: 0.0241  memory: 10770  loss: 31.0117  decode.loss_cls: 0.0347  decode.loss_mask: 0.9190  decode.loss_dice: 0.8440  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.9217  decode.d0.loss_dice: 0.8326  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.9258  decode.d1.loss_dice: 0.8530  decode.d2.loss_cls: 0.1039  decode.d2.loss_mask: 0.9145  decode.d2.loss_dice: 0.8439  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.9138  decode.d3.loss_dice: 0.8452  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.9129  decode.d4.loss_dice: 0.8461  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.9156  decode.d5.loss_dice: 0.8458  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.9095  decode.d6.loss_dice: 0.8455  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.9122  decode.d7.loss_dice: 0.8709  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.9110  decode.d8.loss_dice: 0.8385  mix_decode.loss_cls: 0.1036  mix_decode.loss_mask: 0.5214  mix_decode.loss_dice: 0.6748  mix_decode.d0.loss_cls: 0.1223  mix_decode.d0.loss_mask: 0.4906  mix_decode.d0.loss_dice: 0.6843  mix_decode.d1.loss_cls: 0.1224  mix_decode.d1.loss_mask: 0.4817  mix_decode.d1.loss_dice: 0.6588  mix_decode.d2.loss_cls: 0.1301  mix_decode.d2.loss_mask: 0.4850  mix_decode.d2.loss_dice: 0.6632  mix_decode.d3.loss_cls: 0.1125  mix_decode.d3.loss_mask: 0.4791  mix_decode.d3.loss_dice: 0.6506  mix_decode.d4.loss_cls: 0.1134  mix_decode.d4.loss_mask: 0.4797  mix_decode.d4.loss_dice: 0.6655  mix_decode.d5.loss_cls: 0.1140  mix_decode.d5.loss_mask: 0.4815  mix_decode.d5.loss_dice: 0.6667  mix_decode.d6.loss_cls: 0.1407  mix_decode.d6.loss_mask: 0.4843  mix_decode.d6.loss_dice: 0.6644  mix_decode.d7.loss_cls: 0.1107  mix_decode.d7.loss_mask: 0.4782  mix_decode.d7.loss_dice: 0.6665  mix_decode.d8.loss_cls: 0.1129  mix_decode.d8.loss_mask: 0.4825  mix_decode.d8.loss_dice: 0.6662
2025/03/28 12:57:26 - mmengine - INFO - Iter(train) [11800/20000]  base_lr: 4.4825e-05 lr: 4.4825e-05  eta: 2:00:56  time: 1.0798  data_time: 0.0236  memory: 10773  loss: 30.0048  decode.loss_cls: 0.0202  decode.loss_mask: 0.9553  decode.loss_dice: 0.8079  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.9582  decode.d0.loss_dice: 0.8019  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.9569  decode.d1.loss_dice: 0.8231  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.9481  decode.d2.loss_dice: 0.8091  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.9544  decode.d3.loss_dice: 0.8115  decode.d4.loss_cls: 0.0212  decode.d4.loss_mask: 0.9514  decode.d4.loss_dice: 0.8085  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.9519  decode.d5.loss_dice: 0.8144  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.9520  decode.d6.loss_dice: 0.8097  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.9504  decode.d7.loss_dice: 0.8121  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.9547  decode.d8.loss_dice: 0.8130  mix_decode.loss_cls: 0.0392  mix_decode.loss_mask: 0.5381  mix_decode.loss_dice: 0.6125  mix_decode.d0.loss_cls: 0.0916  mix_decode.d0.loss_mask: 0.5422  mix_decode.d0.loss_dice: 0.6368  mix_decode.d1.loss_cls: 0.0541  mix_decode.d1.loss_mask: 0.5380  mix_decode.d1.loss_dice: 0.6102  mix_decode.d2.loss_cls: 0.0914  mix_decode.d2.loss_mask: 0.5353  mix_decode.d2.loss_dice: 0.6073  mix_decode.d3.loss_cls: 0.0617  mix_decode.d3.loss_mask: 0.5386  mix_decode.d3.loss_dice: 0.5978  mix_decode.d4.loss_cls: 0.0579  mix_decode.d4.loss_mask: 0.5391  mix_decode.d4.loss_dice: 0.6034  mix_decode.d5.loss_cls: 0.0590  mix_decode.d5.loss_mask: 0.5379  mix_decode.d5.loss_dice: 0.6014  mix_decode.d6.loss_cls: 0.0603  mix_decode.d6.loss_mask: 0.5428  mix_decode.d6.loss_dice: 0.6062  mix_decode.d7.loss_cls: 0.0457  mix_decode.d7.loss_mask: 0.5407  mix_decode.d7.loss_dice: 0.6126  mix_decode.d8.loss_cls: 0.0394  mix_decode.d8.loss_mask: 0.5415  mix_decode.d8.loss_dice: 0.6065
2025/03/28 12:58:20 - mmengine - INFO - Iter(train) [11850/20000]  base_lr: 4.4579e-05 lr: 4.4579e-05  eta: 2:00:18  time: 1.0793  data_time: 0.0233  memory: 10772  loss: 28.8114  decode.loss_cls: 0.0063  decode.loss_mask: 0.8612  decode.loss_dice: 0.7721  decode.d0.loss_cls: 0.0891  decode.d0.loss_mask: 0.8735  decode.d0.loss_dice: 0.7690  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.8588  decode.d1.loss_dice: 0.7687  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.8618  decode.d2.loss_dice: 0.7746  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.8620  decode.d3.loss_dice: 0.7697  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.8660  decode.d4.loss_dice: 0.7730  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.8604  decode.d5.loss_dice: 0.7735  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.8575  decode.d6.loss_dice: 0.7709  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.8557  decode.d7.loss_dice: 0.7789  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.8614  decode.d8.loss_dice: 0.7727  mix_decode.loss_cls: 0.0709  mix_decode.loss_mask: 0.4828  mix_decode.loss_dice: 0.6661  mix_decode.d0.loss_cls: 0.1102  mix_decode.d0.loss_mask: 0.4789  mix_decode.d0.loss_dice: 0.6857  mix_decode.d1.loss_cls: 0.1172  mix_decode.d1.loss_mask: 0.4835  mix_decode.d1.loss_dice: 0.6497  mix_decode.d2.loss_cls: 0.1047  mix_decode.d2.loss_mask: 0.4834  mix_decode.d2.loss_dice: 0.6390  mix_decode.d3.loss_cls: 0.0996  mix_decode.d3.loss_mask: 0.4795  mix_decode.d3.loss_dice: 0.6421  mix_decode.d4.loss_cls: 0.0826  mix_decode.d4.loss_mask: 0.4852  mix_decode.d4.loss_dice: 0.6486  mix_decode.d5.loss_cls: 0.0928  mix_decode.d5.loss_mask: 0.4842  mix_decode.d5.loss_dice: 0.6361  mix_decode.d6.loss_cls: 0.0783  mix_decode.d6.loss_mask: 0.4842  mix_decode.d6.loss_dice: 0.6710  mix_decode.d7.loss_cls: 0.0909  mix_decode.d7.loss_mask: 0.4769  mix_decode.d7.loss_dice: 0.6612  mix_decode.d8.loss_cls: 0.0937  mix_decode.d8.loss_mask: 0.4746  mix_decode.d8.loss_dice: 0.6498
2025/03/28 12:59:14 - mmengine - INFO - Iter(train) [11900/20000]  base_lr: 4.4333e-05 lr: 4.4333e-05  eta: 1:59:40  time: 1.0778  data_time: 0.0226  memory: 10772  loss: 31.6777  decode.loss_cls: 0.0600  decode.loss_mask: 1.0543  decode.loss_dice: 0.9161  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 1.0622  decode.d0.loss_dice: 0.9021  decode.d1.loss_cls: 0.1206  decode.d1.loss_mask: 1.0635  decode.d1.loss_dice: 0.9235  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 1.0605  decode.d2.loss_dice: 0.9230  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 1.0633  decode.d3.loss_dice: 0.9154  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 1.0631  decode.d4.loss_dice: 0.9390  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 1.0569  decode.d5.loss_dice: 0.9127  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 1.0517  decode.d6.loss_dice: 0.9203  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 1.0502  decode.d7.loss_dice: 0.9148  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 1.0535  decode.d8.loss_dice: 0.9138  mix_decode.loss_cls: 0.0736  mix_decode.loss_mask: 0.4685  mix_decode.loss_dice: 0.5640  mix_decode.d0.loss_cls: 0.0978  mix_decode.d0.loss_mask: 0.4711  mix_decode.d0.loss_dice: 0.5789  mix_decode.d1.loss_cls: 0.0810  mix_decode.d1.loss_mask: 0.4600  mix_decode.d1.loss_dice: 0.5637  mix_decode.d2.loss_cls: 0.0935  mix_decode.d2.loss_mask: 0.4625  mix_decode.d2.loss_dice: 0.5712  mix_decode.d3.loss_cls: 0.0808  mix_decode.d3.loss_mask: 0.4667  mix_decode.d3.loss_dice: 0.5621  mix_decode.d4.loss_cls: 0.0765  mix_decode.d4.loss_mask: 0.4674  mix_decode.d4.loss_dice: 0.5696  mix_decode.d5.loss_cls: 0.0773  mix_decode.d5.loss_mask: 0.4652  mix_decode.d5.loss_dice: 0.5719  mix_decode.d6.loss_cls: 0.0815  mix_decode.d6.loss_mask: 0.4676  mix_decode.d6.loss_dice: 0.5743  mix_decode.d7.loss_cls: 0.0816  mix_decode.d7.loss_mask: 0.4644  mix_decode.d7.loss_dice: 0.5777  mix_decode.d8.loss_cls: 0.0792  mix_decode.d8.loss_mask: 0.4622  mix_decode.d8.loss_dice: 0.5687
2025/03/28 13:00:08 - mmengine - INFO - Iter(train) [11950/20000]  base_lr: 4.4087e-05 lr: 4.4087e-05  eta: 1:59:02  time: 1.0776  data_time: 0.0227  memory: 10775  loss: 34.1552  decode.loss_cls: 0.0149  decode.loss_mask: 1.0547  decode.loss_dice: 0.8919  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 1.0674  decode.d0.loss_dice: 0.8653  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 1.0546  decode.d1.loss_dice: 0.8885  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 1.0511  decode.d2.loss_dice: 0.8716  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 1.0558  decode.d3.loss_dice: 0.8759  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 1.0590  decode.d4.loss_dice: 0.8822  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 1.0502  decode.d5.loss_dice: 0.8840  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 1.0583  decode.d6.loss_dice: 0.8777  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 1.0566  decode.d7.loss_dice: 0.8866  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 1.0547  decode.d8.loss_dice: 0.8965  mix_decode.loss_cls: 0.0747  mix_decode.loss_mask: 0.5907  mix_decode.loss_dice: 0.7722  mix_decode.d0.loss_cls: 0.1299  mix_decode.d0.loss_mask: 0.5889  mix_decode.d0.loss_dice: 0.7869  mix_decode.d1.loss_cls: 0.1346  mix_decode.d1.loss_mask: 0.5715  mix_decode.d1.loss_dice: 0.7755  mix_decode.d2.loss_cls: 0.0926  mix_decode.d2.loss_mask: 0.5789  mix_decode.d2.loss_dice: 0.7710  mix_decode.d3.loss_cls: 0.1086  mix_decode.d3.loss_mask: 0.5903  mix_decode.d3.loss_dice: 0.7496  mix_decode.d4.loss_cls: 0.0892  mix_decode.d4.loss_mask: 0.6017  mix_decode.d4.loss_dice: 0.7682  mix_decode.d5.loss_cls: 0.0678  mix_decode.d5.loss_mask: 0.6021  mix_decode.d5.loss_dice: 0.7740  mix_decode.d6.loss_cls: 0.0997  mix_decode.d6.loss_mask: 0.5773  mix_decode.d6.loss_dice: 0.7731  mix_decode.d7.loss_cls: 0.0766  mix_decode.d7.loss_mask: 0.5960  mix_decode.d7.loss_dice: 0.7820  mix_decode.d8.loss_cls: 0.0715  mix_decode.d8.loss_mask: 0.5867  mix_decode.d8.loss_dice: 0.7559
2025/03/28 13:01:02 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 13:01:02 - mmengine - INFO - Iter(train) [12000/20000]  base_lr: 4.3840e-05 lr: 4.3840e-05  eta: 1:58:25  time: 1.0775  data_time: 0.0225  memory: 10775  loss: 27.0033  decode.loss_cls: 0.0057  decode.loss_mask: 0.8357  decode.loss_dice: 0.7831  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.8518  decode.d0.loss_dice: 0.7803  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 0.8359  decode.d1.loss_dice: 0.7841  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.8346  decode.d2.loss_dice: 0.7764  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.8351  decode.d3.loss_dice: 0.7871  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.8357  decode.d4.loss_dice: 0.7944  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.8394  decode.d5.loss_dice: 0.7849  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.8378  decode.d6.loss_dice: 0.7887  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.8412  decode.d7.loss_dice: 0.7901  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.8439  decode.d8.loss_dice: 0.7913  mix_decode.loss_cls: 0.0626  mix_decode.loss_mask: 0.4299  mix_decode.loss_dice: 0.5594  mix_decode.d0.loss_cls: 0.0757  mix_decode.d0.loss_mask: 0.4378  mix_decode.d0.loss_dice: 0.5924  mix_decode.d1.loss_cls: 0.0628  mix_decode.d1.loss_mask: 0.4397  mix_decode.d1.loss_dice: 0.5632  mix_decode.d2.loss_cls: 0.0702  mix_decode.d2.loss_mask: 0.4341  mix_decode.d2.loss_dice: 0.5608  mix_decode.d3.loss_cls: 0.0655  mix_decode.d3.loss_mask: 0.4368  mix_decode.d3.loss_dice: 0.5571  mix_decode.d4.loss_cls: 0.0609  mix_decode.d4.loss_mask: 0.4386  mix_decode.d4.loss_dice: 0.5639  mix_decode.d5.loss_cls: 0.0710  mix_decode.d5.loss_mask: 0.4318  mix_decode.d5.loss_dice: 0.5568  mix_decode.d6.loss_cls: 0.0561  mix_decode.d6.loss_mask: 0.4389  mix_decode.d6.loss_dice: 0.5554  mix_decode.d7.loss_cls: 0.0638  mix_decode.d7.loss_mask: 0.4224  mix_decode.d7.loss_dice: 0.5487  mix_decode.d8.loss_cls: 0.0638  mix_decode.d8.loss_mask: 0.4310  mix_decode.d8.loss_dice: 0.5597
2025/03/28 13:01:02 - mmengine - INFO - Saving checkpoint at 12000 iterations
2025/03/28 13:01:07 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0847  data_time: 0.0018  memory: 3070  
2025/03/28 13:01:12 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:43  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:16 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:38  time: 0.0850  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:20 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:34  time: 0.0849  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:24 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0850  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:29 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:25  time: 0.0851  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:33 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:21  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 13:01:37 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:17  time: 0.0849  data_time: 0.0017  memory: 3070  
2025/03/28 13:01:41 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0849  data_time: 0.0018  memory: 3070  
2025/03/28 13:01:46 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:08  time: 0.0849  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:50 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:04  time: 0.0849  data_time: 0.0019  memory: 3070  
2025/03/28 13:01:54 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:00  time: 0.0882  data_time: 0.0020  memory: 3070  
2025/03/28 13:01:59 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:03 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:52  time: 0.0854  data_time: 0.0019  memory: 3070  
2025/03/28 13:02:07 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:47  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:11 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:43  time: 0.0854  data_time: 0.0020  memory: 3070  
2025/03/28 13:02:16 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:20 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:24 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:30  time: 0.0849  data_time: 0.0017  memory: 3070  
2025/03/28 13:02:28 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0851  data_time: 0.0019  memory: 3070  
2025/03/28 13:02:33 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:37 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0858  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:41 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:13  time: 0.0853  data_time: 0.0017  memory: 3070  
2025/03/28 13:02:46 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:50 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:54 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 13:02:58 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:03 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0853  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:07 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0855  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:11 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 13:03:16 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:20 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0852  data_time: 0.0019  memory: 3070  
2025/03/28 13:03:24 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0853  data_time: 0.0019  memory: 3070  
2025/03/28 13:03:28 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:26  time: 0.0851  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:33 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0851  data_time: 0.0019  memory: 3070  
2025/03/28 13:03:37 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:41 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0850  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:45 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0850  data_time: 0.0019  memory: 3070  
2025/03/28 13:03:50 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0849  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:54 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0852  data_time: 0.0018  memory: 3070  
2025/03/28 13:03:55 - mmengine - INFO - per class results:
2025/03/28 13:03:55 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 75.13 | 90.59 |
|      building      | 88.66 | 95.52 |
|   low_vegetation   | 63.35 | 90.47 |
|        tree        | 47.14 | 50.02 |
|        car         | 76.72 | 89.93 |
|      clutter       |  9.51 | 10.05 |
+--------------------+-------+-------+
2025/03/28 13:03:55 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 81.0500  mIoU: 60.0800  mAcc: 71.1000  data_time: 0.0019  time: 0.0854
2025/03/28 13:04:49 - mmengine - INFO - Iter(train) [12050/20000]  base_lr: 4.3594e-05 lr: 4.3594e-05  eta: 1:57:47  time: 1.0770  data_time: 0.0227  memory: 10779  loss: 30.9430  decode.loss_cls: 0.0115  decode.loss_mask: 1.0909  decode.loss_dice: 0.9102  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 1.0989  decode.d0.loss_dice: 0.9438  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 1.0934  decode.d1.loss_dice: 0.9117  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 1.0803  decode.d2.loss_dice: 0.8856  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 1.0774  decode.d3.loss_dice: 0.8986  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 1.0714  decode.d4.loss_dice: 0.8906  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 1.0783  decode.d5.loss_dice: 0.8865  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 1.0801  decode.d6.loss_dice: 0.8772  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 1.0945  decode.d7.loss_dice: 0.9033  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 1.0958  decode.d8.loss_dice: 0.9049  mix_decode.loss_cls: 0.0846  mix_decode.loss_mask: 0.4543  mix_decode.loss_dice: 0.5018  mix_decode.d0.loss_cls: 0.1019  mix_decode.d0.loss_mask: 0.4616  mix_decode.d0.loss_dice: 0.5512  mix_decode.d1.loss_cls: 0.1146  mix_decode.d1.loss_mask: 0.4597  mix_decode.d1.loss_dice: 0.5202  mix_decode.d2.loss_cls: 0.0993  mix_decode.d2.loss_mask: 0.4556  mix_decode.d2.loss_dice: 0.5085  mix_decode.d3.loss_cls: 0.0750  mix_decode.d3.loss_mask: 0.4589  mix_decode.d3.loss_dice: 0.5018  mix_decode.d4.loss_cls: 0.1220  mix_decode.d4.loss_mask: 0.4509  mix_decode.d4.loss_dice: 0.5067  mix_decode.d5.loss_cls: 0.0723  mix_decode.d5.loss_mask: 0.4632  mix_decode.d5.loss_dice: 0.5119  mix_decode.d6.loss_cls: 0.1266  mix_decode.d6.loss_mask: 0.4490  mix_decode.d6.loss_dice: 0.4906  mix_decode.d7.loss_cls: 0.1169  mix_decode.d7.loss_mask: 0.4453  mix_decode.d7.loss_dice: 0.4827  mix_decode.d8.loss_cls: 0.1009  mix_decode.d8.loss_mask: 0.4503  mix_decode.d8.loss_dice: 0.5175
2025/03/28 13:05:43 - mmengine - INFO - Iter(train) [12100/20000]  base_lr: 4.3347e-05 lr: 4.3347e-05  eta: 1:57:08  time: 1.0826  data_time: 0.0225  memory: 10774  loss: 29.1697  decode.loss_cls: 0.0084  decode.loss_mask: 0.8956  decode.loss_dice: 0.7731  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.8971  decode.d0.loss_dice: 0.7766  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.8995  decode.d1.loss_dice: 0.7847  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.9029  decode.d2.loss_dice: 0.7829  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.8979  decode.d3.loss_dice: 0.7874  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.8916  decode.d4.loss_dice: 0.7887  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.8974  decode.d5.loss_dice: 0.7730  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.8898  decode.d6.loss_dice: 0.7799  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.9030  decode.d7.loss_dice: 0.7818  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.8967  decode.d8.loss_dice: 0.7794  mix_decode.loss_cls: 0.0520  mix_decode.loss_mask: 0.5725  mix_decode.loss_dice: 0.5835  mix_decode.d0.loss_cls: 0.1195  mix_decode.d0.loss_mask: 0.5787  mix_decode.d0.loss_dice: 0.6046  mix_decode.d1.loss_cls: 0.0867  mix_decode.d1.loss_mask: 0.5650  mix_decode.d1.loss_dice: 0.5806  mix_decode.d2.loss_cls: 0.0831  mix_decode.d2.loss_mask: 0.5635  mix_decode.d2.loss_dice: 0.5753  mix_decode.d3.loss_cls: 0.0532  mix_decode.d3.loss_mask: 0.5719  mix_decode.d3.loss_dice: 0.5833  mix_decode.d4.loss_cls: 0.0491  mix_decode.d4.loss_mask: 0.5736  mix_decode.d4.loss_dice: 0.5960  mix_decode.d5.loss_cls: 0.0484  mix_decode.d5.loss_mask: 0.5753  mix_decode.d5.loss_dice: 0.5883  mix_decode.d6.loss_cls: 0.0545  mix_decode.d6.loss_mask: 0.5717  mix_decode.d6.loss_dice: 0.5887  mix_decode.d7.loss_cls: 0.0722  mix_decode.d7.loss_mask: 0.5664  mix_decode.d7.loss_dice: 0.5839  mix_decode.d8.loss_cls: 0.0459  mix_decode.d8.loss_mask: 0.5679  mix_decode.d8.loss_dice: 0.5761
2025/03/28 13:06:37 - mmengine - INFO - Iter(train) [12150/20000]  base_lr: 4.3100e-05 lr: 4.3100e-05  eta: 1:56:30  time: 1.0768  data_time: 0.0226  memory: 10782  loss: 26.2339  decode.loss_cls: 0.0113  decode.loss_mask: 0.8014  decode.loss_dice: 0.7373  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.7993  decode.d0.loss_dice: 0.7272  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.8020  decode.d1.loss_dice: 0.7151  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.8049  decode.d2.loss_dice: 0.7177  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.8063  decode.d3.loss_dice: 0.7429  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.8024  decode.d4.loss_dice: 0.7354  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.8013  decode.d5.loss_dice: 0.7095  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.8005  decode.d6.loss_dice: 0.7432  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.8008  decode.d7.loss_dice: 0.7059  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.8012  decode.d8.loss_dice: 0.7140  mix_decode.loss_cls: 0.0966  mix_decode.loss_mask: 0.3939  mix_decode.loss_dice: 0.5960  mix_decode.d0.loss_cls: 0.1208  mix_decode.d0.loss_mask: 0.4028  mix_decode.d0.loss_dice: 0.6067  mix_decode.d1.loss_cls: 0.0689  mix_decode.d1.loss_mask: 0.4072  mix_decode.d1.loss_dice: 0.5946  mix_decode.d2.loss_cls: 0.0654  mix_decode.d2.loss_mask: 0.4062  mix_decode.d2.loss_dice: 0.6080  mix_decode.d3.loss_cls: 0.0715  mix_decode.d3.loss_mask: 0.3999  mix_decode.d3.loss_dice: 0.5880  mix_decode.d4.loss_cls: 0.0718  mix_decode.d4.loss_mask: 0.4014  mix_decode.d4.loss_dice: 0.6090  mix_decode.d5.loss_cls: 0.0616  mix_decode.d5.loss_mask: 0.3967  mix_decode.d5.loss_dice: 0.5849  mix_decode.d6.loss_cls: 0.0735  mix_decode.d6.loss_mask: 0.3963  mix_decode.d6.loss_dice: 0.5927  mix_decode.d7.loss_cls: 0.0583  mix_decode.d7.loss_mask: 0.4010  mix_decode.d7.loss_dice: 0.6102  mix_decode.d8.loss_cls: 0.0938  mix_decode.d8.loss_mask: 0.3940  mix_decode.d8.loss_dice: 0.5780
2025/03/28 13:07:31 - mmengine - INFO - Iter(train) [12200/20000]  base_lr: 4.2853e-05 lr: 4.2853e-05  eta: 1:55:51  time: 1.0762  data_time: 0.0228  memory: 10771  loss: 28.2969  decode.loss_cls: 0.0521  decode.loss_mask: 0.8299  decode.loss_dice: 0.7644  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.8377  decode.d0.loss_dice: 0.7957  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.8285  decode.d1.loss_dice: 0.7798  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.8273  decode.d2.loss_dice: 0.7724  decode.d3.loss_cls: 0.0423  decode.d3.loss_mask: 0.8288  decode.d3.loss_dice: 0.7924  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.8300  decode.d4.loss_dice: 0.7693  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.8227  decode.d5.loss_dice: 0.7846  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.8261  decode.d6.loss_dice: 0.7815  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.8254  decode.d7.loss_dice: 0.7761  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.8308  decode.d8.loss_dice: 0.7775  mix_decode.loss_cls: 0.1226  mix_decode.loss_mask: 0.4990  mix_decode.loss_dice: 0.5548  mix_decode.d0.loss_cls: 0.1152  mix_decode.d0.loss_mask: 0.4896  mix_decode.d0.loss_dice: 0.5696  mix_decode.d1.loss_cls: 0.1409  mix_decode.d1.loss_mask: 0.4875  mix_decode.d1.loss_dice: 0.5423  mix_decode.d2.loss_cls: 0.1218  mix_decode.d2.loss_mask: 0.4887  mix_decode.d2.loss_dice: 0.5584  mix_decode.d3.loss_cls: 0.1300  mix_decode.d3.loss_mask: 0.4877  mix_decode.d3.loss_dice: 0.5481  mix_decode.d4.loss_cls: 0.1157  mix_decode.d4.loss_mask: 0.4858  mix_decode.d4.loss_dice: 0.5467  mix_decode.d5.loss_cls: 0.1088  mix_decode.d5.loss_mask: 0.4873  mix_decode.d5.loss_dice: 0.5581  mix_decode.d6.loss_cls: 0.0824  mix_decode.d6.loss_mask: 0.4912  mix_decode.d6.loss_dice: 0.5694  mix_decode.d7.loss_cls: 0.1101  mix_decode.d7.loss_mask: 0.4926  mix_decode.d7.loss_dice: 0.5609  mix_decode.d8.loss_cls: 0.1231  mix_decode.d8.loss_mask: 0.4966  mix_decode.d8.loss_dice: 0.5622
2025/03/28 13:08:25 - mmengine - INFO - Iter(train) [12250/20000]  base_lr: 4.2605e-05 lr: 4.2605e-05  eta: 1:55:13  time: 1.0888  data_time: 0.0225  memory: 10772  loss: 26.5564  decode.loss_cls: 0.0135  decode.loss_mask: 0.8057  decode.loss_dice: 0.7571  decode.d0.loss_cls: 0.0620  decode.d0.loss_mask: 0.8049  decode.d0.loss_dice: 0.7632  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.8003  decode.d1.loss_dice: 0.7686  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.8074  decode.d2.loss_dice: 0.7693  decode.d3.loss_cls: 0.0287  decode.d3.loss_mask: 0.8075  decode.d3.loss_dice: 0.7657  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.8040  decode.d4.loss_dice: 0.7659  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.8027  decode.d5.loss_dice: 0.7724  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.8092  decode.d6.loss_dice: 0.7864  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.8078  decode.d7.loss_dice: 0.7512  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.8064  decode.d8.loss_dice: 0.7684  mix_decode.loss_cls: 0.0673  mix_decode.loss_mask: 0.4301  mix_decode.loss_dice: 0.5307  mix_decode.d0.loss_cls: 0.1135  mix_decode.d0.loss_mask: 0.4269  mix_decode.d0.loss_dice: 0.5657  mix_decode.d1.loss_cls: 0.0904  mix_decode.d1.loss_mask: 0.4367  mix_decode.d1.loss_dice: 0.5143  mix_decode.d2.loss_cls: 0.0729  mix_decode.d2.loss_mask: 0.4336  mix_decode.d2.loss_dice: 0.5344  mix_decode.d3.loss_cls: 0.1045  mix_decode.d3.loss_mask: 0.4261  mix_decode.d3.loss_dice: 0.5362  mix_decode.d4.loss_cls: 0.0639  mix_decode.d4.loss_mask: 0.4321  mix_decode.d4.loss_dice: 0.5493  mix_decode.d5.loss_cls: 0.0819  mix_decode.d5.loss_mask: 0.4270  mix_decode.d5.loss_dice: 0.5474  mix_decode.d6.loss_cls: 0.0562  mix_decode.d6.loss_mask: 0.4321  mix_decode.d6.loss_dice: 0.5463  mix_decode.d7.loss_cls: 0.0694  mix_decode.d7.loss_mask: 0.4345  mix_decode.d7.loss_dice: 0.5320  mix_decode.d8.loss_cls: 0.0705  mix_decode.d8.loss_mask: 0.4285  mix_decode.d8.loss_dice: 0.5354
2025/03/28 13:09:19 - mmengine - INFO - Iter(train) [12300/20000]  base_lr: 4.2358e-05 lr: 4.2358e-05  eta: 1:54:34  time: 1.0734  data_time: 0.0233  memory: 10767  loss: 30.4208  decode.loss_cls: 0.0327  decode.loss_mask: 0.9366  decode.loss_dice: 0.8685  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.9470  decode.d0.loss_dice: 0.8464  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.9413  decode.d1.loss_dice: 0.8786  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.9493  decode.d2.loss_dice: 0.8717  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.9418  decode.d3.loss_dice: 0.8464  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.9463  decode.d4.loss_dice: 0.8534  decode.d5.loss_cls: 0.0223  decode.d5.loss_mask: 0.9389  decode.d5.loss_dice: 0.8661  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.9439  decode.d6.loss_dice: 0.8591  decode.d7.loss_cls: 0.0259  decode.d7.loss_mask: 0.9395  decode.d7.loss_dice: 0.8710  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.9430  decode.d8.loss_dice: 0.8653  mix_decode.loss_cls: 0.1284  mix_decode.loss_mask: 0.4746  mix_decode.loss_dice: 0.5968  mix_decode.d0.loss_cls: 0.1738  mix_decode.d0.loss_mask: 0.4802  mix_decode.d0.loss_dice: 0.6072  mix_decode.d1.loss_cls: 0.1768  mix_decode.d1.loss_mask: 0.4511  mix_decode.d1.loss_dice: 0.5852  mix_decode.d2.loss_cls: 0.1188  mix_decode.d2.loss_mask: 0.4726  mix_decode.d2.loss_dice: 0.5955  mix_decode.d3.loss_cls: 0.0726  mix_decode.d3.loss_mask: 0.4871  mix_decode.d3.loss_dice: 0.5959  mix_decode.d4.loss_cls: 0.1367  mix_decode.d4.loss_mask: 0.4643  mix_decode.d4.loss_dice: 0.5988  mix_decode.d5.loss_cls: 0.1007  mix_decode.d5.loss_mask: 0.4806  mix_decode.d5.loss_dice: 0.5977  mix_decode.d6.loss_cls: 0.1667  mix_decode.d6.loss_mask: 0.4700  mix_decode.d6.loss_dice: 0.5743  mix_decode.d7.loss_cls: 0.1333  mix_decode.d7.loss_mask: 0.4816  mix_decode.d7.loss_dice: 0.5959  mix_decode.d8.loss_cls: 0.1020  mix_decode.d8.loss_mask: 0.4862  mix_decode.d8.loss_dice: 0.6163
2025/03/28 13:10:13 - mmengine - INFO - Iter(train) [12350/20000]  base_lr: 4.2110e-05 lr: 4.2110e-05  eta: 1:53:55  time: 1.0767  data_time: 0.0228  memory: 10782  loss: 28.4567  decode.loss_cls: 0.0366  decode.loss_mask: 0.8554  decode.loss_dice: 0.8420  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.8482  decode.d0.loss_dice: 0.8658  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 0.8521  decode.d1.loss_dice: 0.8068  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.8522  decode.d2.loss_dice: 0.8223  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.8540  decode.d3.loss_dice: 0.8298  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 0.8600  decode.d4.loss_dice: 0.8373  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.8578  decode.d5.loss_dice: 0.8361  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.8585  decode.d6.loss_dice: 0.8111  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.8533  decode.d7.loss_dice: 0.8396  decode.d8.loss_cls: 0.0713  decode.d8.loss_mask: 0.8591  decode.d8.loss_dice: 0.8162  mix_decode.loss_cls: 0.0541  mix_decode.loss_mask: 0.4706  mix_decode.loss_dice: 0.5522  mix_decode.d0.loss_cls: 0.0793  mix_decode.d0.loss_mask: 0.4720  mix_decode.d0.loss_dice: 0.5848  mix_decode.d1.loss_cls: 0.0730  mix_decode.d1.loss_mask: 0.4738  mix_decode.d1.loss_dice: 0.5581  mix_decode.d2.loss_cls: 0.0611  mix_decode.d2.loss_mask: 0.4802  mix_decode.d2.loss_dice: 0.5632  mix_decode.d3.loss_cls: 0.0604  mix_decode.d3.loss_mask: 0.4759  mix_decode.d3.loss_dice: 0.5650  mix_decode.d4.loss_cls: 0.0420  mix_decode.d4.loss_mask: 0.4736  mix_decode.d4.loss_dice: 0.5710  mix_decode.d5.loss_cls: 0.0563  mix_decode.d5.loss_mask: 0.4748  mix_decode.d5.loss_dice: 0.5575  mix_decode.d6.loss_cls: 0.0945  mix_decode.d6.loss_mask: 0.4731  mix_decode.d6.loss_dice: 0.5685  mix_decode.d7.loss_cls: 0.0704  mix_decode.d7.loss_mask: 0.4738  mix_decode.d7.loss_dice: 0.5671  mix_decode.d8.loss_cls: 0.0489  mix_decode.d8.loss_mask: 0.4755  mix_decode.d8.loss_dice: 0.5700
2025/03/28 13:11:06 - mmengine - INFO - Iter(train) [12400/20000]  base_lr: 4.1862e-05 lr: 4.1862e-05  eta: 1:53:16  time: 1.0760  data_time: 0.0224  memory: 10770  loss: 29.9523  decode.loss_cls: 0.0569  decode.loss_mask: 0.9637  decode.loss_dice: 0.8146  decode.d0.loss_cls: 0.1236  decode.d0.loss_mask: 0.9660  decode.d0.loss_dice: 0.8223  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.9554  decode.d1.loss_dice: 0.8294  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.9605  decode.d2.loss_dice: 0.8226  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.9644  decode.d3.loss_dice: 0.8503  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.9601  decode.d4.loss_dice: 0.8345  decode.d5.loss_cls: 0.0530  decode.d5.loss_mask: 0.9617  decode.d5.loss_dice: 0.8214  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.9610  decode.d6.loss_dice: 0.8082  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.9663  decode.d7.loss_dice: 0.8017  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.9658  decode.d8.loss_dice: 0.8204  mix_decode.loss_cls: 0.1396  mix_decode.loss_mask: 0.4449  mix_decode.loss_dice: 0.5666  mix_decode.d0.loss_cls: 0.1016  mix_decode.d0.loss_mask: 0.4590  mix_decode.d0.loss_dice: 0.6368  mix_decode.d1.loss_cls: 0.1120  mix_decode.d1.loss_mask: 0.4430  mix_decode.d1.loss_dice: 0.5804  mix_decode.d2.loss_cls: 0.1202  mix_decode.d2.loss_mask: 0.4565  mix_decode.d2.loss_dice: 0.5747  mix_decode.d3.loss_cls: 0.0892  mix_decode.d3.loss_mask: 0.4554  mix_decode.d3.loss_dice: 0.5700  mix_decode.d4.loss_cls: 0.1166  mix_decode.d4.loss_mask: 0.4423  mix_decode.d4.loss_dice: 0.5822  mix_decode.d5.loss_cls: 0.1115  mix_decode.d5.loss_mask: 0.4476  mix_decode.d5.loss_dice: 0.5860  mix_decode.d6.loss_cls: 0.0800  mix_decode.d6.loss_mask: 0.4521  mix_decode.d6.loss_dice: 0.5837  mix_decode.d7.loss_cls: 0.0965  mix_decode.d7.loss_mask: 0.4458  mix_decode.d7.loss_dice: 0.5895  mix_decode.d8.loss_cls: 0.1194  mix_decode.d8.loss_mask: 0.4380  mix_decode.d8.loss_dice: 0.5780
2025/03/28 13:12:00 - mmengine - INFO - Iter(train) [12450/20000]  base_lr: 4.1615e-05 lr: 4.1615e-05  eta: 1:52:37  time: 1.0743  data_time: 0.0224  memory: 10772  loss: 32.3751  decode.loss_cls: 0.0988  decode.loss_mask: 0.9422  decode.loss_dice: 0.8994  decode.d0.loss_cls: 0.1199  decode.d0.loss_mask: 0.9497  decode.d0.loss_dice: 0.8726  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.9445  decode.d1.loss_dice: 0.8908  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.9449  decode.d2.loss_dice: 0.8830  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.9449  decode.d3.loss_dice: 0.8815  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.9438  decode.d4.loss_dice: 0.9096  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.9480  decode.d5.loss_dice: 0.8796  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.9519  decode.d6.loss_dice: 0.8804  decode.d7.loss_cls: 0.0862  decode.d7.loss_mask: 0.9435  decode.d7.loss_dice: 0.8455  decode.d8.loss_cls: 0.0995  decode.d8.loss_mask: 0.9470  decode.d8.loss_dice: 0.8605  mix_decode.loss_cls: 0.0855  mix_decode.loss_mask: 0.4821  mix_decode.loss_dice: 0.7177  mix_decode.d0.loss_cls: 0.1296  mix_decode.d0.loss_mask: 0.4802  mix_decode.d0.loss_dice: 0.7303  mix_decode.d1.loss_cls: 0.1798  mix_decode.d1.loss_mask: 0.4947  mix_decode.d1.loss_dice: 0.6768  mix_decode.d2.loss_cls: 0.1140  mix_decode.d2.loss_mask: 0.4771  mix_decode.d2.loss_dice: 0.6872  mix_decode.d3.loss_cls: 0.1421  mix_decode.d3.loss_mask: 0.4942  mix_decode.d3.loss_dice: 0.7162  mix_decode.d4.loss_cls: 0.1534  mix_decode.d4.loss_mask: 0.4937  mix_decode.d4.loss_dice: 0.7026  mix_decode.d5.loss_cls: 0.1450  mix_decode.d5.loss_mask: 0.4918  mix_decode.d5.loss_dice: 0.7044  mix_decode.d6.loss_cls: 0.1001  mix_decode.d6.loss_mask: 0.4911  mix_decode.d6.loss_dice: 0.7248  mix_decode.d7.loss_cls: 0.0834  mix_decode.d7.loss_mask: 0.4955  mix_decode.d7.loss_dice: 0.7089  mix_decode.d8.loss_cls: 0.1223  mix_decode.d8.loss_mask: 0.4972  mix_decode.d8.loss_dice: 0.7126
2025/03/28 13:12:54 - mmengine - INFO - Iter(train) [12500/20000]  base_lr: 4.1366e-05 lr: 4.1366e-05  eta: 1:51:57  time: 1.0745  data_time: 0.0222  memory: 10773  loss: 26.3828  decode.loss_cls: 0.0386  decode.loss_mask: 0.8092  decode.loss_dice: 0.7868  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.8142  decode.d0.loss_dice: 0.7843  decode.d1.loss_cls: 0.0920  decode.d1.loss_mask: 0.8049  decode.d1.loss_dice: 0.7672  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.8012  decode.d2.loss_dice: 0.7715  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.8071  decode.d3.loss_dice: 0.7525  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.8062  decode.d4.loss_dice: 0.7736  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.8078  decode.d5.loss_dice: 0.7755  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.8100  decode.d6.loss_dice: 0.7715  decode.d7.loss_cls: 0.0312  decode.d7.loss_mask: 0.8087  decode.d7.loss_dice: 0.7711  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.8094  decode.d8.loss_dice: 0.7720  mix_decode.loss_cls: 0.0605  mix_decode.loss_mask: 0.4543  mix_decode.loss_dice: 0.4805  mix_decode.d0.loss_cls: 0.1215  mix_decode.d0.loss_mask: 0.4632  mix_decode.d0.loss_dice: 0.4749  mix_decode.d1.loss_cls: 0.0958  mix_decode.d1.loss_mask: 0.4476  mix_decode.d1.loss_dice: 0.4617  mix_decode.d2.loss_cls: 0.0653  mix_decode.d2.loss_mask: 0.4500  mix_decode.d2.loss_dice: 0.4699  mix_decode.d3.loss_cls: 0.0650  mix_decode.d3.loss_mask: 0.4589  mix_decode.d3.loss_dice: 0.4724  mix_decode.d4.loss_cls: 0.0836  mix_decode.d4.loss_mask: 0.4471  mix_decode.d4.loss_dice: 0.4686  mix_decode.d5.loss_cls: 0.0862  mix_decode.d5.loss_mask: 0.4552  mix_decode.d5.loss_dice: 0.4661  mix_decode.d6.loss_cls: 0.0757  mix_decode.d6.loss_mask: 0.4565  mix_decode.d6.loss_dice: 0.4729  mix_decode.d7.loss_cls: 0.0954  mix_decode.d7.loss_mask: 0.4551  mix_decode.d7.loss_dice: 0.4585  mix_decode.d8.loss_cls: 0.0585  mix_decode.d8.loss_mask: 0.4602  mix_decode.d8.loss_dice: 0.4789
2025/03/28 13:13:48 - mmengine - INFO - Iter(train) [12550/20000]  base_lr: 4.1118e-05 lr: 4.1118e-05  eta: 1:51:18  time: 1.0792  data_time: 0.0230  memory: 10783  loss: 28.5860  decode.loss_cls: 0.0154  decode.loss_mask: 0.8971  decode.loss_dice: 0.7914  decode.d0.loss_cls: 0.0639  decode.d0.loss_mask: 0.9071  decode.d0.loss_dice: 0.7935  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.8963  decode.d1.loss_dice: 0.7822  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.8919  decode.d2.loss_dice: 0.7922  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.8982  decode.d3.loss_dice: 0.7758  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.8975  decode.d4.loss_dice: 0.7867  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.8945  decode.d5.loss_dice: 0.7852  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.8967  decode.d6.loss_dice: 0.7932  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.8944  decode.d7.loss_dice: 0.7809  decode.d8.loss_cls: 0.0171  decode.d8.loss_mask: 0.8987  decode.d8.loss_dice: 0.7942  mix_decode.loss_cls: 0.0625  mix_decode.loss_mask: 0.4510  mix_decode.loss_dice: 0.6221  mix_decode.d0.loss_cls: 0.1086  mix_decode.d0.loss_mask: 0.4499  mix_decode.d0.loss_dice: 0.6549  mix_decode.d1.loss_cls: 0.0691  mix_decode.d1.loss_mask: 0.4446  mix_decode.d1.loss_dice: 0.6299  mix_decode.d2.loss_cls: 0.0751  mix_decode.d2.loss_mask: 0.4442  mix_decode.d2.loss_dice: 0.6316  mix_decode.d3.loss_cls: 0.0639  mix_decode.d3.loss_mask: 0.4531  mix_decode.d3.loss_dice: 0.6273  mix_decode.d4.loss_cls: 0.0664  mix_decode.d4.loss_mask: 0.4522  mix_decode.d4.loss_dice: 0.6366  mix_decode.d5.loss_cls: 0.0860  mix_decode.d5.loss_mask: 0.4479  mix_decode.d5.loss_dice: 0.6115  mix_decode.d6.loss_cls: 0.0852  mix_decode.d6.loss_mask: 0.4429  mix_decode.d6.loss_dice: 0.6252  mix_decode.d7.loss_cls: 0.0880  mix_decode.d7.loss_mask: 0.4360  mix_decode.d7.loss_dice: 0.6201  mix_decode.d8.loss_cls: 0.0688  mix_decode.d8.loss_mask: 0.4428  mix_decode.d8.loss_dice: 0.6367
2025/03/28 13:14:42 - mmengine - INFO - Iter(train) [12600/20000]  base_lr: 4.0870e-05 lr: 4.0870e-05  eta: 1:50:38  time: 1.0832  data_time: 0.0237  memory: 10780  loss: 27.4177  decode.loss_cls: 0.0085  decode.loss_mask: 0.8708  decode.loss_dice: 0.7563  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.8807  decode.d0.loss_dice: 0.7495  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.8705  decode.d1.loss_dice: 0.7571  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.8729  decode.d2.loss_dice: 0.7581  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.8722  decode.d3.loss_dice: 0.7552  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.8793  decode.d4.loss_dice: 0.7539  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.8775  decode.d5.loss_dice: 0.7573  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.8724  decode.d6.loss_dice: 0.7582  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.8788  decode.d7.loss_dice: 0.7580  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.8716  decode.d8.loss_dice: 0.7521  mix_decode.loss_cls: 0.1098  mix_decode.loss_mask: 0.4324  mix_decode.loss_dice: 0.5350  mix_decode.d0.loss_cls: 0.1062  mix_decode.d0.loss_mask: 0.4488  mix_decode.d0.loss_dice: 0.5833  mix_decode.d1.loss_cls: 0.1644  mix_decode.d1.loss_mask: 0.4344  mix_decode.d1.loss_dice: 0.5275  mix_decode.d2.loss_cls: 0.1570  mix_decode.d2.loss_mask: 0.4324  mix_decode.d2.loss_dice: 0.5191  mix_decode.d3.loss_cls: 0.1099  mix_decode.d3.loss_mask: 0.4369  mix_decode.d3.loss_dice: 0.5341  mix_decode.d4.loss_cls: 0.1295  mix_decode.d4.loss_mask: 0.4356  mix_decode.d4.loss_dice: 0.5363  mix_decode.d5.loss_cls: 0.1107  mix_decode.d5.loss_mask: 0.4396  mix_decode.d5.loss_dice: 0.5353  mix_decode.d6.loss_cls: 0.1090  mix_decode.d6.loss_mask: 0.4296  mix_decode.d6.loss_dice: 0.5249  mix_decode.d7.loss_cls: 0.1133  mix_decode.d7.loss_mask: 0.4340  mix_decode.d7.loss_dice: 0.5331  mix_decode.d8.loss_cls: 0.1212  mix_decode.d8.loss_mask: 0.4371  mix_decode.d8.loss_dice: 0.5332
2025/03/28 13:15:36 - mmengine - INFO - Iter(train) [12650/20000]  base_lr: 4.0621e-05 lr: 4.0621e-05  eta: 1:49:59  time: 1.0764  data_time: 0.0225  memory: 10769  loss: 33.4926  decode.loss_cls: 0.0295  decode.loss_mask: 1.0922  decode.loss_dice: 0.9515  decode.d0.loss_cls: 0.0976  decode.d0.loss_mask: 1.0980  decode.d0.loss_dice: 0.9331  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 1.0903  decode.d1.loss_dice: 0.9459  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 1.0925  decode.d2.loss_dice: 0.9747  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 1.0911  decode.d3.loss_dice: 0.9676  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 1.0931  decode.d4.loss_dice: 0.9580  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 1.0889  decode.d5.loss_dice: 0.9585  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 1.0877  decode.d6.loss_dice: 0.9896  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 1.0885  decode.d7.loss_dice: 0.9444  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 1.0878  decode.d8.loss_dice: 0.9512  mix_decode.loss_cls: 0.0651  mix_decode.loss_mask: 0.5284  mix_decode.loss_dice: 0.6477  mix_decode.d0.loss_cls: 0.0918  mix_decode.d0.loss_mask: 0.5557  mix_decode.d0.loss_dice: 0.6616  mix_decode.d1.loss_cls: 0.0658  mix_decode.d1.loss_mask: 0.5448  mix_decode.d1.loss_dice: 0.6548  mix_decode.d2.loss_cls: 0.0633  mix_decode.d2.loss_mask: 0.5398  mix_decode.d2.loss_dice: 0.6532  mix_decode.d3.loss_cls: 0.0726  mix_decode.d3.loss_mask: 0.5393  mix_decode.d3.loss_dice: 0.6551  mix_decode.d4.loss_cls: 0.0679  mix_decode.d4.loss_mask: 0.5367  mix_decode.d4.loss_dice: 0.6627  mix_decode.d5.loss_cls: 0.0710  mix_decode.d5.loss_mask: 0.5348  mix_decode.d5.loss_dice: 0.6643  mix_decode.d6.loss_cls: 0.0527  mix_decode.d6.loss_mask: 0.5310  mix_decode.d6.loss_dice: 0.6539  mix_decode.d7.loss_cls: 0.0832  mix_decode.d7.loss_mask: 0.5344  mix_decode.d7.loss_dice: 0.6504  mix_decode.d8.loss_cls: 0.0584  mix_decode.d8.loss_mask: 0.5382  mix_decode.d8.loss_dice: 0.6575
2025/03/28 13:16:30 - mmengine - INFO - Iter(train) [12700/20000]  base_lr: 4.0372e-05 lr: 4.0372e-05  eta: 1:49:19  time: 1.0766  data_time: 0.0229  memory: 10773  loss: 26.9570  decode.loss_cls: 0.0031  decode.loss_mask: 0.7876  decode.loss_dice: 0.7286  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 0.7282  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.7917  decode.d1.loss_dice: 0.7389  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.7894  decode.d2.loss_dice: 0.7406  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.7875  decode.d3.loss_dice: 0.7324  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.7883  decode.d4.loss_dice: 0.7350  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.7905  decode.d5.loss_dice: 0.7367  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.7887  decode.d6.loss_dice: 0.7347  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.7843  decode.d7.loss_dice: 0.7256  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.7864  decode.d8.loss_dice: 0.7346  mix_decode.loss_cls: 0.0566  mix_decode.loss_mask: 0.5067  mix_decode.loss_dice: 0.5870  mix_decode.d0.loss_cls: 0.0946  mix_decode.d0.loss_mask: 0.5123  mix_decode.d0.loss_dice: 0.5929  mix_decode.d1.loss_cls: 0.1110  mix_decode.d1.loss_mask: 0.5104  mix_decode.d1.loss_dice: 0.5861  mix_decode.d2.loss_cls: 0.0819  mix_decode.d2.loss_mask: 0.5013  mix_decode.d2.loss_dice: 0.5792  mix_decode.d3.loss_cls: 0.0773  mix_decode.d3.loss_mask: 0.4976  mix_decode.d3.loss_dice: 0.5681  mix_decode.d4.loss_cls: 0.0739  mix_decode.d4.loss_mask: 0.5034  mix_decode.d4.loss_dice: 0.5658  mix_decode.d5.loss_cls: 0.0869  mix_decode.d5.loss_mask: 0.4986  mix_decode.d5.loss_dice: 0.5765  mix_decode.d6.loss_cls: 0.0624  mix_decode.d6.loss_mask: 0.5061  mix_decode.d6.loss_dice: 0.5819  mix_decode.d7.loss_cls: 0.1026  mix_decode.d7.loss_mask: 0.4963  mix_decode.d7.loss_dice: 0.5521  mix_decode.d8.loss_cls: 0.0916  mix_decode.d8.loss_mask: 0.5035  mix_decode.d8.loss_dice: 0.5799
2025/03/28 13:17:24 - mmengine - INFO - Iter(train) [12750/20000]  base_lr: 4.0123e-05 lr: 4.0123e-05  eta: 1:48:39  time: 1.0766  data_time: 0.0222  memory: 10765  loss: 27.5973  decode.loss_cls: 0.0972  decode.loss_mask: 0.9045  decode.loss_dice: 0.8486  decode.d0.loss_cls: 0.1090  decode.d0.loss_mask: 0.9282  decode.d0.loss_dice: 0.8894  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.8988  decode.d1.loss_dice: 0.8451  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.8995  decode.d2.loss_dice: 0.8876  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.9028  decode.d3.loss_dice: 0.8388  decode.d4.loss_cls: 0.0926  decode.d4.loss_mask: 0.9037  decode.d4.loss_dice: 0.8548  decode.d5.loss_cls: 0.0914  decode.d5.loss_mask: 0.8991  decode.d5.loss_dice: 0.8515  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.9054  decode.d6.loss_dice: 0.8538  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.9006  decode.d7.loss_dice: 0.8426  decode.d8.loss_cls: 0.1095  decode.d8.loss_mask: 0.9060  decode.d8.loss_dice: 0.8826  mix_decode.loss_cls: 0.0245  mix_decode.loss_mask: 0.4019  mix_decode.loss_dice: 0.4694  mix_decode.d0.loss_cls: 0.0598  mix_decode.d0.loss_mask: 0.4079  mix_decode.d0.loss_dice: 0.4869  mix_decode.d1.loss_cls: 0.0601  mix_decode.d1.loss_mask: 0.3972  mix_decode.d1.loss_dice: 0.4736  mix_decode.d2.loss_cls: 0.0493  mix_decode.d2.loss_mask: 0.4039  mix_decode.d2.loss_dice: 0.4754  mix_decode.d3.loss_cls: 0.0393  mix_decode.d3.loss_mask: 0.4027  mix_decode.d3.loss_dice: 0.4619  mix_decode.d4.loss_cls: 0.0261  mix_decode.d4.loss_mask: 0.4050  mix_decode.d4.loss_dice: 0.4532  mix_decode.d5.loss_cls: 0.0419  mix_decode.d5.loss_mask: 0.4027  mix_decode.d5.loss_dice: 0.4673  mix_decode.d6.loss_cls: 0.0294  mix_decode.d6.loss_mask: 0.4060  mix_decode.d6.loss_dice: 0.4797  mix_decode.d7.loss_cls: 0.0293  mix_decode.d7.loss_mask: 0.4005  mix_decode.d7.loss_dice: 0.4754  mix_decode.d8.loss_cls: 0.0393  mix_decode.d8.loss_mask: 0.3990  mix_decode.d8.loss_dice: 0.4813
2025/03/28 13:18:18 - mmengine - INFO - Iter(train) [12800/20000]  base_lr: 3.9874e-05 lr: 3.9874e-05  eta: 1:47:59  time: 1.0930  data_time: 0.0246  memory: 10769  loss: 26.8677  decode.loss_cls: 0.0095  decode.loss_mask: 0.9067  decode.loss_dice: 0.7907  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.9201  decode.d0.loss_dice: 0.7886  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.9091  decode.d1.loss_dice: 0.7895  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.9108  decode.d2.loss_dice: 0.7853  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.9104  decode.d3.loss_dice: 0.7916  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.9043  decode.d4.loss_dice: 0.7854  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.9053  decode.d5.loss_dice: 0.7853  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.9037  decode.d6.loss_dice: 0.7844  decode.d7.loss_cls: 0.0111  decode.d7.loss_mask: 0.9023  decode.d7.loss_dice: 0.7837  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.9061  decode.d8.loss_dice: 0.7915  mix_decode.loss_cls: 0.0937  mix_decode.loss_mask: 0.3999  mix_decode.loss_dice: 0.4688  mix_decode.d0.loss_cls: 0.1135  mix_decode.d0.loss_mask: 0.4047  mix_decode.d0.loss_dice: 0.5095  mix_decode.d1.loss_cls: 0.1130  mix_decode.d1.loss_mask: 0.4009  mix_decode.d1.loss_dice: 0.4717  mix_decode.d2.loss_cls: 0.1329  mix_decode.d2.loss_mask: 0.3971  mix_decode.d2.loss_dice: 0.4524  mix_decode.d3.loss_cls: 0.1089  mix_decode.d3.loss_mask: 0.3990  mix_decode.d3.loss_dice: 0.4649  mix_decode.d4.loss_cls: 0.0904  mix_decode.d4.loss_mask: 0.3982  mix_decode.d4.loss_dice: 0.4625  mix_decode.d5.loss_cls: 0.1040  mix_decode.d5.loss_mask: 0.3981  mix_decode.d5.loss_dice: 0.4659  mix_decode.d6.loss_cls: 0.0995  mix_decode.d6.loss_mask: 0.3985  mix_decode.d6.loss_dice: 0.4531  mix_decode.d7.loss_cls: 0.1076  mix_decode.d7.loss_mask: 0.3972  mix_decode.d7.loss_dice: 0.4554  mix_decode.d8.loss_cls: 0.1189  mix_decode.d8.loss_mask: 0.4004  mix_decode.d8.loss_dice: 0.4645
2025/03/28 13:19:12 - mmengine - INFO - Iter(train) [12850/20000]  base_lr: 3.9625e-05 lr: 3.9625e-05  eta: 1:47:19  time: 1.0760  data_time: 0.0224  memory: 10775  loss: 21.7862  decode.loss_cls: 0.0080  decode.loss_mask: 0.7045  decode.loss_dice: 0.6435  decode.d0.loss_cls: 0.0870  decode.d0.loss_mask: 0.7026  decode.d0.loss_dice: 0.6479  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.7035  decode.d1.loss_dice: 0.6499  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.6984  decode.d2.loss_dice: 0.6478  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.7048  decode.d3.loss_dice: 0.6494  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.7069  decode.d4.loss_dice: 0.6458  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.7103  decode.d5.loss_dice: 0.6477  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.7055  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.7128  decode.d7.loss_dice: 0.6725  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.7067  decode.d8.loss_dice: 0.6524  mix_decode.loss_cls: 0.0391  mix_decode.loss_mask: 0.3140  mix_decode.loss_dice: 0.4351  mix_decode.d0.loss_cls: 0.1025  mix_decode.d0.loss_mask: 0.3200  mix_decode.d0.loss_dice: 0.4435  mix_decode.d1.loss_cls: 0.1101  mix_decode.d1.loss_mask: 0.3138  mix_decode.d1.loss_dice: 0.4250  mix_decode.d2.loss_cls: 0.0456  mix_decode.d2.loss_mask: 0.3179  mix_decode.d2.loss_dice: 0.4326  mix_decode.d3.loss_cls: 0.0383  mix_decode.d3.loss_mask: 0.3134  mix_decode.d3.loss_dice: 0.4230  mix_decode.d4.loss_cls: 0.0345  mix_decode.d4.loss_mask: 0.3158  mix_decode.d4.loss_dice: 0.4263  mix_decode.d5.loss_cls: 0.0380  mix_decode.d5.loss_mask: 0.3159  mix_decode.d5.loss_dice: 0.4290  mix_decode.d6.loss_cls: 0.0361  mix_decode.d6.loss_mask: 0.3161  mix_decode.d6.loss_dice: 0.4327  mix_decode.d7.loss_cls: 0.0741  mix_decode.d7.loss_mask: 0.3171  mix_decode.d7.loss_dice: 0.4276  mix_decode.d8.loss_cls: 0.0473  mix_decode.d8.loss_mask: 0.3109  mix_decode.d8.loss_dice: 0.4320
2025/03/28 13:20:05 - mmengine - INFO - Iter(train) [12900/20000]  base_lr: 3.9375e-05 lr: 3.9375e-05  eta: 1:46:39  time: 1.0716  data_time: 0.0227  memory: 10768  loss: 30.6850  decode.loss_cls: 0.0271  decode.loss_mask: 0.8749  decode.loss_dice: 0.8629  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.8885  decode.d0.loss_dice: 0.8470  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.8720  decode.d1.loss_dice: 0.8533  decode.d2.loss_cls: 0.0371  decode.d2.loss_mask: 0.8760  decode.d2.loss_dice: 0.8583  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.8728  decode.d3.loss_dice: 0.8423  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.8706  decode.d4.loss_dice: 0.8461  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.8754  decode.d5.loss_dice: 0.8581  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.8738  decode.d6.loss_dice: 0.8436  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.8775  decode.d7.loss_dice: 0.8440  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.8730  decode.d8.loss_dice: 0.8483  mix_decode.loss_cls: 0.1902  mix_decode.loss_mask: 0.4610  mix_decode.loss_dice: 0.6722  mix_decode.d0.loss_cls: 0.1170  mix_decode.d0.loss_mask: 0.4805  mix_decode.d0.loss_dice: 0.7168  mix_decode.d1.loss_cls: 0.1716  mix_decode.d1.loss_mask: 0.4733  mix_decode.d1.loss_dice: 0.6729  mix_decode.d2.loss_cls: 0.1801  mix_decode.d2.loss_mask: 0.4677  mix_decode.d2.loss_dice: 0.6673  mix_decode.d3.loss_cls: 0.1624  mix_decode.d3.loss_mask: 0.4694  mix_decode.d3.loss_dice: 0.6725  mix_decode.d4.loss_cls: 0.1620  mix_decode.d4.loss_mask: 0.4740  mix_decode.d4.loss_dice: 0.6746  mix_decode.d5.loss_cls: 0.1573  mix_decode.d5.loss_mask: 0.4746  mix_decode.d5.loss_dice: 0.6717  mix_decode.d6.loss_cls: 0.1735  mix_decode.d6.loss_mask: 0.4744  mix_decode.d6.loss_dice: 0.6672  mix_decode.d7.loss_cls: 0.1531  mix_decode.d7.loss_mask: 0.4730  mix_decode.d7.loss_dice: 0.6854  mix_decode.d8.loss_cls: 0.1823  mix_decode.d8.loss_mask: 0.4614  mix_decode.d8.loss_dice: 0.6626
2025/03/28 13:20:59 - mmengine - INFO - Iter(train) [12950/20000]  base_lr: 3.9126e-05 lr: 3.9126e-05  eta: 1:45:59  time: 1.0894  data_time: 0.0236  memory: 10769  loss: 25.5147  decode.loss_cls: 0.0085  decode.loss_mask: 0.8219  decode.loss_dice: 0.8079  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.8218  decode.d0.loss_dice: 0.8069  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.8296  decode.d1.loss_dice: 0.8245  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.8299  decode.d2.loss_dice: 0.7998  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.8284  decode.d3.loss_dice: 0.8159  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.8246  decode.d4.loss_dice: 0.7957  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.8223  decode.d5.loss_dice: 0.7924  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.8263  decode.d6.loss_dice: 0.8195  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.8278  decode.d7.loss_dice: 0.8100  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.8151  decode.d8.loss_dice: 0.7865  mix_decode.loss_cls: 0.0567  mix_decode.loss_mask: 0.3434  mix_decode.loss_dice: 0.4652  mix_decode.d0.loss_cls: 0.0826  mix_decode.d0.loss_mask: 0.3483  mix_decode.d0.loss_dice: 0.4804  mix_decode.d1.loss_cls: 0.1197  mix_decode.d1.loss_mask: 0.3466  mix_decode.d1.loss_dice: 0.4692  mix_decode.d2.loss_cls: 0.0942  mix_decode.d2.loss_mask: 0.3401  mix_decode.d2.loss_dice: 0.4646  mix_decode.d3.loss_cls: 0.0856  mix_decode.d3.loss_mask: 0.3421  mix_decode.d3.loss_dice: 0.4620  mix_decode.d4.loss_cls: 0.1017  mix_decode.d4.loss_mask: 0.3463  mix_decode.d4.loss_dice: 0.4630  mix_decode.d5.loss_cls: 0.0578  mix_decode.d5.loss_mask: 0.3557  mix_decode.d5.loss_dice: 0.4723  mix_decode.d6.loss_cls: 0.0591  mix_decode.d6.loss_mask: 0.3557  mix_decode.d6.loss_dice: 0.4855  mix_decode.d7.loss_cls: 0.0983  mix_decode.d7.loss_mask: 0.3429  mix_decode.d7.loss_dice: 0.4673  mix_decode.d8.loss_cls: 0.0860  mix_decode.d8.loss_mask: 0.3472  mix_decode.d8.loss_dice: 0.4802
2025/03/28 13:21:53 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 13:21:53 - mmengine - INFO - Iter(train) [13000/20000]  base_lr: 3.8876e-05 lr: 3.8876e-05  eta: 1:45:19  time: 1.0788  data_time: 0.0228  memory: 10780  loss: 31.0801  decode.loss_cls: 0.0252  decode.loss_mask: 1.0046  decode.loss_dice: 0.9081  decode.d0.loss_cls: 0.1064  decode.d0.loss_mask: 1.0192  decode.d0.loss_dice: 0.9212  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 1.0039  decode.d1.loss_dice: 0.9372  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 1.0086  decode.d2.loss_dice: 0.9601  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 1.0006  decode.d3.loss_dice: 0.9363  decode.d4.loss_cls: 0.0253  decode.d4.loss_mask: 1.0033  decode.d4.loss_dice: 0.9498  decode.d5.loss_cls: 0.0240  decode.d5.loss_mask: 1.0003  decode.d5.loss_dice: 0.9120  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 1.0021  decode.d6.loss_dice: 0.9471  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.9992  decode.d7.loss_dice: 0.9123  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 1.0034  decode.d8.loss_dice: 0.9446  mix_decode.loss_cls: 0.1235  mix_decode.loss_mask: 0.4255  mix_decode.loss_dice: 0.5679  mix_decode.d0.loss_cls: 0.1150  mix_decode.d0.loss_mask: 0.4360  mix_decode.d0.loss_dice: 0.5925  mix_decode.d1.loss_cls: 0.1162  mix_decode.d1.loss_mask: 0.4264  mix_decode.d1.loss_dice: 0.5737  mix_decode.d2.loss_cls: 0.1221  mix_decode.d2.loss_mask: 0.4254  mix_decode.d2.loss_dice: 0.5664  mix_decode.d3.loss_cls: 0.1380  mix_decode.d3.loss_mask: 0.4198  mix_decode.d3.loss_dice: 0.5537  mix_decode.d4.loss_cls: 0.1156  mix_decode.d4.loss_mask: 0.4244  mix_decode.d4.loss_dice: 0.5716  mix_decode.d5.loss_cls: 0.1119  mix_decode.d5.loss_mask: 0.4296  mix_decode.d5.loss_dice: 0.5836  mix_decode.d6.loss_cls: 0.1421  mix_decode.d6.loss_mask: 0.4219  mix_decode.d6.loss_dice: 0.5620  mix_decode.d7.loss_cls: 0.1367  mix_decode.d7.loss_mask: 0.4243  mix_decode.d7.loss_dice: 0.5716  mix_decode.d8.loss_cls: 0.1481  mix_decode.d8.loss_mask: 0.4251  mix_decode.d8.loss_dice: 0.5679
2025/03/28 13:22:47 - mmengine - INFO - Iter(train) [13050/20000]  base_lr: 3.8626e-05 lr: 3.8626e-05  eta: 1:44:38  time: 1.0724  data_time: 0.0222  memory: 10773  loss: 25.5965  decode.loss_cls: 0.0154  decode.loss_mask: 0.7785  decode.loss_dice: 0.7291  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.7789  decode.d0.loss_dice: 0.7100  decode.d1.loss_cls: 0.0181  decode.d1.loss_mask: 0.7728  decode.d1.loss_dice: 0.6909  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.7787  decode.d2.loss_dice: 0.7277  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.7740  decode.d3.loss_dice: 0.6950  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.7731  decode.d4.loss_dice: 0.7194  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.7680  decode.d5.loss_dice: 0.7136  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.7696  decode.d6.loss_dice: 0.7272  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.7773  decode.d7.loss_dice: 0.7266  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.7776  decode.d8.loss_dice: 0.7109  mix_decode.loss_cls: 0.0744  mix_decode.loss_mask: 0.4050  mix_decode.loss_dice: 0.5436  mix_decode.d0.loss_cls: 0.1016  mix_decode.d0.loss_mask: 0.4116  mix_decode.d0.loss_dice: 0.5562  mix_decode.d1.loss_cls: 0.1134  mix_decode.d1.loss_mask: 0.3910  mix_decode.d1.loss_dice: 0.5237  mix_decode.d2.loss_cls: 0.1111  mix_decode.d2.loss_mask: 0.3888  mix_decode.d2.loss_dice: 0.5276  mix_decode.d3.loss_cls: 0.0968  mix_decode.d3.loss_mask: 0.4019  mix_decode.d3.loss_dice: 0.5398  mix_decode.d4.loss_cls: 0.0807  mix_decode.d4.loss_mask: 0.4039  mix_decode.d4.loss_dice: 0.5305  mix_decode.d5.loss_cls: 0.1003  mix_decode.d5.loss_mask: 0.4020  mix_decode.d5.loss_dice: 0.5384  mix_decode.d6.loss_cls: 0.1186  mix_decode.d6.loss_mask: 0.4028  mix_decode.d6.loss_dice: 0.5306  mix_decode.d7.loss_cls: 0.1196  mix_decode.d7.loss_mask: 0.4029  mix_decode.d7.loss_dice: 0.5389  mix_decode.d8.loss_cls: 0.0660  mix_decode.d8.loss_mask: 0.4043  mix_decode.d8.loss_dice: 0.5348
2025/03/28 13:23:41 - mmengine - INFO - Iter(train) [13100/20000]  base_lr: 3.8376e-05 lr: 3.8376e-05  eta: 1:43:57  time: 1.0754  data_time: 0.0223  memory: 10780  loss: 29.7420  decode.loss_cls: 0.0084  decode.loss_mask: 0.9519  decode.loss_dice: 0.8475  decode.d0.loss_cls: 0.0690  decode.d0.loss_mask: 0.9614  decode.d0.loss_dice: 0.8324  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.9506  decode.d1.loss_dice: 0.8517  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.9536  decode.d2.loss_dice: 0.8499  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.9429  decode.d3.loss_dice: 0.8341  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.9399  decode.d4.loss_dice: 0.8347  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.9395  decode.d5.loss_dice: 0.8305  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.9586  decode.d6.loss_dice: 0.8438  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.9530  decode.d7.loss_dice: 0.8565  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.9545  decode.d8.loss_dice: 0.8469  mix_decode.loss_cls: 0.0557  mix_decode.loss_mask: 0.4590  mix_decode.loss_dice: 0.6320  mix_decode.d0.loss_cls: 0.0835  mix_decode.d0.loss_mask: 0.4708  mix_decode.d0.loss_dice: 0.6534  mix_decode.d1.loss_cls: 0.0586  mix_decode.d1.loss_mask: 0.4628  mix_decode.d1.loss_dice: 0.6440  mix_decode.d2.loss_cls: 0.0510  mix_decode.d2.loss_mask: 0.4669  mix_decode.d2.loss_dice: 0.6320  mix_decode.d3.loss_cls: 0.0380  mix_decode.d3.loss_mask: 0.4581  mix_decode.d3.loss_dice: 0.6362  mix_decode.d4.loss_cls: 0.0512  mix_decode.d4.loss_mask: 0.4574  mix_decode.d4.loss_dice: 0.6367  mix_decode.d5.loss_cls: 0.0511  mix_decode.d5.loss_mask: 0.4556  mix_decode.d5.loss_dice: 0.6406  mix_decode.d6.loss_cls: 0.0549  mix_decode.d6.loss_mask: 0.4590  mix_decode.d6.loss_dice: 0.6411  mix_decode.d7.loss_cls: 0.0349  mix_decode.d7.loss_mask: 0.4611  mix_decode.d7.loss_dice: 0.6366  mix_decode.d8.loss_cls: 0.0405  mix_decode.d8.loss_mask: 0.4642  mix_decode.d8.loss_dice: 0.6409
2025/03/28 13:24:35 - mmengine - INFO - Iter(train) [13150/20000]  base_lr: 3.8125e-05 lr: 3.8125e-05  eta: 1:43:17  time: 1.0716  data_time: 0.0221  memory: 10782  loss: 28.8762  decode.loss_cls: 0.0248  decode.loss_mask: 0.8246  decode.loss_dice: 0.7941  decode.d0.loss_cls: 0.1735  decode.d0.loss_mask: 0.8205  decode.d0.loss_dice: 0.7668  decode.d1.loss_cls: 0.1091  decode.d1.loss_mask: 0.8188  decode.d1.loss_dice: 0.7800  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.8275  decode.d2.loss_dice: 0.7435  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.8244  decode.d3.loss_dice: 0.7777  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.8246  decode.d4.loss_dice: 0.7501  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.8214  decode.d5.loss_dice: 0.7638  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.8232  decode.d6.loss_dice: 0.7692  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.8244  decode.d7.loss_dice: 0.7769  decode.d8.loss_cls: 0.0759  decode.d8.loss_mask: 0.8223  decode.d8.loss_dice: 0.7633  mix_decode.loss_cls: 0.0696  mix_decode.loss_mask: 0.5223  mix_decode.loss_dice: 0.6046  mix_decode.d0.loss_cls: 0.1135  mix_decode.d0.loss_mask: 0.5145  mix_decode.d0.loss_dice: 0.5983  mix_decode.d1.loss_cls: 0.0827  mix_decode.d1.loss_mask: 0.5229  mix_decode.d1.loss_dice: 0.6071  mix_decode.d2.loss_cls: 0.0985  mix_decode.d2.loss_mask: 0.5133  mix_decode.d2.loss_dice: 0.5954  mix_decode.d3.loss_cls: 0.0851  mix_decode.d3.loss_mask: 0.5139  mix_decode.d3.loss_dice: 0.6016  mix_decode.d4.loss_cls: 0.0979  mix_decode.d4.loss_mask: 0.5146  mix_decode.d4.loss_dice: 0.6035  mix_decode.d5.loss_cls: 0.0874  mix_decode.d5.loss_mask: 0.5126  mix_decode.d5.loss_dice: 0.6089  mix_decode.d6.loss_cls: 0.1189  mix_decode.d6.loss_mask: 0.5242  mix_decode.d6.loss_dice: 0.6000  mix_decode.d7.loss_cls: 0.0858  mix_decode.d7.loss_mask: 0.5278  mix_decode.d7.loss_dice: 0.6211  mix_decode.d8.loss_cls: 0.0714  mix_decode.d8.loss_mask: 0.5251  mix_decode.d8.loss_dice: 0.6186
2025/03/28 13:25:29 - mmengine - INFO - Iter(train) [13200/20000]  base_lr: 3.7875e-05 lr: 3.7875e-05  eta: 1:42:36  time: 1.0755  data_time: 0.0228  memory: 10773  loss: 27.7722  decode.loss_cls: 0.0104  decode.loss_mask: 0.7710  decode.loss_dice: 0.8030  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 0.7660  decode.d0.loss_dice: 0.7804  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.7666  decode.d1.loss_dice: 0.7879  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.7644  decode.d2.loss_dice: 0.8080  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.7626  decode.d3.loss_dice: 0.8094  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.7680  decode.d4.loss_dice: 0.8135  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.7639  decode.d5.loss_dice: 0.8080  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.7625  decode.d6.loss_dice: 0.8011  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.7729  decode.d7.loss_dice: 0.7834  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.7660  decode.d8.loss_dice: 0.8049  mix_decode.loss_cls: 0.0530  mix_decode.loss_mask: 0.5021  mix_decode.loss_dice: 0.6149  mix_decode.d0.loss_cls: 0.1250  mix_decode.d0.loss_mask: 0.4976  mix_decode.d0.loss_dice: 0.6230  mix_decode.d1.loss_cls: 0.0875  mix_decode.d1.loss_mask: 0.4960  mix_decode.d1.loss_dice: 0.6077  mix_decode.d2.loss_cls: 0.0802  mix_decode.d2.loss_mask: 0.5005  mix_decode.d2.loss_dice: 0.6195  mix_decode.d3.loss_cls: 0.0672  mix_decode.d3.loss_mask: 0.5003  mix_decode.d3.loss_dice: 0.6096  mix_decode.d4.loss_cls: 0.0537  mix_decode.d4.loss_mask: 0.4958  mix_decode.d4.loss_dice: 0.6184  mix_decode.d5.loss_cls: 0.0724  mix_decode.d5.loss_mask: 0.4821  mix_decode.d5.loss_dice: 0.6135  mix_decode.d6.loss_cls: 0.0499  mix_decode.d6.loss_mask: 0.4967  mix_decode.d6.loss_dice: 0.6174  mix_decode.d7.loss_cls: 0.0359  mix_decode.d7.loss_mask: 0.5281  mix_decode.d7.loss_dice: 0.6260  mix_decode.d8.loss_cls: 0.0330  mix_decode.d8.loss_mask: 0.5254  mix_decode.d8.loss_dice: 0.6222
2025/03/28 13:26:22 - mmengine - INFO - Iter(train) [13250/20000]  base_lr: 3.7624e-05 lr: 3.7624e-05  eta: 1:41:55  time: 1.0765  data_time: 0.0228  memory: 10770  loss: 25.7941  decode.loss_cls: 0.0068  decode.loss_mask: 0.8069  decode.loss_dice: 0.7492  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.7945  decode.d0.loss_dice: 0.7541  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.8025  decode.d1.loss_dice: 0.7534  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.7991  decode.d2.loss_dice: 0.7526  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.8038  decode.d3.loss_dice: 0.7437  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.8064  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 0.7389  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.8075  decode.d6.loss_dice: 0.7354  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.8030  decode.d7.loss_dice: 0.7448  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.8049  decode.d8.loss_dice: 0.7534  mix_decode.loss_cls: 0.0672  mix_decode.loss_mask: 0.4141  mix_decode.loss_dice: 0.5237  mix_decode.d0.loss_cls: 0.1297  mix_decode.d0.loss_mask: 0.4004  mix_decode.d0.loss_dice: 0.5361  mix_decode.d1.loss_cls: 0.0697  mix_decode.d1.loss_mask: 0.4196  mix_decode.d1.loss_dice: 0.5189  mix_decode.d2.loss_cls: 0.0703  mix_decode.d2.loss_mask: 0.4049  mix_decode.d2.loss_dice: 0.5240  mix_decode.d3.loss_cls: 0.0801  mix_decode.d3.loss_mask: 0.4076  mix_decode.d3.loss_dice: 0.5237  mix_decode.d4.loss_cls: 0.0867  mix_decode.d4.loss_mask: 0.4105  mix_decode.d4.loss_dice: 0.5196  mix_decode.d5.loss_cls: 0.0741  mix_decode.d5.loss_mask: 0.4111  mix_decode.d5.loss_dice: 0.5045  mix_decode.d6.loss_cls: 0.0830  mix_decode.d6.loss_mask: 0.4368  mix_decode.d6.loss_dice: 0.5213  mix_decode.d7.loss_cls: 0.0661  mix_decode.d7.loss_mask: 0.4171  mix_decode.d7.loss_dice: 0.5180  mix_decode.d8.loss_cls: 0.0690  mix_decode.d8.loss_mask: 0.4097  mix_decode.d8.loss_dice: 0.5270
2025/03/28 13:27:16 - mmengine - INFO - Iter(train) [13300/20000]  base_lr: 3.7373e-05 lr: 3.7373e-05  eta: 1:41:14  time: 1.0773  data_time: 0.0222  memory: 10778  loss: 30.2543  decode.loss_cls: 0.0907  decode.loss_mask: 0.9008  decode.loss_dice: 0.8013  decode.d0.loss_cls: 0.1091  decode.d0.loss_mask: 0.9165  decode.d0.loss_dice: 0.8583  decode.d1.loss_cls: 0.1011  decode.d1.loss_mask: 0.9034  decode.d1.loss_dice: 0.8691  decode.d2.loss_cls: 0.1227  decode.d2.loss_mask: 0.8993  decode.d2.loss_dice: 0.7973  decode.d3.loss_cls: 0.1083  decode.d3.loss_mask: 0.9033  decode.d3.loss_dice: 0.8130  decode.d4.loss_cls: 0.0448  decode.d4.loss_mask: 0.9060  decode.d4.loss_dice: 0.8412  decode.d5.loss_cls: 0.1131  decode.d5.loss_mask: 0.9008  decode.d5.loss_dice: 0.8070  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.9056  decode.d6.loss_dice: 0.8069  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.9080  decode.d7.loss_dice: 0.8283  decode.d8.loss_cls: 0.1585  decode.d8.loss_mask: 0.8983  decode.d8.loss_dice: 0.8121  mix_decode.loss_cls: 0.1490  mix_decode.loss_mask: 0.4225  mix_decode.loss_dice: 0.6299  mix_decode.d0.loss_cls: 0.0868  mix_decode.d0.loss_mask: 0.4298  mix_decode.d0.loss_dice: 0.6575  mix_decode.d1.loss_cls: 0.1074  mix_decode.d1.loss_mask: 0.4296  mix_decode.d1.loss_dice: 0.6431  mix_decode.d2.loss_cls: 0.1243  mix_decode.d2.loss_mask: 0.4244  mix_decode.d2.loss_dice: 0.6384  mix_decode.d3.loss_cls: 0.1569  mix_decode.d3.loss_mask: 0.4218  mix_decode.d3.loss_dice: 0.6211  mix_decode.d4.loss_cls: 0.1423  mix_decode.d4.loss_mask: 0.4245  mix_decode.d4.loss_dice: 0.6203  mix_decode.d5.loss_cls: 0.1389  mix_decode.d5.loss_mask: 0.4259  mix_decode.d5.loss_dice: 0.6194  mix_decode.d6.loss_cls: 0.1744  mix_decode.d6.loss_mask: 0.4270  mix_decode.d6.loss_dice: 0.6111  mix_decode.d7.loss_cls: 0.1467  mix_decode.d7.loss_mask: 0.4266  mix_decode.d7.loss_dice: 0.6275  mix_decode.d8.loss_cls: 0.1583  mix_decode.d8.loss_mask: 0.4236  mix_decode.d8.loss_dice: 0.6404
2025/03/28 13:28:10 - mmengine - INFO - Iter(train) [13350/20000]  base_lr: 3.7122e-05 lr: 3.7122e-05  eta: 1:40:33  time: 1.0811  data_time: 0.0238  memory: 10769  loss: 28.3902  decode.loss_cls: 0.0167  decode.loss_mask: 0.8177  decode.loss_dice: 0.8000  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.8282  decode.d0.loss_dice: 0.8020  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.8186  decode.d1.loss_dice: 0.7872  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.8189  decode.d2.loss_dice: 0.7774  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.8135  decode.d3.loss_dice: 0.7891  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.8157  decode.d4.loss_dice: 0.7844  decode.d5.loss_cls: 0.0214  decode.d5.loss_mask: 0.8196  decode.d5.loss_dice: 0.7944  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.8094  decode.d6.loss_dice: 0.7807  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.8156  decode.d7.loss_dice: 0.7840  decode.d8.loss_cls: 0.0188  decode.d8.loss_mask: 0.8144  decode.d8.loss_dice: 0.7877  mix_decode.loss_cls: 0.2159  mix_decode.loss_mask: 0.4246  mix_decode.loss_dice: 0.5348  mix_decode.d0.loss_cls: 0.2442  mix_decode.d0.loss_mask: 0.3987  mix_decode.d0.loss_dice: 0.5617  mix_decode.d1.loss_cls: 0.2105  mix_decode.d1.loss_mask: 0.4718  mix_decode.d1.loss_dice: 0.5233  mix_decode.d2.loss_cls: 0.1757  mix_decode.d2.loss_mask: 0.5004  mix_decode.d2.loss_dice: 0.5391  mix_decode.d3.loss_cls: 0.1925  mix_decode.d3.loss_mask: 0.4842  mix_decode.d3.loss_dice: 0.5367  mix_decode.d4.loss_cls: 0.1959  mix_decode.d4.loss_mask: 0.4630  mix_decode.d4.loss_dice: 0.5410  mix_decode.d5.loss_cls: 0.1702  mix_decode.d5.loss_mask: 0.4644  mix_decode.d5.loss_dice: 0.5299  mix_decode.d6.loss_cls: 0.1927  mix_decode.d6.loss_mask: 0.4549  mix_decode.d6.loss_dice: 0.5268  mix_decode.d7.loss_cls: 0.2332  mix_decode.d7.loss_mask: 0.4608  mix_decode.d7.loss_dice: 0.5432  mix_decode.d8.loss_cls: 0.2058  mix_decode.d8.loss_mask: 0.4262  mix_decode.d8.loss_dice: 0.5658
2025/03/28 13:29:04 - mmengine - INFO - Iter(train) [13400/20000]  base_lr: 3.6871e-05 lr: 3.6871e-05  eta: 1:39:52  time: 1.0765  data_time: 0.0225  memory: 10781  loss: 27.7572  decode.loss_cls: 0.0640  decode.loss_mask: 0.8094  decode.loss_dice: 0.7148  decode.d0.loss_cls: 0.1335  decode.d0.loss_mask: 0.8081  decode.d0.loss_dice: 0.7508  decode.d1.loss_cls: 0.1070  decode.d1.loss_mask: 0.8032  decode.d1.loss_dice: 0.7057  decode.d2.loss_cls: 0.0989  decode.d2.loss_mask: 0.8036  decode.d2.loss_dice: 0.7030  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 0.8077  decode.d3.loss_dice: 0.7154  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.8075  decode.d4.loss_dice: 0.7084  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 0.8094  decode.d5.loss_dice: 0.7091  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.8162  decode.d6.loss_dice: 0.7181  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.8094  decode.d7.loss_dice: 0.7186  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.8053  decode.d8.loss_dice: 0.7188  mix_decode.loss_cls: 0.1551  mix_decode.loss_mask: 0.4330  mix_decode.loss_dice: 0.5605  mix_decode.d0.loss_cls: 0.1126  mix_decode.d0.loss_mask: 0.4409  mix_decode.d0.loss_dice: 0.6356  mix_decode.d1.loss_cls: 0.1448  mix_decode.d1.loss_mask: 0.4383  mix_decode.d1.loss_dice: 0.6180  mix_decode.d2.loss_cls: 0.1338  mix_decode.d2.loss_mask: 0.4359  mix_decode.d2.loss_dice: 0.5746  mix_decode.d3.loss_cls: 0.1702  mix_decode.d3.loss_mask: 0.4319  mix_decode.d3.loss_dice: 0.5482  mix_decode.d4.loss_cls: 0.1500  mix_decode.d4.loss_mask: 0.4323  mix_decode.d4.loss_dice: 0.5505  mix_decode.d5.loss_cls: 0.1928  mix_decode.d5.loss_mask: 0.4345  mix_decode.d5.loss_dice: 0.5548  mix_decode.d6.loss_cls: 0.1850  mix_decode.d6.loss_mask: 0.4416  mix_decode.d6.loss_dice: 0.5744  mix_decode.d7.loss_cls: 0.1529  mix_decode.d7.loss_mask: 0.4406  mix_decode.d7.loss_dice: 0.5794  mix_decode.d8.loss_cls: 0.1578  mix_decode.d8.loss_mask: 0.4358  mix_decode.d8.loss_dice: 0.5735
2025/03/28 13:29:58 - mmengine - INFO - Iter(train) [13450/20000]  base_lr: 3.6619e-05 lr: 3.6619e-05  eta: 1:39:11  time: 1.0779  data_time: 0.0226  memory: 10780  loss: 27.9225  decode.loss_cls: 0.0653  decode.loss_mask: 0.8323  decode.loss_dice: 0.7638  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.8386  decode.d0.loss_dice: 0.7939  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.8402  decode.d1.loss_dice: 0.7654  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.8391  decode.d2.loss_dice: 0.7589  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.8381  decode.d3.loss_dice: 0.7599  decode.d4.loss_cls: 0.0461  decode.d4.loss_mask: 0.8412  decode.d4.loss_dice: 0.7644  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.8358  decode.d5.loss_dice: 0.7676  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.8360  decode.d6.loss_dice: 0.7763  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 0.7610  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 0.8312  decode.d8.loss_dice: 0.7538  mix_decode.loss_cls: 0.0777  mix_decode.loss_mask: 0.4443  mix_decode.loss_dice: 0.5716  mix_decode.d0.loss_cls: 0.1501  mix_decode.d0.loss_mask: 0.4619  mix_decode.d0.loss_dice: 0.6090  mix_decode.d1.loss_cls: 0.1224  mix_decode.d1.loss_mask: 0.4667  mix_decode.d1.loss_dice: 0.5753  mix_decode.d2.loss_cls: 0.0921  mix_decode.d2.loss_mask: 0.4915  mix_decode.d2.loss_dice: 0.5815  mix_decode.d3.loss_cls: 0.0851  mix_decode.d3.loss_mask: 0.4467  mix_decode.d3.loss_dice: 0.5793  mix_decode.d4.loss_cls: 0.0736  mix_decode.d4.loss_mask: 0.4673  mix_decode.d4.loss_dice: 0.5832  mix_decode.d5.loss_cls: 0.0869  mix_decode.d5.loss_mask: 0.4480  mix_decode.d5.loss_dice: 0.5815  mix_decode.d6.loss_cls: 0.1130  mix_decode.d6.loss_mask: 0.4415  mix_decode.d6.loss_dice: 0.5790  mix_decode.d7.loss_cls: 0.0764  mix_decode.d7.loss_mask: 0.4435  mix_decode.d7.loss_dice: 0.5685  mix_decode.d8.loss_cls: 0.1044  mix_decode.d8.loss_mask: 0.4433  mix_decode.d8.loss_dice: 0.5655
2025/03/28 13:30:52 - mmengine - INFO - Iter(train) [13500/20000]  base_lr: 3.6368e-05 lr: 3.6368e-05  eta: 1:38:29  time: 1.0729  data_time: 0.0221  memory: 10774  loss: 26.8923  decode.loss_cls: 0.0198  decode.loss_mask: 0.7865  decode.loss_dice: 0.7585  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.7838  decode.d0.loss_dice: 0.7591  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.7857  decode.d1.loss_dice: 0.7439  decode.d2.loss_cls: 0.0308  decode.d2.loss_mask: 0.7828  decode.d2.loss_dice: 0.7439  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.7864  decode.d3.loss_dice: 0.7635  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.7826  decode.d4.loss_dice: 0.7473  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.7869  decode.d5.loss_dice: 0.7593  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.7843  decode.d6.loss_dice: 0.7490  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.7902  decode.d7.loss_dice: 0.7595  decode.d8.loss_cls: 0.0234  decode.d8.loss_mask: 0.7879  decode.d8.loss_dice: 0.7593  mix_decode.loss_cls: 0.1269  mix_decode.loss_mask: 0.4223  mix_decode.loss_dice: 0.5522  mix_decode.d0.loss_cls: 0.1661  mix_decode.d0.loss_mask: 0.4137  mix_decode.d0.loss_dice: 0.5801  mix_decode.d1.loss_cls: 0.1553  mix_decode.d1.loss_mask: 0.4159  mix_decode.d1.loss_dice: 0.5490  mix_decode.d2.loss_cls: 0.1215  mix_decode.d2.loss_mask: 0.4096  mix_decode.d2.loss_dice: 0.5438  mix_decode.d3.loss_cls: 0.1224  mix_decode.d3.loss_mask: 0.4156  mix_decode.d3.loss_dice: 0.5731  mix_decode.d4.loss_cls: 0.1473  mix_decode.d4.loss_mask: 0.4122  mix_decode.d4.loss_dice: 0.5681  mix_decode.d5.loss_cls: 0.1311  mix_decode.d5.loss_mask: 0.4149  mix_decode.d5.loss_dice: 0.5534  mix_decode.d6.loss_cls: 0.1279  mix_decode.d6.loss_mask: 0.4330  mix_decode.d6.loss_dice: 0.5501  mix_decode.d7.loss_cls: 0.1096  mix_decode.d7.loss_mask: 0.4249  mix_decode.d7.loss_dice: 0.5669  mix_decode.d8.loss_cls: 0.1048  mix_decode.d8.loss_mask: 0.4190  mix_decode.d8.loss_dice: 0.5636
2025/03/28 13:31:46 - mmengine - INFO - Iter(train) [13550/20000]  base_lr: 3.6116e-05 lr: 3.6116e-05  eta: 1:37:48  time: 1.0892  data_time: 0.0241  memory: 10771  loss: 29.2361  decode.loss_cls: 0.0175  decode.loss_mask: 0.8751  decode.loss_dice: 0.8464  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.8776  decode.d0.loss_dice: 0.8456  decode.d1.loss_cls: 0.0197  decode.d1.loss_mask: 0.8687  decode.d1.loss_dice: 0.8330  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.8707  decode.d2.loss_dice: 0.8358  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.8688  decode.d3.loss_dice: 0.8410  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.8761  decode.d4.loss_dice: 0.8296  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.8710  decode.d5.loss_dice: 0.8372  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.8686  decode.d6.loss_dice: 0.8282  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.8735  decode.d7.loss_dice: 0.8389  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.8680  decode.d8.loss_dice: 0.8343  mix_decode.loss_cls: 0.0997  mix_decode.loss_mask: 0.4547  mix_decode.loss_dice: 0.6394  mix_decode.d0.loss_cls: 0.1018  mix_decode.d0.loss_mask: 0.4600  mix_decode.d0.loss_dice: 0.6688  mix_decode.d1.loss_cls: 0.0746  mix_decode.d1.loss_mask: 0.4540  mix_decode.d1.loss_dice: 0.6454  mix_decode.d2.loss_cls: 0.0776  mix_decode.d2.loss_mask: 0.4509  mix_decode.d2.loss_dice: 0.6409  mix_decode.d3.loss_cls: 0.0835  mix_decode.d3.loss_mask: 0.4533  mix_decode.d3.loss_dice: 0.6593  mix_decode.d4.loss_cls: 0.0679  mix_decode.d4.loss_mask: 0.4503  mix_decode.d4.loss_dice: 0.6535  mix_decode.d5.loss_cls: 0.0852  mix_decode.d5.loss_mask: 0.4456  mix_decode.d5.loss_dice: 0.6598  mix_decode.d6.loss_cls: 0.0909  mix_decode.d6.loss_mask: 0.4459  mix_decode.d6.loss_dice: 0.6553  mix_decode.d7.loss_cls: 0.0756  mix_decode.d7.loss_mask: 0.4502  mix_decode.d7.loss_dice: 0.6610  mix_decode.d8.loss_cls: 0.0771  mix_decode.d8.loss_mask: 0.4565  mix_decode.d8.loss_dice: 0.6488
2025/03/28 13:32:40 - mmengine - INFO - Iter(train) [13600/20000]  base_lr: 3.5864e-05 lr: 3.5864e-05  eta: 1:37:07  time: 1.0954  data_time: 0.0249  memory: 10775  loss: 25.4699  decode.loss_cls: 0.0143  decode.loss_mask: 0.8466  decode.loss_dice: 0.7356  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.8624  decode.d0.loss_dice: 0.7756  decode.d1.loss_cls: 0.0240  decode.d1.loss_mask: 0.8511  decode.d1.loss_dice: 0.7650  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.8599  decode.d2.loss_dice: 0.7548  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.8497  decode.d3.loss_dice: 0.7471  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.8524  decode.d4.loss_dice: 0.7466  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.8514  decode.d5.loss_dice: 0.7407  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.8498  decode.d6.loss_dice: 0.7363  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.8486  decode.d7.loss_dice: 0.7428  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.8548  decode.d8.loss_dice: 0.7528  mix_decode.loss_cls: 0.0624  mix_decode.loss_mask: 0.3718  mix_decode.loss_dice: 0.4690  mix_decode.d0.loss_cls: 0.1140  mix_decode.d0.loss_mask: 0.3797  mix_decode.d0.loss_dice: 0.4996  mix_decode.d1.loss_cls: 0.0886  mix_decode.d1.loss_mask: 0.3557  mix_decode.d1.loss_dice: 0.4845  mix_decode.d2.loss_cls: 0.0903  mix_decode.d2.loss_mask: 0.3602  mix_decode.d2.loss_dice: 0.4716  mix_decode.d3.loss_cls: 0.0709  mix_decode.d3.loss_mask: 0.3673  mix_decode.d3.loss_dice: 0.4566  mix_decode.d4.loss_cls: 0.0682  mix_decode.d4.loss_mask: 0.3697  mix_decode.d4.loss_dice: 0.4736  mix_decode.d5.loss_cls: 0.1071  mix_decode.d5.loss_mask: 0.3594  mix_decode.d5.loss_dice: 0.4594  mix_decode.d6.loss_cls: 0.0410  mix_decode.d6.loss_mask: 0.3703  mix_decode.d6.loss_dice: 0.4920  mix_decode.d7.loss_cls: 0.0698  mix_decode.d7.loss_mask: 0.3698  mix_decode.d7.loss_dice: 0.4817  mix_decode.d8.loss_cls: 0.0654  mix_decode.d8.loss_mask: 0.3670  mix_decode.d8.loss_dice: 0.4821
2025/03/28 13:33:34 - mmengine - INFO - Iter(train) [13650/20000]  base_lr: 3.5611e-05 lr: 3.5611e-05  eta: 1:36:25  time: 1.0766  data_time: 0.0224  memory: 10772  loss: 25.1949  decode.loss_cls: 0.0197  decode.loss_mask: 0.7122  decode.loss_dice: 0.6832  decode.d0.loss_cls: 0.0874  decode.d0.loss_mask: 0.7172  decode.d0.loss_dice: 0.6856  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.7132  decode.d1.loss_dice: 0.6650  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.7107  decode.d2.loss_dice: 0.6705  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.7082  decode.d3.loss_dice: 0.6727  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.7163  decode.d4.loss_dice: 0.6819  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.7124  decode.d5.loss_dice: 0.6802  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.7056  decode.d6.loss_dice: 0.6728  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.7093  decode.d7.loss_dice: 0.6805  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.7133  decode.d8.loss_dice: 0.6826  mix_decode.loss_cls: 0.0620  mix_decode.loss_mask: 0.4354  mix_decode.loss_dice: 0.5796  mix_decode.d0.loss_cls: 0.1045  mix_decode.d0.loss_mask: 0.4365  mix_decode.d0.loss_dice: 0.6132  mix_decode.d1.loss_cls: 0.1131  mix_decode.d1.loss_mask: 0.4350  mix_decode.d1.loss_dice: 0.5736  mix_decode.d2.loss_cls: 0.0822  mix_decode.d2.loss_mask: 0.4307  mix_decode.d2.loss_dice: 0.5776  mix_decode.d3.loss_cls: 0.0880  mix_decode.d3.loss_mask: 0.4342  mix_decode.d3.loss_dice: 0.5694  mix_decode.d4.loss_cls: 0.0868  mix_decode.d4.loss_mask: 0.4348  mix_decode.d4.loss_dice: 0.5697  mix_decode.d5.loss_cls: 0.0853  mix_decode.d5.loss_mask: 0.4300  mix_decode.d5.loss_dice: 0.5717  mix_decode.d6.loss_cls: 0.0725  mix_decode.d6.loss_mask: 0.4356  mix_decode.d6.loss_dice: 0.5865  mix_decode.d7.loss_cls: 0.0900  mix_decode.d7.loss_mask: 0.4348  mix_decode.d7.loss_dice: 0.5945  mix_decode.d8.loss_cls: 0.0705  mix_decode.d8.loss_mask: 0.4333  mix_decode.d8.loss_dice: 0.5906
2025/03/28 13:34:28 - mmengine - INFO - Iter(train) [13700/20000]  base_lr: 3.5359e-05 lr: 3.5359e-05  eta: 1:35:43  time: 1.0785  data_time: 0.0225  memory: 10767  loss: 27.1982  decode.loss_cls: 0.0061  decode.loss_mask: 0.8048  decode.loss_dice: 0.7471  decode.d0.loss_cls: 0.0640  decode.d0.loss_mask: 0.8120  decode.d0.loss_dice: 0.7440  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.8087  decode.d1.loss_dice: 0.7436  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.8109  decode.d2.loss_dice: 0.7478  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.8078  decode.d3.loss_dice: 0.7436  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.8099  decode.d4.loss_dice: 0.7494  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.8102  decode.d5.loss_dice: 0.7481  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 0.7454  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.8101  decode.d7.loss_dice: 0.7457  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.8139  decode.d8.loss_dice: 0.7347  mix_decode.loss_cls: 0.1287  mix_decode.loss_mask: 0.4587  mix_decode.loss_dice: 0.6034  mix_decode.d0.loss_cls: 0.1451  mix_decode.d0.loss_mask: 0.4214  mix_decode.d0.loss_dice: 0.6288  mix_decode.d1.loss_cls: 0.1294  mix_decode.d1.loss_mask: 0.4199  mix_decode.d1.loss_dice: 0.6038  mix_decode.d2.loss_cls: 0.1199  mix_decode.d2.loss_mask: 0.4287  mix_decode.d2.loss_dice: 0.5911  mix_decode.d3.loss_cls: 0.1268  mix_decode.d3.loss_mask: 0.4269  mix_decode.d3.loss_dice: 0.5909  mix_decode.d4.loss_cls: 0.1006  mix_decode.d4.loss_mask: 0.4232  mix_decode.d4.loss_dice: 0.6031  mix_decode.d5.loss_cls: 0.1139  mix_decode.d5.loss_mask: 0.4279  mix_decode.d5.loss_dice: 0.6181  mix_decode.d6.loss_cls: 0.0791  mix_decode.d6.loss_mask: 0.4622  mix_decode.d6.loss_dice: 0.5981  mix_decode.d7.loss_cls: 0.1007  mix_decode.d7.loss_mask: 0.4232  mix_decode.d7.loss_dice: 0.6010  mix_decode.d8.loss_cls: 0.1233  mix_decode.d8.loss_mask: 0.4263  mix_decode.d8.loss_dice: 0.5963
2025/03/28 13:35:22 - mmengine - INFO - Iter(train) [13750/20000]  base_lr: 3.5106e-05 lr: 3.5106e-05  eta: 1:35:02  time: 1.0778  data_time: 0.0228  memory: 10770  loss: 26.7692  decode.loss_cls: 0.0617  decode.loss_mask: 0.8360  decode.loss_dice: 0.7150  decode.d0.loss_cls: 0.1057  decode.d0.loss_mask: 0.8456  decode.d0.loss_dice: 0.7047  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.8374  decode.d1.loss_dice: 0.7201  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.8416  decode.d2.loss_dice: 0.7167  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.8355  decode.d3.loss_dice: 0.7139  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.8339  decode.d4.loss_dice: 0.7148  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.8344  decode.d5.loss_dice: 0.7131  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.8329  decode.d6.loss_dice: 0.7165  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.8365  decode.d7.loss_dice: 0.7165  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.8330  decode.d8.loss_dice: 0.7152  mix_decode.loss_cls: 0.0609  mix_decode.loss_mask: 0.4097  mix_decode.loss_dice: 0.5710  mix_decode.d0.loss_cls: 0.0901  mix_decode.d0.loss_mask: 0.4265  mix_decode.d0.loss_dice: 0.6114  mix_decode.d1.loss_cls: 0.0533  mix_decode.d1.loss_mask: 0.4126  mix_decode.d1.loss_dice: 0.5905  mix_decode.d2.loss_cls: 0.0823  mix_decode.d2.loss_mask: 0.4100  mix_decode.d2.loss_dice: 0.5800  mix_decode.d3.loss_cls: 0.0718  mix_decode.d3.loss_mask: 0.4069  mix_decode.d3.loss_dice: 0.5476  mix_decode.d4.loss_cls: 0.0828  mix_decode.d4.loss_mask: 0.4089  mix_decode.d4.loss_dice: 0.5678  mix_decode.d5.loss_cls: 0.0611  mix_decode.d5.loss_mask: 0.4039  mix_decode.d5.loss_dice: 0.5680  mix_decode.d6.loss_cls: 0.0886  mix_decode.d6.loss_mask: 0.4055  mix_decode.d6.loss_dice: 0.5585  mix_decode.d7.loss_cls: 0.0729  mix_decode.d7.loss_mask: 0.4078  mix_decode.d7.loss_dice: 0.5762  mix_decode.d8.loss_cls: 0.0962  mix_decode.d8.loss_mask: 0.4107  mix_decode.d8.loss_dice: 0.5584
2025/03/28 13:36:16 - mmengine - INFO - Iter(train) [13800/20000]  base_lr: 3.4853e-05 lr: 3.4853e-05  eta: 1:34:20  time: 1.0805  data_time: 0.0232  memory: 10779  loss: 24.6452  decode.loss_cls: 0.0205  decode.loss_mask: 0.6474  decode.loss_dice: 0.7261  decode.d0.loss_cls: 0.0917  decode.d0.loss_mask: 0.6466  decode.d0.loss_dice: 0.7226  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.6507  decode.d1.loss_dice: 0.7286  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.6484  decode.d2.loss_dice: 0.7294  decode.d3.loss_cls: 0.0484  decode.d3.loss_mask: 0.6504  decode.d3.loss_dice: 0.7231  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.6543  decode.d4.loss_dice: 0.7278  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.6492  decode.d5.loss_dice: 0.7317  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.6548  decode.d6.loss_dice: 0.7280  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.6552  decode.d7.loss_dice: 0.7366  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.6516  decode.d8.loss_dice: 0.7412  mix_decode.loss_cls: 0.0603  mix_decode.loss_mask: 0.4067  mix_decode.loss_dice: 0.5838  mix_decode.d0.loss_cls: 0.0737  mix_decode.d0.loss_mask: 0.4177  mix_decode.d0.loss_dice: 0.5936  mix_decode.d1.loss_cls: 0.0570  mix_decode.d1.loss_mask: 0.4083  mix_decode.d1.loss_dice: 0.5836  mix_decode.d2.loss_cls: 0.0541  mix_decode.d2.loss_mask: 0.4073  mix_decode.d2.loss_dice: 0.5860  mix_decode.d3.loss_cls: 0.0511  mix_decode.d3.loss_mask: 0.4035  mix_decode.d3.loss_dice: 0.5839  mix_decode.d4.loss_cls: 0.0519  mix_decode.d4.loss_mask: 0.4026  mix_decode.d4.loss_dice: 0.5829  mix_decode.d5.loss_cls: 0.0495  mix_decode.d5.loss_mask: 0.4020  mix_decode.d5.loss_dice: 0.5644  mix_decode.d6.loss_cls: 0.0509  mix_decode.d6.loss_mask: 0.4074  mix_decode.d6.loss_dice: 0.5791  mix_decode.d7.loss_cls: 0.0541  mix_decode.d7.loss_mask: 0.4040  mix_decode.d7.loss_dice: 0.5714  mix_decode.d8.loss_cls: 0.0564  mix_decode.d8.loss_mask: 0.4055  mix_decode.d8.loss_dice: 0.5749
2025/03/28 13:37:10 - mmengine - INFO - Iter(train) [13850/20000]  base_lr: 3.4600e-05 lr: 3.4600e-05  eta: 1:33:38  time: 1.0788  data_time: 0.0226  memory: 10772  loss: 26.5958  decode.loss_cls: 0.0689  decode.loss_mask: 0.7259  decode.loss_dice: 0.7314  decode.d0.loss_cls: 0.0895  decode.d0.loss_mask: 0.7356  decode.d0.loss_dice: 0.7556  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.7308  decode.d1.loss_dice: 0.7581  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.7312  decode.d2.loss_dice: 0.7497  decode.d3.loss_cls: 0.0639  decode.d3.loss_mask: 0.7254  decode.d3.loss_dice: 0.7384  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.7305  decode.d4.loss_dice: 0.7197  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.7280  decode.d5.loss_dice: 0.7408  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.7306  decode.d6.loss_dice: 0.7288  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.7253  decode.d7.loss_dice: 0.7469  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.7244  decode.d8.loss_dice: 0.7402  mix_decode.loss_cls: 0.0464  mix_decode.loss_mask: 0.4803  mix_decode.loss_dice: 0.6016  mix_decode.d0.loss_cls: 0.0803  mix_decode.d0.loss_mask: 0.4763  mix_decode.d0.loss_dice: 0.5965  mix_decode.d1.loss_cls: 0.0451  mix_decode.d1.loss_mask: 0.4724  mix_decode.d1.loss_dice: 0.5901  mix_decode.d2.loss_cls: 0.0451  mix_decode.d2.loss_mask: 0.4819  mix_decode.d2.loss_dice: 0.5849  mix_decode.d3.loss_cls: 0.0408  mix_decode.d3.loss_mask: 0.4818  mix_decode.d3.loss_dice: 0.5964  mix_decode.d4.loss_cls: 0.0589  mix_decode.d4.loss_mask: 0.4801  mix_decode.d4.loss_dice: 0.5887  mix_decode.d5.loss_cls: 0.0411  mix_decode.d5.loss_mask: 0.4813  mix_decode.d5.loss_dice: 0.5918  mix_decode.d6.loss_cls: 0.0681  mix_decode.d6.loss_mask: 0.4800  mix_decode.d6.loss_dice: 0.5928  mix_decode.d7.loss_cls: 0.0680  mix_decode.d7.loss_mask: 0.4746  mix_decode.d7.loss_dice: 0.5986  mix_decode.d8.loss_cls: 0.0669  mix_decode.d8.loss_mask: 0.4795  mix_decode.d8.loss_dice: 0.5878
2025/03/28 13:38:04 - mmengine - INFO - Iter(train) [13900/20000]  base_lr: 3.4347e-05 lr: 3.4347e-05  eta: 1:32:56  time: 1.0817  data_time: 0.0236  memory: 10771  loss: 27.6894  decode.loss_cls: 0.0950  decode.loss_mask: 0.7495  decode.loss_dice: 0.8304  decode.d0.loss_cls: 0.0647  decode.d0.loss_mask: 0.7889  decode.d0.loss_dice: 0.8751  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.7556  decode.d1.loss_dice: 0.8513  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.7532  decode.d2.loss_dice: 0.8215  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.7498  decode.d3.loss_dice: 0.8286  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.7578  decode.d4.loss_dice: 0.8424  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.7532  decode.d5.loss_dice: 0.8369  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.7525  decode.d6.loss_dice: 0.8403  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.7522  decode.d7.loss_dice: 0.8377  decode.d8.loss_cls: 0.0887  decode.d8.loss_mask: 0.7516  decode.d8.loss_dice: 0.8213  mix_decode.loss_cls: 0.1255  mix_decode.loss_mask: 0.4299  mix_decode.loss_dice: 0.5342  mix_decode.d0.loss_cls: 0.1235  mix_decode.d0.loss_mask: 0.4637  mix_decode.d0.loss_dice: 0.5712  mix_decode.d1.loss_cls: 0.1345  mix_decode.d1.loss_mask: 0.4373  mix_decode.d1.loss_dice: 0.5397  mix_decode.d2.loss_cls: 0.1090  mix_decode.d2.loss_mask: 0.4335  mix_decode.d2.loss_dice: 0.5385  mix_decode.d3.loss_cls: 0.1170  mix_decode.d3.loss_mask: 0.4285  mix_decode.d3.loss_dice: 0.5350  mix_decode.d4.loss_cls: 0.1369  mix_decode.d4.loss_mask: 0.4372  mix_decode.d4.loss_dice: 0.5385  mix_decode.d5.loss_cls: 0.1375  mix_decode.d5.loss_mask: 0.4398  mix_decode.d5.loss_dice: 0.5342  mix_decode.d6.loss_cls: 0.1239  mix_decode.d6.loss_mask: 0.4295  mix_decode.d6.loss_dice: 0.5333  mix_decode.d7.loss_cls: 0.1447  mix_decode.d7.loss_mask: 0.4303  mix_decode.d7.loss_dice: 0.5258  mix_decode.d8.loss_cls: 0.1227  mix_decode.d8.loss_mask: 0.4314  mix_decode.d8.loss_dice: 0.5344
2025/03/28 13:38:59 - mmengine - INFO - Iter(train) [13950/20000]  base_lr: 3.4094e-05 lr: 3.4094e-05  eta: 1:32:14  time: 1.0799  data_time: 0.0225  memory: 10777  loss: 27.7780  decode.loss_cls: 0.0326  decode.loss_mask: 0.7523  decode.loss_dice: 0.8314  decode.d0.loss_cls: 0.0785  decode.d0.loss_mask: 0.7540  decode.d0.loss_dice: 0.8597  decode.d1.loss_cls: 0.0859  decode.d1.loss_mask: 0.7543  decode.d1.loss_dice: 0.8418  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.7510  decode.d2.loss_dice: 0.8283  decode.d3.loss_cls: 0.0250  decode.d3.loss_mask: 0.7506  decode.d3.loss_dice: 0.8360  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.7542  decode.d4.loss_dice: 0.8241  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.7522  decode.d5.loss_dice: 0.8287  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.7571  decode.d6.loss_dice: 0.8330  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.7588  decode.d7.loss_dice: 0.8248  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.7494  decode.d8.loss_dice: 0.8303  mix_decode.loss_cls: 0.0773  mix_decode.loss_mask: 0.4387  mix_decode.loss_dice: 0.6247  mix_decode.d0.loss_cls: 0.0822  mix_decode.d0.loss_mask: 0.4541  mix_decode.d0.loss_dice: 0.6572  mix_decode.d1.loss_cls: 0.1170  mix_decode.d1.loss_mask: 0.4437  mix_decode.d1.loss_dice: 0.6095  mix_decode.d2.loss_cls: 0.0725  mix_decode.d2.loss_mask: 0.4441  mix_decode.d2.loss_dice: 0.5934  mix_decode.d3.loss_cls: 0.0745  mix_decode.d3.loss_mask: 0.4428  mix_decode.d3.loss_dice: 0.6027  mix_decode.d4.loss_cls: 0.0859  mix_decode.d4.loss_mask: 0.4400  mix_decode.d4.loss_dice: 0.6062  mix_decode.d5.loss_cls: 0.0457  mix_decode.d5.loss_mask: 0.4459  mix_decode.d5.loss_dice: 0.6348  mix_decode.d6.loss_cls: 0.0734  mix_decode.d6.loss_mask: 0.4420  mix_decode.d6.loss_dice: 0.6238  mix_decode.d7.loss_cls: 0.0599  mix_decode.d7.loss_mask: 0.4546  mix_decode.d7.loss_dice: 0.6256  mix_decode.d8.loss_cls: 0.0905  mix_decode.d8.loss_mask: 0.4411  mix_decode.d8.loss_dice: 0.6209
2025/03/28 13:39:53 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 13:39:53 - mmengine - INFO - Iter(train) [14000/20000]  base_lr: 3.3840e-05 lr: 3.3840e-05  eta: 1:31:32  time: 1.0803  data_time: 0.0227  memory: 10774  loss: 26.7061  decode.loss_cls: 0.0794  decode.loss_mask: 0.7801  decode.loss_dice: 0.7762  decode.d0.loss_cls: 0.1185  decode.d0.loss_mask: 0.7789  decode.d0.loss_dice: 0.7754  decode.d1.loss_cls: 0.0240  decode.d1.loss_mask: 0.7898  decode.d1.loss_dice: 0.7845  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.7881  decode.d2.loss_dice: 0.7849  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.7875  decode.d3.loss_dice: 0.7903  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.7898  decode.d4.loss_dice: 0.7864  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.7809  decode.d5.loss_dice: 0.7778  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.7859  decode.d6.loss_dice: 0.7946  decode.d7.loss_cls: 0.0254  decode.d7.loss_mask: 0.7820  decode.d7.loss_dice: 0.7874  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.7902  decode.d8.loss_dice: 0.7803  mix_decode.loss_cls: 0.0809  mix_decode.loss_mask: 0.3998  mix_decode.loss_dice: 0.5668  mix_decode.d0.loss_cls: 0.1089  mix_decode.d0.loss_mask: 0.3925  mix_decode.d0.loss_dice: 0.5961  mix_decode.d1.loss_cls: 0.1374  mix_decode.d1.loss_mask: 0.3893  mix_decode.d1.loss_dice: 0.5653  mix_decode.d2.loss_cls: 0.1146  mix_decode.d2.loss_mask: 0.3960  mix_decode.d2.loss_dice: 0.5653  mix_decode.d3.loss_cls: 0.0760  mix_decode.d3.loss_mask: 0.4023  mix_decode.d3.loss_dice: 0.5555  mix_decode.d4.loss_cls: 0.0864  mix_decode.d4.loss_mask: 0.4044  mix_decode.d4.loss_dice: 0.5680  mix_decode.d5.loss_cls: 0.1060  mix_decode.d5.loss_mask: 0.3984  mix_decode.d5.loss_dice: 0.5581  mix_decode.d6.loss_cls: 0.0825  mix_decode.d6.loss_mask: 0.4001  mix_decode.d6.loss_dice: 0.5593  mix_decode.d7.loss_cls: 0.0899  mix_decode.d7.loss_mask: 0.3975  mix_decode.d7.loss_dice: 0.5559  mix_decode.d8.loss_cls: 0.1068  mix_decode.d8.loss_mask: 0.4033  mix_decode.d8.loss_dice: 0.5659
2025/03/28 13:39:53 - mmengine - INFO - Saving checkpoint at 14000 iterations
2025/03/28 13:39:58 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0852  data_time: 0.0018  memory: 3071  
2025/03/28 13:40:02 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:44  time: 0.0853  data_time: 0.0018  memory: 3071  
2025/03/28 13:40:07 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:39  time: 0.0853  data_time: 0.0018  memory: 3071  
2025/03/28 13:40:11 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:35  time: 0.0853  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:15 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:20 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:27  time: 0.0882  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:24 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:23  time: 0.0855  data_time: 0.0018  memory: 3071  
2025/03/28 13:40:28 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:18  time: 0.0857  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:33 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:14  time: 0.0872  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:37 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:10  time: 0.1037  data_time: 0.0017  memory: 3071  
2025/03/28 13:40:41 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:06  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:46 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:01  time: 0.0854  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:50 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:57  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:40:54 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:53  time: 0.0854  data_time: 0.0017  memory: 3071  
2025/03/28 13:40:58 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:48  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:03 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:44  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:07 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:40  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:11 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:16 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:31  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:20 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:27  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:24 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:28 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0857  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:33 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:14  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:41:37 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:10  time: 0.0872  data_time: 0.0020  memory: 3071  
2025/03/28 13:41:41 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0854  data_time: 0.0018  memory: 3071  
2025/03/28 13:41:46 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0853  data_time: 0.0018  memory: 3071  
2025/03/28 13:41:50 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:57  time: 0.0855  data_time: 0.0018  memory: 3071  
2025/03/28 13:41:54 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0854  data_time: 0.0018  memory: 3071  
2025/03/28 13:41:58 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0854  data_time: 0.0018  memory: 3071  
2025/03/28 13:42:03 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:07 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:40  time: 0.0855  data_time: 0.0018  memory: 3071  
2025/03/28 13:42:11 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:16 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0855  data_time: 0.0018  memory: 3071  
2025/03/28 13:42:20 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:27  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:24 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0855  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:28 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0857  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:33 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:37 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0857  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:41 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0857  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:46 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0856  data_time: 0.0019  memory: 3071  
2025/03/28 13:42:47 - mmengine - INFO - per class results:
2025/03/28 13:42:47 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 75.79 | 88.96 |
|      building      | 87.79 | 95.67 |
|   low_vegetation   | 62.07 | 91.84 |
|        tree        | 47.36 | 49.55 |
|        car         |  75.5 | 88.98 |
|      clutter       | 11.31 | 12.11 |
+--------------------+-------+-------+
2025/03/28 13:42:47 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 80.8600  mIoU: 59.9700  mAcc: 71.1800  data_time: 0.0019  time: 0.0858
2025/03/28 13:43:41 - mmengine - INFO - Iter(train) [14050/20000]  base_lr: 3.3586e-05 lr: 3.3586e-05  eta: 1:30:49  time: 1.0792  data_time: 0.0234  memory: 10775  loss: 28.1808  decode.loss_cls: 0.1871  decode.loss_mask: 0.8570  decode.loss_dice: 0.7772  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 0.9033  decode.d0.loss_dice: 0.7991  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 0.9025  decode.d1.loss_dice: 0.7808  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.8992  decode.d2.loss_dice: 0.7973  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.8963  decode.d3.loss_dice: 0.7917  decode.d4.loss_cls: 0.0670  decode.d4.loss_mask: 0.9111  decode.d4.loss_dice: 0.8094  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.9035  decode.d5.loss_dice: 0.8136  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 0.8577  decode.d6.loss_dice: 0.7736  decode.d7.loss_cls: 0.1364  decode.d7.loss_mask: 0.8583  decode.d7.loss_dice: 0.8023  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.8993  decode.d8.loss_dice: 0.7924  mix_decode.loss_cls: 0.0711  mix_decode.loss_mask: 0.4313  mix_decode.loss_dice: 0.5379  mix_decode.d0.loss_cls: 0.0476  mix_decode.d0.loss_mask: 0.4363  mix_decode.d0.loss_dice: 0.5520  mix_decode.d1.loss_cls: 0.0863  mix_decode.d1.loss_mask: 0.4336  mix_decode.d1.loss_dice: 0.5452  mix_decode.d2.loss_cls: 0.0579  mix_decode.d2.loss_mask: 0.4328  mix_decode.d2.loss_dice: 0.5575  mix_decode.d3.loss_cls: 0.0475  mix_decode.d3.loss_mask: 0.4329  mix_decode.d3.loss_dice: 0.5320  mix_decode.d4.loss_cls: 0.0543  mix_decode.d4.loss_mask: 0.4338  mix_decode.d4.loss_dice: 0.5269  mix_decode.d5.loss_cls: 0.0548  mix_decode.d5.loss_mask: 0.4351  mix_decode.d5.loss_dice: 0.5536  mix_decode.d6.loss_cls: 0.0366  mix_decode.d6.loss_mask: 0.4398  mix_decode.d6.loss_dice: 0.5481  mix_decode.d7.loss_cls: 0.0668  mix_decode.d7.loss_mask: 0.4330  mix_decode.d7.loss_dice: 0.5325  mix_decode.d8.loss_cls: 0.0460  mix_decode.d8.loss_mask: 0.4301  mix_decode.d8.loss_dice: 0.5428
2025/03/28 13:44:35 - mmengine - INFO - Iter(train) [14100/20000]  base_lr: 3.3332e-05 lr: 3.3332e-05  eta: 1:30:07  time: 1.0796  data_time: 0.0227  memory: 10776  loss: 28.4023  decode.loss_cls: 0.0560  decode.loss_mask: 0.8805  decode.loss_dice: 0.7258  decode.d0.loss_cls: 0.1352  decode.d0.loss_mask: 0.8893  decode.d0.loss_dice: 0.7297  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.8761  decode.d1.loss_dice: 0.7334  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.8773  decode.d2.loss_dice: 0.7274  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.8754  decode.d3.loss_dice: 0.7288  decode.d4.loss_cls: 0.0482  decode.d4.loss_mask: 0.8721  decode.d4.loss_dice: 0.7290  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.8735  decode.d5.loss_dice: 0.7378  decode.d6.loss_cls: 0.0481  decode.d6.loss_mask: 0.8746  decode.d6.loss_dice: 0.7348  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.8778  decode.d7.loss_dice: 0.7354  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.8741  decode.d8.loss_dice: 0.7347  mix_decode.loss_cls: 0.1067  mix_decode.loss_mask: 0.5210  mix_decode.loss_dice: 0.5346  mix_decode.d0.loss_cls: 0.1290  mix_decode.d0.loss_mask: 0.5240  mix_decode.d0.loss_dice: 0.5450  mix_decode.d1.loss_cls: 0.1295  mix_decode.d1.loss_mask: 0.5229  mix_decode.d1.loss_dice: 0.5397  mix_decode.d2.loss_cls: 0.1211  mix_decode.d2.loss_mask: 0.5073  mix_decode.d2.loss_dice: 0.5408  mix_decode.d3.loss_cls: 0.1061  mix_decode.d3.loss_mask: 0.5193  mix_decode.d3.loss_dice: 0.5341  mix_decode.d4.loss_cls: 0.1044  mix_decode.d4.loss_mask: 0.5175  mix_decode.d4.loss_dice: 0.5401  mix_decode.d5.loss_cls: 0.1197  mix_decode.d5.loss_mask: 0.5036  mix_decode.d5.loss_dice: 0.5376  mix_decode.d6.loss_cls: 0.1131  mix_decode.d6.loss_mask: 0.5111  mix_decode.d6.loss_dice: 0.5578  mix_decode.d7.loss_cls: 0.1178  mix_decode.d7.loss_mask: 0.5121  mix_decode.d7.loss_dice: 0.5419  mix_decode.d8.loss_cls: 0.1018  mix_decode.d8.loss_mask: 0.5146  mix_decode.d8.loss_dice: 0.5280
2025/03/28 13:45:29 - mmengine - INFO - Iter(train) [14150/20000]  base_lr: 3.3078e-05 lr: 3.3078e-05  eta: 1:29:25  time: 1.0746  data_time: 0.0224  memory: 10771  loss: 24.3672  decode.loss_cls: 0.0114  decode.loss_mask: 0.7425  decode.loss_dice: 0.6873  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.7584  decode.d0.loss_dice: 0.6840  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.7514  decode.d1.loss_dice: 0.6941  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.7490  decode.d2.loss_dice: 0.6780  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.7507  decode.d3.loss_dice: 0.6858  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.7423  decode.d4.loss_dice: 0.6842  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.7402  decode.d5.loss_dice: 0.6871  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.7430  decode.d6.loss_dice: 0.6868  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.7436  decode.d7.loss_dice: 0.6820  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.7460  decode.d8.loss_dice: 0.6869  mix_decode.loss_cls: 0.0958  mix_decode.loss_mask: 0.3780  mix_decode.loss_dice: 0.4956  mix_decode.d0.loss_cls: 0.1427  mix_decode.d0.loss_mask: 0.3815  mix_decode.d0.loss_dice: 0.5106  mix_decode.d1.loss_cls: 0.1680  mix_decode.d1.loss_mask: 0.3747  mix_decode.d1.loss_dice: 0.4696  mix_decode.d2.loss_cls: 0.1420  mix_decode.d2.loss_mask: 0.3705  mix_decode.d2.loss_dice: 0.4720  mix_decode.d3.loss_cls: 0.1077  mix_decode.d3.loss_mask: 0.3763  mix_decode.d3.loss_dice: 0.4756  mix_decode.d4.loss_cls: 0.1216  mix_decode.d4.loss_mask: 0.3759  mix_decode.d4.loss_dice: 0.4669  mix_decode.d5.loss_cls: 0.1142  mix_decode.d5.loss_mask: 0.3769  mix_decode.d5.loss_dice: 0.4710  mix_decode.d6.loss_cls: 0.1464  mix_decode.d6.loss_mask: 0.3720  mix_decode.d6.loss_dice: 0.4656  mix_decode.d7.loss_cls: 0.1497  mix_decode.d7.loss_mask: 0.3732  mix_decode.d7.loss_dice: 0.4741  mix_decode.d8.loss_cls: 0.1119  mix_decode.d8.loss_mask: 0.3769  mix_decode.d8.loss_dice: 0.4851
2025/03/28 13:46:23 - mmengine - INFO - Iter(train) [14200/20000]  base_lr: 3.2823e-05 lr: 3.2823e-05  eta: 1:28:42  time: 1.0910  data_time: 0.0244  memory: 10767  loss: 26.6738  decode.loss_cls: 0.0176  decode.loss_mask: 0.9010  decode.loss_dice: 0.7399  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.9124  decode.d0.loss_dice: 0.7261  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.8978  decode.d1.loss_dice: 0.7513  decode.d2.loss_cls: 0.0192  decode.d2.loss_mask: 0.8979  decode.d2.loss_dice: 0.7310  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.8970  decode.d3.loss_dice: 0.7570  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.9039  decode.d4.loss_dice: 0.7427  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.8952  decode.d5.loss_dice: 0.7358  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.9062  decode.d6.loss_dice: 0.7516  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.9022  decode.d7.loss_dice: 0.7352  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.8996  decode.d8.loss_dice: 0.7421  mix_decode.loss_cls: 0.0637  mix_decode.loss_mask: 0.4194  mix_decode.loss_dice: 0.5086  mix_decode.d0.loss_cls: 0.1094  mix_decode.d0.loss_mask: 0.4268  mix_decode.d0.loss_dice: 0.5296  mix_decode.d1.loss_cls: 0.1027  mix_decode.d1.loss_mask: 0.4114  mix_decode.d1.loss_dice: 0.5075  mix_decode.d2.loss_cls: 0.1415  mix_decode.d2.loss_mask: 0.4064  mix_decode.d2.loss_dice: 0.4955  mix_decode.d3.loss_cls: 0.1038  mix_decode.d3.loss_mask: 0.4130  mix_decode.d3.loss_dice: 0.4896  mix_decode.d4.loss_cls: 0.1078  mix_decode.d4.loss_mask: 0.4089  mix_decode.d4.loss_dice: 0.4783  mix_decode.d5.loss_cls: 0.0827  mix_decode.d5.loss_mask: 0.4122  mix_decode.d5.loss_dice: 0.4772  mix_decode.d6.loss_cls: 0.0730  mix_decode.d6.loss_mask: 0.4130  mix_decode.d6.loss_dice: 0.4763  mix_decode.d7.loss_cls: 0.0664  mix_decode.d7.loss_mask: 0.4158  mix_decode.d7.loss_dice: 0.4834  mix_decode.d8.loss_cls: 0.0778  mix_decode.d8.loss_mask: 0.4131  mix_decode.d8.loss_dice: 0.5009
2025/03/28 13:47:17 - mmengine - INFO - Iter(train) [14250/20000]  base_lr: 3.2568e-05 lr: 3.2568e-05  eta: 1:27:59  time: 1.0726  data_time: 0.0224  memory: 10772  loss: 25.2437  decode.loss_cls: 0.0087  decode.loss_mask: 0.6893  decode.loss_dice: 0.6868  decode.d0.loss_cls: 0.0879  decode.d0.loss_mask: 0.6984  decode.d0.loss_dice: 0.6811  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.6911  decode.d1.loss_dice: 0.6949  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.6888  decode.d2.loss_dice: 0.6977  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.6916  decode.d3.loss_dice: 0.6862  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.6916  decode.d4.loss_dice: 0.6993  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.6909  decode.d5.loss_dice: 0.6934  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.6933  decode.d6.loss_dice: 0.6935  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.6900  decode.d7.loss_dice: 0.6966  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.6895  decode.d8.loss_dice: 0.6826  mix_decode.loss_cls: 0.0801  mix_decode.loss_mask: 0.4777  mix_decode.loss_dice: 0.5577  mix_decode.d0.loss_cls: 0.1187  mix_decode.d0.loss_mask: 0.4904  mix_decode.d0.loss_dice: 0.5685  mix_decode.d1.loss_cls: 0.0859  mix_decode.d1.loss_mask: 0.4801  mix_decode.d1.loss_dice: 0.5690  mix_decode.d2.loss_cls: 0.0924  mix_decode.d2.loss_mask: 0.4653  mix_decode.d2.loss_dice: 0.5526  mix_decode.d3.loss_cls: 0.0757  mix_decode.d3.loss_mask: 0.4894  mix_decode.d3.loss_dice: 0.5630  mix_decode.d4.loss_cls: 0.0988  mix_decode.d4.loss_mask: 0.4721  mix_decode.d4.loss_dice: 0.5548  mix_decode.d5.loss_cls: 0.0734  mix_decode.d5.loss_mask: 0.4784  mix_decode.d5.loss_dice: 0.5637  mix_decode.d6.loss_cls: 0.0749  mix_decode.d6.loss_mask: 0.4802  mix_decode.d6.loss_dice: 0.5579  mix_decode.d7.loss_cls: 0.0761  mix_decode.d7.loss_mask: 0.4788  mix_decode.d7.loss_dice: 0.5650  mix_decode.d8.loss_cls: 0.0644  mix_decode.d8.loss_mask: 0.4925  mix_decode.d8.loss_dice: 0.5503
2025/03/28 13:48:11 - mmengine - INFO - Iter(train) [14300/20000]  base_lr: 3.2313e-05 lr: 3.2313e-05  eta: 1:27:17  time: 1.0898  data_time: 0.0236  memory: 10770  loss: 31.3292  decode.loss_cls: 0.0300  decode.loss_mask: 0.9018  decode.loss_dice: 0.9321  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.9038  decode.d0.loss_dice: 0.9389  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.9009  decode.d1.loss_dice: 0.9618  decode.d2.loss_cls: 0.0205  decode.d2.loss_mask: 0.8968  decode.d2.loss_dice: 0.9318  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.9009  decode.d3.loss_dice: 0.9423  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.8982  decode.d4.loss_dice: 0.9384  decode.d5.loss_cls: 0.0243  decode.d5.loss_mask: 0.8968  decode.d5.loss_dice: 0.9157  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.8943  decode.d6.loss_dice: 0.9219  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.8992  decode.d7.loss_dice: 0.9362  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 0.8969  decode.d8.loss_dice: 0.9411  mix_decode.loss_cls: 0.1496  mix_decode.loss_mask: 0.4678  mix_decode.loss_dice: 0.6490  mix_decode.d0.loss_cls: 0.1518  mix_decode.d0.loss_mask: 0.4759  mix_decode.d0.loss_dice: 0.6586  mix_decode.d1.loss_cls: 0.1066  mix_decode.d1.loss_mask: 0.4826  mix_decode.d1.loss_dice: 0.6804  mix_decode.d2.loss_cls: 0.1688  mix_decode.d2.loss_mask: 0.4670  mix_decode.d2.loss_dice: 0.6242  mix_decode.d3.loss_cls: 0.1380  mix_decode.d3.loss_mask: 0.4647  mix_decode.d3.loss_dice: 0.6253  mix_decode.d4.loss_cls: 0.1428  mix_decode.d4.loss_mask: 0.4677  mix_decode.d4.loss_dice: 0.6398  mix_decode.d5.loss_cls: 0.1537  mix_decode.d5.loss_mask: 0.4666  mix_decode.d5.loss_dice: 0.6370  mix_decode.d6.loss_cls: 0.1712  mix_decode.d6.loss_mask: 0.4718  mix_decode.d6.loss_dice: 0.6337  mix_decode.d7.loss_cls: 0.1098  mix_decode.d7.loss_mask: 0.4728  mix_decode.d7.loss_dice: 0.6370  mix_decode.d8.loss_cls: 0.1366  mix_decode.d8.loss_mask: 0.4646  mix_decode.d8.loss_dice: 0.6397
2025/03/28 13:49:05 - mmengine - INFO - Iter(train) [14350/20000]  base_lr: 3.2058e-05 lr: 3.2058e-05  eta: 1:26:34  time: 1.0810  data_time: 0.0233  memory: 10776  loss: 31.6157  decode.loss_cls: 0.0075  decode.loss_mask: 1.0271  decode.loss_dice: 0.8840  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 1.0263  decode.d0.loss_dice: 0.8730  decode.d1.loss_cls: 0.0488  decode.d1.loss_mask: 1.0214  decode.d1.loss_dice: 0.8659  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 1.0298  decode.d2.loss_dice: 0.8580  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 1.0240  decode.d3.loss_dice: 0.8724  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 1.0237  decode.d4.loss_dice: 0.8680  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 1.0354  decode.d5.loss_dice: 0.8723  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 1.0227  decode.d6.loss_dice: 0.8645  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 1.0193  decode.d7.loss_dice: 0.8792  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 1.0265  decode.d8.loss_dice: 0.8662  mix_decode.loss_cls: 0.1359  mix_decode.loss_mask: 0.4370  mix_decode.loss_dice: 0.6621  mix_decode.d0.loss_cls: 0.1318  mix_decode.d0.loss_mask: 0.4454  mix_decode.d0.loss_dice: 0.7013  mix_decode.d1.loss_cls: 0.1033  mix_decode.d1.loss_mask: 0.4427  mix_decode.d1.loss_dice: 0.6896  mix_decode.d2.loss_cls: 0.1164  mix_decode.d2.loss_mask: 0.4407  mix_decode.d2.loss_dice: 0.6746  mix_decode.d3.loss_cls: 0.1158  mix_decode.d3.loss_mask: 0.4396  mix_decode.d3.loss_dice: 0.6759  mix_decode.d4.loss_cls: 0.1177  mix_decode.d4.loss_mask: 0.4375  mix_decode.d4.loss_dice: 0.6596  mix_decode.d5.loss_cls: 0.1126  mix_decode.d5.loss_mask: 0.4410  mix_decode.d5.loss_dice: 0.6699  mix_decode.d6.loss_cls: 0.1251  mix_decode.d6.loss_mask: 0.4401  mix_decode.d6.loss_dice: 0.6791  mix_decode.d7.loss_cls: 0.1479  mix_decode.d7.loss_mask: 0.4377  mix_decode.d7.loss_dice: 0.6728  mix_decode.d8.loss_cls: 0.1481  mix_decode.d8.loss_mask: 0.4353  mix_decode.d8.loss_dice: 0.6727
2025/03/28 13:49:59 - mmengine - INFO - Iter(train) [14400/20000]  base_lr: 3.1803e-05 lr: 3.1803e-05  eta: 1:25:51  time: 1.0774  data_time: 0.0227  memory: 10774  loss: 23.9427  decode.loss_cls: 0.0772  decode.loss_mask: 0.6948  decode.loss_dice: 0.7263  decode.d0.loss_cls: 0.1012  decode.d0.loss_mask: 0.7028  decode.d0.loss_dice: 0.7757  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.7026  decode.d1.loss_dice: 0.7352  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.7143  decode.d2.loss_dice: 0.7341  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.7093  decode.d3.loss_dice: 0.7120  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.7089  decode.d4.loss_dice: 0.7076  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.7062  decode.d5.loss_dice: 0.7131  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.7001  decode.d6.loss_dice: 0.7172  decode.d7.loss_cls: 0.0333  decode.d7.loss_mask: 0.6999  decode.d7.loss_dice: 0.7441  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.7065  decode.d8.loss_dice: 0.6997  mix_decode.loss_cls: 0.0619  mix_decode.loss_mask: 0.3352  mix_decode.loss_dice: 0.5037  mix_decode.d0.loss_cls: 0.0796  mix_decode.d0.loss_mask: 0.3481  mix_decode.d0.loss_dice: 0.5110  mix_decode.d1.loss_cls: 0.0537  mix_decode.d1.loss_mask: 0.3404  mix_decode.d1.loss_dice: 0.4951  mix_decode.d2.loss_cls: 0.0514  mix_decode.d2.loss_mask: 0.3442  mix_decode.d2.loss_dice: 0.5040  mix_decode.d3.loss_cls: 0.0713  mix_decode.d3.loss_mask: 0.3372  mix_decode.d3.loss_dice: 0.4911  mix_decode.d4.loss_cls: 0.0823  mix_decode.d4.loss_mask: 0.3411  mix_decode.d4.loss_dice: 0.4882  mix_decode.d5.loss_cls: 0.0684  mix_decode.d5.loss_mask: 0.3368  mix_decode.d5.loss_dice: 0.4932  mix_decode.d6.loss_cls: 0.0796  mix_decode.d6.loss_mask: 0.3345  mix_decode.d6.loss_dice: 0.4773  mix_decode.d7.loss_cls: 0.0676  mix_decode.d7.loss_mask: 0.3409  mix_decode.d7.loss_dice: 0.4839  mix_decode.d8.loss_cls: 0.0819  mix_decode.d8.loss_mask: 0.3353  mix_decode.d8.loss_dice: 0.4691
2025/03/28 13:50:53 - mmengine - INFO - Iter(train) [14450/20000]  base_lr: 3.1547e-05 lr: 3.1547e-05  eta: 1:25:08  time: 1.0826  data_time: 0.0227  memory: 10767  loss: 24.8847  decode.loss_cls: 0.0858  decode.loss_mask: 0.7048  decode.loss_dice: 0.7509  decode.d0.loss_cls: 0.1172  decode.d0.loss_mask: 0.7138  decode.d0.loss_dice: 0.7606  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.7069  decode.d1.loss_dice: 0.7338  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.7082  decode.d2.loss_dice: 0.7249  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 0.7153  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.7168  decode.d4.loss_dice: 0.7223  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 0.7168  decode.d5.loss_dice: 0.7734  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 0.7069  decode.d6.loss_dice: 0.7240  decode.d7.loss_cls: 0.0883  decode.d7.loss_mask: 0.7097  decode.d7.loss_dice: 0.7209  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.7134  decode.d8.loss_dice: 0.7222  mix_decode.loss_cls: 0.1022  mix_decode.loss_mask: 0.3596  mix_decode.loss_dice: 0.5041  mix_decode.d0.loss_cls: 0.0713  mix_decode.d0.loss_mask: 0.3668  mix_decode.d0.loss_dice: 0.5399  mix_decode.d1.loss_cls: 0.0821  mix_decode.d1.loss_mask: 0.3577  mix_decode.d1.loss_dice: 0.5019  mix_decode.d2.loss_cls: 0.0965  mix_decode.d2.loss_mask: 0.3615  mix_decode.d2.loss_dice: 0.4953  mix_decode.d3.loss_cls: 0.0848  mix_decode.d3.loss_mask: 0.3585  mix_decode.d3.loss_dice: 0.4968  mix_decode.d4.loss_cls: 0.0875  mix_decode.d4.loss_mask: 0.3603  mix_decode.d4.loss_dice: 0.4837  mix_decode.d5.loss_cls: 0.0817  mix_decode.d5.loss_mask: 0.3609  mix_decode.d5.loss_dice: 0.4974  mix_decode.d6.loss_cls: 0.0854  mix_decode.d6.loss_mask: 0.3601  mix_decode.d6.loss_dice: 0.4957  mix_decode.d7.loss_cls: 0.0972  mix_decode.d7.loss_mask: 0.3584  mix_decode.d7.loss_dice: 0.5025  mix_decode.d8.loss_cls: 0.0924  mix_decode.d8.loss_mask: 0.3652  mix_decode.d8.loss_dice: 0.5046
2025/03/28 13:51:47 - mmengine - INFO - Iter(train) [14500/20000]  base_lr: 3.1291e-05 lr: 3.1291e-05  eta: 1:24:25  time: 1.0765  data_time: 0.0223  memory: 10771  loss: 30.0146  decode.loss_cls: 0.0085  decode.loss_mask: 0.9845  decode.loss_dice: 0.8142  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 1.0059  decode.d0.loss_dice: 0.8290  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.9965  decode.d1.loss_dice: 0.7969  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.9754  decode.d2.loss_dice: 0.7851  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.9871  decode.d3.loss_dice: 0.7910  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.9742  decode.d4.loss_dice: 0.7969  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.9809  decode.d5.loss_dice: 0.8039  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.9747  decode.d6.loss_dice: 0.8113  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.9745  decode.d7.loss_dice: 0.8111  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.9793  decode.d8.loss_dice: 0.8182  mix_decode.loss_cls: 0.0672  mix_decode.loss_mask: 0.5493  mix_decode.loss_dice: 0.5787  mix_decode.d0.loss_cls: 0.0872  mix_decode.d0.loss_mask: 0.5601  mix_decode.d0.loss_dice: 0.5882  mix_decode.d1.loss_cls: 0.0676  mix_decode.d1.loss_mask: 0.5556  mix_decode.d1.loss_dice: 0.5762  mix_decode.d2.loss_cls: 0.0776  mix_decode.d2.loss_mask: 0.5478  mix_decode.d2.loss_dice: 0.5553  mix_decode.d3.loss_cls: 0.0655  mix_decode.d3.loss_mask: 0.5472  mix_decode.d3.loss_dice: 0.5691  mix_decode.d4.loss_cls: 0.0647  mix_decode.d4.loss_mask: 0.5446  mix_decode.d4.loss_dice: 0.5662  mix_decode.d5.loss_cls: 0.0651  mix_decode.d5.loss_mask: 0.5403  mix_decode.d5.loss_dice: 0.5603  mix_decode.d6.loss_cls: 0.0991  mix_decode.d6.loss_mask: 0.5482  mix_decode.d6.loss_dice: 0.5629  mix_decode.d7.loss_cls: 0.0777  mix_decode.d7.loss_mask: 0.5457  mix_decode.d7.loss_dice: 0.5768  mix_decode.d8.loss_cls: 0.0534  mix_decode.d8.loss_mask: 0.5539  mix_decode.d8.loss_dice: 0.5669
2025/03/28 13:52:41 - mmengine - INFO - Iter(train) [14550/20000]  base_lr: 3.1035e-05 lr: 3.1035e-05  eta: 1:23:42  time: 1.0806  data_time: 0.0224  memory: 10763  loss: 27.4181  decode.loss_cls: 0.1216  decode.loss_mask: 0.8688  decode.loss_dice: 0.8545  decode.d0.loss_cls: 0.1038  decode.d0.loss_mask: 0.8823  decode.d0.loss_dice: 0.8609  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.8929  decode.d1.loss_dice: 0.8606  decode.d2.loss_cls: 0.0968  decode.d2.loss_mask: 0.8796  decode.d2.loss_dice: 0.8311  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.8688  decode.d3.loss_dice: 0.8385  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.8797  decode.d4.loss_dice: 0.8458  decode.d5.loss_cls: 0.1026  decode.d5.loss_mask: 0.8775  decode.d5.loss_dice: 0.8365  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.8796  decode.d6.loss_dice: 0.8512  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.8784  decode.d7.loss_dice: 0.8839  decode.d8.loss_cls: 0.0991  decode.d8.loss_mask: 0.8752  decode.d8.loss_dice: 0.8357  mix_decode.loss_cls: 0.0676  mix_decode.loss_mask: 0.4048  mix_decode.loss_dice: 0.4373  mix_decode.d0.loss_cls: 0.0715  mix_decode.d0.loss_mask: 0.3979  mix_decode.d0.loss_dice: 0.4679  mix_decode.d1.loss_cls: 0.0611  mix_decode.d1.loss_mask: 0.4056  mix_decode.d1.loss_dice: 0.4471  mix_decode.d2.loss_cls: 0.0717  mix_decode.d2.loss_mask: 0.4061  mix_decode.d2.loss_dice: 0.4328  mix_decode.d3.loss_cls: 0.0775  mix_decode.d3.loss_mask: 0.4133  mix_decode.d3.loss_dice: 0.4318  mix_decode.d4.loss_cls: 0.0631  mix_decode.d4.loss_mask: 0.4138  mix_decode.d4.loss_dice: 0.4322  mix_decode.d5.loss_cls: 0.0622  mix_decode.d5.loss_mask: 0.4093  mix_decode.d5.loss_dice: 0.4475  mix_decode.d6.loss_cls: 0.0663  mix_decode.d6.loss_mask: 0.4227  mix_decode.d6.loss_dice: 0.4437  mix_decode.d7.loss_cls: 0.0560  mix_decode.d7.loss_mask: 0.4044  mix_decode.d7.loss_dice: 0.4580  mix_decode.d8.loss_cls: 0.0574  mix_decode.d8.loss_mask: 0.4038  mix_decode.d8.loss_dice: 0.4423
2025/03/28 13:53:35 - mmengine - INFO - Iter(train) [14600/20000]  base_lr: 3.0778e-05 lr: 3.0778e-05  eta: 1:22:59  time: 1.0761  data_time: 0.0230  memory: 10769  loss: 26.3361  decode.loss_cls: 0.0316  decode.loss_mask: 0.8290  decode.loss_dice: 0.7345  decode.d0.loss_cls: 0.1158  decode.d0.loss_mask: 0.8402  decode.d0.loss_dice: 0.7302  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.8288  decode.d1.loss_dice: 0.7377  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.8295  decode.d2.loss_dice: 0.7354  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.8275  decode.d3.loss_dice: 0.7327  decode.d4.loss_cls: 0.0280  decode.d4.loss_mask: 0.8289  decode.d4.loss_dice: 0.7369  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.8241  decode.d5.loss_dice: 0.7252  decode.d6.loss_cls: 0.0294  decode.d6.loss_mask: 0.8152  decode.d6.loss_dice: 0.7299  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.8322  decode.d7.loss_dice: 0.7291  decode.d8.loss_cls: 0.0279  decode.d8.loss_mask: 0.8241  decode.d8.loss_dice: 0.7392  mix_decode.loss_cls: 0.0928  mix_decode.loss_mask: 0.4328  mix_decode.loss_dice: 0.4948  mix_decode.d0.loss_cls: 0.1213  mix_decode.d0.loss_mask: 0.4553  mix_decode.d0.loss_dice: 0.5309  mix_decode.d1.loss_cls: 0.1025  mix_decode.d1.loss_mask: 0.4381  mix_decode.d1.loss_dice: 0.5055  mix_decode.d2.loss_cls: 0.0803  mix_decode.d2.loss_mask: 0.4381  mix_decode.d2.loss_dice: 0.5002  mix_decode.d3.loss_cls: 0.0673  mix_decode.d3.loss_mask: 0.4524  mix_decode.d3.loss_dice: 0.5095  mix_decode.d4.loss_cls: 0.0662  mix_decode.d4.loss_mask: 0.4497  mix_decode.d4.loss_dice: 0.5028  mix_decode.d5.loss_cls: 0.0544  mix_decode.d5.loss_mask: 0.4446  mix_decode.d5.loss_dice: 0.5138  mix_decode.d6.loss_cls: 0.0971  mix_decode.d6.loss_mask: 0.4405  mix_decode.d6.loss_dice: 0.5029  mix_decode.d7.loss_cls: 0.0571  mix_decode.d7.loss_mask: 0.4516  mix_decode.d7.loss_dice: 0.5205  mix_decode.d8.loss_cls: 0.0919  mix_decode.d8.loss_mask: 0.4369  mix_decode.d8.loss_dice: 0.4976
2025/03/28 13:54:30 - mmengine - INFO - Iter(train) [14650/20000]  base_lr: 3.0522e-05 lr: 3.0522e-05  eta: 1:22:16  time: 1.0762  data_time: 0.0222  memory: 10775  loss: 28.6224  decode.loss_cls: 0.0275  decode.loss_mask: 0.8440  decode.loss_dice: 0.8032  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.8484  decode.d0.loss_dice: 0.7854  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.8438  decode.d1.loss_dice: 0.7908  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.8496  decode.d2.loss_dice: 0.7955  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.8407  decode.d3.loss_dice: 0.7908  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 0.8482  decode.d4.loss_dice: 0.7933  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.8453  decode.d5.loss_dice: 0.7954  decode.d6.loss_cls: 0.0229  decode.d6.loss_mask: 0.8458  decode.d6.loss_dice: 0.7933  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.8435  decode.d7.loss_dice: 0.7897  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.8444  decode.d8.loss_dice: 0.7971  mix_decode.loss_cls: 0.0450  mix_decode.loss_mask: 0.4865  mix_decode.loss_dice: 0.6282  mix_decode.d0.loss_cls: 0.1337  mix_decode.d0.loss_mask: 0.4931  mix_decode.d0.loss_dice: 0.6145  mix_decode.d1.loss_cls: 0.0918  mix_decode.d1.loss_mask: 0.4887  mix_decode.d1.loss_dice: 0.6170  mix_decode.d2.loss_cls: 0.0824  mix_decode.d2.loss_mask: 0.4796  mix_decode.d2.loss_dice: 0.6227  mix_decode.d3.loss_cls: 0.0651  mix_decode.d3.loss_mask: 0.4880  mix_decode.d3.loss_dice: 0.6205  mix_decode.d4.loss_cls: 0.0767  mix_decode.d4.loss_mask: 0.4802  mix_decode.d4.loss_dice: 0.6070  mix_decode.d5.loss_cls: 0.0793  mix_decode.d5.loss_mask: 0.4814  mix_decode.d5.loss_dice: 0.6111  mix_decode.d6.loss_cls: 0.0654  mix_decode.d6.loss_mask: 0.4877  mix_decode.d6.loss_dice: 0.6011  mix_decode.d7.loss_cls: 0.0589  mix_decode.d7.loss_mask: 0.4922  mix_decode.d7.loss_dice: 0.6230  mix_decode.d8.loss_cls: 0.0462  mix_decode.d8.loss_mask: 0.4825  mix_decode.d8.loss_dice: 0.6292
2025/03/28 13:55:24 - mmengine - INFO - Iter(train) [14700/20000]  base_lr: 3.0265e-05 lr: 3.0265e-05  eta: 1:21:33  time: 1.0809  data_time: 0.0228  memory: 10775  loss: 26.3014  decode.loss_cls: 0.0046  decode.loss_mask: 0.7752  decode.loss_dice: 0.7420  decode.d0.loss_cls: 0.0574  decode.d0.loss_mask: 0.7775  decode.d0.loss_dice: 0.7401  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.7650  decode.d1.loss_dice: 0.7344  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.7651  decode.d2.loss_dice: 0.7229  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.7743  decode.d3.loss_dice: 0.7338  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.7724  decode.d4.loss_dice: 0.7344  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.7676  decode.d5.loss_dice: 0.7281  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.7704  decode.d6.loss_dice: 0.7341  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.7740  decode.d7.loss_dice: 0.7311  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.7726  decode.d8.loss_dice: 0.7250  mix_decode.loss_cls: 0.0769  mix_decode.loss_mask: 0.3972  mix_decode.loss_dice: 0.6442  mix_decode.d0.loss_cls: 0.1156  mix_decode.d0.loss_mask: 0.4032  mix_decode.d0.loss_dice: 0.6555  mix_decode.d1.loss_cls: 0.0918  mix_decode.d1.loss_mask: 0.3770  mix_decode.d1.loss_dice: 0.6376  mix_decode.d2.loss_cls: 0.0995  mix_decode.d2.loss_mask: 0.3912  mix_decode.d2.loss_dice: 0.6273  mix_decode.d3.loss_cls: 0.0802  mix_decode.d3.loss_mask: 0.3775  mix_decode.d3.loss_dice: 0.6405  mix_decode.d4.loss_cls: 0.0917  mix_decode.d4.loss_mask: 0.3827  mix_decode.d4.loss_dice: 0.6303  mix_decode.d5.loss_cls: 0.0547  mix_decode.d5.loss_mask: 0.3952  mix_decode.d5.loss_dice: 0.6470  mix_decode.d6.loss_cls: 0.0506  mix_decode.d6.loss_mask: 0.3968  mix_decode.d6.loss_dice: 0.6420  mix_decode.d7.loss_cls: 0.0889  mix_decode.d7.loss_mask: 0.3926  mix_decode.d7.loss_dice: 0.6307  mix_decode.d8.loss_cls: 0.1040  mix_decode.d8.loss_mask: 0.3805  mix_decode.d8.loss_dice: 0.6508
2025/03/28 13:56:18 - mmengine - INFO - Iter(train) [14750/20000]  base_lr: 3.0008e-05 lr: 3.0008e-05  eta: 1:20:49  time: 1.0801  data_time: 0.0224  memory: 10770  loss: 25.8167  decode.loss_cls: 0.0639  decode.loss_mask: 0.7293  decode.loss_dice: 0.7095  decode.d0.loss_cls: 0.1304  decode.d0.loss_mask: 0.7370  decode.d0.loss_dice: 0.7204  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.7344  decode.d1.loss_dice: 0.7024  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.7303  decode.d2.loss_dice: 0.7049  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.7340  decode.d3.loss_dice: 0.6967  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.7302  decode.d4.loss_dice: 0.6933  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.7342  decode.d5.loss_dice: 0.7074  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.7341  decode.d6.loss_dice: 0.7053  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.7347  decode.d7.loss_dice: 0.7100  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.7328  decode.d8.loss_dice: 0.7010  mix_decode.loss_cls: 0.0772  mix_decode.loss_mask: 0.4343  mix_decode.loss_dice: 0.5759  mix_decode.d0.loss_cls: 0.1040  mix_decode.d0.loss_mask: 0.4116  mix_decode.d0.loss_dice: 0.5728  mix_decode.d1.loss_cls: 0.1039  mix_decode.d1.loss_mask: 0.4177  mix_decode.d1.loss_dice: 0.5574  mix_decode.d2.loss_cls: 0.1025  mix_decode.d2.loss_mask: 0.4183  mix_decode.d2.loss_dice: 0.5534  mix_decode.d3.loss_cls: 0.0853  mix_decode.d3.loss_mask: 0.4210  mix_decode.d3.loss_dice: 0.5622  mix_decode.d4.loss_cls: 0.0751  mix_decode.d4.loss_mask: 0.4384  mix_decode.d4.loss_dice: 0.5770  mix_decode.d5.loss_cls: 0.1083  mix_decode.d5.loss_mask: 0.4072  mix_decode.d5.loss_dice: 0.5392  mix_decode.d6.loss_cls: 0.0734  mix_decode.d6.loss_mask: 0.4178  mix_decode.d6.loss_dice: 0.5559  mix_decode.d7.loss_cls: 0.0699  mix_decode.d7.loss_mask: 0.4386  mix_decode.d7.loss_dice: 0.5799  mix_decode.d8.loss_cls: 0.0626  mix_decode.d8.loss_mask: 0.4363  mix_decode.d8.loss_dice: 0.5719
2025/03/28 13:57:12 - mmengine - INFO - Iter(train) [14800/20000]  base_lr: 2.9751e-05 lr: 2.9751e-05  eta: 1:20:06  time: 1.0800  data_time: 0.0227  memory: 10771  loss: 28.0444  decode.loss_cls: 0.0226  decode.loss_mask: 0.8834  decode.loss_dice: 0.8331  decode.d0.loss_cls: 0.0663  decode.d0.loss_mask: 0.8909  decode.d0.loss_dice: 0.8284  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.8893  decode.d1.loss_dice: 0.8348  decode.d2.loss_cls: 0.0350  decode.d2.loss_mask: 0.8857  decode.d2.loss_dice: 0.8233  decode.d3.loss_cls: 0.0245  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 0.7978  decode.d4.loss_cls: 0.0234  decode.d4.loss_mask: 0.8854  decode.d4.loss_dice: 0.8278  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.8851  decode.d5.loss_dice: 0.8295  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.8833  decode.d6.loss_dice: 0.8257  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.8869  decode.d7.loss_dice: 0.8311  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.8938  decode.d8.loss_dice: 0.8371  mix_decode.loss_cls: 0.0591  mix_decode.loss_mask: 0.4420  mix_decode.loss_dice: 0.5555  mix_decode.d0.loss_cls: 0.0697  mix_decode.d0.loss_mask: 0.4506  mix_decode.d0.loss_dice: 0.5950  mix_decode.d1.loss_cls: 0.0848  mix_decode.d1.loss_mask: 0.4417  mix_decode.d1.loss_dice: 0.5611  mix_decode.d2.loss_cls: 0.0774  mix_decode.d2.loss_mask: 0.4388  mix_decode.d2.loss_dice: 0.5471  mix_decode.d3.loss_cls: 0.0526  mix_decode.d3.loss_mask: 0.4419  mix_decode.d3.loss_dice: 0.5463  mix_decode.d4.loss_cls: 0.0551  mix_decode.d4.loss_mask: 0.4450  mix_decode.d4.loss_dice: 0.5551  mix_decode.d5.loss_cls: 0.0518  mix_decode.d5.loss_mask: 0.4431  mix_decode.d5.loss_dice: 0.5589  mix_decode.d6.loss_cls: 0.0568  mix_decode.d6.loss_mask: 0.4444  mix_decode.d6.loss_dice: 0.5574  mix_decode.d7.loss_cls: 0.0466  mix_decode.d7.loss_mask: 0.4451  mix_decode.d7.loss_dice: 0.5584  mix_decode.d8.loss_cls: 0.0356  mix_decode.d8.loss_mask: 0.4415  mix_decode.d8.loss_dice: 0.5583
2025/03/28 13:58:06 - mmengine - INFO - Iter(train) [14850/20000]  base_lr: 2.9493e-05 lr: 2.9493e-05  eta: 1:19:23  time: 1.0800  data_time: 0.0225  memory: 10770  loss: 28.9138  decode.loss_cls: 0.0086  decode.loss_mask: 0.9061  decode.loss_dice: 0.7496  decode.d0.loss_cls: 0.0658  decode.d0.loss_mask: 0.9133  decode.d0.loss_dice: 0.7385  decode.d1.loss_cls: 0.0139  decode.d1.loss_mask: 0.9073  decode.d1.loss_dice: 0.7483  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.9031  decode.d2.loss_dice: 0.7462  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.9081  decode.d3.loss_dice: 0.7582  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.9000  decode.d4.loss_dice: 0.7495  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.9076  decode.d5.loss_dice: 0.7500  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.9061  decode.d6.loss_dice: 0.7505  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.9091  decode.d7.loss_dice: 0.7568  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.9060  decode.d8.loss_dice: 0.7528  mix_decode.loss_cls: 0.0728  mix_decode.loss_mask: 0.5504  mix_decode.loss_dice: 0.5930  mix_decode.d0.loss_cls: 0.0773  mix_decode.d0.loss_mask: 0.5585  mix_decode.d0.loss_dice: 0.6042  mix_decode.d1.loss_cls: 0.0865  mix_decode.d1.loss_mask: 0.5490  mix_decode.d1.loss_dice: 0.5948  mix_decode.d2.loss_cls: 0.0791  mix_decode.d2.loss_mask: 0.5609  mix_decode.d2.loss_dice: 0.5893  mix_decode.d3.loss_cls: 0.0594  mix_decode.d3.loss_mask: 0.5690  mix_decode.d3.loss_dice: 0.5838  mix_decode.d4.loss_cls: 0.0623  mix_decode.d4.loss_mask: 0.5592  mix_decode.d4.loss_dice: 0.5993  mix_decode.d5.loss_cls: 0.0626  mix_decode.d5.loss_mask: 0.5571  mix_decode.d5.loss_dice: 0.5871  mix_decode.d6.loss_cls: 0.0742  mix_decode.d6.loss_mask: 0.5502  mix_decode.d6.loss_dice: 0.5774  mix_decode.d7.loss_cls: 0.0599  mix_decode.d7.loss_mask: 0.5691  mix_decode.d7.loss_dice: 0.5922  mix_decode.d8.loss_cls: 0.0627  mix_decode.d8.loss_mask: 0.5540  mix_decode.d8.loss_dice: 0.5982
2025/03/28 13:59:00 - mmengine - INFO - Iter(train) [14900/20000]  base_lr: 2.9235e-05 lr: 2.9235e-05  eta: 1:18:39  time: 1.0768  data_time: 0.0231  memory: 10765  loss: 24.5495  decode.loss_cls: 0.0102  decode.loss_mask: 0.6826  decode.loss_dice: 0.7330  decode.d0.loss_cls: 0.0595  decode.d0.loss_mask: 0.6835  decode.d0.loss_dice: 0.7595  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.6902  decode.d1.loss_dice: 0.7424  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.6810  decode.d2.loss_dice: 0.7344  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.6845  decode.d3.loss_dice: 0.7403  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.6840  decode.d4.loss_dice: 0.7344  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.6825  decode.d5.loss_dice: 0.7319  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.6860  decode.d6.loss_dice: 0.7348  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.6833  decode.d7.loss_dice: 0.7346  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.6781  decode.d8.loss_dice: 0.7278  mix_decode.loss_cls: 0.0954  mix_decode.loss_mask: 0.3691  mix_decode.loss_dice: 0.5440  mix_decode.d0.loss_cls: 0.0827  mix_decode.d0.loss_mask: 0.3769  mix_decode.d0.loss_dice: 0.5910  mix_decode.d1.loss_cls: 0.1111  mix_decode.d1.loss_mask: 0.3751  mix_decode.d1.loss_dice: 0.5480  mix_decode.d2.loss_cls: 0.1223  mix_decode.d2.loss_mask: 0.3704  mix_decode.d2.loss_dice: 0.5134  mix_decode.d3.loss_cls: 0.1229  mix_decode.d3.loss_mask: 0.3703  mix_decode.d3.loss_dice: 0.5223  mix_decode.d4.loss_cls: 0.1250  mix_decode.d4.loss_mask: 0.3708  mix_decode.d4.loss_dice: 0.5198  mix_decode.d5.loss_cls: 0.1169  mix_decode.d5.loss_mask: 0.3683  mix_decode.d5.loss_dice: 0.5290  mix_decode.d6.loss_cls: 0.1066  mix_decode.d6.loss_mask: 0.3675  mix_decode.d6.loss_dice: 0.5375  mix_decode.d7.loss_cls: 0.1096  mix_decode.d7.loss_mask: 0.3672  mix_decode.d7.loss_dice: 0.5356  mix_decode.d8.loss_cls: 0.0960  mix_decode.d8.loss_mask: 0.3683  mix_decode.d8.loss_dice: 0.5314
2025/03/28 13:59:54 - mmengine - INFO - Iter(train) [14950/20000]  base_lr: 2.8977e-05 lr: 2.8977e-05  eta: 1:17:55  time: 1.0823  data_time: 0.0235  memory: 10770  loss: 25.6298  decode.loss_cls: 0.0051  decode.loss_mask: 0.8120  decode.loss_dice: 0.6821  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.8134  decode.d0.loss_dice: 0.6739  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.8115  decode.d1.loss_dice: 0.6765  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.8083  decode.d2.loss_dice: 0.6837  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.8059  decode.d3.loss_dice: 0.6841  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.8067  decode.d4.loss_dice: 0.6859  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.8035  decode.d5.loss_dice: 0.6731  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.8032  decode.d6.loss_dice: 0.6821  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.8036  decode.d7.loss_dice: 0.6837  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.8040  decode.d8.loss_dice: 0.6849  mix_decode.loss_cls: 0.1132  mix_decode.loss_mask: 0.4084  mix_decode.loss_dice: 0.5535  mix_decode.d0.loss_cls: 0.1789  mix_decode.d0.loss_mask: 0.3885  mix_decode.d0.loss_dice: 0.5650  mix_decode.d1.loss_cls: 0.1039  mix_decode.d1.loss_mask: 0.4013  mix_decode.d1.loss_dice: 0.5534  mix_decode.d2.loss_cls: 0.1466  mix_decode.d2.loss_mask: 0.3913  mix_decode.d2.loss_dice: 0.5483  mix_decode.d3.loss_cls: 0.0995  mix_decode.d3.loss_mask: 0.4022  mix_decode.d3.loss_dice: 0.5631  mix_decode.d4.loss_cls: 0.0884  mix_decode.d4.loss_mask: 0.4000  mix_decode.d4.loss_dice: 0.5473  mix_decode.d5.loss_cls: 0.1016  mix_decode.d5.loss_mask: 0.3962  mix_decode.d5.loss_dice: 0.5272  mix_decode.d6.loss_cls: 0.0791  mix_decode.d6.loss_mask: 0.3993  mix_decode.d6.loss_dice: 0.5475  mix_decode.d7.loss_cls: 0.0914  mix_decode.d7.loss_mask: 0.3959  mix_decode.d7.loss_dice: 0.5427  mix_decode.d8.loss_cls: 0.1137  mix_decode.d8.loss_mask: 0.3986  mix_decode.d8.loss_dice: 0.5538
2025/03/28 14:00:49 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 14:00:49 - mmengine - INFO - Iter(train) [15000/20000]  base_lr: 2.8719e-05 lr: 2.8719e-05  eta: 1:17:12  time: 1.0918  data_time: 0.0250  memory: 10776  loss: 25.3974  decode.loss_cls: 0.0169  decode.loss_mask: 0.7970  decode.loss_dice: 0.7130  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 0.7960  decode.d0.loss_dice: 0.6980  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.7971  decode.d1.loss_dice: 0.7215  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.7950  decode.d2.loss_dice: 0.7278  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.7940  decode.d3.loss_dice: 0.7172  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.7998  decode.d4.loss_dice: 0.7222  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.7975  decode.d5.loss_dice: 0.7158  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.7984  decode.d6.loss_dice: 0.7214  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.7981  decode.d7.loss_dice: 0.7271  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.8006  decode.d8.loss_dice: 0.7230  mix_decode.loss_cls: 0.0369  mix_decode.loss_mask: 0.4243  mix_decode.loss_dice: 0.5166  mix_decode.d0.loss_cls: 0.1267  mix_decode.d0.loss_mask: 0.4314  mix_decode.d0.loss_dice: 0.5319  mix_decode.d1.loss_cls: 0.0629  mix_decode.d1.loss_mask: 0.4242  mix_decode.d1.loss_dice: 0.5152  mix_decode.d2.loss_cls: 0.0585  mix_decode.d2.loss_mask: 0.4209  mix_decode.d2.loss_dice: 0.5046  mix_decode.d3.loss_cls: 0.0651  mix_decode.d3.loss_mask: 0.4225  mix_decode.d3.loss_dice: 0.4950  mix_decode.d4.loss_cls: 0.0375  mix_decode.d4.loss_mask: 0.4241  mix_decode.d4.loss_dice: 0.5010  mix_decode.d5.loss_cls: 0.0411  mix_decode.d5.loss_mask: 0.4257  mix_decode.d5.loss_dice: 0.5100  mix_decode.d6.loss_cls: 0.0618  mix_decode.d6.loss_mask: 0.4208  mix_decode.d6.loss_dice: 0.5163  mix_decode.d7.loss_cls: 0.0359  mix_decode.d7.loss_mask: 0.4232  mix_decode.d7.loss_dice: 0.5146  mix_decode.d8.loss_cls: 0.0404  mix_decode.d8.loss_mask: 0.4274  mix_decode.d8.loss_dice: 0.5256
2025/03/28 14:01:43 - mmengine - INFO - Iter(train) [15050/20000]  base_lr: 2.8460e-05 lr: 2.8460e-05  eta: 1:16:28  time: 1.0836  data_time: 0.0228  memory: 10780  loss: 26.2158  decode.loss_cls: 0.0345  decode.loss_mask: 0.7936  decode.loss_dice: 0.7839  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.8043  decode.d0.loss_dice: 0.7795  decode.d1.loss_cls: 0.0399  decode.d1.loss_mask: 0.7947  decode.d1.loss_dice: 0.7716  decode.d2.loss_cls: 0.0335  decode.d2.loss_mask: 0.7951  decode.d2.loss_dice: 0.7660  decode.d3.loss_cls: 0.0347  decode.d3.loss_mask: 0.7930  decode.d3.loss_dice: 0.7545  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.7892  decode.d4.loss_dice: 0.7831  decode.d5.loss_cls: 0.0273  decode.d5.loss_mask: 0.7928  decode.d5.loss_dice: 0.7740  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.7961  decode.d6.loss_dice: 0.7490  decode.d7.loss_cls: 0.0999  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 0.7674  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.7933  decode.d8.loss_dice: 0.7587  mix_decode.loss_cls: 0.0425  mix_decode.loss_mask: 0.4205  mix_decode.loss_dice: 0.5346  mix_decode.d0.loss_cls: 0.0732  mix_decode.d0.loss_mask: 0.4313  mix_decode.d0.loss_dice: 0.5605  mix_decode.d1.loss_cls: 0.0485  mix_decode.d1.loss_mask: 0.4276  mix_decode.d1.loss_dice: 0.5366  mix_decode.d2.loss_cls: 0.0387  mix_decode.d2.loss_mask: 0.4259  mix_decode.d2.loss_dice: 0.5468  mix_decode.d3.loss_cls: 0.0405  mix_decode.d3.loss_mask: 0.4242  mix_decode.d3.loss_dice: 0.5287  mix_decode.d4.loss_cls: 0.0395  mix_decode.d4.loss_mask: 0.4260  mix_decode.d4.loss_dice: 0.5352  mix_decode.d5.loss_cls: 0.0360  mix_decode.d5.loss_mask: 0.4231  mix_decode.d5.loss_dice: 0.5362  mix_decode.d6.loss_cls: 0.0717  mix_decode.d6.loss_mask: 0.4246  mix_decode.d6.loss_dice: 0.5228  mix_decode.d7.loss_cls: 0.0708  mix_decode.d7.loss_mask: 0.4243  mix_decode.d7.loss_dice: 0.5260  mix_decode.d8.loss_cls: 0.0520  mix_decode.d8.loss_mask: 0.4184  mix_decode.d8.loss_dice: 0.5195
2025/03/28 14:02:37 - mmengine - INFO - Iter(train) [15100/20000]  base_lr: 2.8201e-05 lr: 2.8201e-05  eta: 1:15:44  time: 1.0801  data_time: 0.0232  memory: 10767  loss: 25.5100  decode.loss_cls: 0.0037  decode.loss_mask: 0.7003  decode.loss_dice: 0.6565  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.6932  decode.d0.loss_dice: 0.6498  decode.d1.loss_cls: 0.0133  decode.d1.loss_mask: 0.6999  decode.d1.loss_dice: 0.6565  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.6972  decode.d2.loss_dice: 0.6576  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.7003  decode.d3.loss_dice: 0.6511  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.6969  decode.d4.loss_dice: 0.6515  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.7003  decode.d5.loss_dice: 0.6554  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.7016  decode.d6.loss_dice: 0.6535  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.7013  decode.d7.loss_dice: 0.6514  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.7031  decode.d8.loss_dice: 0.6604  mix_decode.loss_cls: 0.1495  mix_decode.loss_mask: 0.4455  mix_decode.loss_dice: 0.6065  mix_decode.d0.loss_cls: 0.1246  mix_decode.d0.loss_mask: 0.4518  mix_decode.d0.loss_dice: 0.6466  mix_decode.d1.loss_cls: 0.1366  mix_decode.d1.loss_mask: 0.4400  mix_decode.d1.loss_dice: 0.5957  mix_decode.d2.loss_cls: 0.1837  mix_decode.d2.loss_mask: 0.4426  mix_decode.d2.loss_dice: 0.5870  mix_decode.d3.loss_cls: 0.1272  mix_decode.d3.loss_mask: 0.4451  mix_decode.d3.loss_dice: 0.6052  mix_decode.d4.loss_cls: 0.1290  mix_decode.d4.loss_mask: 0.4442  mix_decode.d4.loss_dice: 0.6117  mix_decode.d5.loss_cls: 0.1291  mix_decode.d5.loss_mask: 0.4433  mix_decode.d5.loss_dice: 0.6026  mix_decode.d6.loss_cls: 0.1041  mix_decode.d6.loss_mask: 0.4409  mix_decode.d6.loss_dice: 0.6075  mix_decode.d7.loss_cls: 0.1208  mix_decode.d7.loss_mask: 0.4405  mix_decode.d7.loss_dice: 0.5938  mix_decode.d8.loss_cls: 0.1311  mix_decode.d8.loss_mask: 0.4436  mix_decode.d8.loss_dice: 0.6018
2025/03/28 14:03:31 - mmengine - INFO - Iter(train) [15150/20000]  base_lr: 2.7942e-05 lr: 2.7942e-05  eta: 1:15:00  time: 1.0789  data_time: 0.0225  memory: 10770  loss: 26.0946  decode.loss_cls: 0.0284  decode.loss_mask: 0.7385  decode.loss_dice: 0.7531  decode.d0.loss_cls: 0.0749  decode.d0.loss_mask: 0.7476  decode.d0.loss_dice: 0.7574  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.7401  decode.d1.loss_dice: 0.7563  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.7381  decode.d2.loss_dice: 0.7563  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.7393  decode.d3.loss_dice: 0.7337  decode.d4.loss_cls: 0.0256  decode.d4.loss_mask: 0.7372  decode.d4.loss_dice: 0.7437  decode.d5.loss_cls: 0.0253  decode.d5.loss_mask: 0.7325  decode.d5.loss_dice: 0.7376  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.7364  decode.d6.loss_dice: 0.7336  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.7437  decode.d7.loss_dice: 0.7246  decode.d8.loss_cls: 0.0213  decode.d8.loss_mask: 0.7370  decode.d8.loss_dice: 0.7440  mix_decode.loss_cls: 0.0867  mix_decode.loss_mask: 0.4193  mix_decode.loss_dice: 0.5943  mix_decode.d0.loss_cls: 0.1030  mix_decode.d0.loss_mask: 0.4239  mix_decode.d0.loss_dice: 0.6002  mix_decode.d1.loss_cls: 0.1099  mix_decode.d1.loss_mask: 0.4129  mix_decode.d1.loss_dice: 0.5767  mix_decode.d2.loss_cls: 0.0971  mix_decode.d2.loss_mask: 0.4162  mix_decode.d2.loss_dice: 0.5754  mix_decode.d3.loss_cls: 0.1015  mix_decode.d3.loss_mask: 0.4159  mix_decode.d3.loss_dice: 0.5748  mix_decode.d4.loss_cls: 0.1155  mix_decode.d4.loss_mask: 0.4205  mix_decode.d4.loss_dice: 0.5664  mix_decode.d5.loss_cls: 0.0789  mix_decode.d5.loss_mask: 0.4183  mix_decode.d5.loss_dice: 0.5804  mix_decode.d6.loss_cls: 0.0775  mix_decode.d6.loss_mask: 0.4140  mix_decode.d6.loss_dice: 0.5750  mix_decode.d7.loss_cls: 0.0968  mix_decode.d7.loss_mask: 0.4177  mix_decode.d7.loss_dice: 0.5813  mix_decode.d8.loss_cls: 0.0929  mix_decode.d8.loss_mask: 0.4254  mix_decode.d8.loss_dice: 0.5839
2025/03/28 14:04:25 - mmengine - INFO - Iter(train) [15200/20000]  base_lr: 2.7683e-05 lr: 2.7683e-05  eta: 1:14:16  time: 1.0890  data_time: 0.0236  memory: 10771  loss: 27.9850  decode.loss_cls: 0.0091  decode.loss_mask: 0.9218  decode.loss_dice: 0.7740  decode.d0.loss_cls: 0.0632  decode.d0.loss_mask: 0.9249  decode.d0.loss_dice: 0.7666  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.9240  decode.d1.loss_dice: 0.7744  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.9182  decode.d2.loss_dice: 0.7635  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.9189  decode.d3.loss_dice: 0.7701  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.9158  decode.d4.loss_dice: 0.7644  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.9164  decode.d5.loss_dice: 0.7680  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.9168  decode.d6.loss_dice: 0.7701  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.9177  decode.d7.loss_dice: 0.7774  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.9226  decode.d8.loss_dice: 0.7651  mix_decode.loss_cls: 0.0475  mix_decode.loss_mask: 0.5135  mix_decode.loss_dice: 0.5037  mix_decode.d0.loss_cls: 0.0884  mix_decode.d0.loss_mask: 0.5117  mix_decode.d0.loss_dice: 0.5311  mix_decode.d1.loss_cls: 0.0577  mix_decode.d1.loss_mask: 0.5159  mix_decode.d1.loss_dice: 0.5157  mix_decode.d2.loss_cls: 0.0929  mix_decode.d2.loss_mask: 0.5174  mix_decode.d2.loss_dice: 0.5037  mix_decode.d3.loss_cls: 0.0605  mix_decode.d3.loss_mask: 0.5150  mix_decode.d3.loss_dice: 0.5038  mix_decode.d4.loss_cls: 0.0519  mix_decode.d4.loss_mask: 0.5241  mix_decode.d4.loss_dice: 0.5004  mix_decode.d5.loss_cls: 0.0532  mix_decode.d5.loss_mask: 0.5224  mix_decode.d5.loss_dice: 0.5149  mix_decode.d6.loss_cls: 0.0696  mix_decode.d6.loss_mask: 0.5213  mix_decode.d6.loss_dice: 0.5023  mix_decode.d7.loss_cls: 0.0812  mix_decode.d7.loss_mask: 0.5206  mix_decode.d7.loss_dice: 0.5104  mix_decode.d8.loss_cls: 0.0510  mix_decode.d8.loss_mask: 0.5190  mix_decode.d8.loss_dice: 0.5125
2025/03/28 14:05:20 - mmengine - INFO - Iter(train) [15250/20000]  base_lr: 2.7423e-05 lr: 2.7423e-05  eta: 1:13:32  time: 1.0797  data_time: 0.0229  memory: 10776  loss: 29.4851  decode.loss_cls: 0.0720  decode.loss_mask: 0.8666  decode.loss_dice: 0.8240  decode.d0.loss_cls: 0.0861  decode.d0.loss_mask: 0.8802  decode.d0.loss_dice: 0.8247  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.8748  decode.d1.loss_dice: 0.8330  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.8710  decode.d2.loss_dice: 0.8273  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.8698  decode.d3.loss_dice: 0.8216  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.8728  decode.d4.loss_dice: 0.8143  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.8676  decode.d5.loss_dice: 0.8133  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.8688  decode.d6.loss_dice: 0.8199  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.8706  decode.d7.loss_dice: 0.8246  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.8736  decode.d8.loss_dice: 0.8502  mix_decode.loss_cls: 0.1071  mix_decode.loss_mask: 0.4700  mix_decode.loss_dice: 0.6097  mix_decode.d0.loss_cls: 0.1359  mix_decode.d0.loss_mask: 0.4717  mix_decode.d0.loss_dice: 0.6388  mix_decode.d1.loss_cls: 0.1273  mix_decode.d1.loss_mask: 0.4523  mix_decode.d1.loss_dice: 0.6136  mix_decode.d2.loss_cls: 0.1124  mix_decode.d2.loss_mask: 0.4593  mix_decode.d2.loss_dice: 0.6084  mix_decode.d3.loss_cls: 0.1122  mix_decode.d3.loss_mask: 0.4704  mix_decode.d3.loss_dice: 0.5878  mix_decode.d4.loss_cls: 0.0940  mix_decode.d4.loss_mask: 0.4657  mix_decode.d4.loss_dice: 0.6007  mix_decode.d5.loss_cls: 0.0996  mix_decode.d5.loss_mask: 0.4668  mix_decode.d5.loss_dice: 0.6106  mix_decode.d6.loss_cls: 0.1341  mix_decode.d6.loss_mask: 0.4647  mix_decode.d6.loss_dice: 0.5975  mix_decode.d7.loss_cls: 0.1124  mix_decode.d7.loss_mask: 0.4650  mix_decode.d7.loss_dice: 0.6050  mix_decode.d8.loss_cls: 0.1135  mix_decode.d8.loss_mask: 0.4603  mix_decode.d8.loss_dice: 0.6060
2025/03/28 14:06:14 - mmengine - INFO - Iter(train) [15300/20000]  base_lr: 2.7163e-05 lr: 2.7163e-05  eta: 1:12:48  time: 1.0777  data_time: 0.0223  memory: 10779  loss: 28.0332  decode.loss_cls: 0.0108  decode.loss_mask: 0.8212  decode.loss_dice: 0.7549  decode.d0.loss_cls: 0.0795  decode.d0.loss_mask: 0.8243  decode.d0.loss_dice: 0.7287  decode.d1.loss_cls: 0.0182  decode.d1.loss_mask: 0.8137  decode.d1.loss_dice: 0.7450  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.8176  decode.d2.loss_dice: 0.7341  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.8173  decode.d3.loss_dice: 0.7349  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.8194  decode.d4.loss_dice: 0.7399  decode.d5.loss_cls: 0.0214  decode.d5.loss_mask: 0.8090  decode.d5.loss_dice: 0.7391  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.8173  decode.d6.loss_dice: 0.7432  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.8155  decode.d7.loss_dice: 0.7426  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.8151  decode.d8.loss_dice: 0.7510  mix_decode.loss_cls: 0.0846  mix_decode.loss_mask: 0.5036  mix_decode.loss_dice: 0.6252  mix_decode.d0.loss_cls: 0.1312  mix_decode.d0.loss_mask: 0.5010  mix_decode.d0.loss_dice: 0.6585  mix_decode.d1.loss_cls: 0.0748  mix_decode.d1.loss_mask: 0.5245  mix_decode.d1.loss_dice: 0.6317  mix_decode.d2.loss_cls: 0.0784  mix_decode.d2.loss_mask: 0.5254  mix_decode.d2.loss_dice: 0.6094  mix_decode.d3.loss_cls: 0.0967  mix_decode.d3.loss_mask: 0.5170  mix_decode.d3.loss_dice: 0.5958  mix_decode.d4.loss_cls: 0.0690  mix_decode.d4.loss_mask: 0.5231  mix_decode.d4.loss_dice: 0.6124  mix_decode.d5.loss_cls: 0.1036  mix_decode.d5.loss_mask: 0.5054  mix_decode.d5.loss_dice: 0.6117  mix_decode.d6.loss_cls: 0.0900  mix_decode.d6.loss_mask: 0.5122  mix_decode.d6.loss_dice: 0.6251  mix_decode.d7.loss_cls: 0.1029  mix_decode.d7.loss_mask: 0.5076  mix_decode.d7.loss_dice: 0.5883  mix_decode.d8.loss_cls: 0.1050  mix_decode.d8.loss_mask: 0.4979  mix_decode.d8.loss_dice: 0.6172
2025/03/28 14:07:08 - mmengine - INFO - Iter(train) [15350/20000]  base_lr: 2.6903e-05 lr: 2.6903e-05  eta: 1:12:04  time: 1.0813  data_time: 0.0227  memory: 10772  loss: 29.1091  decode.loss_cls: 0.0286  decode.loss_mask: 0.7924  decode.loss_dice: 0.8387  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.8006  decode.d0.loss_dice: 0.8787  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 0.7978  decode.d1.loss_dice: 0.8320  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.7986  decode.d2.loss_dice: 0.8179  decode.d3.loss_cls: 0.0838  decode.d3.loss_mask: 0.8023  decode.d3.loss_dice: 0.8354  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.8002  decode.d4.loss_dice: 0.8545  decode.d5.loss_cls: 0.0286  decode.d5.loss_mask: 0.8002  decode.d5.loss_dice: 0.8627  decode.d6.loss_cls: 0.0217  decode.d6.loss_mask: 0.8004  decode.d6.loss_dice: 0.8347  decode.d7.loss_cls: 0.0350  decode.d7.loss_mask: 0.8027  decode.d7.loss_dice: 0.8519  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.7957  decode.d8.loss_dice: 0.8476  mix_decode.loss_cls: 0.1330  mix_decode.loss_mask: 0.4582  mix_decode.loss_dice: 0.6074  mix_decode.d0.loss_cls: 0.0990  mix_decode.d0.loss_mask: 0.4822  mix_decode.d0.loss_dice: 0.6973  mix_decode.d1.loss_cls: 0.1358  mix_decode.d1.loss_mask: 0.4662  mix_decode.d1.loss_dice: 0.6270  mix_decode.d2.loss_cls: 0.1007  mix_decode.d2.loss_mask: 0.4625  mix_decode.d2.loss_dice: 0.6209  mix_decode.d3.loss_cls: 0.1488  mix_decode.d3.loss_mask: 0.4556  mix_decode.d3.loss_dice: 0.6106  mix_decode.d4.loss_cls: 0.1123  mix_decode.d4.loss_mask: 0.4608  mix_decode.d4.loss_dice: 0.6167  mix_decode.d5.loss_cls: 0.0977  mix_decode.d5.loss_mask: 0.4589  mix_decode.d5.loss_dice: 0.6346  mix_decode.d6.loss_cls: 0.1045  mix_decode.d6.loss_mask: 0.4659  mix_decode.d6.loss_dice: 0.6119  mix_decode.d7.loss_cls: 0.1153  mix_decode.d7.loss_mask: 0.4631  mix_decode.d7.loss_dice: 0.6152  mix_decode.d8.loss_cls: 0.1332  mix_decode.d8.loss_mask: 0.4579  mix_decode.d8.loss_dice: 0.6253
2025/03/28 14:08:02 - mmengine - INFO - Iter(train) [15400/20000]  base_lr: 2.6642e-05 lr: 2.6642e-05  eta: 1:11:20  time: 1.0756  data_time: 0.0224  memory: 10774  loss: 25.9468  decode.loss_cls: 0.1320  decode.loss_mask: 0.6917  decode.loss_dice: 0.7360  decode.d0.loss_cls: 0.1612  decode.d0.loss_mask: 0.7037  decode.d0.loss_dice: 0.7920  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.7002  decode.d1.loss_dice: 0.7957  decode.d2.loss_cls: 0.1261  decode.d2.loss_mask: 0.7005  decode.d2.loss_dice: 0.7477  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.6923  decode.d3.loss_dice: 0.7925  decode.d4.loss_cls: 0.1095  decode.d4.loss_mask: 0.7003  decode.d4.loss_dice: 0.7774  decode.d5.loss_cls: 0.1522  decode.d5.loss_mask: 0.6965  decode.d5.loss_dice: 0.7958  decode.d6.loss_cls: 0.1316  decode.d6.loss_mask: 0.6971  decode.d6.loss_dice: 0.7596  decode.d7.loss_cls: 0.1416  decode.d7.loss_mask: 0.6936  decode.d7.loss_dice: 0.7480  decode.d8.loss_cls: 0.1683  decode.d8.loss_mask: 0.6945  decode.d8.loss_dice: 0.7630  mix_decode.loss_cls: 0.1004  mix_decode.loss_mask: 0.3363  mix_decode.loss_dice: 0.5623  mix_decode.d0.loss_cls: 0.0971  mix_decode.d0.loss_mask: 0.3326  mix_decode.d0.loss_dice: 0.6021  mix_decode.d1.loss_cls: 0.1160  mix_decode.d1.loss_mask: 0.3340  mix_decode.d1.loss_dice: 0.5209  mix_decode.d2.loss_cls: 0.1198  mix_decode.d2.loss_mask: 0.3334  mix_decode.d2.loss_dice: 0.5378  mix_decode.d3.loss_cls: 0.1104  mix_decode.d3.loss_mask: 0.3350  mix_decode.d3.loss_dice: 0.5314  mix_decode.d4.loss_cls: 0.1145  mix_decode.d4.loss_mask: 0.3355  mix_decode.d4.loss_dice: 0.5275  mix_decode.d5.loss_cls: 0.1349  mix_decode.d5.loss_mask: 0.3371  mix_decode.d5.loss_dice: 0.5207  mix_decode.d6.loss_cls: 0.1395  mix_decode.d6.loss_mask: 0.3388  mix_decode.d6.loss_dice: 0.5297  mix_decode.d7.loss_cls: 0.1227  mix_decode.d7.loss_mask: 0.3366  mix_decode.d7.loss_dice: 0.5398  mix_decode.d8.loss_cls: 0.1252  mix_decode.d8.loss_mask: 0.3375  mix_decode.d8.loss_dice: 0.5548
2025/03/28 14:08:56 - mmengine - INFO - Iter(train) [15450/20000]  base_lr: 2.6382e-05 lr: 2.6382e-05  eta: 1:10:35  time: 1.0833  data_time: 0.0235  memory: 10785  loss: 27.6294  decode.loss_cls: 0.0175  decode.loss_mask: 0.7807  decode.loss_dice: 0.7061  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.7938  decode.d0.loss_dice: 0.7125  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.7792  decode.d1.loss_dice: 0.7114  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.7785  decode.d2.loss_dice: 0.6944  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.7917  decode.d3.loss_dice: 0.7094  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.7814  decode.d4.loss_dice: 0.7087  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.7893  decode.d5.loss_dice: 0.7101  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.7793  decode.d6.loss_dice: 0.7055  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.7838  decode.d7.loss_dice: 0.7123  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.7788  decode.d8.loss_dice: 0.7135  mix_decode.loss_cls: 0.1134  mix_decode.loss_mask: 0.5189  mix_decode.loss_dice: 0.6200  mix_decode.d0.loss_cls: 0.1785  mix_decode.d0.loss_mask: 0.5122  mix_decode.d0.loss_dice: 0.6301  mix_decode.d1.loss_cls: 0.1285  mix_decode.d1.loss_mask: 0.5039  mix_decode.d1.loss_dice: 0.6114  mix_decode.d2.loss_cls: 0.1298  mix_decode.d2.loss_mask: 0.5075  mix_decode.d2.loss_dice: 0.5866  mix_decode.d3.loss_cls: 0.1054  mix_decode.d3.loss_mask: 0.5135  mix_decode.d3.loss_dice: 0.6055  mix_decode.d4.loss_cls: 0.1107  mix_decode.d4.loss_mask: 0.5086  mix_decode.d4.loss_dice: 0.6146  mix_decode.d5.loss_cls: 0.1385  mix_decode.d5.loss_mask: 0.5059  mix_decode.d5.loss_dice: 0.5989  mix_decode.d6.loss_cls: 0.1270  mix_decode.d6.loss_mask: 0.5159  mix_decode.d6.loss_dice: 0.5971  mix_decode.d7.loss_cls: 0.1174  mix_decode.d7.loss_mask: 0.5071  mix_decode.d7.loss_dice: 0.6291  mix_decode.d8.loss_cls: 0.1243  mix_decode.d8.loss_mask: 0.5059  mix_decode.d8.loss_dice: 0.6134
2025/03/28 14:09:50 - mmengine - INFO - Iter(train) [15500/20000]  base_lr: 2.6121e-05 lr: 2.6121e-05  eta: 1:09:51  time: 1.0766  data_time: 0.0223  memory: 10776  loss: 27.9805  decode.loss_cls: 0.0407  decode.loss_mask: 0.8501  decode.loss_dice: 0.8192  decode.d0.loss_cls: 0.0772  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 0.8305  decode.d1.loss_cls: 0.0567  decode.d1.loss_mask: 0.8518  decode.d1.loss_dice: 0.7711  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 0.8211  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.8495  decode.d3.loss_dice: 0.8088  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 0.8104  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.8520  decode.d5.loss_dice: 0.8246  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.8488  decode.d6.loss_dice: 0.8222  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.8496  decode.d7.loss_dice: 0.8113  decode.d8.loss_cls: 0.0880  decode.d8.loss_mask: 0.8453  decode.d8.loss_dice: 0.8251  mix_decode.loss_cls: 0.0834  mix_decode.loss_mask: 0.4435  mix_decode.loss_dice: 0.5401  mix_decode.d0.loss_cls: 0.0753  mix_decode.d0.loss_mask: 0.4718  mix_decode.d0.loss_dice: 0.5717  mix_decode.d1.loss_cls: 0.0506  mix_decode.d1.loss_mask: 0.4442  mix_decode.d1.loss_dice: 0.5633  mix_decode.d2.loss_cls: 0.0863  mix_decode.d2.loss_mask: 0.4399  mix_decode.d2.loss_dice: 0.5368  mix_decode.d3.loss_cls: 0.0863  mix_decode.d3.loss_mask: 0.4453  mix_decode.d3.loss_dice: 0.5484  mix_decode.d4.loss_cls: 0.1109  mix_decode.d4.loss_mask: 0.4463  mix_decode.d4.loss_dice: 0.5256  mix_decode.d5.loss_cls: 0.0662  mix_decode.d5.loss_mask: 0.4574  mix_decode.d5.loss_dice: 0.5445  mix_decode.d6.loss_cls: 0.0869  mix_decode.d6.loss_mask: 0.4465  mix_decode.d6.loss_dice: 0.5395  mix_decode.d7.loss_cls: 0.0862  mix_decode.d7.loss_mask: 0.4439  mix_decode.d7.loss_dice: 0.5430  mix_decode.d8.loss_cls: 0.0836  mix_decode.d8.loss_mask: 0.4436  mix_decode.d8.loss_dice: 0.5434
2025/03/28 14:10:44 - mmengine - INFO - Iter(train) [15550/20000]  base_lr: 2.5859e-05 lr: 2.5859e-05  eta: 1:09:07  time: 1.0766  data_time: 0.0221  memory: 10771  loss: 27.7559  decode.loss_cls: 0.0070  decode.loss_mask: 0.8699  decode.loss_dice: 0.7524  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.8795  decode.d0.loss_dice: 0.7478  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.8740  decode.d1.loss_dice: 0.7709  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.8711  decode.d2.loss_dice: 0.7626  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.8675  decode.d3.loss_dice: 0.7587  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.8690  decode.d4.loss_dice: 0.7581  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.8712  decode.d5.loss_dice: 0.7550  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.8683  decode.d6.loss_dice: 0.7604  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.8680  decode.d7.loss_dice: 0.7667  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.8760  decode.d8.loss_dice: 0.7579  mix_decode.loss_cls: 0.0744  mix_decode.loss_mask: 0.4374  mix_decode.loss_dice: 0.6008  mix_decode.d0.loss_cls: 0.0913  mix_decode.d0.loss_mask: 0.4391  mix_decode.d0.loss_dice: 0.6194  mix_decode.d1.loss_cls: 0.0800  mix_decode.d1.loss_mask: 0.4264  mix_decode.d1.loss_dice: 0.6124  mix_decode.d2.loss_cls: 0.0930  mix_decode.d2.loss_mask: 0.4370  mix_decode.d2.loss_dice: 0.5969  mix_decode.d3.loss_cls: 0.1386  mix_decode.d3.loss_mask: 0.4292  mix_decode.d3.loss_dice: 0.5833  mix_decode.d4.loss_cls: 0.1315  mix_decode.d4.loss_mask: 0.4227  mix_decode.d4.loss_dice: 0.5752  mix_decode.d5.loss_cls: 0.1192  mix_decode.d5.loss_mask: 0.4268  mix_decode.d5.loss_dice: 0.5877  mix_decode.d6.loss_cls: 0.0886  mix_decode.d6.loss_mask: 0.4435  mix_decode.d6.loss_dice: 0.5942  mix_decode.d7.loss_cls: 0.1020  mix_decode.d7.loss_mask: 0.4356  mix_decode.d7.loss_dice: 0.5880  mix_decode.d8.loss_cls: 0.0821  mix_decode.d8.loss_mask: 0.4312  mix_decode.d8.loss_dice: 0.6027
2025/03/28 14:11:37 - mmengine - INFO - Iter(train) [15600/20000]  base_lr: 2.5598e-05 lr: 2.5598e-05  eta: 1:08:22  time: 1.0831  data_time: 0.0235  memory: 10777  loss: 26.7330  decode.loss_cls: 0.0151  decode.loss_mask: 0.8610  decode.loss_dice: 0.8112  decode.d0.loss_cls: 0.1017  decode.d0.loss_mask: 0.8631  decode.d0.loss_dice: 0.8069  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.8592  decode.d1.loss_dice: 0.7917  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.8577  decode.d2.loss_dice: 0.7802  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.8631  decode.d3.loss_dice: 0.7969  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.8596  decode.d4.loss_dice: 0.7990  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.8575  decode.d5.loss_dice: 0.7933  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 0.8600  decode.d6.loss_dice: 0.7995  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.8595  decode.d7.loss_dice: 0.8157  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.8646  decode.d8.loss_dice: 0.8089  mix_decode.loss_cls: 0.0670  mix_decode.loss_mask: 0.3887  mix_decode.loss_dice: 0.4985  mix_decode.d0.loss_cls: 0.0617  mix_decode.d0.loss_mask: 0.4060  mix_decode.d0.loss_dice: 0.5498  mix_decode.d1.loss_cls: 0.0460  mix_decode.d1.loss_mask: 0.3893  mix_decode.d1.loss_dice: 0.5276  mix_decode.d2.loss_cls: 0.0557  mix_decode.d2.loss_mask: 0.3910  mix_decode.d2.loss_dice: 0.5119  mix_decode.d3.loss_cls: 0.0525  mix_decode.d3.loss_mask: 0.3910  mix_decode.d3.loss_dice: 0.5134  mix_decode.d4.loss_cls: 0.0593  mix_decode.d4.loss_mask: 0.3870  mix_decode.d4.loss_dice: 0.5190  mix_decode.d5.loss_cls: 0.0700  mix_decode.d5.loss_mask: 0.3914  mix_decode.d5.loss_dice: 0.5165  mix_decode.d6.loss_cls: 0.0670  mix_decode.d6.loss_mask: 0.3937  mix_decode.d6.loss_dice: 0.5120  mix_decode.d7.loss_cls: 0.0585  mix_decode.d7.loss_mask: 0.3909  mix_decode.d7.loss_dice: 0.5227  mix_decode.d8.loss_cls: 0.0697  mix_decode.d8.loss_mask: 0.3902  mix_decode.d8.loss_dice: 0.5172
2025/03/28 14:12:31 - mmengine - INFO - Iter(train) [15650/20000]  base_lr: 2.5336e-05 lr: 2.5336e-05  eta: 1:07:37  time: 1.0778  data_time: 0.0225  memory: 10772  loss: 25.6006  decode.loss_cls: 0.0619  decode.loss_mask: 0.7175  decode.loss_dice: 0.6816  decode.d0.loss_cls: 0.0574  decode.d0.loss_mask: 0.7177  decode.d0.loss_dice: 0.6833  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.7228  decode.d1.loss_dice: 0.6619  decode.d2.loss_cls: 0.0206  decode.d2.loss_mask: 0.7160  decode.d2.loss_dice: 0.6686  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 0.7179  decode.d3.loss_dice: 0.6717  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.7145  decode.d4.loss_dice: 0.6877  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.7185  decode.d5.loss_dice: 0.6530  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.7187  decode.d6.loss_dice: 0.6685  decode.d7.loss_cls: 0.0267  decode.d7.loss_mask: 0.7181  decode.d7.loss_dice: 0.6707  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.7172  decode.d8.loss_dice: 0.6630  mix_decode.loss_cls: 0.0612  mix_decode.loss_mask: 0.5310  mix_decode.loss_dice: 0.5382  mix_decode.d0.loss_cls: 0.0955  mix_decode.d0.loss_mask: 0.5330  mix_decode.d0.loss_dice: 0.5434  mix_decode.d1.loss_cls: 0.0878  mix_decode.d1.loss_mask: 0.5302  mix_decode.d1.loss_dice: 0.5336  mix_decode.d2.loss_cls: 0.0711  mix_decode.d2.loss_mask: 0.5306  mix_decode.d2.loss_dice: 0.5415  mix_decode.d3.loss_cls: 0.0585  mix_decode.d3.loss_mask: 0.5270  mix_decode.d3.loss_dice: 0.5357  mix_decode.d4.loss_cls: 0.0650  mix_decode.d4.loss_mask: 0.5266  mix_decode.d4.loss_dice: 0.5416  mix_decode.d5.loss_cls: 0.0519  mix_decode.d5.loss_mask: 0.5312  mix_decode.d5.loss_dice: 0.5467  mix_decode.d6.loss_cls: 0.0601  mix_decode.d6.loss_mask: 0.5287  mix_decode.d6.loss_dice: 0.5351  mix_decode.d7.loss_cls: 0.0879  mix_decode.d7.loss_mask: 0.5349  mix_decode.d7.loss_dice: 0.5291  mix_decode.d8.loss_cls: 0.0465  mix_decode.d8.loss_mask: 0.5298  mix_decode.d8.loss_dice: 0.5431
2025/03/28 14:13:25 - mmengine - INFO - Iter(train) [15700/20000]  base_lr: 2.5073e-05 lr: 2.5073e-05  eta: 1:06:53  time: 1.0714  data_time: 0.0224  memory: 10772  loss: 28.0113  decode.loss_cls: 0.0101  decode.loss_mask: 0.8608  decode.loss_dice: 0.7562  decode.d0.loss_cls: 0.0647  decode.d0.loss_mask: 0.8635  decode.d0.loss_dice: 0.7306  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.8581  decode.d1.loss_dice: 0.7525  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.8645  decode.d2.loss_dice: 0.7554  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.8598  decode.d3.loss_dice: 0.7551  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.8661  decode.d4.loss_dice: 0.7600  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.8677  decode.d5.loss_dice: 0.7554  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.8624  decode.d6.loss_dice: 0.7614  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.8663  decode.d7.loss_dice: 0.7678  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.8655  decode.d8.loss_dice: 0.7618  mix_decode.loss_cls: 0.0762  mix_decode.loss_mask: 0.4700  mix_decode.loss_dice: 0.6073  mix_decode.d0.loss_cls: 0.0742  mix_decode.d0.loss_mask: 0.4817  mix_decode.d0.loss_dice: 0.6468  mix_decode.d1.loss_cls: 0.0892  mix_decode.d1.loss_mask: 0.4705  mix_decode.d1.loss_dice: 0.6226  mix_decode.d2.loss_cls: 0.1084  mix_decode.d2.loss_mask: 0.4706  mix_decode.d2.loss_dice: 0.6164  mix_decode.d3.loss_cls: 0.0658  mix_decode.d3.loss_mask: 0.4680  mix_decode.d3.loss_dice: 0.6094  mix_decode.d4.loss_cls: 0.0632  mix_decode.d4.loss_mask: 0.4703  mix_decode.d4.loss_dice: 0.6129  mix_decode.d5.loss_cls: 0.0905  mix_decode.d5.loss_mask: 0.4671  mix_decode.d5.loss_dice: 0.6062  mix_decode.d6.loss_cls: 0.0633  mix_decode.d6.loss_mask: 0.4697  mix_decode.d6.loss_dice: 0.6263  mix_decode.d7.loss_cls: 0.0766  mix_decode.d7.loss_mask: 0.4730  mix_decode.d7.loss_dice: 0.6285  mix_decode.d8.loss_cls: 0.0763  mix_decode.d8.loss_mask: 0.4676  mix_decode.d8.loss_dice: 0.6118
2025/03/28 14:14:19 - mmengine - INFO - Iter(train) [15750/20000]  base_lr: 2.4811e-05 lr: 2.4811e-05  eta: 1:06:08  time: 1.0749  data_time: 0.0226  memory: 10770  loss: 26.3202  decode.loss_cls: 0.0621  decode.loss_mask: 0.7606  decode.loss_dice: 0.7556  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.7764  decode.d0.loss_dice: 0.7933  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.7638  decode.d1.loss_dice: 0.7758  decode.d2.loss_cls: 0.0656  decode.d2.loss_mask: 0.7595  decode.d2.loss_dice: 0.7482  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.7532  decode.d3.loss_dice: 0.7393  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.7543  decode.d4.loss_dice: 0.7552  decode.d5.loss_cls: 0.0786  decode.d5.loss_mask: 0.7551  decode.d5.loss_dice: 0.7548  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.7550  decode.d6.loss_dice: 0.7475  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.7595  decode.d7.loss_dice: 0.7702  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.7534  decode.d8.loss_dice: 0.7420  mix_decode.loss_cls: 0.1051  mix_decode.loss_mask: 0.4221  mix_decode.loss_dice: 0.5185  mix_decode.d0.loss_cls: 0.1382  mix_decode.d0.loss_mask: 0.4298  mix_decode.d0.loss_dice: 0.5054  mix_decode.d1.loss_cls: 0.1059  mix_decode.d1.loss_mask: 0.4235  mix_decode.d1.loss_dice: 0.5008  mix_decode.d2.loss_cls: 0.1437  mix_decode.d2.loss_mask: 0.4196  mix_decode.d2.loss_dice: 0.4941  mix_decode.d3.loss_cls: 0.1335  mix_decode.d3.loss_mask: 0.4195  mix_decode.d3.loss_dice: 0.5015  mix_decode.d4.loss_cls: 0.1280  mix_decode.d4.loss_mask: 0.4228  mix_decode.d4.loss_dice: 0.4934  mix_decode.d5.loss_cls: 0.1376  mix_decode.d5.loss_mask: 0.4260  mix_decode.d5.loss_dice: 0.5012  mix_decode.d6.loss_cls: 0.1169  mix_decode.d6.loss_mask: 0.4179  mix_decode.d6.loss_dice: 0.5101  mix_decode.d7.loss_cls: 0.1169  mix_decode.d7.loss_mask: 0.4263  mix_decode.d7.loss_dice: 0.5089  mix_decode.d8.loss_cls: 0.1069  mix_decode.d8.loss_mask: 0.4260  mix_decode.d8.loss_dice: 0.4959
2025/03/28 14:15:13 - mmengine - INFO - Iter(train) [15800/20000]  base_lr: 2.4548e-05 lr: 2.4548e-05  eta: 1:05:23  time: 1.0701  data_time: 0.0230  memory: 10776  loss: 27.8580  decode.loss_cls: 0.0348  decode.loss_mask: 0.8640  decode.loss_dice: 0.8124  decode.d0.loss_cls: 0.0692  decode.d0.loss_mask: 0.8665  decode.d0.loss_dice: 0.8538  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.8709  decode.d1.loss_dice: 0.8630  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.8740  decode.d2.loss_dice: 0.8469  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.8623  decode.d3.loss_dice: 0.8566  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.8673  decode.d4.loss_dice: 0.8536  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.8647  decode.d5.loss_dice: 0.8535  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.8662  decode.d6.loss_dice: 0.8560  decode.d7.loss_cls: 0.0259  decode.d7.loss_mask: 0.8627  decode.d7.loss_dice: 0.8701  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.8686  decode.d8.loss_dice: 0.8337  mix_decode.loss_cls: 0.0465  mix_decode.loss_mask: 0.4490  mix_decode.loss_dice: 0.4975  mix_decode.d0.loss_cls: 0.1020  mix_decode.d0.loss_mask: 0.4644  mix_decode.d0.loss_dice: 0.5212  mix_decode.d1.loss_cls: 0.0584  mix_decode.d1.loss_mask: 0.4549  mix_decode.d1.loss_dice: 0.5189  mix_decode.d2.loss_cls: 0.0405  mix_decode.d2.loss_mask: 0.4585  mix_decode.d2.loss_dice: 0.5125  mix_decode.d3.loss_cls: 0.0616  mix_decode.d3.loss_mask: 0.4568  mix_decode.d3.loss_dice: 0.5213  mix_decode.d4.loss_cls: 0.0414  mix_decode.d4.loss_mask: 0.4618  mix_decode.d4.loss_dice: 0.5100  mix_decode.d5.loss_cls: 0.0430  mix_decode.d5.loss_mask: 0.4478  mix_decode.d5.loss_dice: 0.5162  mix_decode.d6.loss_cls: 0.0475  mix_decode.d6.loss_mask: 0.4472  mix_decode.d6.loss_dice: 0.5205  mix_decode.d7.loss_cls: 0.0467  mix_decode.d7.loss_mask: 0.4609  mix_decode.d7.loss_dice: 0.5059  mix_decode.d8.loss_cls: 0.0456  mix_decode.d8.loss_mask: 0.4504  mix_decode.d8.loss_dice: 0.5172
2025/03/28 14:16:07 - mmengine - INFO - Iter(train) [15850/20000]  base_lr: 2.4285e-05 lr: 2.4285e-05  eta: 1:04:38  time: 1.0743  data_time: 0.0226  memory: 10770  loss: 28.5509  decode.loss_cls: 0.0109  decode.loss_mask: 0.8734  decode.loss_dice: 0.7817  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.8780  decode.d0.loss_dice: 0.7725  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.8646  decode.d1.loss_dice: 0.7789  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.8655  decode.d2.loss_dice: 0.7784  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.8684  decode.d3.loss_dice: 0.7787  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.8658  decode.d4.loss_dice: 0.7742  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.8696  decode.d5.loss_dice: 0.7736  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.8717  decode.d6.loss_dice: 0.7711  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.8715  decode.d7.loss_dice: 0.7830  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.8699  decode.d8.loss_dice: 0.7815  mix_decode.loss_cls: 0.1173  mix_decode.loss_mask: 0.4510  mix_decode.loss_dice: 0.5847  mix_decode.d0.loss_cls: 0.1566  mix_decode.d0.loss_mask: 0.4532  mix_decode.d0.loss_dice: 0.6192  mix_decode.d1.loss_cls: 0.1315  mix_decode.d1.loss_mask: 0.4533  mix_decode.d1.loss_dice: 0.6068  mix_decode.d2.loss_cls: 0.1422  mix_decode.d2.loss_mask: 0.4557  mix_decode.d2.loss_dice: 0.6023  mix_decode.d3.loss_cls: 0.1699  mix_decode.d3.loss_mask: 0.4474  mix_decode.d3.loss_dice: 0.6030  mix_decode.d4.loss_cls: 0.1556  mix_decode.d4.loss_mask: 0.4500  mix_decode.d4.loss_dice: 0.5849  mix_decode.d5.loss_cls: 0.0888  mix_decode.d5.loss_mask: 0.4601  mix_decode.d5.loss_dice: 0.5901  mix_decode.d6.loss_cls: 0.1350  mix_decode.d6.loss_mask: 0.4473  mix_decode.d6.loss_dice: 0.5885  mix_decode.d7.loss_cls: 0.1384  mix_decode.d7.loss_mask: 0.4507  mix_decode.d7.loss_dice: 0.5919  mix_decode.d8.loss_cls: 0.1526  mix_decode.d8.loss_mask: 0.4467  mix_decode.d8.loss_dice: 0.6000
2025/03/28 14:17:01 - mmengine - INFO - Iter(train) [15900/20000]  base_lr: 2.4021e-05 lr: 2.4021e-05  eta: 1:03:54  time: 1.1006  data_time: 0.0263  memory: 10780  loss: 31.8893  decode.loss_cls: 0.0234  decode.loss_mask: 1.0049  decode.loss_dice: 0.8914  decode.d0.loss_cls: 0.0741  decode.d0.loss_mask: 1.0322  decode.d0.loss_dice: 0.8728  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 1.0120  decode.d1.loss_dice: 0.8844  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 1.0055  decode.d2.loss_dice: 0.8798  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 1.0130  decode.d3.loss_dice: 0.8997  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 1.0119  decode.d4.loss_dice: 0.8791  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 1.0167  decode.d5.loss_dice: 0.8909  decode.d6.loss_cls: 0.0201  decode.d6.loss_mask: 1.0062  decode.d6.loss_dice: 0.8875  decode.d7.loss_cls: 0.0187  decode.d7.loss_mask: 1.0095  decode.d7.loss_dice: 0.8928  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 1.0008  decode.d8.loss_dice: 0.8801  mix_decode.loss_cls: 0.1604  mix_decode.loss_mask: 0.4611  mix_decode.loss_dice: 0.6681  mix_decode.d0.loss_cls: 0.0960  mix_decode.d0.loss_mask: 0.4574  mix_decode.d0.loss_dice: 0.6980  mix_decode.d1.loss_cls: 0.1451  mix_decode.d1.loss_mask: 0.4341  mix_decode.d1.loss_dice: 0.6401  mix_decode.d2.loss_cls: 0.1189  mix_decode.d2.loss_mask: 0.4274  mix_decode.d2.loss_dice: 0.6465  mix_decode.d3.loss_cls: 0.1648  mix_decode.d3.loss_mask: 0.4366  mix_decode.d3.loss_dice: 0.6391  mix_decode.d4.loss_cls: 0.1194  mix_decode.d4.loss_mask: 0.4511  mix_decode.d4.loss_dice: 0.6540  mix_decode.d5.loss_cls: 0.1396  mix_decode.d5.loss_mask: 0.4376  mix_decode.d5.loss_dice: 0.6566  mix_decode.d6.loss_cls: 0.1576  mix_decode.d6.loss_mask: 0.4436  mix_decode.d6.loss_dice: 0.6728  mix_decode.d7.loss_cls: 0.1260  mix_decode.d7.loss_mask: 0.4899  mix_decode.d7.loss_dice: 0.6734  mix_decode.d8.loss_cls: 0.1568  mix_decode.d8.loss_mask: 0.4695  mix_decode.d8.loss_dice: 0.6481
2025/03/28 14:17:55 - mmengine - INFO - Iter(train) [15950/20000]  base_lr: 2.3758e-05 lr: 2.3758e-05  eta: 1:03:09  time: 1.0754  data_time: 0.0227  memory: 10770  loss: 25.0924  decode.loss_cls: 0.0353  decode.loss_mask: 0.6432  decode.loss_dice: 0.6583  decode.d0.loss_cls: 0.1248  decode.d0.loss_mask: 0.6457  decode.d0.loss_dice: 0.7122  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.6417  decode.d1.loss_dice: 0.6561  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.6403  decode.d2.loss_dice: 0.6662  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.6393  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0812  decode.d4.loss_mask: 0.6394  decode.d4.loss_dice: 0.6621  decode.d5.loss_cls: 0.0789  decode.d5.loss_mask: 0.6433  decode.d5.loss_dice: 0.6509  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.6481  decode.d6.loss_dice: 0.6590  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.6425  decode.d7.loss_dice: 0.6632  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.6459  decode.d8.loss_dice: 0.6621  mix_decode.loss_cls: 0.0602  mix_decode.loss_mask: 0.4631  mix_decode.loss_dice: 0.5897  mix_decode.d0.loss_cls: 0.1158  mix_decode.d0.loss_mask: 0.4684  mix_decode.d0.loss_dice: 0.5854  mix_decode.d1.loss_cls: 0.0905  mix_decode.d1.loss_mask: 0.4643  mix_decode.d1.loss_dice: 0.5877  mix_decode.d2.loss_cls: 0.0683  mix_decode.d2.loss_mask: 0.4608  mix_decode.d2.loss_dice: 0.5860  mix_decode.d3.loss_cls: 0.0626  mix_decode.d3.loss_mask: 0.4588  mix_decode.d3.loss_dice: 0.5961  mix_decode.d4.loss_cls: 0.0705  mix_decode.d4.loss_mask: 0.4543  mix_decode.d4.loss_dice: 0.5936  mix_decode.d5.loss_cls: 0.0759  mix_decode.d5.loss_mask: 0.4658  mix_decode.d5.loss_dice: 0.5868  mix_decode.d6.loss_cls: 0.1078  mix_decode.d6.loss_mask: 0.4615  mix_decode.d6.loss_dice: 0.5666  mix_decode.d7.loss_cls: 0.0561  mix_decode.d7.loss_mask: 0.4625  mix_decode.d7.loss_dice: 0.6010  mix_decode.d8.loss_cls: 0.0802  mix_decode.d8.loss_mask: 0.4654  mix_decode.d8.loss_dice: 0.5963
2025/03/28 14:18:49 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 14:18:49 - mmengine - INFO - Iter(train) [16000/20000]  base_lr: 2.3493e-05 lr: 2.3493e-05  eta: 1:02:24  time: 1.0896  data_time: 0.0245  memory: 10773  loss: 29.0100  decode.loss_cls: 0.0053  decode.loss_mask: 0.8275  decode.loss_dice: 0.7615  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.8340  decode.d0.loss_dice: 0.7458  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.8305  decode.d1.loss_dice: 0.7559  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.8259  decode.d2.loss_dice: 0.7543  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.8294  decode.d3.loss_dice: 0.7539  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.8266  decode.d4.loss_dice: 0.7573  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.8258  decode.d5.loss_dice: 0.7609  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.8282  decode.d6.loss_dice: 0.7619  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.8281  decode.d7.loss_dice: 0.7570  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.8309  decode.d8.loss_dice: 0.7591  mix_decode.loss_cls: 0.1392  mix_decode.loss_mask: 0.5039  mix_decode.loss_dice: 0.6423  mix_decode.d0.loss_cls: 0.1339  mix_decode.d0.loss_mask: 0.5175  mix_decode.d0.loss_dice: 0.7040  mix_decode.d1.loss_cls: 0.1407  mix_decode.d1.loss_mask: 0.5051  mix_decode.d1.loss_dice: 0.6489  mix_decode.d2.loss_cls: 0.1382  mix_decode.d2.loss_mask: 0.5027  mix_decode.d2.loss_dice: 0.6537  mix_decode.d3.loss_cls: 0.1686  mix_decode.d3.loss_mask: 0.5060  mix_decode.d3.loss_dice: 0.6291  mix_decode.d4.loss_cls: 0.1950  mix_decode.d4.loss_mask: 0.4956  mix_decode.d4.loss_dice: 0.6225  mix_decode.d5.loss_cls: 0.1350  mix_decode.d5.loss_mask: 0.5027  mix_decode.d5.loss_dice: 0.6499  mix_decode.d6.loss_cls: 0.1430  mix_decode.d6.loss_mask: 0.5067  mix_decode.d6.loss_dice: 0.6525  mix_decode.d7.loss_cls: 0.1222  mix_decode.d7.loss_mask: 0.5085  mix_decode.d7.loss_dice: 0.6625  mix_decode.d8.loss_cls: 0.1633  mix_decode.d8.loss_mask: 0.4999  mix_decode.d8.loss_dice: 0.6310
2025/03/28 14:18:49 - mmengine - INFO - Saving checkpoint at 16000 iterations
2025/03/28 14:18:54 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:18:58 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:43  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:03 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:39  time: 0.0851  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:07 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:35  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:11 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0850  data_time: 0.0017  memory: 3068  
2025/03/28 14:19:16 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:26  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:20 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:22  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:24 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:18  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 14:19:28 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:33 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:09  time: 0.0854  data_time: 0.0020  memory: 3068  
2025/03/28 14:19:37 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:05  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:41 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:00  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 14:19:45 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:50 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:52  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:54 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:48  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:19:58 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:43  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:20:03 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:20:07 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:20:11 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:31  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:20:15 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0851  data_time: 0.0019  memory: 3068  
2025/03/28 14:20:20 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 14:20:24 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:20:28 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:14  time: 0.0850  data_time: 0.0017  memory: 3068  
2025/03/28 14:20:33 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:20:37 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0850  data_time: 0.0018  memory: 3068  
2025/03/28 14:20:41 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:20:45 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:20:50 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0882  data_time: 0.0020  memory: 3068  
2025/03/28 14:20:54 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0856  data_time: 0.0020  memory: 3068  
2025/03/28 14:20:58 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0882  data_time: 0.0019  memory: 3068  
2025/03/28 14:21:03 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0855  data_time: 0.0019  memory: 3068  
2025/03/28 14:21:07 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 14:21:11 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:21:15 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:27  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:21:20 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:21:24 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0855  data_time: 0.0019  memory: 3068  
2025/03/28 14:21:28 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 14:21:33 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0858  data_time: 0.0020  memory: 3068  
2025/03/28 14:21:37 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0850  data_time: 0.0017  memory: 3068  
2025/03/28 14:21:41 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:21:43 - mmengine - INFO - per class results:
2025/03/28 14:21:43 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 73.52 | 88.03 |
|      building      | 87.87 | 94.88 |
|   low_vegetation   | 59.96 | 92.26 |
|        tree        | 43.18 | 44.81 |
|        car         | 75.34 | 87.61 |
|      clutter       |  8.01 |  8.3  |
+--------------------+-------+-------+
2025/03/28 14:21:43 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 79.4500  mIoU: 57.9800  mAcc: 69.3100  data_time: 0.0019  time: 0.0855
2025/03/28 14:22:36 - mmengine - INFO - Iter(train) [16050/20000]  base_lr: 2.3229e-05 lr: 2.3229e-05  eta: 1:01:39  time: 1.0759  data_time: 0.0228  memory: 10775  loss: 26.1171  decode.loss_cls: 0.0157  decode.loss_mask: 0.8520  decode.loss_dice: 0.7499  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.8525  decode.d0.loss_dice: 0.7404  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.8532  decode.d1.loss_dice: 0.7384  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.8447  decode.d2.loss_dice: 0.7304  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.8504  decode.d3.loss_dice: 0.7496  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.8477  decode.d4.loss_dice: 0.7374  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.8486  decode.d5.loss_dice: 0.7401  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.8487  decode.d6.loss_dice: 0.7533  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.8484  decode.d7.loss_dice: 0.7447  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.8458  decode.d8.loss_dice: 0.7417  mix_decode.loss_cls: 0.0637  mix_decode.loss_mask: 0.4173  mix_decode.loss_dice: 0.4985  mix_decode.d0.loss_cls: 0.0857  mix_decode.d0.loss_mask: 0.4362  mix_decode.d0.loss_dice: 0.5106  mix_decode.d1.loss_cls: 0.0623  mix_decode.d1.loss_mask: 0.4226  mix_decode.d1.loss_dice: 0.5124  mix_decode.d2.loss_cls: 0.0666  mix_decode.d2.loss_mask: 0.4210  mix_decode.d2.loss_dice: 0.5086  mix_decode.d3.loss_cls: 0.0626  mix_decode.d3.loss_mask: 0.4194  mix_decode.d3.loss_dice: 0.5074  mix_decode.d4.loss_cls: 0.0662  mix_decode.d4.loss_mask: 0.4193  mix_decode.d4.loss_dice: 0.5006  mix_decode.d5.loss_cls: 0.0646  mix_decode.d5.loss_mask: 0.4183  mix_decode.d5.loss_dice: 0.5040  mix_decode.d6.loss_cls: 0.0691  mix_decode.d6.loss_mask: 0.4180  mix_decode.d6.loss_dice: 0.5057  mix_decode.d7.loss_cls: 0.0627  mix_decode.d7.loss_mask: 0.4207  mix_decode.d7.loss_dice: 0.5158  mix_decode.d8.loss_cls: 0.0460  mix_decode.d8.loss_mask: 0.4198  mix_decode.d8.loss_dice: 0.5115
2025/03/28 14:23:31 - mmengine - INFO - Iter(train) [16100/20000]  base_lr: 2.2964e-05 lr: 2.2964e-05  eta: 1:00:54  time: 1.0798  data_time: 0.0231  memory: 10770  loss: 26.8604  decode.loss_cls: 0.0085  decode.loss_mask: 0.7421  decode.loss_dice: 0.7260  decode.d0.loss_cls: 0.0591  decode.d0.loss_mask: 0.7418  decode.d0.loss_dice: 0.7390  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.7434  decode.d1.loss_dice: 0.7409  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.7411  decode.d2.loss_dice: 0.7325  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.7429  decode.d3.loss_dice: 0.7314  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.7479  decode.d4.loss_dice: 0.7286  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.7464  decode.d5.loss_dice: 0.7376  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.7456  decode.d6.loss_dice: 0.7237  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.7430  decode.d7.loss_dice: 0.7349  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.7449  decode.d8.loss_dice: 0.7356  mix_decode.loss_cls: 0.1045  mix_decode.loss_mask: 0.4440  mix_decode.loss_dice: 0.6382  mix_decode.d0.loss_cls: 0.1166  mix_decode.d0.loss_mask: 0.4537  mix_decode.d0.loss_dice: 0.6636  mix_decode.d1.loss_cls: 0.0845  mix_decode.d1.loss_mask: 0.4417  mix_decode.d1.loss_dice: 0.6499  mix_decode.d2.loss_cls: 0.1239  mix_decode.d2.loss_mask: 0.4321  mix_decode.d2.loss_dice: 0.6302  mix_decode.d3.loss_cls: 0.1097  mix_decode.d3.loss_mask: 0.4343  mix_decode.d3.loss_dice: 0.6368  mix_decode.d4.loss_cls: 0.1420  mix_decode.d4.loss_mask: 0.4317  mix_decode.d4.loss_dice: 0.6179  mix_decode.d5.loss_cls: 0.1226  mix_decode.d5.loss_mask: 0.4430  mix_decode.d5.loss_dice: 0.6278  mix_decode.d6.loss_cls: 0.1355  mix_decode.d6.loss_mask: 0.4583  mix_decode.d6.loss_dice: 0.6175  mix_decode.d7.loss_cls: 0.1057  mix_decode.d7.loss_mask: 0.4453  mix_decode.d7.loss_dice: 0.6575  mix_decode.d8.loss_cls: 0.1088  mix_decode.d8.loss_mask: 0.4296  mix_decode.d8.loss_dice: 0.6222
2025/03/28 14:24:24 - mmengine - INFO - Iter(train) [16150/20000]  base_lr: 2.2699e-05 lr: 2.2699e-05  eta: 1:00:08  time: 1.0768  data_time: 0.0230  memory: 10774  loss: 30.7319  decode.loss_cls: 0.0157  decode.loss_mask: 0.9406  decode.loss_dice: 0.8412  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.9406  decode.d0.loss_dice: 0.8516  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.9353  decode.d1.loss_dice: 0.8429  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.9330  decode.d2.loss_dice: 0.8394  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.9424  decode.d3.loss_dice: 0.8474  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.9463  decode.d4.loss_dice: 0.8580  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.9376  decode.d5.loss_dice: 0.8435  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.9376  decode.d6.loss_dice: 0.8341  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.9398  decode.d7.loss_dice: 0.8497  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.9382  decode.d8.loss_dice: 0.8442  mix_decode.loss_cls: 0.1021  mix_decode.loss_mask: 0.4606  mix_decode.loss_dice: 0.6825  mix_decode.d0.loss_cls: 0.0742  mix_decode.d0.loss_mask: 0.4704  mix_decode.d0.loss_dice: 0.7436  mix_decode.d1.loss_cls: 0.1085  mix_decode.d1.loss_mask: 0.4558  mix_decode.d1.loss_dice: 0.7041  mix_decode.d2.loss_cls: 0.1197  mix_decode.d2.loss_mask: 0.4604  mix_decode.d2.loss_dice: 0.6909  mix_decode.d3.loss_cls: 0.1224  mix_decode.d3.loss_mask: 0.4531  mix_decode.d3.loss_dice: 0.6794  mix_decode.d4.loss_cls: 0.1211  mix_decode.d4.loss_mask: 0.4525  mix_decode.d4.loss_dice: 0.6912  mix_decode.d5.loss_cls: 0.1430  mix_decode.d5.loss_mask: 0.4489  mix_decode.d5.loss_dice: 0.6944  mix_decode.d6.loss_cls: 0.1355  mix_decode.d6.loss_mask: 0.4552  mix_decode.d6.loss_dice: 0.6655  mix_decode.d7.loss_cls: 0.1092  mix_decode.d7.loss_mask: 0.4569  mix_decode.d7.loss_dice: 0.6891  mix_decode.d8.loss_cls: 0.1036  mix_decode.d8.loss_mask: 0.4614  mix_decode.d8.loss_dice: 0.7062
2025/03/28 14:25:18 - mmengine - INFO - Iter(train) [16200/20000]  base_lr: 2.2434e-05 lr: 2.2434e-05  eta: 0:59:23  time: 1.0790  data_time: 0.0226  memory: 10779  loss: 27.4851  decode.loss_cls: 0.0783  decode.loss_mask: 0.7816  decode.loss_dice: 0.7728  decode.d0.loss_cls: 0.0906  decode.d0.loss_mask: 0.7882  decode.d0.loss_dice: 0.7954  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.7829  decode.d1.loss_dice: 0.7917  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.7810  decode.d2.loss_dice: 0.7811  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.7854  decode.d3.loss_dice: 0.7545  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.7832  decode.d4.loss_dice: 0.7610  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 0.7642  decode.d6.loss_cls: 0.1003  decode.d6.loss_mask: 0.7825  decode.d6.loss_dice: 0.7828  decode.d7.loss_cls: 0.1382  decode.d7.loss_mask: 0.7899  decode.d7.loss_dice: 0.7506  decode.d8.loss_cls: 0.0812  decode.d8.loss_mask: 0.7894  decode.d8.loss_dice: 0.7544  mix_decode.loss_cls: 0.1010  mix_decode.loss_mask: 0.4276  mix_decode.loss_dice: 0.5698  mix_decode.d0.loss_cls: 0.0775  mix_decode.d0.loss_mask: 0.4260  mix_decode.d0.loss_dice: 0.6200  mix_decode.d1.loss_cls: 0.1166  mix_decode.d1.loss_mask: 0.4304  mix_decode.d1.loss_dice: 0.5675  mix_decode.d2.loss_cls: 0.0987  mix_decode.d2.loss_mask: 0.4286  mix_decode.d2.loss_dice: 0.5882  mix_decode.d3.loss_cls: 0.0884  mix_decode.d3.loss_mask: 0.4258  mix_decode.d3.loss_dice: 0.5641  mix_decode.d4.loss_cls: 0.1238  mix_decode.d4.loss_mask: 0.4176  mix_decode.d4.loss_dice: 0.5753  mix_decode.d5.loss_cls: 0.0894  mix_decode.d5.loss_mask: 0.4303  mix_decode.d5.loss_dice: 0.5795  mix_decode.d6.loss_cls: 0.1129  mix_decode.d6.loss_mask: 0.4268  mix_decode.d6.loss_dice: 0.5792  mix_decode.d7.loss_cls: 0.0816  mix_decode.d7.loss_mask: 0.4249  mix_decode.d7.loss_dice: 0.5705  mix_decode.d8.loss_cls: 0.1130  mix_decode.d8.loss_mask: 0.4223  mix_decode.d8.loss_dice: 0.6021
2025/03/28 14:26:12 - mmengine - INFO - Iter(train) [16250/20000]  base_lr: 2.2168e-05 lr: 2.2168e-05  eta: 0:58:38  time: 1.0752  data_time: 0.0226  memory: 10769  loss: 29.5776  decode.loss_cls: 0.1582  decode.loss_mask: 0.7458  decode.loss_dice: 0.8276  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.7455  decode.d0.loss_dice: 0.9184  decode.d1.loss_cls: 0.2299  decode.d1.loss_mask: 0.7433  decode.d1.loss_dice: 0.8627  decode.d2.loss_cls: 0.1636  decode.d2.loss_mask: 0.7440  decode.d2.loss_dice: 0.8282  decode.d3.loss_cls: 0.1684  decode.d3.loss_mask: 0.7468  decode.d3.loss_dice: 0.8116  decode.d4.loss_cls: 0.1372  decode.d4.loss_mask: 0.7473  decode.d4.loss_dice: 0.8524  decode.d5.loss_cls: 0.1502  decode.d5.loss_mask: 0.7477  decode.d5.loss_dice: 0.8526  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 0.7518  decode.d6.loss_dice: 0.8481  decode.d7.loss_cls: 0.1686  decode.d7.loss_mask: 0.7436  decode.d7.loss_dice: 0.8398  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 0.7569  decode.d8.loss_dice: 0.8102  mix_decode.loss_cls: 0.1468  mix_decode.loss_mask: 0.4655  mix_decode.loss_dice: 0.5813  mix_decode.d0.loss_cls: 0.1963  mix_decode.d0.loss_mask: 0.4214  mix_decode.d0.loss_dice: 0.6510  mix_decode.d1.loss_cls: 0.2046  mix_decode.d1.loss_mask: 0.4478  mix_decode.d1.loss_dice: 0.5713  mix_decode.d2.loss_cls: 0.1620  mix_decode.d2.loss_mask: 0.4491  mix_decode.d2.loss_dice: 0.5843  mix_decode.d3.loss_cls: 0.1556  mix_decode.d3.loss_mask: 0.4474  mix_decode.d3.loss_dice: 0.5757  mix_decode.d4.loss_cls: 0.1675  mix_decode.d4.loss_mask: 0.4427  mix_decode.d4.loss_dice: 0.5632  mix_decode.d5.loss_cls: 0.1514  mix_decode.d5.loss_mask: 0.4512  mix_decode.d5.loss_dice: 0.5741  mix_decode.d6.loss_cls: 0.1837  mix_decode.d6.loss_mask: 0.4663  mix_decode.d6.loss_dice: 0.5779  mix_decode.d7.loss_cls: 0.1654  mix_decode.d7.loss_mask: 0.4607  mix_decode.d7.loss_dice: 0.5809  mix_decode.d8.loss_cls: 0.1588  mix_decode.d8.loss_mask: 0.4622  mix_decode.d8.loss_dice: 0.5863
2025/03/28 14:27:06 - mmengine - INFO - Iter(train) [16300/20000]  base_lr: 2.1902e-05 lr: 2.1902e-05  eta: 0:57:53  time: 1.0850  data_time: 0.0235  memory: 10780  loss: 27.4633  decode.loss_cls: 0.0154  decode.loss_mask: 0.9321  decode.loss_dice: 0.7696  decode.d0.loss_cls: 0.0690  decode.d0.loss_mask: 0.9378  decode.d0.loss_dice: 0.7716  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.9318  decode.d1.loss_dice: 0.7826  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.9295  decode.d2.loss_dice: 0.7758  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.9286  decode.d3.loss_dice: 0.7664  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.9332  decode.d4.loss_dice: 0.7721  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.9299  decode.d5.loss_dice: 0.7723  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.9352  decode.d6.loss_dice: 0.7736  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.9334  decode.d7.loss_dice: 0.7840  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.9397  decode.d8.loss_dice: 0.7744  mix_decode.loss_cls: 0.0955  mix_decode.loss_mask: 0.4046  mix_decode.loss_dice: 0.4909  mix_decode.d0.loss_cls: 0.1924  mix_decode.d0.loss_mask: 0.4098  mix_decode.d0.loss_dice: 0.5093  mix_decode.d1.loss_cls: 0.1492  mix_decode.d1.loss_mask: 0.4101  mix_decode.d1.loss_dice: 0.4864  mix_decode.d2.loss_cls: 0.1216  mix_decode.d2.loss_mask: 0.4099  mix_decode.d2.loss_dice: 0.4973  mix_decode.d3.loss_cls: 0.0873  mix_decode.d3.loss_mask: 0.4086  mix_decode.d3.loss_dice: 0.4884  mix_decode.d4.loss_cls: 0.1094  mix_decode.d4.loss_mask: 0.4059  mix_decode.d4.loss_dice: 0.4949  mix_decode.d5.loss_cls: 0.1035  mix_decode.d5.loss_mask: 0.4072  mix_decode.d5.loss_dice: 0.4877  mix_decode.d6.loss_cls: 0.1126  mix_decode.d6.loss_mask: 0.4059  mix_decode.d6.loss_dice: 0.4839  mix_decode.d7.loss_cls: 0.0993  mix_decode.d7.loss_mask: 0.4043  mix_decode.d7.loss_dice: 0.4904  mix_decode.d8.loss_cls: 0.0914  mix_decode.d8.loss_mask: 0.4126  mix_decode.d8.loss_dice: 0.5125
2025/03/28 14:28:00 - mmengine - INFO - Iter(train) [16350/20000]  base_lr: 2.1635e-05 lr: 2.1635e-05  eta: 0:57:07  time: 1.0765  data_time: 0.0227  memory: 10778  loss: 26.8652  decode.loss_cls: 0.0099  decode.loss_mask: 0.8491  decode.loss_dice: 0.7390  decode.d0.loss_cls: 0.0884  decode.d0.loss_mask: 0.8655  decode.d0.loss_dice: 0.7433  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.8554  decode.d1.loss_dice: 0.7297  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 0.7354  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.8512  decode.d3.loss_dice: 0.7323  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.8505  decode.d4.loss_dice: 0.7316  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.8482  decode.d5.loss_dice: 0.7276  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.8524  decode.d6.loss_dice: 0.7269  decode.d7.loss_cls: 0.0116  decode.d7.loss_mask: 0.8507  decode.d7.loss_dice: 0.7322  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.8508  decode.d8.loss_dice: 0.7273  mix_decode.loss_cls: 0.0439  mix_decode.loss_mask: 0.4215  mix_decode.loss_dice: 0.6053  mix_decode.d0.loss_cls: 0.0602  mix_decode.d0.loss_mask: 0.4255  mix_decode.d0.loss_dice: 0.6297  mix_decode.d1.loss_cls: 0.0960  mix_decode.d1.loss_mask: 0.4219  mix_decode.d1.loss_dice: 0.5906  mix_decode.d2.loss_cls: 0.0762  mix_decode.d2.loss_mask: 0.4175  mix_decode.d2.loss_dice: 0.5820  mix_decode.d3.loss_cls: 0.0859  mix_decode.d3.loss_mask: 0.4174  mix_decode.d3.loss_dice: 0.5658  mix_decode.d4.loss_cls: 0.0808  mix_decode.d4.loss_mask: 0.4170  mix_decode.d4.loss_dice: 0.5988  mix_decode.d5.loss_cls: 0.0696  mix_decode.d5.loss_mask: 0.4128  mix_decode.d5.loss_dice: 0.5704  mix_decode.d6.loss_cls: 0.0690  mix_decode.d6.loss_mask: 0.4189  mix_decode.d6.loss_dice: 0.5742  mix_decode.d7.loss_cls: 0.0766  mix_decode.d7.loss_mask: 0.4189  mix_decode.d7.loss_dice: 0.5996  mix_decode.d8.loss_cls: 0.0528  mix_decode.d8.loss_mask: 0.4200  mix_decode.d8.loss_dice: 0.6028
2025/03/28 14:28:54 - mmengine - INFO - Iter(train) [16400/20000]  base_lr: 2.1368e-05 lr: 2.1368e-05  eta: 0:56:22  time: 1.0756  data_time: 0.0227  memory: 10775  loss: 25.6402  decode.loss_cls: 0.0036  decode.loss_mask: 0.8125  decode.loss_dice: 0.6850  decode.d0.loss_cls: 0.0555  decode.d0.loss_mask: 0.8108  decode.d0.loss_dice: 0.6819  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.8108  decode.d1.loss_dice: 0.6896  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.8028  decode.d2.loss_dice: 0.6805  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.8116  decode.d3.loss_dice: 0.6840  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.8091  decode.d4.loss_dice: 0.6832  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.8057  decode.d5.loss_dice: 0.6749  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.8058  decode.d6.loss_dice: 0.6713  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.8141  decode.d7.loss_dice: 0.6838  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.8189  decode.d8.loss_dice: 0.6800  mix_decode.loss_cls: 0.1024  mix_decode.loss_mask: 0.4018  mix_decode.loss_dice: 0.5468  mix_decode.d0.loss_cls: 0.1172  mix_decode.d0.loss_mask: 0.4197  mix_decode.d0.loss_dice: 0.5720  mix_decode.d1.loss_cls: 0.0682  mix_decode.d1.loss_mask: 0.4018  mix_decode.d1.loss_dice: 0.5698  mix_decode.d2.loss_cls: 0.1096  mix_decode.d2.loss_mask: 0.4055  mix_decode.d2.loss_dice: 0.5594  mix_decode.d3.loss_cls: 0.1007  mix_decode.d3.loss_mask: 0.4028  mix_decode.d3.loss_dice: 0.5501  mix_decode.d4.loss_cls: 0.1167  mix_decode.d4.loss_mask: 0.3954  mix_decode.d4.loss_dice: 0.5419  mix_decode.d5.loss_cls: 0.1010  mix_decode.d5.loss_mask: 0.4020  mix_decode.d5.loss_dice: 0.5529  mix_decode.d6.loss_cls: 0.0973  mix_decode.d6.loss_mask: 0.3967  mix_decode.d6.loss_dice: 0.5573  mix_decode.d7.loss_cls: 0.1133  mix_decode.d7.loss_mask: 0.4052  mix_decode.d7.loss_dice: 0.5525  mix_decode.d8.loss_cls: 0.1028  mix_decode.d8.loss_mask: 0.4026  mix_decode.d8.loss_dice: 0.5689
2025/03/28 14:29:48 - mmengine - INFO - Iter(train) [16450/20000]  base_lr: 2.1101e-05 lr: 2.1101e-05  eta: 0:55:36  time: 1.0696  data_time: 0.0225  memory: 10779  loss: 26.2539  decode.loss_cls: 0.0325  decode.loss_mask: 0.7883  decode.loss_dice: 0.7219  decode.d0.loss_cls: 0.1275  decode.d0.loss_mask: 0.7909  decode.d0.loss_dice: 0.7099  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.7874  decode.d1.loss_dice: 0.7321  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.7848  decode.d2.loss_dice: 0.7226  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 0.7867  decode.d3.loss_dice: 0.7179  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.7881  decode.d4.loss_dice: 0.7176  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.7888  decode.d5.loss_dice: 0.7190  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 0.7881  decode.d6.loss_dice: 0.7103  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.7811  decode.d7.loss_dice: 0.7154  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.7817  decode.d8.loss_dice: 0.7129  mix_decode.loss_cls: 0.0531  mix_decode.loss_mask: 0.4487  mix_decode.loss_dice: 0.5537  mix_decode.d0.loss_cls: 0.0839  mix_decode.d0.loss_mask: 0.4563  mix_decode.d0.loss_dice: 0.5877  mix_decode.d1.loss_cls: 0.0662  mix_decode.d1.loss_mask: 0.4432  mix_decode.d1.loss_dice: 0.5587  mix_decode.d2.loss_cls: 0.0797  mix_decode.d2.loss_mask: 0.4466  mix_decode.d2.loss_dice: 0.5537  mix_decode.d3.loss_cls: 0.0648  mix_decode.d3.loss_mask: 0.4451  mix_decode.d3.loss_dice: 0.5379  mix_decode.d4.loss_cls: 0.0632  mix_decode.d4.loss_mask: 0.4435  mix_decode.d4.loss_dice: 0.5549  mix_decode.d5.loss_cls: 0.0642  mix_decode.d5.loss_mask: 0.4440  mix_decode.d5.loss_dice: 0.5480  mix_decode.d6.loss_cls: 0.0699  mix_decode.d6.loss_mask: 0.4464  mix_decode.d6.loss_dice: 0.5429  mix_decode.d7.loss_cls: 0.0584  mix_decode.d7.loss_mask: 0.4437  mix_decode.d7.loss_dice: 0.5507  mix_decode.d8.loss_cls: 0.0546  mix_decode.d8.loss_mask: 0.4461  mix_decode.d8.loss_dice: 0.5542
2025/03/28 14:30:42 - mmengine - INFO - Iter(train) [16500/20000]  base_lr: 2.0833e-05 lr: 2.0833e-05  eta: 0:54:51  time: 1.0766  data_time: 0.0229  memory: 10781  loss: 26.7164  decode.loss_cls: 0.0174  decode.loss_mask: 0.7780  decode.loss_dice: 0.7124  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 0.7383  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.7834  decode.d1.loss_dice: 0.7298  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.7884  decode.d2.loss_dice: 0.7054  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.7810  decode.d3.loss_dice: 0.7058  decode.d4.loss_cls: 0.0461  decode.d4.loss_mask: 0.7827  decode.d4.loss_dice: 0.7067  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.7825  decode.d5.loss_dice: 0.7293  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.7847  decode.d6.loss_dice: 0.7373  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.7812  decode.d7.loss_dice: 0.7205  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.7792  decode.d8.loss_dice: 0.7111  mix_decode.loss_cls: 0.0899  mix_decode.loss_mask: 0.4286  mix_decode.loss_dice: 0.6068  mix_decode.d0.loss_cls: 0.0969  mix_decode.d0.loss_mask: 0.4305  mix_decode.d0.loss_dice: 0.6408  mix_decode.d1.loss_cls: 0.1037  mix_decode.d1.loss_mask: 0.4208  mix_decode.d1.loss_dice: 0.5959  mix_decode.d2.loss_cls: 0.0998  mix_decode.d2.loss_mask: 0.4267  mix_decode.d2.loss_dice: 0.6082  mix_decode.d3.loss_cls: 0.0918  mix_decode.d3.loss_mask: 0.4300  mix_decode.d3.loss_dice: 0.6315  mix_decode.d4.loss_cls: 0.1009  mix_decode.d4.loss_mask: 0.4215  mix_decode.d4.loss_dice: 0.6134  mix_decode.d5.loss_cls: 0.0757  mix_decode.d5.loss_mask: 0.4232  mix_decode.d5.loss_dice: 0.6107  mix_decode.d6.loss_cls: 0.0599  mix_decode.d6.loss_mask: 0.4404  mix_decode.d6.loss_dice: 0.6308  mix_decode.d7.loss_cls: 0.0986  mix_decode.d7.loss_mask: 0.4282  mix_decode.d7.loss_dice: 0.6081  mix_decode.d8.loss_cls: 0.1034  mix_decode.d8.loss_mask: 0.4327  mix_decode.d8.loss_dice: 0.6070
2025/03/28 14:31:36 - mmengine - INFO - Iter(train) [16550/20000]  base_lr: 2.0565e-05 lr: 2.0565e-05  eta: 0:54:05  time: 1.0800  data_time: 0.0241  memory: 10771  loss: 27.3280  decode.loss_cls: 0.0505  decode.loss_mask: 0.8104  decode.loss_dice: 0.7195  decode.d0.loss_cls: 0.1090  decode.d0.loss_mask: 0.8252  decode.d0.loss_dice: 0.7602  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 0.8128  decode.d1.loss_dice: 0.7097  decode.d2.loss_cls: 0.0453  decode.d2.loss_mask: 0.8195  decode.d2.loss_dice: 0.7310  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.8123  decode.d3.loss_dice: 0.7282  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.8155  decode.d4.loss_dice: 0.7338  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.8176  decode.d5.loss_dice: 0.7199  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.8132  decode.d6.loss_dice: 0.7253  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.8133  decode.d7.loss_dice: 0.7277  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.8091  decode.d8.loss_dice: 0.7293  mix_decode.loss_cls: 0.1271  mix_decode.loss_mask: 0.4486  mix_decode.loss_dice: 0.5755  mix_decode.d0.loss_cls: 0.1669  mix_decode.d0.loss_mask: 0.4288  mix_decode.d0.loss_dice: 0.5951  mix_decode.d1.loss_cls: 0.1099  mix_decode.d1.loss_mask: 0.4239  mix_decode.d1.loss_dice: 0.5806  mix_decode.d2.loss_cls: 0.1392  mix_decode.d2.loss_mask: 0.4313  mix_decode.d2.loss_dice: 0.5642  mix_decode.d3.loss_cls: 0.1297  mix_decode.d3.loss_mask: 0.4252  mix_decode.d3.loss_dice: 0.5565  mix_decode.d4.loss_cls: 0.1414  mix_decode.d4.loss_mask: 0.4205  mix_decode.d4.loss_dice: 0.5660  mix_decode.d5.loss_cls: 0.1310  mix_decode.d5.loss_mask: 0.4296  mix_decode.d5.loss_dice: 0.5695  mix_decode.d6.loss_cls: 0.1166  mix_decode.d6.loss_mask: 0.4326  mix_decode.d6.loss_dice: 0.5590  mix_decode.d7.loss_cls: 0.1252  mix_decode.d7.loss_mask: 0.4528  mix_decode.d7.loss_dice: 0.5841  mix_decode.d8.loss_cls: 0.1122  mix_decode.d8.loss_mask: 0.4356  mix_decode.d8.loss_dice: 0.5738
2025/03/28 14:32:30 - mmengine - INFO - Iter(train) [16600/20000]  base_lr: 2.0297e-05 lr: 2.0297e-05  eta: 0:53:20  time: 1.0744  data_time: 0.0226  memory: 10774  loss: 28.3566  decode.loss_cls: 0.0671  decode.loss_mask: 0.8504  decode.loss_dice: 0.7268  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.8796  decode.d0.loss_dice: 0.7567  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.8539  decode.d1.loss_dice: 0.7515  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.8606  decode.d2.loss_dice: 0.7378  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.8533  decode.d3.loss_dice: 0.7440  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.8513  decode.d4.loss_dice: 0.7436  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.8555  decode.d5.loss_dice: 0.7447  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.8527  decode.d6.loss_dice: 0.7148  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.8556  decode.d7.loss_dice: 0.7315  decode.d8.loss_cls: 0.0392  decode.d8.loss_mask: 0.8532  decode.d8.loss_dice: 0.7465  mix_decode.loss_cls: 0.0445  mix_decode.loss_mask: 0.4856  mix_decode.loss_dice: 0.6271  mix_decode.d0.loss_cls: 0.0772  mix_decode.d0.loss_mask: 0.5025  mix_decode.d0.loss_dice: 0.6775  mix_decode.d1.loss_cls: 0.0638  mix_decode.d1.loss_mask: 0.4920  mix_decode.d1.loss_dice: 0.6502  mix_decode.d2.loss_cls: 0.0657  mix_decode.d2.loss_mask: 0.4833  mix_decode.d2.loss_dice: 0.6431  mix_decode.d3.loss_cls: 0.0578  mix_decode.d3.loss_mask: 0.4822  mix_decode.d3.loss_dice: 0.6382  mix_decode.d4.loss_cls: 0.0386  mix_decode.d4.loss_mask: 0.4850  mix_decode.d4.loss_dice: 0.6550  mix_decode.d5.loss_cls: 0.0587  mix_decode.d5.loss_mask: 0.4839  mix_decode.d5.loss_dice: 0.6496  mix_decode.d6.loss_cls: 0.0396  mix_decode.d6.loss_mask: 0.4824  mix_decode.d6.loss_dice: 0.6435  mix_decode.d7.loss_cls: 0.0451  mix_decode.d7.loss_mask: 0.4875  mix_decode.d7.loss_dice: 0.6331  mix_decode.d8.loss_cls: 0.0490  mix_decode.d8.loss_mask: 0.4826  mix_decode.d8.loss_dice: 0.6478
2025/03/28 14:33:24 - mmengine - INFO - Iter(train) [16650/20000]  base_lr: 2.0028e-05 lr: 2.0028e-05  eta: 0:52:34  time: 1.0841  data_time: 0.0245  memory: 10773  loss: 25.2311  decode.loss_cls: 0.0177  decode.loss_mask: 0.8575  decode.loss_dice: 0.7645  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.8702  decode.d0.loss_dice: 0.7488  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.8620  decode.d1.loss_dice: 0.7757  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.8566  decode.d2.loss_dice: 0.7641  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.8574  decode.d3.loss_dice: 0.7711  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.8585  decode.d4.loss_dice: 0.7636  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.8703  decode.d5.loss_dice: 0.7668  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.8720  decode.d6.loss_dice: 0.7630  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.8756  decode.d7.loss_dice: 0.7678  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.8748  decode.d8.loss_dice: 0.7675  mix_decode.loss_cls: 0.0548  mix_decode.loss_mask: 0.3420  mix_decode.loss_dice: 0.4636  mix_decode.d0.loss_cls: 0.1148  mix_decode.d0.loss_mask: 0.3511  mix_decode.d0.loss_dice: 0.4633  mix_decode.d1.loss_cls: 0.0739  mix_decode.d1.loss_mask: 0.3403  mix_decode.d1.loss_dice: 0.4568  mix_decode.d2.loss_cls: 0.1102  mix_decode.d2.loss_mask: 0.3391  mix_decode.d2.loss_dice: 0.4387  mix_decode.d3.loss_cls: 0.0624  mix_decode.d3.loss_mask: 0.3381  mix_decode.d3.loss_dice: 0.4497  mix_decode.d4.loss_cls: 0.0922  mix_decode.d4.loss_mask: 0.3379  mix_decode.d4.loss_dice: 0.4438  mix_decode.d5.loss_cls: 0.1046  mix_decode.d5.loss_mask: 0.3343  mix_decode.d5.loss_dice: 0.4324  mix_decode.d6.loss_cls: 0.0796  mix_decode.d6.loss_mask: 0.3387  mix_decode.d6.loss_dice: 0.4411  mix_decode.d7.loss_cls: 0.0813  mix_decode.d7.loss_mask: 0.3379  mix_decode.d7.loss_dice: 0.4304  mix_decode.d8.loss_cls: 0.0885  mix_decode.d8.loss_mask: 0.3377  mix_decode.d8.loss_dice: 0.4387
2025/03/28 14:34:18 - mmengine - INFO - Iter(train) [16700/20000]  base_lr: 1.9759e-05 lr: 1.9759e-05  eta: 0:51:48  time: 1.0840  data_time: 0.0233  memory: 10774  loss: 28.2441  decode.loss_cls: 0.0125  decode.loss_mask: 0.8353  decode.loss_dice: 0.7337  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.8405  decode.d0.loss_dice: 0.7534  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.8261  decode.d1.loss_dice: 0.7407  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.8274  decode.d2.loss_dice: 0.7211  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.8231  decode.d3.loss_dice: 0.7352  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.8311  decode.d4.loss_dice: 0.7329  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.8324  decode.d5.loss_dice: 0.7297  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.8267  decode.d6.loss_dice: 0.7188  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.8252  decode.d7.loss_dice: 0.7286  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.8331  decode.d8.loss_dice: 0.7411  mix_decode.loss_cls: 0.0536  mix_decode.loss_mask: 0.5126  mix_decode.loss_dice: 0.6639  mix_decode.d0.loss_cls: 0.1098  mix_decode.d0.loss_mask: 0.5115  mix_decode.d0.loss_dice: 0.6629  mix_decode.d1.loss_cls: 0.0723  mix_decode.d1.loss_mask: 0.5115  mix_decode.d1.loss_dice: 0.6524  mix_decode.d2.loss_cls: 0.0641  mix_decode.d2.loss_mask: 0.5022  mix_decode.d2.loss_dice: 0.6568  mix_decode.d3.loss_cls: 0.0696  mix_decode.d3.loss_mask: 0.5099  mix_decode.d3.loss_dice: 0.6595  mix_decode.d4.loss_cls: 0.0482  mix_decode.d4.loss_mask: 0.5168  mix_decode.d4.loss_dice: 0.6513  mix_decode.d5.loss_cls: 0.0671  mix_decode.d5.loss_mask: 0.5057  mix_decode.d5.loss_dice: 0.6617  mix_decode.d6.loss_cls: 0.0734  mix_decode.d6.loss_mask: 0.5088  mix_decode.d6.loss_dice: 0.6641  mix_decode.d7.loss_cls: 0.0532  mix_decode.d7.loss_mask: 0.5083  mix_decode.d7.loss_dice: 0.6623  mix_decode.d8.loss_cls: 0.0548  mix_decode.d8.loss_mask: 0.5053  mix_decode.d8.loss_dice: 0.6706
2025/03/28 14:35:12 - mmengine - INFO - Iter(train) [16750/20000]  base_lr: 1.9489e-05 lr: 1.9489e-05  eta: 0:51:02  time: 1.0771  data_time: 0.0230  memory: 10777  loss: 26.4609  decode.loss_cls: 0.0060  decode.loss_mask: 0.8453  decode.loss_dice: 0.7176  decode.d0.loss_cls: 0.0570  decode.d0.loss_mask: 0.8541  decode.d0.loss_dice: 0.7092  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.8476  decode.d1.loss_dice: 0.7205  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.8504  decode.d2.loss_dice: 0.7231  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.8526  decode.d3.loss_dice: 0.7254  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.8505  decode.d4.loss_dice: 0.7262  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.8507  decode.d5.loss_dice: 0.7190  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.8469  decode.d6.loss_dice: 0.7200  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.8472  decode.d7.loss_dice: 0.7216  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.8477  decode.d8.loss_dice: 0.7218  mix_decode.loss_cls: 0.0771  mix_decode.loss_mask: 0.4520  mix_decode.loss_dice: 0.5311  mix_decode.d0.loss_cls: 0.0896  mix_decode.d0.loss_mask: 0.4584  mix_decode.d0.loss_dice: 0.5496  mix_decode.d1.loss_cls: 0.0729  mix_decode.d1.loss_mask: 0.4451  mix_decode.d1.loss_dice: 0.5290  mix_decode.d2.loss_cls: 0.0753  mix_decode.d2.loss_mask: 0.4440  mix_decode.d2.loss_dice: 0.5289  mix_decode.d3.loss_cls: 0.0993  mix_decode.d3.loss_mask: 0.4464  mix_decode.d3.loss_dice: 0.5211  mix_decode.d4.loss_cls: 0.0977  mix_decode.d4.loss_mask: 0.4485  mix_decode.d4.loss_dice: 0.5185  mix_decode.d5.loss_cls: 0.1031  mix_decode.d5.loss_mask: 0.4433  mix_decode.d5.loss_dice: 0.5135  mix_decode.d6.loss_cls: 0.1292  mix_decode.d6.loss_mask: 0.4467  mix_decode.d6.loss_dice: 0.4826  mix_decode.d7.loss_cls: 0.1087  mix_decode.d7.loss_mask: 0.4485  mix_decode.d7.loss_dice: 0.5213  mix_decode.d8.loss_cls: 0.0818  mix_decode.d8.loss_mask: 0.4496  mix_decode.d8.loss_dice: 0.5369
2025/03/28 14:36:06 - mmengine - INFO - Iter(train) [16800/20000]  base_lr: 1.9219e-05 lr: 1.9219e-05  eta: 0:50:17  time: 1.0815  data_time: 0.0242  memory: 10785  loss: 30.4178  decode.loss_cls: 0.0052  decode.loss_mask: 0.9440  decode.loss_dice: 0.8196  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.9505  decode.d0.loss_dice: 0.8149  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.9504  decode.d1.loss_dice: 0.8259  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.9520  decode.d2.loss_dice: 0.8203  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.9401  decode.d3.loss_dice: 0.8230  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.9447  decode.d4.loss_dice: 0.8222  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.9466  decode.d5.loss_dice: 0.8232  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.9419  decode.d6.loss_dice: 0.8247  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.9417  decode.d7.loss_dice: 0.8225  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.9482  decode.d8.loss_dice: 0.8208  mix_decode.loss_cls: 0.0767  mix_decode.loss_mask: 0.5249  mix_decode.loss_dice: 0.6483  mix_decode.d0.loss_cls: 0.1010  mix_decode.d0.loss_mask: 0.5294  mix_decode.d0.loss_dice: 0.6835  mix_decode.d1.loss_cls: 0.1259  mix_decode.d1.loss_mask: 0.4951  mix_decode.d1.loss_dice: 0.6472  mix_decode.d2.loss_cls: 0.1059  mix_decode.d2.loss_mask: 0.4906  mix_decode.d2.loss_dice: 0.6429  mix_decode.d3.loss_cls: 0.1211  mix_decode.d3.loss_mask: 0.5085  mix_decode.d3.loss_dice: 0.6488  mix_decode.d4.loss_cls: 0.1056  mix_decode.d4.loss_mask: 0.4888  mix_decode.d4.loss_dice: 0.6432  mix_decode.d5.loss_cls: 0.0829  mix_decode.d5.loss_mask: 0.5206  mix_decode.d5.loss_dice: 0.6463  mix_decode.d6.loss_cls: 0.0740  mix_decode.d6.loss_mask: 0.5163  mix_decode.d6.loss_dice: 0.6673  mix_decode.d7.loss_cls: 0.0905  mix_decode.d7.loss_mask: 0.5144  mix_decode.d7.loss_dice: 0.6609  mix_decode.d8.loss_cls: 0.0711  mix_decode.d8.loss_mask: 0.5278  mix_decode.d8.loss_dice: 0.6452
2025/03/28 14:37:00 - mmengine - INFO - Iter(train) [16850/20000]  base_lr: 1.8948e-05 lr: 1.8948e-05  eta: 0:49:31  time: 1.0778  data_time: 0.0231  memory: 10771  loss: 25.5176  decode.loss_cls: 0.0117  decode.loss_mask: 0.7032  decode.loss_dice: 0.6996  decode.d0.loss_cls: 0.1390  decode.d0.loss_mask: 0.7210  decode.d0.loss_dice: 0.7064  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.7114  decode.d1.loss_dice: 0.7112  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.7201  decode.d2.loss_dice: 0.6995  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.7108  decode.d3.loss_dice: 0.7058  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.7098  decode.d4.loss_dice: 0.6849  decode.d5.loss_cls: 0.0477  decode.d5.loss_mask: 0.7102  decode.d5.loss_dice: 0.7083  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.7056  decode.d6.loss_dice: 0.6954  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.7037  decode.d7.loss_dice: 0.7049  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.7051  decode.d8.loss_dice: 0.7103  mix_decode.loss_cls: 0.0746  mix_decode.loss_mask: 0.4745  mix_decode.loss_dice: 0.5419  mix_decode.d0.loss_cls: 0.1266  mix_decode.d0.loss_mask: 0.4863  mix_decode.d0.loss_dice: 0.5542  mix_decode.d1.loss_cls: 0.0973  mix_decode.d1.loss_mask: 0.4712  mix_decode.d1.loss_dice: 0.5382  mix_decode.d2.loss_cls: 0.0727  mix_decode.d2.loss_mask: 0.4702  mix_decode.d2.loss_dice: 0.5433  mix_decode.d3.loss_cls: 0.0624  mix_decode.d3.loss_mask: 0.4683  mix_decode.d3.loss_dice: 0.5389  mix_decode.d4.loss_cls: 0.0646  mix_decode.d4.loss_mask: 0.4710  mix_decode.d4.loss_dice: 0.5435  mix_decode.d5.loss_cls: 0.0469  mix_decode.d5.loss_mask: 0.4747  mix_decode.d5.loss_dice: 0.5562  mix_decode.d6.loss_cls: 0.0472  mix_decode.d6.loss_mask: 0.4713  mix_decode.d6.loss_dice: 0.5672  mix_decode.d7.loss_cls: 0.0583  mix_decode.d7.loss_mask: 0.4748  mix_decode.d7.loss_dice: 0.5516  mix_decode.d8.loss_cls: 0.0590  mix_decode.d8.loss_mask: 0.4711  mix_decode.d8.loss_dice: 0.5447
2025/03/28 14:37:54 - mmengine - INFO - Iter(train) [16900/20000]  base_lr: 1.8677e-05 lr: 1.8677e-05  eta: 0:48:45  time: 1.0736  data_time: 0.0227  memory: 10776  loss: 26.1305  decode.loss_cls: 0.0034  decode.loss_mask: 0.7816  decode.loss_dice: 0.6998  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.7728  decode.d0.loss_dice: 0.6948  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.7794  decode.d1.loss_dice: 0.7039  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.7811  decode.d2.loss_dice: 0.7063  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.7824  decode.d3.loss_dice: 0.6991  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.7803  decode.d4.loss_dice: 0.6935  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 0.6948  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.7834  decode.d6.loss_dice: 0.7029  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.7790  decode.d7.loss_dice: 0.6998  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.7840  decode.d8.loss_dice: 0.6960  mix_decode.loss_cls: 0.0595  mix_decode.loss_mask: 0.4759  mix_decode.loss_dice: 0.5834  mix_decode.d0.loss_cls: 0.0887  mix_decode.d0.loss_mask: 0.4843  mix_decode.d0.loss_dice: 0.6032  mix_decode.d1.loss_cls: 0.0372  mix_decode.d1.loss_mask: 0.4713  mix_decode.d1.loss_dice: 0.5889  mix_decode.d2.loss_cls: 0.0774  mix_decode.d2.loss_mask: 0.4766  mix_decode.d2.loss_dice: 0.5635  mix_decode.d3.loss_cls: 0.0675  mix_decode.d3.loss_mask: 0.4770  mix_decode.d3.loss_dice: 0.5706  mix_decode.d4.loss_cls: 0.0621  mix_decode.d4.loss_mask: 0.4813  mix_decode.d4.loss_dice: 0.5769  mix_decode.d5.loss_cls: 0.0706  mix_decode.d5.loss_mask: 0.4762  mix_decode.d5.loss_dice: 0.5716  mix_decode.d6.loss_cls: 0.0635  mix_decode.d6.loss_mask: 0.4780  mix_decode.d6.loss_dice: 0.5734  mix_decode.d7.loss_cls: 0.0609  mix_decode.d7.loss_mask: 0.4822  mix_decode.d7.loss_dice: 0.5840  mix_decode.d8.loss_cls: 0.0676  mix_decode.d8.loss_mask: 0.4838  mix_decode.d8.loss_dice: 0.5766
2025/03/28 14:38:47 - mmengine - INFO - Iter(train) [16950/20000]  base_lr: 1.8406e-05 lr: 1.8406e-05  eta: 0:47:59  time: 1.0723  data_time: 0.0227  memory: 10784  loss: 27.1774  decode.loss_cls: 0.0103  decode.loss_mask: 0.8569  decode.loss_dice: 0.7039  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.8577  decode.d0.loss_dice: 0.6926  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.8568  decode.d1.loss_dice: 0.7034  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.8555  decode.d2.loss_dice: 0.6947  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.8551  decode.d3.loss_dice: 0.7006  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.8557  decode.d4.loss_dice: 0.6968  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.8530  decode.d5.loss_dice: 0.7036  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.8569  decode.d6.loss_dice: 0.7027  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.8491  decode.d7.loss_dice: 0.7015  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.8529  decode.d8.loss_dice: 0.7040  mix_decode.loss_cls: 0.0905  mix_decode.loss_mask: 0.4749  mix_decode.loss_dice: 0.5721  mix_decode.d0.loss_cls: 0.0633  mix_decode.d0.loss_mask: 0.4857  mix_decode.d0.loss_dice: 0.6228  mix_decode.d1.loss_cls: 0.0848  mix_decode.d1.loss_mask: 0.4734  mix_decode.d1.loss_dice: 0.5991  mix_decode.d2.loss_cls: 0.1061  mix_decode.d2.loss_mask: 0.4678  mix_decode.d2.loss_dice: 0.5668  mix_decode.d3.loss_cls: 0.0823  mix_decode.d3.loss_mask: 0.4674  mix_decode.d3.loss_dice: 0.5701  mix_decode.d4.loss_cls: 0.0788  mix_decode.d4.loss_mask: 0.4730  mix_decode.d4.loss_dice: 0.5913  mix_decode.d5.loss_cls: 0.1076  mix_decode.d5.loss_mask: 0.4659  mix_decode.d5.loss_dice: 0.5639  mix_decode.d6.loss_cls: 0.0756  mix_decode.d6.loss_mask: 0.4781  mix_decode.d6.loss_dice: 0.5945  mix_decode.d7.loss_cls: 0.0599  mix_decode.d7.loss_mask: 0.4803  mix_decode.d7.loss_dice: 0.5923  mix_decode.d8.loss_cls: 0.0912  mix_decode.d8.loss_mask: 0.4705  mix_decode.d8.loss_dice: 0.5735
2025/03/28 14:39:41 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 14:39:41 - mmengine - INFO - Iter(train) [17000/20000]  base_lr: 1.8134e-05 lr: 1.8134e-05  eta: 0:47:13  time: 1.0915  data_time: 0.0245  memory: 10774  loss: 26.5197  decode.loss_cls: 0.0635  decode.loss_mask: 0.7835  decode.loss_dice: 0.6632  decode.d0.loss_cls: 0.1479  decode.d0.loss_mask: 0.8032  decode.d0.loss_dice: 0.7420  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.7938  decode.d1.loss_dice: 0.7106  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.7972  decode.d2.loss_dice: 0.7095  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.7878  decode.d3.loss_dice: 0.6991  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.7916  decode.d4.loss_dice: 0.7050  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.7873  decode.d5.loss_dice: 0.7096  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.7820  decode.d6.loss_dice: 0.7263  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.7882  decode.d7.loss_dice: 0.7047  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.7855  decode.d8.loss_dice: 0.6961  mix_decode.loss_cls: 0.0602  mix_decode.loss_mask: 0.4088  mix_decode.loss_dice: 0.5896  mix_decode.d0.loss_cls: 0.1037  mix_decode.d0.loss_mask: 0.4246  mix_decode.d0.loss_dice: 0.6406  mix_decode.d1.loss_cls: 0.0802  mix_decode.d1.loss_mask: 0.4195  mix_decode.d1.loss_dice: 0.6129  mix_decode.d2.loss_cls: 0.0826  mix_decode.d2.loss_mask: 0.4153  mix_decode.d2.loss_dice: 0.5942  mix_decode.d3.loss_cls: 0.0748  mix_decode.d3.loss_mask: 0.4141  mix_decode.d3.loss_dice: 0.5960  mix_decode.d4.loss_cls: 0.0713  mix_decode.d4.loss_mask: 0.4110  mix_decode.d4.loss_dice: 0.5837  mix_decode.d5.loss_cls: 0.0679  mix_decode.d5.loss_mask: 0.4066  mix_decode.d5.loss_dice: 0.5808  mix_decode.d6.loss_cls: 0.0645  mix_decode.d6.loss_mask: 0.4109  mix_decode.d6.loss_dice: 0.5937  mix_decode.d7.loss_cls: 0.0610  mix_decode.d7.loss_mask: 0.4096  mix_decode.d7.loss_dice: 0.5893  mix_decode.d8.loss_cls: 0.0681  mix_decode.d8.loss_mask: 0.4123  mix_decode.d8.loss_dice: 0.5962
2025/03/28 14:40:35 - mmengine - INFO - Iter(train) [17050/20000]  base_lr: 1.7862e-05 lr: 1.7862e-05  eta: 0:46:27  time: 1.0745  data_time: 0.0228  memory: 10786  loss: 23.6663  decode.loss_cls: 0.0125  decode.loss_mask: 0.7075  decode.loss_dice: 0.6747  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.7106  decode.d0.loss_dice: 0.6639  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.7024  decode.d1.loss_dice: 0.6733  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.7100  decode.d2.loss_dice: 0.6786  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.7095  decode.d3.loss_dice: 0.6741  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.7051  decode.d4.loss_dice: 0.6769  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.7073  decode.d5.loss_dice: 0.6803  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.7074  decode.d6.loss_dice: 0.6711  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.7061  decode.d7.loss_dice: 0.6756  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.7074  decode.d8.loss_dice: 0.6748  mix_decode.loss_cls: 0.1188  mix_decode.loss_mask: 0.3967  mix_decode.loss_dice: 0.4482  mix_decode.d0.loss_cls: 0.1412  mix_decode.d0.loss_mask: 0.4017  mix_decode.d0.loss_dice: 0.4539  mix_decode.d1.loss_cls: 0.1082  mix_decode.d1.loss_mask: 0.4009  mix_decode.d1.loss_dice: 0.4587  mix_decode.d2.loss_cls: 0.1290  mix_decode.d2.loss_mask: 0.4034  mix_decode.d2.loss_dice: 0.4529  mix_decode.d3.loss_cls: 0.1061  mix_decode.d3.loss_mask: 0.4010  mix_decode.d3.loss_dice: 0.4461  mix_decode.d4.loss_cls: 0.0914  mix_decode.d4.loss_mask: 0.4040  mix_decode.d4.loss_dice: 0.4612  mix_decode.d5.loss_cls: 0.1103  mix_decode.d5.loss_mask: 0.4028  mix_decode.d5.loss_dice: 0.4421  mix_decode.d6.loss_cls: 0.0966  mix_decode.d6.loss_mask: 0.4066  mix_decode.d6.loss_dice: 0.4596  mix_decode.d7.loss_cls: 0.0933  mix_decode.d7.loss_mask: 0.4037  mix_decode.d7.loss_dice: 0.4574  mix_decode.d8.loss_cls: 0.1053  mix_decode.d8.loss_mask: 0.4037  mix_decode.d8.loss_dice: 0.4517
2025/03/28 14:41:29 - mmengine - INFO - Iter(train) [17100/20000]  base_lr: 1.7589e-05 lr: 1.7589e-05  eta: 0:45:41  time: 1.0807  data_time: 0.0229  memory: 10769  loss: 25.8306  decode.loss_cls: 0.0158  decode.loss_mask: 0.8301  decode.loss_dice: 0.6785  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.8406  decode.d0.loss_dice: 0.6639  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.8347  decode.d1.loss_dice: 0.6808  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.8275  decode.d2.loss_dice: 0.6718  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.8242  decode.d3.loss_dice: 0.6874  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.8279  decode.d4.loss_dice: 0.6804  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.8216  decode.d5.loss_dice: 0.6682  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.8217  decode.d6.loss_dice: 0.6763  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.8260  decode.d7.loss_dice: 0.6788  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.8310  decode.d8.loss_dice: 0.6754  mix_decode.loss_cls: 0.0971  mix_decode.loss_mask: 0.4229  mix_decode.loss_dice: 0.5155  mix_decode.d0.loss_cls: 0.1352  mix_decode.d0.loss_mask: 0.4372  mix_decode.d0.loss_dice: 0.5483  mix_decode.d1.loss_cls: 0.1175  mix_decode.d1.loss_mask: 0.4301  mix_decode.d1.loss_dice: 0.5312  mix_decode.d2.loss_cls: 0.0991  mix_decode.d2.loss_mask: 0.4288  mix_decode.d2.loss_dice: 0.5260  mix_decode.d3.loss_cls: 0.0952  mix_decode.d3.loss_mask: 0.4271  mix_decode.d3.loss_dice: 0.5187  mix_decode.d4.loss_cls: 0.1114  mix_decode.d4.loss_mask: 0.4273  mix_decode.d4.loss_dice: 0.5127  mix_decode.d5.loss_cls: 0.1020  mix_decode.d5.loss_mask: 0.4282  mix_decode.d5.loss_dice: 0.5174  mix_decode.d6.loss_cls: 0.0894  mix_decode.d6.loss_mask: 0.4268  mix_decode.d6.loss_dice: 0.5236  mix_decode.d7.loss_cls: 0.1065  mix_decode.d7.loss_mask: 0.4250  mix_decode.d7.loss_dice: 0.5231  mix_decode.d8.loss_cls: 0.1084  mix_decode.d8.loss_mask: 0.4267  mix_decode.d8.loss_dice: 0.5132
2025/03/28 14:42:23 - mmengine - INFO - Iter(train) [17150/20000]  base_lr: 1.7316e-05 lr: 1.7316e-05  eta: 0:44:55  time: 1.0896  data_time: 0.0242  memory: 10773  loss: 26.8720  decode.loss_cls: 0.0632  decode.loss_mask: 0.8841  decode.loss_dice: 0.7874  decode.d0.loss_cls: 0.0730  decode.d0.loss_mask: 0.9042  decode.d0.loss_dice: 0.7890  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.8957  decode.d1.loss_dice: 0.7970  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.8924  decode.d2.loss_dice: 0.8004  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.8859  decode.d3.loss_dice: 0.7890  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.9037  decode.d4.loss_dice: 0.8064  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.8962  decode.d5.loss_dice: 0.8063  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.8957  decode.d6.loss_dice: 0.7980  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.8810  decode.d7.loss_dice: 0.7856  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.8818  decode.d8.loss_dice: 0.7817  mix_decode.loss_cls: 0.1124  mix_decode.loss_mask: 0.3336  mix_decode.loss_dice: 0.5175  mix_decode.d0.loss_cls: 0.1405  mix_decode.d0.loss_mask: 0.3408  mix_decode.d0.loss_dice: 0.5484  mix_decode.d1.loss_cls: 0.1388  mix_decode.d1.loss_mask: 0.3434  mix_decode.d1.loss_dice: 0.5159  mix_decode.d2.loss_cls: 0.1198  mix_decode.d2.loss_mask: 0.3409  mix_decode.d2.loss_dice: 0.5063  mix_decode.d3.loss_cls: 0.1100  mix_decode.d3.loss_mask: 0.3384  mix_decode.d3.loss_dice: 0.5043  mix_decode.d4.loss_cls: 0.0998  mix_decode.d4.loss_mask: 0.3361  mix_decode.d4.loss_dice: 0.5005  mix_decode.d5.loss_cls: 0.1189  mix_decode.d5.loss_mask: 0.3378  mix_decode.d5.loss_dice: 0.5045  mix_decode.d6.loss_cls: 0.0886  mix_decode.d6.loss_mask: 0.3433  mix_decode.d6.loss_dice: 0.5209  mix_decode.d7.loss_cls: 0.0827  mix_decode.d7.loss_mask: 0.3405  mix_decode.d7.loss_dice: 0.5242  mix_decode.d8.loss_cls: 0.0945  mix_decode.d8.loss_mask: 0.3406  mix_decode.d8.loss_dice: 0.5136
2025/03/28 14:43:17 - mmengine - INFO - Iter(train) [17200/20000]  base_lr: 1.7043e-05 lr: 1.7043e-05  eta: 0:44:08  time: 1.0814  data_time: 0.0232  memory: 10776  loss: 26.2580  decode.loss_cls: 0.0092  decode.loss_mask: 0.7708  decode.loss_dice: 0.7029  decode.d0.loss_cls: 0.0651  decode.d0.loss_mask: 0.7718  decode.d0.loss_dice: 0.6902  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.7697  decode.d1.loss_dice: 0.7044  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.7720  decode.d2.loss_dice: 0.7084  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.7741  decode.d3.loss_dice: 0.7097  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.7711  decode.d4.loss_dice: 0.7057  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.7686  decode.d5.loss_dice: 0.6973  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.7679  decode.d6.loss_dice: 0.6991  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.7715  decode.d7.loss_dice: 0.7076  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.7686  decode.d8.loss_dice: 0.6927  mix_decode.loss_cls: 0.0753  mix_decode.loss_mask: 0.4405  mix_decode.loss_dice: 0.6077  mix_decode.d0.loss_cls: 0.0847  mix_decode.d0.loss_mask: 0.4533  mix_decode.d0.loss_dice: 0.6315  mix_decode.d1.loss_cls: 0.0688  mix_decode.d1.loss_mask: 0.4477  mix_decode.d1.loss_dice: 0.6199  mix_decode.d2.loss_cls: 0.1045  mix_decode.d2.loss_mask: 0.4479  mix_decode.d2.loss_dice: 0.5912  mix_decode.d3.loss_cls: 0.0739  mix_decode.d3.loss_mask: 0.4415  mix_decode.d3.loss_dice: 0.6147  mix_decode.d4.loss_cls: 0.0935  mix_decode.d4.loss_mask: 0.4373  mix_decode.d4.loss_dice: 0.5895  mix_decode.d5.loss_cls: 0.0978  mix_decode.d5.loss_mask: 0.4375  mix_decode.d5.loss_dice: 0.5845  mix_decode.d6.loss_cls: 0.1027  mix_decode.d6.loss_mask: 0.4405  mix_decode.d6.loss_dice: 0.5896  mix_decode.d7.loss_cls: 0.0912  mix_decode.d7.loss_mask: 0.4477  mix_decode.d7.loss_dice: 0.6198  mix_decode.d8.loss_cls: 0.0760  mix_decode.d8.loss_mask: 0.4413  mix_decode.d8.loss_dice: 0.6047
2025/03/28 14:44:12 - mmengine - INFO - Iter(train) [17250/20000]  base_lr: 1.6768e-05 lr: 1.6768e-05  eta: 0:43:22  time: 1.0746  data_time: 0.0224  memory: 10769  loss: 23.3969  decode.loss_cls: 0.0064  decode.loss_mask: 0.7044  decode.loss_dice: 0.6722  decode.d0.loss_cls: 0.0648  decode.d0.loss_mask: 0.7054  decode.d0.loss_dice: 0.6642  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.7040  decode.d1.loss_dice: 0.6752  decode.d2.loss_cls: 0.0094  decode.d2.loss_mask: 0.7024  decode.d2.loss_dice: 0.6822  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.7072  decode.d3.loss_dice: 0.6748  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.7035  decode.d4.loss_dice: 0.6731  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.7032  decode.d5.loss_dice: 0.6726  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.7001  decode.d6.loss_dice: 0.6804  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.7075  decode.d7.loss_dice: 0.6831  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.7042  decode.d8.loss_dice: 0.6819  mix_decode.loss_cls: 0.0358  mix_decode.loss_mask: 0.3873  mix_decode.loss_dice: 0.5072  mix_decode.d0.loss_cls: 0.0479  mix_decode.d0.loss_mask: 0.3854  mix_decode.d0.loss_dice: 0.5263  mix_decode.d1.loss_cls: 0.0675  mix_decode.d1.loss_mask: 0.3873  mix_decode.d1.loss_dice: 0.5183  mix_decode.d2.loss_cls: 0.0592  mix_decode.d2.loss_mask: 0.3855  mix_decode.d2.loss_dice: 0.5157  mix_decode.d3.loss_cls: 0.0413  mix_decode.d3.loss_mask: 0.3877  mix_decode.d3.loss_dice: 0.5108  mix_decode.d4.loss_cls: 0.0567  mix_decode.d4.loss_mask: 0.3880  mix_decode.d4.loss_dice: 0.5156  mix_decode.d5.loss_cls: 0.0439  mix_decode.d5.loss_mask: 0.3896  mix_decode.d5.loss_dice: 0.5036  mix_decode.d6.loss_cls: 0.0503  mix_decode.d6.loss_mask: 0.3859  mix_decode.d6.loss_dice: 0.4959  mix_decode.d7.loss_cls: 0.0390  mix_decode.d7.loss_mask: 0.3897  mix_decode.d7.loss_dice: 0.5093  mix_decode.d8.loss_cls: 0.0388  mix_decode.d8.loss_mask: 0.3887  mix_decode.d8.loss_dice: 0.5030
2025/03/28 14:45:05 - mmengine - INFO - Iter(train) [17300/20000]  base_lr: 1.6494e-05 lr: 1.6494e-05  eta: 0:42:36  time: 1.0975  data_time: 0.0247  memory: 10768  loss: 24.6286  decode.loss_cls: 0.0177  decode.loss_mask: 0.8285  decode.loss_dice: 0.6384  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 0.8373  decode.d0.loss_dice: 0.6389  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.8247  decode.d1.loss_dice: 0.6357  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.8231  decode.d2.loss_dice: 0.6403  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.8249  decode.d3.loss_dice: 0.6478  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.8268  decode.d4.loss_dice: 0.6299  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.8256  decode.d5.loss_dice: 0.6420  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.8272  decode.d6.loss_dice: 0.6569  decode.d7.loss_cls: 0.0223  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 0.6597  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.8238  decode.d8.loss_dice: 0.6299  mix_decode.loss_cls: 0.0398  mix_decode.loss_mask: 0.4102  mix_decode.loss_dice: 0.5118  mix_decode.d0.loss_cls: 0.0775  mix_decode.d0.loss_mask: 0.3988  mix_decode.d0.loss_dice: 0.5286  mix_decode.d1.loss_cls: 0.0697  mix_decode.d1.loss_mask: 0.3881  mix_decode.d1.loss_dice: 0.5045  mix_decode.d2.loss_cls: 0.0702  mix_decode.d2.loss_mask: 0.3827  mix_decode.d2.loss_dice: 0.5006  mix_decode.d3.loss_cls: 0.0646  mix_decode.d3.loss_mask: 0.3902  mix_decode.d3.loss_dice: 0.4966  mix_decode.d4.loss_cls: 0.0657  mix_decode.d4.loss_mask: 0.3847  mix_decode.d4.loss_dice: 0.4947  mix_decode.d5.loss_cls: 0.0408  mix_decode.d5.loss_mask: 0.4103  mix_decode.d5.loss_dice: 0.5207  mix_decode.d6.loss_cls: 0.0438  mix_decode.d6.loss_mask: 0.4066  mix_decode.d6.loss_dice: 0.5044  mix_decode.d7.loss_cls: 0.0545  mix_decode.d7.loss_mask: 0.4105  mix_decode.d7.loss_dice: 0.5163  mix_decode.d8.loss_cls: 0.0597  mix_decode.d8.loss_mask: 0.4076  mix_decode.d8.loss_dice: 0.5074
2025/03/28 14:46:00 - mmengine - INFO - Iter(train) [17350/20000]  base_lr: 1.6219e-05 lr: 1.6219e-05  eta: 0:41:50  time: 1.0809  data_time: 0.0228  memory: 10772  loss: 26.1686  decode.loss_cls: 0.0070  decode.loss_mask: 0.8040  decode.loss_dice: 0.6837  decode.d0.loss_cls: 0.0695  decode.d0.loss_mask: 0.8162  decode.d0.loss_dice: 0.6985  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.8053  decode.d1.loss_dice: 0.6900  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.8072  decode.d2.loss_dice: 0.6843  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.8080  decode.d3.loss_dice: 0.6848  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.8089  decode.d4.loss_dice: 0.6897  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.8087  decode.d5.loss_dice: 0.6840  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.8066  decode.d6.loss_dice: 0.6893  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.8074  decode.d7.loss_dice: 0.6889  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.8058  decode.d8.loss_dice: 0.6819  mix_decode.loss_cls: 0.0698  mix_decode.loss_mask: 0.4626  mix_decode.loss_dice: 0.5575  mix_decode.d0.loss_cls: 0.1251  mix_decode.d0.loss_mask: 0.4669  mix_decode.d0.loss_dice: 0.5732  mix_decode.d1.loss_cls: 0.0634  mix_decode.d1.loss_mask: 0.4801  mix_decode.d1.loss_dice: 0.5621  mix_decode.d2.loss_cls: 0.0678  mix_decode.d2.loss_mask: 0.4831  mix_decode.d2.loss_dice: 0.5580  mix_decode.d3.loss_cls: 0.0949  mix_decode.d3.loss_mask: 0.4713  mix_decode.d3.loss_dice: 0.5437  mix_decode.d4.loss_cls: 0.0757  mix_decode.d4.loss_mask: 0.4846  mix_decode.d4.loss_dice: 0.5446  mix_decode.d5.loss_cls: 0.0622  mix_decode.d5.loss_mask: 0.4838  mix_decode.d5.loss_dice: 0.5541  mix_decode.d6.loss_cls: 0.0626  mix_decode.d6.loss_mask: 0.4833  mix_decode.d6.loss_dice: 0.5569  mix_decode.d7.loss_cls: 0.0578  mix_decode.d7.loss_mask: 0.4870  mix_decode.d7.loss_dice: 0.5540  mix_decode.d8.loss_cls: 0.0334  mix_decode.d8.loss_mask: 0.4865  mix_decode.d8.loss_dice: 0.5637
2025/03/28 14:46:53 - mmengine - INFO - Iter(train) [17400/20000]  base_lr: 1.5943e-05 lr: 1.5943e-05  eta: 0:41:03  time: 1.0743  data_time: 0.0225  memory: 10771  loss: 25.9808  decode.loss_cls: 0.0333  decode.loss_mask: 0.7515  decode.loss_dice: 0.7748  decode.d0.loss_cls: 0.1191  decode.d0.loss_mask: 0.7467  decode.d0.loss_dice: 0.7686  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.7467  decode.d1.loss_dice: 0.7767  decode.d2.loss_cls: 0.0410  decode.d2.loss_mask: 0.7468  decode.d2.loss_dice: 0.7733  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.7469  decode.d3.loss_dice: 0.7643  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.7441  decode.d4.loss_dice: 0.7621  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.7401  decode.d5.loss_dice: 0.7593  decode.d6.loss_cls: 0.0345  decode.d6.loss_mask: 0.7446  decode.d6.loss_dice: 0.7491  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.7584  decode.d7.loss_dice: 0.7964  decode.d8.loss_cls: 0.0323  decode.d8.loss_mask: 0.7461  decode.d8.loss_dice: 0.7638  mix_decode.loss_cls: 0.0569  mix_decode.loss_mask: 0.3655  mix_decode.loss_dice: 0.6025  mix_decode.d0.loss_cls: 0.0840  mix_decode.d0.loss_mask: 0.3667  mix_decode.d0.loss_dice: 0.6141  mix_decode.d1.loss_cls: 0.0899  mix_decode.d1.loss_mask: 0.3652  mix_decode.d1.loss_dice: 0.5894  mix_decode.d2.loss_cls: 0.0516  mix_decode.d2.loss_mask: 0.3644  mix_decode.d2.loss_dice: 0.6083  mix_decode.d3.loss_cls: 0.0690  mix_decode.d3.loss_mask: 0.3648  mix_decode.d3.loss_dice: 0.5924  mix_decode.d4.loss_cls: 0.0568  mix_decode.d4.loss_mask: 0.3653  mix_decode.d4.loss_dice: 0.5964  mix_decode.d5.loss_cls: 0.0745  mix_decode.d5.loss_mask: 0.3603  mix_decode.d5.loss_dice: 0.5795  mix_decode.d6.loss_cls: 0.0470  mix_decode.d6.loss_mask: 0.3671  mix_decode.d6.loss_dice: 0.6068  mix_decode.d7.loss_cls: 0.0751  mix_decode.d7.loss_mask: 0.3651  mix_decode.d7.loss_dice: 0.5893  mix_decode.d8.loss_cls: 0.0472  mix_decode.d8.loss_mask: 0.3619  mix_decode.d8.loss_dice: 0.6088
2025/03/28 14:47:47 - mmengine - INFO - Iter(train) [17450/20000]  base_lr: 1.5667e-05 lr: 1.5667e-05  eta: 0:40:17  time: 1.0783  data_time: 0.0225  memory: 10772  loss: 29.4849  decode.loss_cls: 0.0518  decode.loss_mask: 0.9508  decode.loss_dice: 0.8299  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.9575  decode.d0.loss_dice: 0.8350  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.9507  decode.d1.loss_dice: 0.8142  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.9509  decode.d2.loss_dice: 0.8036  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.9534  decode.d3.loss_dice: 0.8241  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.9547  decode.d4.loss_dice: 0.8386  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.9578  decode.d5.loss_dice: 0.8020  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.9545  decode.d6.loss_dice: 0.8378  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.9506  decode.d7.loss_dice: 0.8122  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.9456  decode.d8.loss_dice: 0.8337  mix_decode.loss_cls: 0.0534  mix_decode.loss_mask: 0.4735  mix_decode.loss_dice: 0.5924  mix_decode.d0.loss_cls: 0.0669  mix_decode.d0.loss_mask: 0.4865  mix_decode.d0.loss_dice: 0.6462  mix_decode.d1.loss_cls: 0.0972  mix_decode.d1.loss_mask: 0.4805  mix_decode.d1.loss_dice: 0.5983  mix_decode.d2.loss_cls: 0.0698  mix_decode.d2.loss_mask: 0.4764  mix_decode.d2.loss_dice: 0.6030  mix_decode.d3.loss_cls: 0.0499  mix_decode.d3.loss_mask: 0.4809  mix_decode.d3.loss_dice: 0.5875  mix_decode.d4.loss_cls: 0.0569  mix_decode.d4.loss_mask: 0.4788  mix_decode.d4.loss_dice: 0.5931  mix_decode.d5.loss_cls: 0.0475  mix_decode.d5.loss_mask: 0.4812  mix_decode.d5.loss_dice: 0.5918  mix_decode.d6.loss_cls: 0.0494  mix_decode.d6.loss_mask: 0.4835  mix_decode.d6.loss_dice: 0.6030  mix_decode.d7.loss_cls: 0.0696  mix_decode.d7.loss_mask: 0.4786  mix_decode.d7.loss_dice: 0.5952  mix_decode.d8.loss_cls: 0.0559  mix_decode.d8.loss_mask: 0.4786  mix_decode.d8.loss_dice: 0.5937
2025/03/28 14:48:41 - mmengine - INFO - Iter(train) [17500/20000]  base_lr: 1.5390e-05 lr: 1.5390e-05  eta: 0:39:30  time: 1.0744  data_time: 0.0225  memory: 10779  loss: 23.6153  decode.loss_cls: 0.0267  decode.loss_mask: 0.6775  decode.loss_dice: 0.6795  decode.d0.loss_cls: 0.0828  decode.d0.loss_mask: 0.6838  decode.d0.loss_dice: 0.6781  decode.d1.loss_cls: 0.0334  decode.d1.loss_mask: 0.6817  decode.d1.loss_dice: 0.6913  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.6758  decode.d2.loss_dice: 0.6834  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.6775  decode.d3.loss_dice: 0.6829  decode.d4.loss_cls: 0.0218  decode.d4.loss_mask: 0.6730  decode.d4.loss_dice: 0.6832  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.6836  decode.d5.loss_dice: 0.6823  decode.d6.loss_cls: 0.0213  decode.d6.loss_mask: 0.6801  decode.d6.loss_dice: 0.6825  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.6828  decode.d7.loss_dice: 0.6807  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.6825  decode.d8.loss_dice: 0.6828  mix_decode.loss_cls: 0.0760  mix_decode.loss_mask: 0.3597  mix_decode.loss_dice: 0.4983  mix_decode.d0.loss_cls: 0.1137  mix_decode.d0.loss_mask: 0.3674  mix_decode.d0.loss_dice: 0.5136  mix_decode.d1.loss_cls: 0.0849  mix_decode.d1.loss_mask: 0.3558  mix_decode.d1.loss_dice: 0.4938  mix_decode.d2.loss_cls: 0.0841  mix_decode.d2.loss_mask: 0.3596  mix_decode.d2.loss_dice: 0.4939  mix_decode.d3.loss_cls: 0.1259  mix_decode.d3.loss_mask: 0.3553  mix_decode.d3.loss_dice: 0.4810  mix_decode.d4.loss_cls: 0.1241  mix_decode.d4.loss_mask: 0.3577  mix_decode.d4.loss_dice: 0.4893  mix_decode.d5.loss_cls: 0.0764  mix_decode.d5.loss_mask: 0.3610  mix_decode.d5.loss_dice: 0.5180  mix_decode.d6.loss_cls: 0.0992  mix_decode.d6.loss_mask: 0.3566  mix_decode.d6.loss_dice: 0.5010  mix_decode.d7.loss_cls: 0.0732  mix_decode.d7.loss_mask: 0.3631  mix_decode.d7.loss_dice: 0.5182  mix_decode.d8.loss_cls: 0.0806  mix_decode.d8.loss_mask: 0.3643  mix_decode.d8.loss_dice: 0.5200
2025/03/28 14:49:35 - mmengine - INFO - Iter(train) [17550/20000]  base_lr: 1.5113e-05 lr: 1.5113e-05  eta: 0:38:44  time: 1.0689  data_time: 0.0225  memory: 10771  loss: 22.6028  decode.loss_cls: 0.0222  decode.loss_mask: 0.7173  decode.loss_dice: 0.6665  decode.d0.loss_cls: 0.0682  decode.d0.loss_mask: 0.7228  decode.d0.loss_dice: 0.6804  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.7180  decode.d1.loss_dice: 0.6710  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.7231  decode.d2.loss_dice: 0.6545  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.7180  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.7175  decode.d4.loss_dice: 0.6602  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.7199  decode.d5.loss_dice: 0.6787  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.7188  decode.d6.loss_dice: 0.6596  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.7164  decode.d7.loss_dice: 0.6545  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.7199  decode.d8.loss_dice: 0.6562  mix_decode.loss_cls: 0.0578  mix_decode.loss_mask: 0.3400  mix_decode.loss_dice: 0.4444  mix_decode.d0.loss_cls: 0.1007  mix_decode.d0.loss_mask: 0.3382  mix_decode.d0.loss_dice: 0.4772  mix_decode.d1.loss_cls: 0.0716  mix_decode.d1.loss_mask: 0.3383  mix_decode.d1.loss_dice: 0.4596  mix_decode.d2.loss_cls: 0.0659  mix_decode.d2.loss_mask: 0.3405  mix_decode.d2.loss_dice: 0.4439  mix_decode.d3.loss_cls: 0.0598  mix_decode.d3.loss_mask: 0.3428  mix_decode.d3.loss_dice: 0.4448  mix_decode.d4.loss_cls: 0.0597  mix_decode.d4.loss_mask: 0.3425  mix_decode.d4.loss_dice: 0.4400  mix_decode.d5.loss_cls: 0.0576  mix_decode.d5.loss_mask: 0.3438  mix_decode.d5.loss_dice: 0.4432  mix_decode.d6.loss_cls: 0.0588  mix_decode.d6.loss_mask: 0.3399  mix_decode.d6.loss_dice: 0.4551  mix_decode.d7.loss_cls: 0.0598  mix_decode.d7.loss_mask: 0.3428  mix_decode.d7.loss_dice: 0.4312  mix_decode.d8.loss_cls: 0.0549  mix_decode.d8.loss_mask: 0.3428  mix_decode.d8.loss_dice: 0.4597
2025/03/28 14:50:29 - mmengine - INFO - Iter(train) [17600/20000]  base_lr: 1.4835e-05 lr: 1.4835e-05  eta: 0:37:57  time: 1.0737  data_time: 0.0231  memory: 10776  loss: 26.1057  decode.loss_cls: 0.0041  decode.loss_mask: 0.8002  decode.loss_dice: 0.6899  decode.d0.loss_cls: 0.0579  decode.d0.loss_mask: 0.8094  decode.d0.loss_dice: 0.6715  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.7961  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.8002  decode.d2.loss_dice: 0.6882  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.7953  decode.d3.loss_dice: 0.6862  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.7991  decode.d4.loss_dice: 0.6940  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.7964  decode.d5.loss_dice: 0.6895  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.7999  decode.d6.loss_dice: 0.6930  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.7937  decode.d7.loss_dice: 0.6923  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.7997  decode.d8.loss_dice: 0.6938  mix_decode.loss_cls: 0.0392  mix_decode.loss_mask: 0.4591  mix_decode.loss_dice: 0.6003  mix_decode.d0.loss_cls: 0.0831  mix_decode.d0.loss_mask: 0.4650  mix_decode.d0.loss_dice: 0.5998  mix_decode.d1.loss_cls: 0.0871  mix_decode.d1.loss_mask: 0.4438  mix_decode.d1.loss_dice: 0.5947  mix_decode.d2.loss_cls: 0.0839  mix_decode.d2.loss_mask: 0.4504  mix_decode.d2.loss_dice: 0.5792  mix_decode.d3.loss_cls: 0.0596  mix_decode.d3.loss_mask: 0.4608  mix_decode.d3.loss_dice: 0.5914  mix_decode.d4.loss_cls: 0.0608  mix_decode.d4.loss_mask: 0.4550  mix_decode.d4.loss_dice: 0.5942  mix_decode.d5.loss_cls: 0.0573  mix_decode.d5.loss_mask: 0.4535  mix_decode.d5.loss_dice: 0.5978  mix_decode.d6.loss_cls: 0.0665  mix_decode.d6.loss_mask: 0.4515  mix_decode.d6.loss_dice: 0.5963  mix_decode.d7.loss_cls: 0.0737  mix_decode.d7.loss_mask: 0.4494  mix_decode.d7.loss_dice: 0.5820  mix_decode.d8.loss_cls: 0.0584  mix_decode.d8.loss_mask: 0.4546  mix_decode.d8.loss_dice: 0.5862
2025/03/28 14:51:23 - mmengine - INFO - Iter(train) [17650/20000]  base_lr: 1.4556e-05 lr: 1.4556e-05  eta: 0:37:11  time: 1.0715  data_time: 0.0224  memory: 10775  loss: 27.5797  decode.loss_cls: 0.0213  decode.loss_mask: 0.9306  decode.loss_dice: 0.8804  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.9335  decode.d0.loss_dice: 0.8851  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.9285  decode.d1.loss_dice: 0.8727  decode.d2.loss_cls: 0.0228  decode.d2.loss_mask: 0.9357  decode.d2.loss_dice: 0.8885  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.9277  decode.d3.loss_dice: 0.8759  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.9301  decode.d4.loss_dice: 0.8835  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.9344  decode.d5.loss_dice: 0.8508  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.9278  decode.d6.loss_dice: 0.8742  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.9328  decode.d7.loss_dice: 0.8814  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.9314  decode.d8.loss_dice: 0.8845  mix_decode.loss_cls: 0.0658  mix_decode.loss_mask: 0.3405  mix_decode.loss_dice: 0.5026  mix_decode.d0.loss_cls: 0.0584  mix_decode.d0.loss_mask: 0.3468  mix_decode.d0.loss_dice: 0.5358  mix_decode.d1.loss_cls: 0.0538  mix_decode.d1.loss_mask: 0.3401  mix_decode.d1.loss_dice: 0.5126  mix_decode.d2.loss_cls: 0.0642  mix_decode.d2.loss_mask: 0.3403  mix_decode.d2.loss_dice: 0.5035  mix_decode.d3.loss_cls: 0.0667  mix_decode.d3.loss_mask: 0.3400  mix_decode.d3.loss_dice: 0.4779  mix_decode.d4.loss_cls: 0.0430  mix_decode.d4.loss_mask: 0.3377  mix_decode.d4.loss_dice: 0.5023  mix_decode.d5.loss_cls: 0.0741  mix_decode.d5.loss_mask: 0.3356  mix_decode.d5.loss_dice: 0.4763  mix_decode.d6.loss_cls: 0.0762  mix_decode.d6.loss_mask: 0.3409  mix_decode.d6.loss_dice: 0.4820  mix_decode.d7.loss_cls: 0.0855  mix_decode.d7.loss_mask: 0.3396  mix_decode.d7.loss_dice: 0.4931  mix_decode.d8.loss_cls: 0.0445  mix_decode.d8.loss_mask: 0.3366  mix_decode.d8.loss_dice: 0.5199
2025/03/28 14:52:17 - mmengine - INFO - Iter(train) [17700/20000]  base_lr: 1.4277e-05 lr: 1.4277e-05  eta: 0:36:24  time: 1.0777  data_time: 0.0229  memory: 10770  loss: 27.5558  decode.loss_cls: 0.0094  decode.loss_mask: 0.9102  decode.loss_dice: 0.7214  decode.d0.loss_cls: 0.0856  decode.d0.loss_mask: 0.9098  decode.d0.loss_dice: 0.7406  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.9107  decode.d1.loss_dice: 0.7349  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.9071  decode.d2.loss_dice: 0.7194  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.9158  decode.d3.loss_dice: 0.7278  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.9110  decode.d4.loss_dice: 0.7132  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.9085  decode.d5.loss_dice: 0.7159  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.9067  decode.d6.loss_dice: 0.7180  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.9018  decode.d7.loss_dice: 0.7257  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.9065  decode.d8.loss_dice: 0.7126  mix_decode.loss_cls: 0.1201  mix_decode.loss_mask: 0.4394  mix_decode.loss_dice: 0.5173  mix_decode.d0.loss_cls: 0.1702  mix_decode.d0.loss_mask: 0.4208  mix_decode.d0.loss_dice: 0.5801  mix_decode.d1.loss_cls: 0.1556  mix_decode.d1.loss_mask: 0.4307  mix_decode.d1.loss_dice: 0.5337  mix_decode.d2.loss_cls: 0.1583  mix_decode.d2.loss_mask: 0.4345  mix_decode.d2.loss_dice: 0.5173  mix_decode.d3.loss_cls: 0.1085  mix_decode.d3.loss_mask: 0.4384  mix_decode.d3.loss_dice: 0.5448  mix_decode.d4.loss_cls: 0.1466  mix_decode.d4.loss_mask: 0.4404  mix_decode.d4.loss_dice: 0.5358  mix_decode.d5.loss_cls: 0.1609  mix_decode.d5.loss_mask: 0.4292  mix_decode.d5.loss_dice: 0.5061  mix_decode.d6.loss_cls: 0.1493  mix_decode.d6.loss_mask: 0.4321  mix_decode.d6.loss_dice: 0.5297  mix_decode.d7.loss_cls: 0.1412  mix_decode.d7.loss_mask: 0.4335  mix_decode.d7.loss_dice: 0.5150  mix_decode.d8.loss_cls: 0.0985  mix_decode.d8.loss_mask: 0.4452  mix_decode.d8.loss_dice: 0.5130
2025/03/28 14:53:11 - mmengine - INFO - Iter(train) [17750/20000]  base_lr: 1.3998e-05 lr: 1.3998e-05  eta: 0:35:37  time: 1.0711  data_time: 0.0230  memory: 10779  loss: 26.9926  decode.loss_cls: 0.0060  decode.loss_mask: 0.7667  decode.loss_dice: 0.7082  decode.d0.loss_cls: 0.1161  decode.d0.loss_mask: 0.7819  decode.d0.loss_dice: 0.6963  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.7733  decode.d1.loss_dice: 0.7051  decode.d2.loss_cls: 0.0255  decode.d2.loss_mask: 0.7726  decode.d2.loss_dice: 0.7141  decode.d3.loss_cls: 0.0304  decode.d3.loss_mask: 0.7708  decode.d3.loss_dice: 0.7037  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.7691  decode.d4.loss_dice: 0.7022  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.7714  decode.d5.loss_dice: 0.7012  decode.d6.loss_cls: 0.0313  decode.d6.loss_mask: 0.7696  decode.d6.loss_dice: 0.7013  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.7729  decode.d7.loss_dice: 0.6981  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.7677  decode.d8.loss_dice: 0.7087  mix_decode.loss_cls: 0.0923  mix_decode.loss_mask: 0.4606  mix_decode.loss_dice: 0.6612  mix_decode.d0.loss_cls: 0.0727  mix_decode.d0.loss_mask: 0.4613  mix_decode.d0.loss_dice: 0.6768  mix_decode.d1.loss_cls: 0.0582  mix_decode.d1.loss_mask: 0.4632  mix_decode.d1.loss_dice: 0.6584  mix_decode.d2.loss_cls: 0.0989  mix_decode.d2.loss_mask: 0.4607  mix_decode.d2.loss_dice: 0.6369  mix_decode.d3.loss_cls: 0.0692  mix_decode.d3.loss_mask: 0.4648  mix_decode.d3.loss_dice: 0.6495  mix_decode.d4.loss_cls: 0.0692  mix_decode.d4.loss_mask: 0.4615  mix_decode.d4.loss_dice: 0.6643  mix_decode.d5.loss_cls: 0.0707  mix_decode.d5.loss_mask: 0.4558  mix_decode.d5.loss_dice: 0.6399  mix_decode.d6.loss_cls: 0.0737  mix_decode.d6.loss_mask: 0.4566  mix_decode.d6.loss_dice: 0.6233  mix_decode.d7.loss_cls: 0.0613  mix_decode.d7.loss_mask: 0.4651  mix_decode.d7.loss_dice: 0.6633  mix_decode.d8.loss_cls: 0.0731  mix_decode.d8.loss_mask: 0.4634  mix_decode.d8.loss_dice: 0.6615
2025/03/28 14:54:04 - mmengine - INFO - Iter(train) [17800/20000]  base_lr: 1.3717e-05 lr: 1.3717e-05  eta: 0:34:51  time: 1.0712  data_time: 0.0227  memory: 10772  loss: 26.1058  decode.loss_cls: 0.0089  decode.loss_mask: 0.7061  decode.loss_dice: 0.6523  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.7032  decode.d0.loss_dice: 0.6458  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.7011  decode.d1.loss_dice: 0.6431  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.6988  decode.d2.loss_dice: 0.6441  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.6944  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.6986  decode.d4.loss_dice: 0.6513  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.7013  decode.d5.loss_dice: 0.6552  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.7043  decode.d6.loss_dice: 0.6524  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.7036  decode.d7.loss_dice: 0.6589  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.7010  decode.d8.loss_dice: 0.6460  mix_decode.loss_cls: 0.1323  mix_decode.loss_mask: 0.4343  mix_decode.loss_dice: 0.6512  mix_decode.d0.loss_cls: 0.1127  mix_decode.d0.loss_mask: 0.4540  mix_decode.d0.loss_dice: 0.7053  mix_decode.d1.loss_cls: 0.1856  mix_decode.d1.loss_mask: 0.4444  mix_decode.d1.loss_dice: 0.6520  mix_decode.d2.loss_cls: 0.1828  mix_decode.d2.loss_mask: 0.4332  mix_decode.d2.loss_dice: 0.6397  mix_decode.d3.loss_cls: 0.1707  mix_decode.d3.loss_mask: 0.4337  mix_decode.d3.loss_dice: 0.6093  mix_decode.d4.loss_cls: 0.1712  mix_decode.d4.loss_mask: 0.4439  mix_decode.d4.loss_dice: 0.6335  mix_decode.d5.loss_cls: 0.1719  mix_decode.d5.loss_mask: 0.4333  mix_decode.d5.loss_dice: 0.6357  mix_decode.d6.loss_cls: 0.1849  mix_decode.d6.loss_mask: 0.4327  mix_decode.d6.loss_dice: 0.6104  mix_decode.d7.loss_cls: 0.1500  mix_decode.d7.loss_mask: 0.4380  mix_decode.d7.loss_dice: 0.6394  mix_decode.d8.loss_cls: 0.1678  mix_decode.d8.loss_mask: 0.4364  mix_decode.d8.loss_dice: 0.6297
2025/03/28 14:54:58 - mmengine - INFO - Iter(train) [17850/20000]  base_lr: 1.3437e-05 lr: 1.3437e-05  eta: 0:34:04  time: 1.0807  data_time: 0.0231  memory: 10770  loss: 24.5234  decode.loss_cls: 0.0036  decode.loss_mask: 0.7163  decode.loss_dice: 0.6541  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.7144  decode.d0.loss_dice: 0.6426  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.7119  decode.d1.loss_dice: 0.6584  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.7141  decode.d2.loss_dice: 0.6554  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.7157  decode.d3.loss_dice: 0.6589  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.7177  decode.d4.loss_dice: 0.6555  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.7121  decode.d5.loss_dice: 0.6522  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.7134  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.7128  decode.d7.loss_dice: 0.6479  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.7135  decode.d8.loss_dice: 0.6537  mix_decode.loss_cls: 0.0552  mix_decode.loss_mask: 0.4246  mix_decode.loss_dice: 0.5626  mix_decode.d0.loss_cls: 0.0857  mix_decode.d0.loss_mask: 0.4495  mix_decode.d0.loss_dice: 0.6013  mix_decode.d1.loss_cls: 0.1116  mix_decode.d1.loss_mask: 0.4365  mix_decode.d1.loss_dice: 0.5822  mix_decode.d2.loss_cls: 0.0605  mix_decode.d2.loss_mask: 0.4300  mix_decode.d2.loss_dice: 0.5715  mix_decode.d3.loss_cls: 0.0785  mix_decode.d3.loss_mask: 0.4278  mix_decode.d3.loss_dice: 0.5626  mix_decode.d4.loss_cls: 0.0776  mix_decode.d4.loss_mask: 0.4293  mix_decode.d4.loss_dice: 0.5588  mix_decode.d5.loss_cls: 0.0613  mix_decode.d5.loss_mask: 0.4292  mix_decode.d5.loss_dice: 0.5614  mix_decode.d6.loss_cls: 0.0580  mix_decode.d6.loss_mask: 0.4344  mix_decode.d6.loss_dice: 0.5644  mix_decode.d7.loss_cls: 0.0622  mix_decode.d7.loss_mask: 0.4300  mix_decode.d7.loss_dice: 0.5679  mix_decode.d8.loss_cls: 0.0841  mix_decode.d8.loss_mask: 0.4262  mix_decode.d8.loss_dice: 0.5625
2025/03/28 14:55:52 - mmengine - INFO - Iter(train) [17900/20000]  base_lr: 1.3155e-05 lr: 1.3155e-05  eta: 0:33:17  time: 1.0733  data_time: 0.0231  memory: 10770  loss: 26.9698  decode.loss_cls: 0.0616  decode.loss_mask: 0.7996  decode.loss_dice: 0.7942  decode.d0.loss_cls: 0.1107  decode.d0.loss_mask: 0.8090  decode.d0.loss_dice: 0.8369  decode.d1.loss_cls: 0.0400  decode.d1.loss_mask: 0.7956  decode.d1.loss_dice: 0.8096  decode.d2.loss_cls: 0.0665  decode.d2.loss_mask: 0.7950  decode.d2.loss_dice: 0.7877  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.7991  decode.d3.loss_dice: 0.7850  decode.d4.loss_cls: 0.0257  decode.d4.loss_mask: 0.7991  decode.d4.loss_dice: 0.8122  decode.d5.loss_cls: 0.0240  decode.d5.loss_mask: 0.8024  decode.d5.loss_dice: 0.8155  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.8014  decode.d6.loss_dice: 0.8161  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.8015  decode.d7.loss_dice: 0.7884  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.8028  decode.d8.loss_dice: 0.8265  mix_decode.loss_cls: 0.1002  mix_decode.loss_mask: 0.3760  mix_decode.loss_dice: 0.5610  mix_decode.d0.loss_cls: 0.1622  mix_decode.d0.loss_mask: 0.3887  mix_decode.d0.loss_dice: 0.5615  mix_decode.d1.loss_cls: 0.0872  mix_decode.d1.loss_mask: 0.3738  mix_decode.d1.loss_dice: 0.5388  mix_decode.d2.loss_cls: 0.1233  mix_decode.d2.loss_mask: 0.3716  mix_decode.d2.loss_dice: 0.5514  mix_decode.d3.loss_cls: 0.0753  mix_decode.d3.loss_mask: 0.3770  mix_decode.d3.loss_dice: 0.5438  mix_decode.d4.loss_cls: 0.1109  mix_decode.d4.loss_mask: 0.3780  mix_decode.d4.loss_dice: 0.5669  mix_decode.d5.loss_cls: 0.0809  mix_decode.d5.loss_mask: 0.3835  mix_decode.d5.loss_dice: 0.5600  mix_decode.d6.loss_cls: 0.0893  mix_decode.d6.loss_mask: 0.3863  mix_decode.d6.loss_dice: 0.5602  mix_decode.d7.loss_cls: 0.0829  mix_decode.d7.loss_mask: 0.3841  mix_decode.d7.loss_dice: 0.5639  mix_decode.d8.loss_cls: 0.1045  mix_decode.d8.loss_mask: 0.3829  mix_decode.d8.loss_dice: 0.5474
2025/03/28 14:56:47 - mmengine - INFO - Iter(train) [17950/20000]  base_lr: 1.2873e-05 lr: 1.2873e-05  eta: 0:32:30  time: 1.0878  data_time: 0.0235  memory: 10777  loss: 24.0681  decode.loss_cls: 0.0031  decode.loss_mask: 0.7793  decode.loss_dice: 0.6449  decode.d0.loss_cls: 0.0615  decode.d0.loss_mask: 0.7775  decode.d0.loss_dice: 0.6456  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.7795  decode.d1.loss_dice: 0.6562  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.7792  decode.d2.loss_dice: 0.6468  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.7793  decode.d3.loss_dice: 0.6392  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.7799  decode.d4.loss_dice: 0.6495  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.7745  decode.d5.loss_dice: 0.6430  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.7781  decode.d6.loss_dice: 0.6441  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.7760  decode.d7.loss_dice: 0.6433  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.7757  decode.d8.loss_dice: 0.6468  mix_decode.loss_cls: 0.0498  mix_decode.loss_mask: 0.3878  mix_decode.loss_dice: 0.5295  mix_decode.d0.loss_cls: 0.0646  mix_decode.d0.loss_mask: 0.3839  mix_decode.d0.loss_dice: 0.5430  mix_decode.d1.loss_cls: 0.0469  mix_decode.d1.loss_mask: 0.3862  mix_decode.d1.loss_dice: 0.5375  mix_decode.d2.loss_cls: 0.0555  mix_decode.d2.loss_mask: 0.3849  mix_decode.d2.loss_dice: 0.5273  mix_decode.d3.loss_cls: 0.0567  mix_decode.d3.loss_mask: 0.3842  mix_decode.d3.loss_dice: 0.5239  mix_decode.d4.loss_cls: 0.0725  mix_decode.d4.loss_mask: 0.3814  mix_decode.d4.loss_dice: 0.5226  mix_decode.d5.loss_cls: 0.0516  mix_decode.d5.loss_mask: 0.3864  mix_decode.d5.loss_dice: 0.5287  mix_decode.d6.loss_cls: 0.0713  mix_decode.d6.loss_mask: 0.3898  mix_decode.d6.loss_dice: 0.5240  mix_decode.d7.loss_cls: 0.0710  mix_decode.d7.loss_mask: 0.3841  mix_decode.d7.loss_dice: 0.5229  mix_decode.d8.loss_cls: 0.0490  mix_decode.d8.loss_mask: 0.3844  mix_decode.d8.loss_dice: 0.5315
2025/03/28 14:57:41 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 14:57:41 - mmengine - INFO - Iter(train) [18000/20000]  base_lr: 1.2590e-05 lr: 1.2590e-05  eta: 0:31:43  time: 1.0953  data_time: 0.0240  memory: 10776  loss: 27.0644  decode.loss_cls: 0.0122  decode.loss_mask: 0.8081  decode.loss_dice: 0.6935  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 0.8222  decode.d0.loss_dice: 0.7062  decode.d1.loss_cls: 0.0240  decode.d1.loss_mask: 0.8114  decode.d1.loss_dice: 0.6937  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.8113  decode.d2.loss_dice: 0.6890  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.8114  decode.d3.loss_dice: 0.6917  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.8073  decode.d4.loss_dice: 0.6870  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.8138  decode.d5.loss_dice: 0.6973  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.8054  decode.d6.loss_dice: 0.6880  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.8080  decode.d7.loss_dice: 0.6949  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.8072  decode.d8.loss_dice: 0.6965  mix_decode.loss_cls: 0.0778  mix_decode.loss_mask: 0.4224  mix_decode.loss_dice: 0.6563  mix_decode.d0.loss_cls: 0.1038  mix_decode.d0.loss_mask: 0.4184  mix_decode.d0.loss_dice: 0.6879  mix_decode.d1.loss_cls: 0.1170  mix_decode.d1.loss_mask: 0.4184  mix_decode.d1.loss_dice: 0.6391  mix_decode.d2.loss_cls: 0.1396  mix_decode.d2.loss_mask: 0.4187  mix_decode.d2.loss_dice: 0.6371  mix_decode.d3.loss_cls: 0.1344  mix_decode.d3.loss_mask: 0.4226  mix_decode.d3.loss_dice: 0.6431  mix_decode.d4.loss_cls: 0.1339  mix_decode.d4.loss_mask: 0.4165  mix_decode.d4.loss_dice: 0.6383  mix_decode.d5.loss_cls: 0.1224  mix_decode.d5.loss_mask: 0.4170  mix_decode.d5.loss_dice: 0.6265  mix_decode.d6.loss_cls: 0.1117  mix_decode.d6.loss_mask: 0.4179  mix_decode.d6.loss_dice: 0.6368  mix_decode.d7.loss_cls: 0.1342  mix_decode.d7.loss_mask: 0.4170  mix_decode.d7.loss_dice: 0.6270  mix_decode.d8.loss_cls: 0.1559  mix_decode.d8.loss_mask: 0.4192  mix_decode.d8.loss_dice: 0.6196
2025/03/28 14:57:41 - mmengine - INFO - Saving checkpoint at 18000 iterations
2025/03/28 14:57:47 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:50  time: 0.0876  data_time: 0.0019  memory: 3068  
2025/03/28 14:57:51 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:45  time: 0.0852  data_time: 0.0019  memory: 3068  
2025/03/28 14:57:55 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:40  time: 0.0862  data_time: 0.0020  memory: 3068  
2025/03/28 14:58:00 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:36  time: 0.0849  data_time: 0.0018  memory: 3068  
2025/03/28 14:58:04 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:31  time: 0.0849  data_time: 0.0018  memory: 3068  
2025/03/28 14:58:08 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:26  time: 0.0849  data_time: 0.0019  memory: 3068  
2025/03/28 14:58:12 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:22  time: 0.0850  data_time: 0.0017  memory: 3068  
2025/03/28 14:58:17 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:18  time: 0.0851  data_time: 0.0017  memory: 3068  
2025/03/28 14:58:21 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0869  data_time: 0.0023  memory: 3068  
2025/03/28 14:58:25 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:09  time: 0.0849  data_time: 0.0019  memory: 3068  
2025/03/28 14:58:29 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:05  time: 0.0849  data_time: 0.0019  memory: 3068  
2025/03/28 14:58:34 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:00  time: 0.0850  data_time: 0.0018  memory: 3068  
2025/03/28 14:58:38 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:58:42 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:52  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:58:47 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:48  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:58:51 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:43  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:58:55 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 14:58:59 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:35  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:04 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:30  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 14:59:08 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:12 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:16 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:18  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:21 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:13  time: 0.0853  data_time: 0.0019  memory: 3068  
2025/03/28 14:59:25 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:29 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0887  data_time: 0.0021  memory: 3068  
2025/03/28 14:59:34 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:01  time: 0.0856  data_time: 0.0019  memory: 3068  
2025/03/28 14:59:38 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0853  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:42 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0854  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:46 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0856  data_time: 0.0019  memory: 3068  
2025/03/28 14:59:51 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:44  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 14:59:55 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0852  data_time: 0.0018  memory: 3068  
2025/03/28 14:59:59 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0870  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:04 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0863  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:08 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:27  time: 0.0861  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:12 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:17 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0854  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:21 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0855  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:25 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0855  data_time: 0.0018  memory: 3068  
2025/03/28 15:00:29 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0855  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:34 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0857  data_time: 0.0019  memory: 3068  
2025/03/28 15:00:35 - mmengine - INFO - per class results:
2025/03/28 15:00:35 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 74.25 | 89.04 |
|      building      | 84.97 | 95.58 |
|   low_vegetation   | 61.23 | 91.46 |
|        tree        | 40.87 | 42.27 |
|        car         |  75.4 | 88.53 |
|      clutter       |  7.25 |  7.49 |
+--------------------+-------+-------+
2025/03/28 15:00:35 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 79.3100  mIoU: 57.3300  mAcc: 69.0600  data_time: 0.0019  time: 0.0855
2025/03/28 15:01:29 - mmengine - INFO - Iter(train) [18050/20000]  base_lr: 1.2306e-05 lr: 1.2306e-05  eta: 0:30:57  time: 1.0799  data_time: 0.0225  memory: 10772  loss: 25.5571  decode.loss_cls: 0.0033  decode.loss_mask: 0.6994  decode.loss_dice: 0.6744  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.6975  decode.d0.loss_dice: 0.6737  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.6991  decode.d1.loss_dice: 0.6896  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.7034  decode.d2.loss_dice: 0.6838  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.6921  decode.d3.loss_dice: 0.6779  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.6937  decode.d4.loss_dice: 0.6905  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.6974  decode.d5.loss_dice: 0.6842  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.6942  decode.d6.loss_dice: 0.6725  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.6985  decode.d7.loss_dice: 0.6805  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.6954  decode.d8.loss_dice: 0.6749  mix_decode.loss_cls: 0.1203  mix_decode.loss_mask: 0.4206  mix_decode.loss_dice: 0.6192  mix_decode.d0.loss_cls: 0.2033  mix_decode.d0.loss_mask: 0.4369  mix_decode.d0.loss_dice: 0.6340  mix_decode.d1.loss_cls: 0.1180  mix_decode.d1.loss_mask: 0.4246  mix_decode.d1.loss_dice: 0.6476  mix_decode.d2.loss_cls: 0.0946  mix_decode.d2.loss_mask: 0.4203  mix_decode.d2.loss_dice: 0.6112  mix_decode.d3.loss_cls: 0.1192  mix_decode.d3.loss_mask: 0.4255  mix_decode.d3.loss_dice: 0.6173  mix_decode.d4.loss_cls: 0.1007  mix_decode.d4.loss_mask: 0.4234  mix_decode.d4.loss_dice: 0.6189  mix_decode.d5.loss_cls: 0.1180  mix_decode.d5.loss_mask: 0.4207  mix_decode.d5.loss_dice: 0.6005  mix_decode.d6.loss_cls: 0.1422  mix_decode.d6.loss_mask: 0.4268  mix_decode.d6.loss_dice: 0.6184  mix_decode.d7.loss_cls: 0.1060  mix_decode.d7.loss_mask: 0.4250  mix_decode.d7.loss_dice: 0.6180  mix_decode.d8.loss_cls: 0.1140  mix_decode.d8.loss_mask: 0.4168  mix_decode.d8.loss_dice: 0.6200
2025/03/28 15:02:23 - mmengine - INFO - Iter(train) [18100/20000]  base_lr: 1.2022e-05 lr: 1.2022e-05  eta: 0:30:10  time: 1.0790  data_time: 0.0235  memory: 10767  loss: 25.1308  decode.loss_cls: 0.0080  decode.loss_mask: 0.8388  decode.loss_dice: 0.7117  decode.d0.loss_cls: 0.0912  decode.d0.loss_mask: 0.8497  decode.d0.loss_dice: 0.7051  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.8402  decode.d1.loss_dice: 0.7069  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.8369  decode.d2.loss_dice: 0.7090  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.8324  decode.d3.loss_dice: 0.7125  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.8395  decode.d4.loss_dice: 0.7152  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.8337  decode.d5.loss_dice: 0.7098  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.8394  decode.d6.loss_dice: 0.7102  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.8355  decode.d7.loss_dice: 0.7073  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.8376  decode.d8.loss_dice: 0.7145  mix_decode.loss_cls: 0.0466  mix_decode.loss_mask: 0.3608  mix_decode.loss_dice: 0.5242  mix_decode.d0.loss_cls: 0.1190  mix_decode.d0.loss_mask: 0.3611  mix_decode.d0.loss_dice: 0.5410  mix_decode.d1.loss_cls: 0.0810  mix_decode.d1.loss_mask: 0.3588  mix_decode.d1.loss_dice: 0.5236  mix_decode.d2.loss_cls: 0.0442  mix_decode.d2.loss_mask: 0.3551  mix_decode.d2.loss_dice: 0.5283  mix_decode.d3.loss_cls: 0.0744  mix_decode.d3.loss_mask: 0.3555  mix_decode.d3.loss_dice: 0.5209  mix_decode.d4.loss_cls: 0.0604  mix_decode.d4.loss_mask: 0.3529  mix_decode.d4.loss_dice: 0.5185  mix_decode.d5.loss_cls: 0.0666  mix_decode.d5.loss_mask: 0.3529  mix_decode.d5.loss_dice: 0.5216  mix_decode.d6.loss_cls: 0.0513  mix_decode.d6.loss_mask: 0.3566  mix_decode.d6.loss_dice: 0.5245  mix_decode.d7.loss_cls: 0.0701  mix_decode.d7.loss_mask: 0.3520  mix_decode.d7.loss_dice: 0.5041  mix_decode.d8.loss_cls: 0.0696  mix_decode.d8.loss_mask: 0.3574  mix_decode.d8.loss_dice: 0.5136
2025/03/28 15:03:17 - mmengine - INFO - Iter(train) [18150/20000]  base_lr: 1.1737e-05 lr: 1.1737e-05  eta: 0:29:23  time: 1.0780  data_time: 0.0226  memory: 10772  loss: 24.9439  decode.loss_cls: 0.0134  decode.loss_mask: 0.6941  decode.loss_dice: 0.7313  decode.d0.loss_cls: 0.0593  decode.d0.loss_mask: 0.7047  decode.d0.loss_dice: 0.7203  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.7003  decode.d1.loss_dice: 0.7340  decode.d2.loss_cls: 0.0180  decode.d2.loss_mask: 0.6954  decode.d2.loss_dice: 0.7286  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.6969  decode.d3.loss_dice: 0.7396  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.6990  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.6908  decode.d5.loss_dice: 0.7382  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.6955  decode.d6.loss_dice: 0.7316  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.6951  decode.d7.loss_dice: 0.7323  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.6904  decode.d8.loss_dice: 0.7285  mix_decode.loss_cls: 0.0687  mix_decode.loss_mask: 0.4256  mix_decode.loss_dice: 0.5579  mix_decode.d0.loss_cls: 0.0869  mix_decode.d0.loss_mask: 0.4278  mix_decode.d0.loss_dice: 0.5843  mix_decode.d1.loss_cls: 0.0631  mix_decode.d1.loss_mask: 0.4314  mix_decode.d1.loss_dice: 0.5558  mix_decode.d2.loss_cls: 0.0735  mix_decode.d2.loss_mask: 0.4183  mix_decode.d2.loss_dice: 0.5405  mix_decode.d3.loss_cls: 0.0890  mix_decode.d3.loss_mask: 0.4185  mix_decode.d3.loss_dice: 0.5301  mix_decode.d4.loss_cls: 0.1119  mix_decode.d4.loss_mask: 0.4092  mix_decode.d4.loss_dice: 0.5290  mix_decode.d5.loss_cls: 0.0809  mix_decode.d5.loss_mask: 0.4071  mix_decode.d5.loss_dice: 0.5305  mix_decode.d6.loss_cls: 0.0876  mix_decode.d6.loss_mask: 0.4155  mix_decode.d6.loss_dice: 0.5310  mix_decode.d7.loss_cls: 0.0751  mix_decode.d7.loss_mask: 0.4136  mix_decode.d7.loss_dice: 0.5485  mix_decode.d8.loss_cls: 0.0640  mix_decode.d8.loss_mask: 0.4261  mix_decode.d8.loss_dice: 0.5590
2025/03/28 15:04:11 - mmengine - INFO - Iter(train) [18200/20000]  base_lr: 1.1451e-05 lr: 1.1451e-05  eta: 0:28:36  time: 1.0816  data_time: 0.0233  memory: 10775  loss: 27.6649  decode.loss_cls: 0.0123  decode.loss_mask: 0.7880  decode.loss_dice: 0.7632  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.7947  decode.d0.loss_dice: 0.7803  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.7886  decode.d1.loss_dice: 0.7746  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.7856  decode.d2.loss_dice: 0.7620  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.7863  decode.d3.loss_dice: 0.7662  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.7827  decode.d4.loss_dice: 0.7537  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.7837  decode.d5.loss_dice: 0.7594  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.7901  decode.d6.loss_dice: 0.7662  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.7865  decode.d7.loss_dice: 0.7649  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.7853  decode.d8.loss_dice: 0.7685  mix_decode.loss_cls: 0.0873  mix_decode.loss_mask: 0.5137  mix_decode.loss_dice: 0.5959  mix_decode.d0.loss_cls: 0.0856  mix_decode.d0.loss_mask: 0.5194  mix_decode.d0.loss_dice: 0.6032  mix_decode.d1.loss_cls: 0.0801  mix_decode.d1.loss_mask: 0.5136  mix_decode.d1.loss_dice: 0.5947  mix_decode.d2.loss_cls: 0.0864  mix_decode.d2.loss_mask: 0.5093  mix_decode.d2.loss_dice: 0.5983  mix_decode.d3.loss_cls: 0.1018  mix_decode.d3.loss_mask: 0.5034  mix_decode.d3.loss_dice: 0.5652  mix_decode.d4.loss_cls: 0.0896  mix_decode.d4.loss_mask: 0.5082  mix_decode.d4.loss_dice: 0.5912  mix_decode.d5.loss_cls: 0.1017  mix_decode.d5.loss_mask: 0.5109  mix_decode.d5.loss_dice: 0.5840  mix_decode.d6.loss_cls: 0.0755  mix_decode.d6.loss_mask: 0.5123  mix_decode.d6.loss_dice: 0.6081  mix_decode.d7.loss_cls: 0.1010  mix_decode.d7.loss_mask: 0.5078  mix_decode.d7.loss_dice: 0.5679  mix_decode.d8.loss_cls: 0.0672  mix_decode.d8.loss_mask: 0.5140  mix_decode.d8.loss_dice: 0.5973
2025/03/28 15:05:05 - mmengine - INFO - Iter(train) [18250/20000]  base_lr: 1.1164e-05 lr: 1.1164e-05  eta: 0:27:49  time: 1.0838  data_time: 0.0238  memory: 10785  loss: 25.4500  decode.loss_cls: 0.0306  decode.loss_mask: 0.7540  decode.loss_dice: 0.6805  decode.d0.loss_cls: 0.1061  decode.d0.loss_mask: 0.7539  decode.d0.loss_dice: 0.7221  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.7559  decode.d1.loss_dice: 0.6756  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.7501  decode.d2.loss_dice: 0.6938  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.7462  decode.d3.loss_dice: 0.6611  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.7513  decode.d4.loss_dice: 0.6613  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.7563  decode.d5.loss_dice: 0.6731  decode.d6.loss_cls: 0.0263  decode.d6.loss_mask: 0.7553  decode.d6.loss_dice: 0.6582  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.7599  decode.d7.loss_dice: 0.6951  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.7567  decode.d8.loss_dice: 0.6560  mix_decode.loss_cls: 0.0894  mix_decode.loss_mask: 0.4522  mix_decode.loss_dice: 0.5236  mix_decode.d0.loss_cls: 0.1208  mix_decode.d0.loss_mask: 0.4213  mix_decode.d0.loss_dice: 0.5505  mix_decode.d1.loss_cls: 0.1600  mix_decode.d1.loss_mask: 0.4210  mix_decode.d1.loss_dice: 0.5122  mix_decode.d2.loss_cls: 0.1409  mix_decode.d2.loss_mask: 0.4322  mix_decode.d2.loss_dice: 0.5172  mix_decode.d3.loss_cls: 0.1050  mix_decode.d3.loss_mask: 0.4356  mix_decode.d3.loss_dice: 0.5222  mix_decode.d4.loss_cls: 0.1192  mix_decode.d4.loss_mask: 0.4308  mix_decode.d4.loss_dice: 0.5149  mix_decode.d5.loss_cls: 0.0738  mix_decode.d5.loss_mask: 0.4477  mix_decode.d5.loss_dice: 0.5297  mix_decode.d6.loss_cls: 0.1051  mix_decode.d6.loss_mask: 0.4407  mix_decode.d6.loss_dice: 0.5247  mix_decode.d7.loss_cls: 0.1199  mix_decode.d7.loss_mask: 0.4526  mix_decode.d7.loss_dice: 0.5384  mix_decode.d8.loss_cls: 0.0553  mix_decode.d8.loss_mask: 0.4584  mix_decode.d8.loss_dice: 0.5436
2025/03/28 15:06:00 - mmengine - INFO - Iter(train) [18300/20000]  base_lr: 1.0877e-05 lr: 1.0877e-05  eta: 0:27:01  time: 1.0795  data_time: 0.0229  memory: 10773  loss: 25.5256  decode.loss_cls: 0.0108  decode.loss_mask: 0.6951  decode.loss_dice: 0.6753  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 0.7090  decode.d0.loss_dice: 0.7054  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.6967  decode.d1.loss_dice: 0.6810  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.6966  decode.d2.loss_dice: 0.6853  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.6959  decode.d3.loss_dice: 0.6778  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.6958  decode.d4.loss_dice: 0.6823  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.6966  decode.d5.loss_dice: 0.6679  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.6961  decode.d6.loss_dice: 0.6747  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.6992  decode.d7.loss_dice: 0.6733  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.6997  decode.d8.loss_dice: 0.6809  mix_decode.loss_cls: 0.0614  mix_decode.loss_mask: 0.4658  mix_decode.loss_dice: 0.6015  mix_decode.d0.loss_cls: 0.0761  mix_decode.d0.loss_mask: 0.4846  mix_decode.d0.loss_dice: 0.6221  mix_decode.d1.loss_cls: 0.0955  mix_decode.d1.loss_mask: 0.4782  mix_decode.d1.loss_dice: 0.6135  mix_decode.d2.loss_cls: 0.0720  mix_decode.d2.loss_mask: 0.4803  mix_decode.d2.loss_dice: 0.5970  mix_decode.d3.loss_cls: 0.0562  mix_decode.d3.loss_mask: 0.4754  mix_decode.d3.loss_dice: 0.5998  mix_decode.d4.loss_cls: 0.0387  mix_decode.d4.loss_mask: 0.4776  mix_decode.d4.loss_dice: 0.6094  mix_decode.d5.loss_cls: 0.0610  mix_decode.d5.loss_mask: 0.4727  mix_decode.d5.loss_dice: 0.6004  mix_decode.d6.loss_cls: 0.0786  mix_decode.d6.loss_mask: 0.4835  mix_decode.d6.loss_dice: 0.6104  mix_decode.d7.loss_cls: 0.0683  mix_decode.d7.loss_mask: 0.4768  mix_decode.d7.loss_dice: 0.5943  mix_decode.d8.loss_cls: 0.0631  mix_decode.d8.loss_mask: 0.4745  mix_decode.d8.loss_dice: 0.5968
2025/03/28 15:06:54 - mmengine - INFO - Iter(train) [18350/20000]  base_lr: 1.0588e-05 lr: 1.0588e-05  eta: 0:26:14  time: 1.0775  data_time: 0.0224  memory: 10777  loss: 28.8374  decode.loss_cls: 0.0085  decode.loss_mask: 0.8186  decode.loss_dice: 0.7380  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.8271  decode.d0.loss_dice: 0.7464  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.8238  decode.d1.loss_dice: 0.7414  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.8202  decode.d2.loss_dice: 0.7431  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.8196  decode.d3.loss_dice: 0.7467  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.8199  decode.d4.loss_dice: 0.7244  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.8204  decode.d5.loss_dice: 0.7320  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.8240  decode.d6.loss_dice: 0.7421  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.8208  decode.d7.loss_dice: 0.7400  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.8180  decode.d8.loss_dice: 0.7423  mix_decode.loss_cls: 0.1170  mix_decode.loss_mask: 0.5513  mix_decode.loss_dice: 0.6398  mix_decode.d0.loss_cls: 0.1712  mix_decode.d0.loss_mask: 0.5497  mix_decode.d0.loss_dice: 0.6453  mix_decode.d1.loss_cls: 0.1042  mix_decode.d1.loss_mask: 0.5455  mix_decode.d1.loss_dice: 0.6480  mix_decode.d2.loss_cls: 0.0821  mix_decode.d2.loss_mask: 0.5600  mix_decode.d2.loss_dice: 0.6586  mix_decode.d3.loss_cls: 0.1190  mix_decode.d3.loss_mask: 0.5482  mix_decode.d3.loss_dice: 0.6327  mix_decode.d4.loss_cls: 0.0906  mix_decode.d4.loss_mask: 0.5497  mix_decode.d4.loss_dice: 0.6291  mix_decode.d5.loss_cls: 0.0982  mix_decode.d5.loss_mask: 0.5544  mix_decode.d5.loss_dice: 0.6382  mix_decode.d6.loss_cls: 0.1240  mix_decode.d6.loss_mask: 0.5538  mix_decode.d6.loss_dice: 0.6417  mix_decode.d7.loss_cls: 0.1145  mix_decode.d7.loss_mask: 0.5406  mix_decode.d7.loss_dice: 0.6306  mix_decode.d8.loss_cls: 0.1486  mix_decode.d8.loss_mask: 0.5434  mix_decode.d8.loss_dice: 0.6160
2025/03/28 15:07:49 - mmengine - INFO - Iter(train) [18400/20000]  base_lr: 1.0299e-05 lr: 1.0299e-05  eta: 0:25:27  time: 1.1298  data_time: 0.0284  memory: 10774  loss: 27.4130  decode.loss_cls: 0.0547  decode.loss_mask: 0.8266  decode.loss_dice: 0.7146  decode.d0.loss_cls: 0.1069  decode.d0.loss_mask: 0.8260  decode.d0.loss_dice: 0.7285  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.8246  decode.d1.loss_dice: 0.7288  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.8287  decode.d2.loss_dice: 0.7323  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.8256  decode.d3.loss_dice: 0.7239  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.8244  decode.d4.loss_dice: 0.7328  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.8265  decode.d5.loss_dice: 0.7341  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.8219  decode.d6.loss_dice: 0.7171  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.8276  decode.d7.loss_dice: 0.7406  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.8236  decode.d8.loss_dice: 0.7373  mix_decode.loss_cls: 0.1674  mix_decode.loss_mask: 0.4324  mix_decode.loss_dice: 0.5413  mix_decode.d0.loss_cls: 0.1779  mix_decode.d0.loss_mask: 0.4459  mix_decode.d0.loss_dice: 0.5949  mix_decode.d1.loss_cls: 0.1254  mix_decode.d1.loss_mask: 0.4342  mix_decode.d1.loss_dice: 0.5427  mix_decode.d2.loss_cls: 0.1410  mix_decode.d2.loss_mask: 0.4299  mix_decode.d2.loss_dice: 0.5428  mix_decode.d3.loss_cls: 0.1264  mix_decode.d3.loss_mask: 0.4347  mix_decode.d3.loss_dice: 0.5425  mix_decode.d4.loss_cls: 0.1086  mix_decode.d4.loss_mask: 0.4322  mix_decode.d4.loss_dice: 0.5699  mix_decode.d5.loss_cls: 0.1361  mix_decode.d5.loss_mask: 0.4299  mix_decode.d5.loss_dice: 0.5681  mix_decode.d6.loss_cls: 0.1896  mix_decode.d6.loss_mask: 0.4309  mix_decode.d6.loss_dice: 0.5483  mix_decode.d7.loss_cls: 0.1495  mix_decode.d7.loss_mask: 0.4325  mix_decode.d7.loss_dice: 0.5594  mix_decode.d8.loss_cls: 0.1409  mix_decode.d8.loss_mask: 0.4335  mix_decode.d8.loss_dice: 0.5401
2025/03/28 15:08:44 - mmengine - INFO - Iter(train) [18450/20000]  base_lr: 1.0009e-05 lr: 1.0009e-05  eta: 0:24:40  time: 1.0752  data_time: 0.0228  memory: 10775  loss: 24.7209  decode.loss_cls: 0.0146  decode.loss_mask: 0.7644  decode.loss_dice: 0.7270  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.7749  decode.d0.loss_dice: 0.7386  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.7632  decode.d1.loss_dice: 0.7266  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.7627  decode.d2.loss_dice: 0.7295  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.7636  decode.d3.loss_dice: 0.7157  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.7640  decode.d4.loss_dice: 0.7155  decode.d5.loss_cls: 0.0128  decode.d5.loss_mask: 0.7707  decode.d5.loss_dice: 0.7241  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.7630  decode.d6.loss_dice: 0.7240  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.7624  decode.d7.loss_dice: 0.7249  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.7671  decode.d8.loss_dice: 0.7169  mix_decode.loss_cls: 0.0875  mix_decode.loss_mask: 0.3656  mix_decode.loss_dice: 0.4771  mix_decode.d0.loss_cls: 0.0756  mix_decode.d0.loss_mask: 0.3752  mix_decode.d0.loss_dice: 0.5371  mix_decode.d1.loss_cls: 0.0659  mix_decode.d1.loss_mask: 0.3675  mix_decode.d1.loss_dice: 0.5043  mix_decode.d2.loss_cls: 0.0962  mix_decode.d2.loss_mask: 0.3697  mix_decode.d2.loss_dice: 0.5008  mix_decode.d3.loss_cls: 0.1115  mix_decode.d3.loss_mask: 0.3691  mix_decode.d3.loss_dice: 0.4986  mix_decode.d4.loss_cls: 0.1035  mix_decode.d4.loss_mask: 0.3672  mix_decode.d4.loss_dice: 0.4788  mix_decode.d5.loss_cls: 0.0565  mix_decode.d5.loss_mask: 0.3674  mix_decode.d5.loss_dice: 0.5023  mix_decode.d6.loss_cls: 0.0669  mix_decode.d6.loss_mask: 0.3669  mix_decode.d6.loss_dice: 0.4996  mix_decode.d7.loss_cls: 0.0786  mix_decode.d7.loss_mask: 0.3666  mix_decode.d7.loss_dice: 0.5042  mix_decode.d8.loss_cls: 0.0836  mix_decode.d8.loss_mask: 0.3665  mix_decode.d8.loss_dice: 0.4910
2025/03/28 15:09:38 - mmengine - INFO - Iter(train) [18500/20000]  base_lr: 9.7180e-06 lr: 9.7180e-06  eta: 0:23:53  time: 1.1036  data_time: 0.0253  memory: 10778  loss: 23.1809  decode.loss_cls: 0.0585  decode.loss_mask: 0.6188  decode.loss_dice: 0.6922  decode.d0.loss_cls: 0.1350  decode.d0.loss_mask: 0.6307  decode.d0.loss_dice: 0.6956  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.6269  decode.d1.loss_dice: 0.6945  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.6207  decode.d2.loss_dice: 0.6826  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.6146  decode.d3.loss_dice: 0.6864  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.6234  decode.d4.loss_dice: 0.6971  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.6222  decode.d5.loss_dice: 0.6873  decode.d6.loss_cls: 0.0499  decode.d6.loss_mask: 0.6200  decode.d6.loss_dice: 0.6596  decode.d7.loss_cls: 0.0313  decode.d7.loss_mask: 0.6196  decode.d7.loss_dice: 0.6991  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.6171  decode.d8.loss_dice: 0.6759  mix_decode.loss_cls: 0.0506  mix_decode.loss_mask: 0.3890  mix_decode.loss_dice: 0.5044  mix_decode.d0.loss_cls: 0.1133  mix_decode.d0.loss_mask: 0.3924  mix_decode.d0.loss_dice: 0.5109  mix_decode.d1.loss_cls: 0.0953  mix_decode.d1.loss_mask: 0.3898  mix_decode.d1.loss_dice: 0.4998  mix_decode.d2.loss_cls: 0.0829  mix_decode.d2.loss_mask: 0.3881  mix_decode.d2.loss_dice: 0.5034  mix_decode.d3.loss_cls: 0.0799  mix_decode.d3.loss_mask: 0.3835  mix_decode.d3.loss_dice: 0.4981  mix_decode.d4.loss_cls: 0.0495  mix_decode.d4.loss_mask: 0.3884  mix_decode.d4.loss_dice: 0.5152  mix_decode.d5.loss_cls: 0.0777  mix_decode.d5.loss_mask: 0.3802  mix_decode.d5.loss_dice: 0.5077  mix_decode.d6.loss_cls: 0.1094  mix_decode.d6.loss_mask: 0.3841  mix_decode.d6.loss_dice: 0.4855  mix_decode.d7.loss_cls: 0.0570  mix_decode.d7.loss_mask: 0.3864  mix_decode.d7.loss_dice: 0.5083  mix_decode.d8.loss_cls: 0.0465  mix_decode.d8.loss_mask: 0.3869  mix_decode.d8.loss_dice: 0.5135
2025/03/28 15:10:32 - mmengine - INFO - Iter(train) [18550/20000]  base_lr: 9.4259e-06 lr: 9.4259e-06  eta: 0:23:06  time: 1.0821  data_time: 0.0229  memory: 10769  loss: 25.6265  decode.loss_cls: 0.0116  decode.loss_mask: 0.6990  decode.loss_dice: 0.7293  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.7079  decode.d0.loss_dice: 0.7398  decode.d1.loss_cls: 0.0224  decode.d1.loss_mask: 0.7053  decode.d1.loss_dice: 0.7382  decode.d2.loss_cls: 0.0470  decode.d2.loss_mask: 0.7085  decode.d2.loss_dice: 0.7410  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.7030  decode.d3.loss_dice: 0.7393  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.7014  decode.d4.loss_dice: 0.7307  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.7031  decode.d5.loss_dice: 0.7320  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.7082  decode.d6.loss_dice: 0.7312  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.7049  decode.d7.loss_dice: 0.7330  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.7019  decode.d8.loss_dice: 0.7318  mix_decode.loss_cls: 0.1057  mix_decode.loss_mask: 0.4397  mix_decode.loss_dice: 0.5391  mix_decode.d0.loss_cls: 0.0903  mix_decode.d0.loss_mask: 0.4691  mix_decode.d0.loss_dice: 0.6048  mix_decode.d1.loss_cls: 0.1511  mix_decode.d1.loss_mask: 0.4441  mix_decode.d1.loss_dice: 0.5374  mix_decode.d2.loss_cls: 0.1284  mix_decode.d2.loss_mask: 0.4406  mix_decode.d2.loss_dice: 0.5417  mix_decode.d3.loss_cls: 0.1037  mix_decode.d3.loss_mask: 0.4336  mix_decode.d3.loss_dice: 0.5302  mix_decode.d4.loss_cls: 0.1001  mix_decode.d4.loss_mask: 0.4378  mix_decode.d4.loss_dice: 0.5500  mix_decode.d5.loss_cls: 0.0977  mix_decode.d5.loss_mask: 0.4374  mix_decode.d5.loss_dice: 0.5561  mix_decode.d6.loss_cls: 0.0914  mix_decode.d6.loss_mask: 0.4363  mix_decode.d6.loss_dice: 0.5418  mix_decode.d7.loss_cls: 0.1035  mix_decode.d7.loss_mask: 0.4416  mix_decode.d7.loss_dice: 0.5567  mix_decode.d8.loss_cls: 0.0877  mix_decode.d8.loss_mask: 0.4350  mix_decode.d8.loss_dice: 0.5485
2025/03/28 15:11:26 - mmengine - INFO - Iter(train) [18600/20000]  base_lr: 9.1329e-06 lr: 9.1329e-06  eta: 0:22:18  time: 1.0799  data_time: 0.0238  memory: 10779  loss: 25.2448  decode.loss_cls: 0.0181  decode.loss_mask: 0.7282  decode.loss_dice: 0.6361  decode.d0.loss_cls: 0.0885  decode.d0.loss_mask: 0.7315  decode.d0.loss_dice: 0.6455  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.7281  decode.d1.loss_dice: 0.6332  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.7280  decode.d2.loss_dice: 0.6378  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.7287  decode.d3.loss_dice: 0.6335  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.7221  decode.d4.loss_dice: 0.6198  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.7282  decode.d5.loss_dice: 0.6485  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.7260  decode.d6.loss_dice: 0.6281  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.7270  decode.d7.loss_dice: 0.6344  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.7279  decode.d8.loss_dice: 0.6297  mix_decode.loss_cls: 0.1089  mix_decode.loss_mask: 0.3883  mix_decode.loss_dice: 0.6259  mix_decode.d0.loss_cls: 0.1103  mix_decode.d0.loss_mask: 0.3942  mix_decode.d0.loss_dice: 0.6588  mix_decode.d1.loss_cls: 0.1248  mix_decode.d1.loss_mask: 0.3859  mix_decode.d1.loss_dice: 0.6176  mix_decode.d2.loss_cls: 0.1404  mix_decode.d2.loss_mask: 0.3913  mix_decode.d2.loss_dice: 0.6097  mix_decode.d3.loss_cls: 0.1378  mix_decode.d3.loss_mask: 0.3854  mix_decode.d3.loss_dice: 0.6082  mix_decode.d4.loss_cls: 0.1389  mix_decode.d4.loss_mask: 0.3856  mix_decode.d4.loss_dice: 0.6114  mix_decode.d5.loss_cls: 0.1268  mix_decode.d5.loss_mask: 0.3845  mix_decode.d5.loss_dice: 0.6187  mix_decode.d6.loss_cls: 0.1413  mix_decode.d6.loss_mask: 0.3866  mix_decode.d6.loss_dice: 0.6232  mix_decode.d7.loss_cls: 0.1341  mix_decode.d7.loss_mask: 0.3833  mix_decode.d7.loss_dice: 0.6118  mix_decode.d8.loss_cls: 0.1284  mix_decode.d8.loss_mask: 0.3878  mix_decode.d8.loss_dice: 0.6377
2025/03/28 15:12:20 - mmengine - INFO - Iter(train) [18650/20000]  base_lr: 8.8388e-06 lr: 8.8388e-06  eta: 0:21:31  time: 1.0780  data_time: 0.0226  memory: 10771  loss: 27.0520  decode.loss_cls: 0.0114  decode.loss_mask: 0.8490  decode.loss_dice: 0.7691  decode.d0.loss_cls: 0.1176  decode.d0.loss_mask: 0.8530  decode.d0.loss_dice: 0.7716  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.8451  decode.d1.loss_dice: 0.7681  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.8443  decode.d2.loss_dice: 0.7602  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.8455  decode.d3.loss_dice: 0.7654  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.8406  decode.d4.loss_dice: 0.7709  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.8450  decode.d5.loss_dice: 0.7587  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.8486  decode.d6.loss_dice: 0.7691  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.8425  decode.d7.loss_dice: 0.7766  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.8411  decode.d8.loss_dice: 0.7695  mix_decode.loss_cls: 0.1037  mix_decode.loss_mask: 0.4159  mix_decode.loss_dice: 0.5346  mix_decode.d0.loss_cls: 0.1583  mix_decode.d0.loss_mask: 0.4274  mix_decode.d0.loss_dice: 0.5659  mix_decode.d1.loss_cls: 0.1485  mix_decode.d1.loss_mask: 0.4143  mix_decode.d1.loss_dice: 0.5359  mix_decode.d2.loss_cls: 0.1098  mix_decode.d2.loss_mask: 0.4310  mix_decode.d2.loss_dice: 0.5439  mix_decode.d3.loss_cls: 0.0920  mix_decode.d3.loss_mask: 0.4163  mix_decode.d3.loss_dice: 0.5293  mix_decode.d4.loss_cls: 0.0861  mix_decode.d4.loss_mask: 0.4120  mix_decode.d4.loss_dice: 0.5329  mix_decode.d5.loss_cls: 0.0996  mix_decode.d5.loss_mask: 0.4127  mix_decode.d5.loss_dice: 0.5405  mix_decode.d6.loss_cls: 0.1242  mix_decode.d6.loss_mask: 0.4141  mix_decode.d6.loss_dice: 0.5118  mix_decode.d7.loss_cls: 0.1121  mix_decode.d7.loss_mask: 0.4133  mix_decode.d7.loss_dice: 0.5197  mix_decode.d8.loss_cls: 0.1080  mix_decode.d8.loss_mask: 0.4143  mix_decode.d8.loss_dice: 0.5256
2025/03/28 15:13:14 - mmengine - INFO - Iter(train) [18700/20000]  base_lr: 8.5436e-06 lr: 8.5436e-06  eta: 0:20:43  time: 1.0752  data_time: 0.0230  memory: 10776  loss: 22.6616  decode.loss_cls: 0.0163  decode.loss_mask: 0.6463  decode.loss_dice: 0.6299  decode.d0.loss_cls: 0.0628  decode.d0.loss_mask: 0.6436  decode.d0.loss_dice: 0.6768  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.6469  decode.d1.loss_dice: 0.6437  decode.d2.loss_cls: 0.0864  decode.d2.loss_mask: 0.6449  decode.d2.loss_dice: 0.6253  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.6471  decode.d3.loss_dice: 0.6322  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.6487  decode.d4.loss_dice: 0.6259  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.6476  decode.d5.loss_dice: 0.6416  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.6456  decode.d6.loss_dice: 0.6428  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.6470  decode.d7.loss_dice: 0.6369  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.6512  decode.d8.loss_dice: 0.6457  mix_decode.loss_cls: 0.0768  mix_decode.loss_mask: 0.3491  mix_decode.loss_dice: 0.4932  mix_decode.d0.loss_cls: 0.1031  mix_decode.d0.loss_mask: 0.3587  mix_decode.d0.loss_dice: 0.5370  mix_decode.d1.loss_cls: 0.0890  mix_decode.d1.loss_mask: 0.3543  mix_decode.d1.loss_dice: 0.5194  mix_decode.d2.loss_cls: 0.0730  mix_decode.d2.loss_mask: 0.3477  mix_decode.d2.loss_dice: 0.5057  mix_decode.d3.loss_cls: 0.0679  mix_decode.d3.loss_mask: 0.3506  mix_decode.d3.loss_dice: 0.5092  mix_decode.d4.loss_cls: 0.0943  mix_decode.d4.loss_mask: 0.3480  mix_decode.d4.loss_dice: 0.5090  mix_decode.d5.loss_cls: 0.0678  mix_decode.d5.loss_mask: 0.3494  mix_decode.d5.loss_dice: 0.5080  mix_decode.d6.loss_cls: 0.0635  mix_decode.d6.loss_mask: 0.3496  mix_decode.d6.loss_dice: 0.5128  mix_decode.d7.loss_cls: 0.0801  mix_decode.d7.loss_mask: 0.3498  mix_decode.d7.loss_dice: 0.4918  mix_decode.d8.loss_cls: 0.0892  mix_decode.d8.loss_mask: 0.3484  mix_decode.d8.loss_dice: 0.4930
2025/03/28 15:14:08 - mmengine - INFO - Iter(train) [18750/20000]  base_lr: 8.2473e-06 lr: 8.2473e-06  eta: 0:19:56  time: 1.0795  data_time: 0.0233  memory: 10783  loss: 23.5104  decode.loss_cls: 0.0065  decode.loss_mask: 0.7627  decode.loss_dice: 0.5943  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 0.5808  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.7613  decode.d1.loss_dice: 0.5954  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.7649  decode.d2.loss_dice: 0.5917  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.7615  decode.d3.loss_dice: 0.5893  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.7635  decode.d4.loss_dice: 0.5905  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.7662  decode.d5.loss_dice: 0.5861  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.7651  decode.d6.loss_dice: 0.5914  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.7698  decode.d7.loss_dice: 0.5959  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.7582  decode.d8.loss_dice: 0.5865  mix_decode.loss_cls: 0.0610  mix_decode.loss_mask: 0.4227  mix_decode.loss_dice: 0.4744  mix_decode.d0.loss_cls: 0.0896  mix_decode.d0.loss_mask: 0.4403  mix_decode.d0.loss_dice: 0.5141  mix_decode.d1.loss_cls: 0.0625  mix_decode.d1.loss_mask: 0.4276  mix_decode.d1.loss_dice: 0.4927  mix_decode.d2.loss_cls: 0.0987  mix_decode.d2.loss_mask: 0.4240  mix_decode.d2.loss_dice: 0.4700  mix_decode.d3.loss_cls: 0.0971  mix_decode.d3.loss_mask: 0.4221  mix_decode.d3.loss_dice: 0.4732  mix_decode.d4.loss_cls: 0.0654  mix_decode.d4.loss_mask: 0.4243  mix_decode.d4.loss_dice: 0.4739  mix_decode.d5.loss_cls: 0.0692  mix_decode.d5.loss_mask: 0.4225  mix_decode.d5.loss_dice: 0.4714  mix_decode.d6.loss_cls: 0.0708  mix_decode.d6.loss_mask: 0.4288  mix_decode.d6.loss_dice: 0.4893  mix_decode.d7.loss_cls: 0.0431  mix_decode.d7.loss_mask: 0.4266  mix_decode.d7.loss_dice: 0.4979  mix_decode.d8.loss_cls: 0.0583  mix_decode.d8.loss_mask: 0.4231  mix_decode.d8.loss_dice: 0.4830
2025/03/28 15:15:02 - mmengine - INFO - Iter(train) [18800/20000]  base_lr: 7.9498e-06 lr: 7.9498e-06  eta: 0:19:09  time: 1.0759  data_time: 0.0230  memory: 10766  loss: 26.3470  decode.loss_cls: 0.0075  decode.loss_mask: 0.8318  decode.loss_dice: 0.6905  decode.d0.loss_cls: 0.1281  decode.d0.loss_mask: 0.8384  decode.d0.loss_dice: 0.6808  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.8326  decode.d1.loss_dice: 0.7006  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.8337  decode.d2.loss_dice: 0.7009  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.8304  decode.d3.loss_dice: 0.6902  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.8282  decode.d4.loss_dice: 0.6934  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.8326  decode.d5.loss_dice: 0.6888  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.8318  decode.d6.loss_dice: 0.6904  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.8338  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.8315  decode.d8.loss_dice: 0.6899  mix_decode.loss_cls: 0.0583  mix_decode.loss_mask: 0.4688  mix_decode.loss_dice: 0.5629  mix_decode.d0.loss_cls: 0.0804  mix_decode.d0.loss_mask: 0.4864  mix_decode.d0.loss_dice: 0.5626  mix_decode.d1.loss_cls: 0.0742  mix_decode.d1.loss_mask: 0.4695  mix_decode.d1.loss_dice: 0.5515  mix_decode.d2.loss_cls: 0.0624  mix_decode.d2.loss_mask: 0.4677  mix_decode.d2.loss_dice: 0.5595  mix_decode.d3.loss_cls: 0.0712  mix_decode.d3.loss_mask: 0.4683  mix_decode.d3.loss_dice: 0.5400  mix_decode.d4.loss_cls: 0.0603  mix_decode.d4.loss_mask: 0.4691  mix_decode.d4.loss_dice: 0.5643  mix_decode.d5.loss_cls: 0.0511  mix_decode.d5.loss_mask: 0.4696  mix_decode.d5.loss_dice: 0.5572  mix_decode.d6.loss_cls: 0.0492  mix_decode.d6.loss_mask: 0.4709  mix_decode.d6.loss_dice: 0.5712  mix_decode.d7.loss_cls: 0.0481  mix_decode.d7.loss_mask: 0.4740  mix_decode.d7.loss_dice: 0.5623  mix_decode.d8.loss_cls: 0.0481  mix_decode.d8.loss_mask: 0.4687  mix_decode.d8.loss_dice: 0.5568
2025/03/28 15:15:56 - mmengine - INFO - Iter(train) [18850/20000]  base_lr: 7.6510e-06 lr: 7.6510e-06  eta: 0:18:21  time: 1.0746  data_time: 0.0228  memory: 10771  loss: 25.2885  decode.loss_cls: 0.0512  decode.loss_mask: 0.7753  decode.loss_dice: 0.7229  decode.d0.loss_cls: 0.0938  decode.d0.loss_mask: 0.7819  decode.d0.loss_dice: 0.7225  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.7759  decode.d1.loss_dice: 0.7191  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.7806  decode.d2.loss_dice: 0.7092  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.7756  decode.d3.loss_dice: 0.7139  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.7801  decode.d4.loss_dice: 0.7129  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.7753  decode.d5.loss_dice: 0.7102  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.7802  decode.d6.loss_dice: 0.7095  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.7792  decode.d7.loss_dice: 0.7056  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.7776  decode.d8.loss_dice: 0.7136  mix_decode.loss_cls: 0.0753  mix_decode.loss_mask: 0.4518  mix_decode.loss_dice: 0.4649  mix_decode.d0.loss_cls: 0.1141  mix_decode.d0.loss_mask: 0.4443  mix_decode.d0.loss_dice: 0.4769  mix_decode.d1.loss_cls: 0.0926  mix_decode.d1.loss_mask: 0.4465  mix_decode.d1.loss_dice: 0.4559  mix_decode.d2.loss_cls: 0.0874  mix_decode.d2.loss_mask: 0.4400  mix_decode.d2.loss_dice: 0.4637  mix_decode.d3.loss_cls: 0.0674  mix_decode.d3.loss_mask: 0.4435  mix_decode.d3.loss_dice: 0.4591  mix_decode.d4.loss_cls: 0.0730  mix_decode.d4.loss_mask: 0.4405  mix_decode.d4.loss_dice: 0.4413  mix_decode.d5.loss_cls: 0.0651  mix_decode.d5.loss_mask: 0.4486  mix_decode.d5.loss_dice: 0.4585  mix_decode.d6.loss_cls: 0.0520  mix_decode.d6.loss_mask: 0.4517  mix_decode.d6.loss_dice: 0.4719  mix_decode.d7.loss_cls: 0.0832  mix_decode.d7.loss_mask: 0.4502  mix_decode.d7.loss_dice: 0.4578  mix_decode.d8.loss_cls: 0.0487  mix_decode.d8.loss_mask: 0.4484  mix_decode.d8.loss_dice: 0.4700
2025/03/28 15:16:50 - mmengine - INFO - Iter(train) [18900/20000]  base_lr: 7.3510e-06 lr: 7.3510e-06  eta: 0:17:34  time: 1.0853  data_time: 0.0247  memory: 10781  loss: 26.6797  decode.loss_cls: 0.0254  decode.loss_mask: 0.7935  decode.loss_dice: 0.7866  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.7992  decode.d0.loss_dice: 0.7933  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.7995  decode.d1.loss_dice: 0.7795  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.7955  decode.d2.loss_dice: 0.7791  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.7933  decode.d3.loss_dice: 0.7798  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.7943  decode.d4.loss_dice: 0.7668  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.7957  decode.d5.loss_dice: 0.7866  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.7889  decode.d6.loss_dice: 0.7668  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.7936  decode.d7.loss_dice: 0.7922  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.7932  decode.d8.loss_dice: 0.7783  mix_decode.loss_cls: 0.0634  mix_decode.loss_mask: 0.4482  mix_decode.loss_dice: 0.5600  mix_decode.d0.loss_cls: 0.0851  mix_decode.d0.loss_mask: 0.4552  mix_decode.d0.loss_dice: 0.5799  mix_decode.d1.loss_cls: 0.0661  mix_decode.d1.loss_mask: 0.4484  mix_decode.d1.loss_dice: 0.5542  mix_decode.d2.loss_cls: 0.0620  mix_decode.d2.loss_mask: 0.4522  mix_decode.d2.loss_dice: 0.5607  mix_decode.d3.loss_cls: 0.0731  mix_decode.d3.loss_mask: 0.4457  mix_decode.d3.loss_dice: 0.5494  mix_decode.d4.loss_cls: 0.0685  mix_decode.d4.loss_mask: 0.4484  mix_decode.d4.loss_dice: 0.5502  mix_decode.d5.loss_cls: 0.0720  mix_decode.d5.loss_mask: 0.4470  mix_decode.d5.loss_dice: 0.5417  mix_decode.d6.loss_cls: 0.0770  mix_decode.d6.loss_mask: 0.4453  mix_decode.d6.loss_dice: 0.5551  mix_decode.d7.loss_cls: 0.0746  mix_decode.d7.loss_mask: 0.4528  mix_decode.d7.loss_dice: 0.5469  mix_decode.d8.loss_cls: 0.0451  mix_decode.d8.loss_mask: 0.4524  mix_decode.d8.loss_dice: 0.5725
2025/03/28 15:17:44 - mmengine - INFO - Iter(train) [18950/20000]  base_lr: 7.0496e-06 lr: 7.0496e-06  eta: 0:16:46  time: 1.0767  data_time: 0.0225  memory: 10779  loss: 23.8692  decode.loss_cls: 0.0025  decode.loss_mask: 0.6970  decode.loss_dice: 0.6846  decode.d0.loss_cls: 0.0666  decode.d0.loss_mask: 0.6956  decode.d0.loss_dice: 0.6854  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.7003  decode.d1.loss_dice: 0.6874  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.6987  decode.d2.loss_dice: 0.6904  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.6965  decode.d3.loss_dice: 0.6917  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.6983  decode.d4.loss_dice: 0.6803  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.6991  decode.d5.loss_dice: 0.6857  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.7001  decode.d6.loss_dice: 0.6884  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.7009  decode.d7.loss_dice: 0.7020  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.6994  decode.d8.loss_dice: 0.6936  mix_decode.loss_cls: 0.0892  mix_decode.loss_mask: 0.3288  mix_decode.loss_dice: 0.5546  mix_decode.d0.loss_cls: 0.1591  mix_decode.d0.loss_mask: 0.3306  mix_decode.d0.loss_dice: 0.5862  mix_decode.d1.loss_cls: 0.1434  mix_decode.d1.loss_mask: 0.3209  mix_decode.d1.loss_dice: 0.5590  mix_decode.d2.loss_cls: 0.1399  mix_decode.d2.loss_mask: 0.3220  mix_decode.d2.loss_dice: 0.5453  mix_decode.d3.loss_cls: 0.0943  mix_decode.d3.loss_mask: 0.3234  mix_decode.d3.loss_dice: 0.5513  mix_decode.d4.loss_cls: 0.0836  mix_decode.d4.loss_mask: 0.3257  mix_decode.d4.loss_dice: 0.5560  mix_decode.d5.loss_cls: 0.0843  mix_decode.d5.loss_mask: 0.3250  mix_decode.d5.loss_dice: 0.5558  mix_decode.d6.loss_cls: 0.0904  mix_decode.d6.loss_mask: 0.3254  mix_decode.d6.loss_dice: 0.5522  mix_decode.d7.loss_cls: 0.0784  mix_decode.d7.loss_mask: 0.3316  mix_decode.d7.loss_dice: 0.5577  mix_decode.d8.loss_cls: 0.0928  mix_decode.d8.loss_mask: 0.3274  mix_decode.d8.loss_dice: 0.5567
2025/03/28 15:18:38 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 15:18:38 - mmengine - INFO - Iter(train) [19000/20000]  base_lr: 6.7467e-06 lr: 6.7467e-06  eta: 0:15:58  time: 1.0928  data_time: 0.0244  memory: 10768  loss: 27.2246  decode.loss_cls: 0.0750  decode.loss_mask: 0.7391  decode.loss_dice: 0.7019  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.7378  decode.d0.loss_dice: 0.7151  decode.d1.loss_cls: 0.0764  decode.d1.loss_mask: 0.7348  decode.d1.loss_dice: 0.6985  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.7383  decode.d2.loss_dice: 0.6984  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.7307  decode.d3.loss_dice: 0.6811  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 0.6873  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.7319  decode.d5.loss_dice: 0.6878  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.7373  decode.d6.loss_dice: 0.6870  decode.d7.loss_cls: 0.0725  decode.d7.loss_mask: 0.7366  decode.d7.loss_dice: 0.6800  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.7354  decode.d8.loss_dice: 0.6881  mix_decode.loss_cls: 0.0823  mix_decode.loss_mask: 0.4578  mix_decode.loss_dice: 0.6621  mix_decode.d0.loss_cls: 0.1227  mix_decode.d0.loss_mask: 0.4832  mix_decode.d0.loss_dice: 0.7181  mix_decode.d1.loss_cls: 0.1017  mix_decode.d1.loss_mask: 0.4627  mix_decode.d1.loss_dice: 0.6671  mix_decode.d2.loss_cls: 0.0991  mix_decode.d2.loss_mask: 0.4568  mix_decode.d2.loss_dice: 0.6583  mix_decode.d3.loss_cls: 0.0955  mix_decode.d3.loss_mask: 0.4589  mix_decode.d3.loss_dice: 0.6590  mix_decode.d4.loss_cls: 0.0889  mix_decode.d4.loss_mask: 0.4585  mix_decode.d4.loss_dice: 0.6653  mix_decode.d5.loss_cls: 0.0945  mix_decode.d5.loss_mask: 0.4584  mix_decode.d5.loss_dice: 0.6554  mix_decode.d6.loss_cls: 0.0889  mix_decode.d6.loss_mask: 0.4618  mix_decode.d6.loss_dice: 0.6403  mix_decode.d7.loss_cls: 0.0797  mix_decode.d7.loss_mask: 0.4612  mix_decode.d7.loss_dice: 0.6528  mix_decode.d8.loss_cls: 0.1134  mix_decode.d8.loss_mask: 0.4622  mix_decode.d8.loss_dice: 0.6557
2025/03/28 15:19:32 - mmengine - INFO - Iter(train) [19050/20000]  base_lr: 6.4423e-06 lr: 6.4423e-06  eta: 0:15:11  time: 1.0821  data_time: 0.0234  memory: 10771  loss: 22.4510  decode.loss_cls: 0.0076  decode.loss_mask: 0.6411  decode.loss_dice: 0.5597  decode.d0.loss_cls: 0.1176  decode.d0.loss_mask: 0.6363  decode.d0.loss_dice: 0.5555  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.6400  decode.d1.loss_dice: 0.5502  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.6367  decode.d2.loss_dice: 0.5552  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.6378  decode.d3.loss_dice: 0.5588  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.6383  decode.d4.loss_dice: 0.5529  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.6387  decode.d5.loss_dice: 0.5544  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.6380  decode.d6.loss_dice: 0.5593  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.6358  decode.d7.loss_dice: 0.5532  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.6395  decode.d8.loss_dice: 0.5563  mix_decode.loss_cls: 0.0507  mix_decode.loss_mask: 0.4399  mix_decode.loss_dice: 0.5279  mix_decode.d0.loss_cls: 0.0773  mix_decode.d0.loss_mask: 0.4400  mix_decode.d0.loss_dice: 0.5533  mix_decode.d1.loss_cls: 0.0786  mix_decode.d1.loss_mask: 0.4230  mix_decode.d1.loss_dice: 0.5323  mix_decode.d2.loss_cls: 0.0429  mix_decode.d2.loss_mask: 0.4324  mix_decode.d2.loss_dice: 0.5519  mix_decode.d3.loss_cls: 0.0649  mix_decode.d3.loss_mask: 0.4338  mix_decode.d3.loss_dice: 0.5295  mix_decode.d4.loss_cls: 0.0465  mix_decode.d4.loss_mask: 0.4345  mix_decode.d4.loss_dice: 0.5333  mix_decode.d5.loss_cls: 0.0448  mix_decode.d5.loss_mask: 0.4402  mix_decode.d5.loss_dice: 0.5345  mix_decode.d6.loss_cls: 0.0503  mix_decode.d6.loss_mask: 0.4376  mix_decode.d6.loss_dice: 0.5147  mix_decode.d7.loss_cls: 0.0678  mix_decode.d7.loss_mask: 0.4413  mix_decode.d7.loss_dice: 0.5337  mix_decode.d8.loss_cls: 0.0439  mix_decode.d8.loss_mask: 0.4446  mix_decode.d8.loss_dice: 0.5257
2025/03/28 15:20:26 - mmengine - INFO - Iter(train) [19100/20000]  base_lr: 6.1364e-06 lr: 6.1364e-06  eta: 0:14:23  time: 1.0998  data_time: 0.0250  memory: 10766  loss: 22.9035  decode.loss_cls: 0.0057  decode.loss_mask: 0.7150  decode.loss_dice: 0.6292  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 0.7115  decode.d0.loss_dice: 0.6234  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.7077  decode.d1.loss_dice: 0.6234  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.7047  decode.d2.loss_dice: 0.6193  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.7051  decode.d3.loss_dice: 0.6194  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.7033  decode.d4.loss_dice: 0.6241  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.7105  decode.d5.loss_dice: 0.6321  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.7090  decode.d6.loss_dice: 0.6212  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.7091  decode.d7.loss_dice: 0.6341  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.7040  decode.d8.loss_dice: 0.6285  mix_decode.loss_cls: 0.0362  mix_decode.loss_mask: 0.3644  mix_decode.loss_dice: 0.5248  mix_decode.d0.loss_cls: 0.0626  mix_decode.d0.loss_mask: 0.3737  mix_decode.d0.loss_dice: 0.5523  mix_decode.d1.loss_cls: 0.0499  mix_decode.d1.loss_mask: 0.3620  mix_decode.d1.loss_dice: 0.5234  mix_decode.d2.loss_cls: 0.0417  mix_decode.d2.loss_mask: 0.3687  mix_decode.d2.loss_dice: 0.5347  mix_decode.d3.loss_cls: 0.0584  mix_decode.d3.loss_mask: 0.3635  mix_decode.d3.loss_dice: 0.5287  mix_decode.d4.loss_cls: 0.0368  mix_decode.d4.loss_mask: 0.3642  mix_decode.d4.loss_dice: 0.5342  mix_decode.d5.loss_cls: 0.0371  mix_decode.d5.loss_mask: 0.3643  mix_decode.d5.loss_dice: 0.5242  mix_decode.d6.loss_cls: 0.0564  mix_decode.d6.loss_mask: 0.3629  mix_decode.d6.loss_dice: 0.5292  mix_decode.d7.loss_cls: 0.0378  mix_decode.d7.loss_mask: 0.3653  mix_decode.d7.loss_dice: 0.5204  mix_decode.d8.loss_cls: 0.0556  mix_decode.d8.loss_mask: 0.3639  mix_decode.d8.loss_dice: 0.5282
2025/03/28 15:21:20 - mmengine - INFO - Iter(train) [19150/20000]  base_lr: 5.8287e-06 lr: 5.8287e-06  eta: 0:13:35  time: 1.0753  data_time: 0.0229  memory: 10778  loss: 28.4266  decode.loss_cls: 0.0276  decode.loss_mask: 0.8583  decode.loss_dice: 0.7688  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.8741  decode.d0.loss_dice: 0.7647  decode.d1.loss_cls: 0.0313  decode.d1.loss_mask: 0.8632  decode.d1.loss_dice: 0.7680  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 0.8661  decode.d2.loss_dice: 0.7696  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.8660  decode.d3.loss_dice: 0.7723  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.8625  decode.d4.loss_dice: 0.7594  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.8627  decode.d5.loss_dice: 0.7745  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.8619  decode.d6.loss_dice: 0.7612  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.8599  decode.d7.loss_dice: 0.7595  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.8601  decode.d8.loss_dice: 0.7415  mix_decode.loss_cls: 0.0782  mix_decode.loss_mask: 0.5071  mix_decode.loss_dice: 0.5875  mix_decode.d0.loss_cls: 0.1033  mix_decode.d0.loss_mask: 0.5063  mix_decode.d0.loss_dice: 0.6201  mix_decode.d1.loss_cls: 0.0701  mix_decode.d1.loss_mask: 0.4932  mix_decode.d1.loss_dice: 0.5904  mix_decode.d2.loss_cls: 0.0939  mix_decode.d2.loss_mask: 0.4800  mix_decode.d2.loss_dice: 0.5834  mix_decode.d3.loss_cls: 0.0978  mix_decode.d3.loss_mask: 0.5149  mix_decode.d3.loss_dice: 0.6009  mix_decode.d4.loss_cls: 0.0863  mix_decode.d4.loss_mask: 0.5101  mix_decode.d4.loss_dice: 0.5874  mix_decode.d5.loss_cls: 0.0696  mix_decode.d5.loss_mask: 0.5071  mix_decode.d5.loss_dice: 0.5899  mix_decode.d6.loss_cls: 0.0710  mix_decode.d6.loss_mask: 0.5046  mix_decode.d6.loss_dice: 0.5892  mix_decode.d7.loss_cls: 0.0611  mix_decode.d7.loss_mask: 0.5027  mix_decode.d7.loss_dice: 0.5889  mix_decode.d8.loss_cls: 0.0444  mix_decode.d8.loss_mask: 0.5089  mix_decode.d8.loss_dice: 0.6052
2025/03/28 15:22:14 - mmengine - INFO - Iter(train) [19200/20000]  base_lr: 5.5192e-06 lr: 5.5192e-06  eta: 0:12:48  time: 1.0759  data_time: 0.0228  memory: 10780  loss: 22.6970  decode.loss_cls: 0.0066  decode.loss_mask: 0.6592  decode.loss_dice: 0.6115  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 0.6629  decode.d0.loss_dice: 0.6186  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.6567  decode.d1.loss_dice: 0.6119  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.6649  decode.d2.loss_dice: 0.6226  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.6617  decode.d3.loss_dice: 0.6071  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.6540  decode.d4.loss_dice: 0.6116  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.6591  decode.d5.loss_dice: 0.6056  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.6623  decode.d6.loss_dice: 0.6140  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.6594  decode.d7.loss_dice: 0.6100  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.6578  decode.d8.loss_dice: 0.6051  mix_decode.loss_cls: 0.0900  mix_decode.loss_mask: 0.3879  mix_decode.loss_dice: 0.5115  mix_decode.d0.loss_cls: 0.0752  mix_decode.d0.loss_mask: 0.3835  mix_decode.d0.loss_dice: 0.5642  mix_decode.d1.loss_cls: 0.0797  mix_decode.d1.loss_mask: 0.3780  mix_decode.d1.loss_dice: 0.5040  mix_decode.d2.loss_cls: 0.0851  mix_decode.d2.loss_mask: 0.3777  mix_decode.d2.loss_dice: 0.5086  mix_decode.d3.loss_cls: 0.0772  mix_decode.d3.loss_mask: 0.3860  mix_decode.d3.loss_dice: 0.5224  mix_decode.d4.loss_cls: 0.0769  mix_decode.d4.loss_mask: 0.3901  mix_decode.d4.loss_dice: 0.5149  mix_decode.d5.loss_cls: 0.0528  mix_decode.d5.loss_mask: 0.3895  mix_decode.d5.loss_dice: 0.5250  mix_decode.d6.loss_cls: 0.0686  mix_decode.d6.loss_mask: 0.4266  mix_decode.d6.loss_dice: 0.5415  mix_decode.d7.loss_cls: 0.0445  mix_decode.d7.loss_mask: 0.3892  mix_decode.d7.loss_dice: 0.5327  mix_decode.d8.loss_cls: 0.0471  mix_decode.d8.loss_mask: 0.3918  mix_decode.d8.loss_dice: 0.5276
2025/03/28 15:23:08 - mmengine - INFO - Iter(train) [19250/20000]  base_lr: 5.2077e-06 lr: 5.2077e-06  eta: 0:12:00  time: 1.0758  data_time: 0.0228  memory: 10778  loss: 22.9743  decode.loss_cls: 0.0250  decode.loss_mask: 0.6901  decode.loss_dice: 0.6546  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 0.6761  decode.d0.loss_dice: 0.6362  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.6771  decode.d1.loss_dice: 0.6287  decode.d2.loss_cls: 0.0410  decode.d2.loss_mask: 0.6778  decode.d2.loss_dice: 0.6021  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.6761  decode.d3.loss_dice: 0.6248  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.6768  decode.d4.loss_dice: 0.6381  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.6806  decode.d5.loss_dice: 0.6141  decode.d6.loss_cls: 0.0246  decode.d6.loss_mask: 0.6760  decode.d6.loss_dice: 0.6512  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.6792  decode.d7.loss_dice: 0.6190  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.6749  decode.d8.loss_dice: 0.6226  mix_decode.loss_cls: 0.0692  mix_decode.loss_mask: 0.3080  mix_decode.loss_dice: 0.5380  mix_decode.d0.loss_cls: 0.1024  mix_decode.d0.loss_mask: 0.3178  mix_decode.d0.loss_dice: 0.5783  mix_decode.d1.loss_cls: 0.0816  mix_decode.d1.loss_mask: 0.3164  mix_decode.d1.loss_dice: 0.5676  mix_decode.d2.loss_cls: 0.0941  mix_decode.d2.loss_mask: 0.3109  mix_decode.d2.loss_dice: 0.5425  mix_decode.d3.loss_cls: 0.0668  mix_decode.d3.loss_mask: 0.3089  mix_decode.d3.loss_dice: 0.5452  mix_decode.d4.loss_cls: 0.0816  mix_decode.d4.loss_mask: 0.3090  mix_decode.d4.loss_dice: 0.5671  mix_decode.d5.loss_cls: 0.0803  mix_decode.d5.loss_mask: 0.3112  mix_decode.d5.loss_dice: 0.5524  mix_decode.d6.loss_cls: 0.0728  mix_decode.d6.loss_mask: 0.3092  mix_decode.d6.loss_dice: 0.5630  mix_decode.d7.loss_cls: 0.0726  mix_decode.d7.loss_mask: 0.3092  mix_decode.d7.loss_dice: 0.5430  mix_decode.d8.loss_cls: 0.0719  mix_decode.d8.loss_mask: 0.3106  mix_decode.d8.loss_dice: 0.5617
2025/03/28 15:24:02 - mmengine - INFO - Iter(train) [19300/20000]  base_lr: 4.8942e-06 lr: 4.8942e-06  eta: 0:11:12  time: 1.0731  data_time: 0.0226  memory: 10770  loss: 28.2027  decode.loss_cls: 0.0230  decode.loss_mask: 0.8215  decode.loss_dice: 0.8321  decode.d0.loss_cls: 0.1124  decode.d0.loss_mask: 0.8250  decode.d0.loss_dice: 0.8415  decode.d1.loss_cls: 0.0300  decode.d1.loss_mask: 0.8231  decode.d1.loss_dice: 0.8381  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.8248  decode.d2.loss_dice: 0.7942  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.8230  decode.d3.loss_dice: 0.8337  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.8307  decode.d4.loss_dice: 0.8429  decode.d5.loss_cls: 0.0253  decode.d5.loss_mask: 0.8246  decode.d5.loss_dice: 0.8504  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.8206  decode.d6.loss_dice: 0.8197  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.8205  decode.d7.loss_dice: 0.8319  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.8242  decode.d8.loss_dice: 0.8407  mix_decode.loss_cls: 0.0459  mix_decode.loss_mask: 0.4673  mix_decode.loss_dice: 0.6009  mix_decode.d0.loss_cls: 0.0976  mix_decode.d0.loss_mask: 0.4801  mix_decode.d0.loss_dice: 0.6182  mix_decode.d1.loss_cls: 0.0999  mix_decode.d1.loss_mask: 0.4568  mix_decode.d1.loss_dice: 0.6015  mix_decode.d2.loss_cls: 0.0760  mix_decode.d2.loss_mask: 0.4628  mix_decode.d2.loss_dice: 0.6152  mix_decode.d3.loss_cls: 0.0405  mix_decode.d3.loss_mask: 0.4671  mix_decode.d3.loss_dice: 0.5995  mix_decode.d4.loss_cls: 0.0571  mix_decode.d4.loss_mask: 0.4505  mix_decode.d4.loss_dice: 0.6080  mix_decode.d5.loss_cls: 0.0463  mix_decode.d5.loss_mask: 0.4650  mix_decode.d5.loss_dice: 0.5967  mix_decode.d6.loss_cls: 0.0681  mix_decode.d6.loss_mask: 0.4591  mix_decode.d6.loss_dice: 0.5941  mix_decode.d7.loss_cls: 0.0465  mix_decode.d7.loss_mask: 0.4633  mix_decode.d7.loss_dice: 0.5943  mix_decode.d8.loss_cls: 0.0493  mix_decode.d8.loss_mask: 0.4691  mix_decode.d8.loss_dice: 0.6001
2025/03/28 15:24:56 - mmengine - INFO - Iter(train) [19350/20000]  base_lr: 4.5784e-06 lr: 4.5784e-06  eta: 0:10:24  time: 1.0816  data_time: 0.0233  memory: 10779  loss: 25.6568  decode.loss_cls: 0.0109  decode.loss_mask: 0.7608  decode.loss_dice: 0.7005  decode.d0.loss_cls: 0.0663  decode.d0.loss_mask: 0.7608  decode.d0.loss_dice: 0.7030  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.7598  decode.d1.loss_dice: 0.7020  decode.d2.loss_cls: 0.0494  decode.d2.loss_mask: 0.7564  decode.d2.loss_dice: 0.6830  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.7607  decode.d3.loss_dice: 0.7027  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.7571  decode.d4.loss_dice: 0.6824  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 0.7003  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.7558  decode.d6.loss_dice: 0.6914  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.7615  decode.d7.loss_dice: 0.6920  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.7560  decode.d8.loss_dice: 0.6977  mix_decode.loss_cls: 0.0505  mix_decode.loss_mask: 0.4472  mix_decode.loss_dice: 0.5845  mix_decode.d0.loss_cls: 0.0631  mix_decode.d0.loss_mask: 0.4646  mix_decode.d0.loss_dice: 0.6096  mix_decode.d1.loss_cls: 0.0403  mix_decode.d1.loss_mask: 0.4518  mix_decode.d1.loss_dice: 0.5899  mix_decode.d2.loss_cls: 0.0497  mix_decode.d2.loss_mask: 0.4475  mix_decode.d2.loss_dice: 0.5801  mix_decode.d3.loss_cls: 0.0736  mix_decode.d3.loss_mask: 0.4498  mix_decode.d3.loss_dice: 0.5701  mix_decode.d4.loss_cls: 0.0647  mix_decode.d4.loss_mask: 0.4494  mix_decode.d4.loss_dice: 0.5728  mix_decode.d5.loss_cls: 0.0703  mix_decode.d5.loss_mask: 0.4488  mix_decode.d5.loss_dice: 0.5739  mix_decode.d6.loss_cls: 0.0697  mix_decode.d6.loss_mask: 0.4503  mix_decode.d6.loss_dice: 0.5789  mix_decode.d7.loss_cls: 0.0680  mix_decode.d7.loss_mask: 0.4371  mix_decode.d7.loss_dice: 0.5447  mix_decode.d8.loss_cls: 0.0645  mix_decode.d8.loss_mask: 0.4503  mix_decode.d8.loss_dice: 0.5800
2025/03/28 15:25:50 - mmengine - INFO - Iter(train) [19400/20000]  base_lr: 4.2602e-06 lr: 4.2602e-06  eta: 0:09:36  time: 1.0769  data_time: 0.0230  memory: 10768  loss: 26.5623  decode.loss_cls: 0.0110  decode.loss_mask: 0.8137  decode.loss_dice: 0.7484  decode.d0.loss_cls: 0.1340  decode.d0.loss_mask: 0.8080  decode.d0.loss_dice: 0.7630  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.8100  decode.d1.loss_dice: 0.7395  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.8080  decode.d2.loss_dice: 0.7332  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.8162  decode.d3.loss_dice: 0.7444  decode.d4.loss_cls: 0.0524  decode.d4.loss_mask: 0.8154  decode.d4.loss_dice: 0.7363  decode.d5.loss_cls: 0.0573  decode.d5.loss_mask: 0.8143  decode.d5.loss_dice: 0.7339  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.8117  decode.d6.loss_dice: 0.7473  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.8188  decode.d7.loss_dice: 0.7532  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.8124  decode.d8.loss_dice: 0.7519  mix_decode.loss_cls: 0.0571  mix_decode.loss_mask: 0.4192  mix_decode.loss_dice: 0.5418  mix_decode.d0.loss_cls: 0.0864  mix_decode.d0.loss_mask: 0.4310  mix_decode.d0.loss_dice: 0.5752  mix_decode.d1.loss_cls: 0.0635  mix_decode.d1.loss_mask: 0.4242  mix_decode.d1.loss_dice: 0.5727  mix_decode.d2.loss_cls: 0.0757  mix_decode.d2.loss_mask: 0.4173  mix_decode.d2.loss_dice: 0.5444  mix_decode.d3.loss_cls: 0.0544  mix_decode.d3.loss_mask: 0.4192  mix_decode.d3.loss_dice: 0.5561  mix_decode.d4.loss_cls: 0.0685  mix_decode.d4.loss_mask: 0.4224  mix_decode.d4.loss_dice: 0.5628  mix_decode.d5.loss_cls: 0.0624  mix_decode.d5.loss_mask: 0.4213  mix_decode.d5.loss_dice: 0.5611  mix_decode.d6.loss_cls: 0.0651  mix_decode.d6.loss_mask: 0.4196  mix_decode.d6.loss_dice: 0.5513  mix_decode.d7.loss_cls: 0.1002  mix_decode.d7.loss_mask: 0.4187  mix_decode.d7.loss_dice: 0.5480  mix_decode.d8.loss_cls: 0.0846  mix_decode.d8.loss_mask: 0.4180  mix_decode.d8.loss_dice: 0.5312
2025/03/28 15:26:44 - mmengine - INFO - Iter(train) [19450/20000]  base_lr: 3.9393e-06 lr: 3.9393e-06  eta: 0:08:48  time: 1.0771  data_time: 0.0225  memory: 10769  loss: 23.8737  decode.loss_cls: 0.0067  decode.loss_mask: 0.7081  decode.loss_dice: 0.6742  decode.d0.loss_cls: 0.0716  decode.d0.loss_mask: 0.7108  decode.d0.loss_dice: 0.6834  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.7053  decode.d1.loss_dice: 0.6840  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.7070  decode.d2.loss_dice: 0.6808  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.7054  decode.d3.loss_dice: 0.6811  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.7033  decode.d4.loss_dice: 0.6743  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.7030  decode.d5.loss_dice: 0.6785  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.7056  decode.d6.loss_dice: 0.6823  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.7050  decode.d7.loss_dice: 0.6786  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.7078  decode.d8.loss_dice: 0.6728  mix_decode.loss_cls: 0.0440  mix_decode.loss_mask: 0.3498  mix_decode.loss_dice: 0.5741  mix_decode.d0.loss_cls: 0.0881  mix_decode.d0.loss_mask: 0.3553  mix_decode.d0.loss_dice: 0.5963  mix_decode.d1.loss_cls: 0.1055  mix_decode.d1.loss_mask: 0.3527  mix_decode.d1.loss_dice: 0.5516  mix_decode.d2.loss_cls: 0.0700  mix_decode.d2.loss_mask: 0.3482  mix_decode.d2.loss_dice: 0.5701  mix_decode.d3.loss_cls: 0.0489  mix_decode.d3.loss_mask: 0.3522  mix_decode.d3.loss_dice: 0.5633  mix_decode.d4.loss_cls: 0.0852  mix_decode.d4.loss_mask: 0.3496  mix_decode.d4.loss_dice: 0.5644  mix_decode.d5.loss_cls: 0.0612  mix_decode.d5.loss_mask: 0.3524  mix_decode.d5.loss_dice: 0.5665  mix_decode.d6.loss_cls: 0.0703  mix_decode.d6.loss_mask: 0.3484  mix_decode.d6.loss_dice: 0.5633  mix_decode.d7.loss_cls: 0.0776  mix_decode.d7.loss_mask: 0.3488  mix_decode.d7.loss_dice: 0.5606  mix_decode.d8.loss_cls: 0.0454  mix_decode.d8.loss_mask: 0.3502  mix_decode.d8.loss_dice: 0.5676
2025/03/28 15:27:38 - mmengine - INFO - Iter(train) [19500/20000]  base_lr: 3.6155e-06 lr: 3.6155e-06  eta: 0:08:00  time: 1.0953  data_time: 0.0242  memory: 10779  loss: 24.6088  decode.loss_cls: 0.0162  decode.loss_mask: 0.6817  decode.loss_dice: 0.6203  decode.d0.loss_cls: 0.0573  decode.d0.loss_mask: 0.6856  decode.d0.loss_dice: 0.6243  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.6873  decode.d1.loss_dice: 0.6283  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.6882  decode.d2.loss_dice: 0.6311  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.6823  decode.d3.loss_dice: 0.6387  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.6819  decode.d4.loss_dice: 0.6368  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.6817  decode.d5.loss_dice: 0.6333  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.6771  decode.d6.loss_dice: 0.6257  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.6837  decode.d7.loss_dice: 0.6259  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.6843  decode.d8.loss_dice: 0.6304  mix_decode.loss_cls: 0.0743  mix_decode.loss_mask: 0.4297  mix_decode.loss_dice: 0.6231  mix_decode.d0.loss_cls: 0.0835  mix_decode.d0.loss_mask: 0.4285  mix_decode.d0.loss_dice: 0.6656  mix_decode.d1.loss_cls: 0.1045  mix_decode.d1.loss_mask: 0.4198  mix_decode.d1.loss_dice: 0.6254  mix_decode.d2.loss_cls: 0.0929  mix_decode.d2.loss_mask: 0.4239  mix_decode.d2.loss_dice: 0.6092  mix_decode.d3.loss_cls: 0.0784  mix_decode.d3.loss_mask: 0.4259  mix_decode.d3.loss_dice: 0.6218  mix_decode.d4.loss_cls: 0.0714  mix_decode.d4.loss_mask: 0.4331  mix_decode.d4.loss_dice: 0.6191  mix_decode.d5.loss_cls: 0.0733  mix_decode.d5.loss_mask: 0.4293  mix_decode.d5.loss_dice: 0.6128  mix_decode.d6.loss_cls: 0.0731  mix_decode.d6.loss_mask: 0.4250  mix_decode.d6.loss_dice: 0.6266  mix_decode.d7.loss_cls: 0.0509  mix_decode.d7.loss_mask: 0.4338  mix_decode.d7.loss_dice: 0.6406  mix_decode.d8.loss_cls: 0.0636  mix_decode.d8.loss_mask: 0.4319  mix_decode.d8.loss_dice: 0.6159
2025/03/28 15:28:32 - mmengine - INFO - Iter(train) [19550/20000]  base_lr: 3.2884e-06 lr: 3.2884e-06  eta: 0:07:13  time: 1.0777  data_time: 0.0230  memory: 10775  loss: 20.8503  decode.loss_cls: 0.0050  decode.loss_mask: 0.6402  decode.loss_dice: 0.5904  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.6420  decode.d0.loss_dice: 0.5873  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.6351  decode.d1.loss_dice: 0.5826  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.6390  decode.d2.loss_dice: 0.5891  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.6368  decode.d3.loss_dice: 0.5889  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.6354  decode.d4.loss_dice: 0.5872  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.6365  decode.d5.loss_dice: 0.5927  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.6379  decode.d6.loss_dice: 0.5953  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.6379  decode.d7.loss_dice: 0.5864  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.6383  decode.d8.loss_dice: 0.5888  mix_decode.loss_cls: 0.0602  mix_decode.loss_mask: 0.3141  mix_decode.loss_dice: 0.4662  mix_decode.d0.loss_cls: 0.1405  mix_decode.d0.loss_mask: 0.3167  mix_decode.d0.loss_dice: 0.4938  mix_decode.d1.loss_cls: 0.0828  mix_decode.d1.loss_mask: 0.3130  mix_decode.d1.loss_dice: 0.4465  mix_decode.d2.loss_cls: 0.0608  mix_decode.d2.loss_mask: 0.3145  mix_decode.d2.loss_dice: 0.4676  mix_decode.d3.loss_cls: 0.0629  mix_decode.d3.loss_mask: 0.3144  mix_decode.d3.loss_dice: 0.4409  mix_decode.d4.loss_cls: 0.0567  mix_decode.d4.loss_mask: 0.3121  mix_decode.d4.loss_dice: 0.4577  mix_decode.d5.loss_cls: 0.0660  mix_decode.d5.loss_mask: 0.3133  mix_decode.d5.loss_dice: 0.4633  mix_decode.d6.loss_cls: 0.0674  mix_decode.d6.loss_mask: 0.3117  mix_decode.d6.loss_dice: 0.4478  mix_decode.d7.loss_cls: 0.0649  mix_decode.d7.loss_mask: 0.3123  mix_decode.d7.loss_dice: 0.4612  mix_decode.d8.loss_cls: 0.0412  mix_decode.d8.loss_mask: 0.3113  mix_decode.d8.loss_dice: 0.4670
2025/03/28 15:29:26 - mmengine - INFO - Iter(train) [19600/20000]  base_lr: 2.9576e-06 lr: 2.9576e-06  eta: 0:06:25  time: 1.0774  data_time: 0.0228  memory: 10770  loss: 24.6568  decode.loss_cls: 0.0587  decode.loss_mask: 0.6242  decode.loss_dice: 0.6667  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.6252  decode.d0.loss_dice: 0.7156  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.6293  decode.d1.loss_dice: 0.6793  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.6304  decode.d2.loss_dice: 0.6751  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.6220  decode.d3.loss_dice: 0.6694  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.6242  decode.d4.loss_dice: 0.6642  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.6254  decode.d5.loss_dice: 0.6722  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.6286  decode.d6.loss_dice: 0.6491  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.6303  decode.d7.loss_dice: 0.6665  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.6325  decode.d8.loss_dice: 0.6700  mix_decode.loss_cls: 0.0989  mix_decode.loss_mask: 0.4138  mix_decode.loss_dice: 0.5973  mix_decode.d0.loss_cls: 0.1058  mix_decode.d0.loss_mask: 0.4474  mix_decode.d0.loss_dice: 0.6133  mix_decode.d1.loss_cls: 0.1122  mix_decode.d1.loss_mask: 0.4323  mix_decode.d1.loss_dice: 0.5938  mix_decode.d2.loss_cls: 0.1233  mix_decode.d2.loss_mask: 0.4155  mix_decode.d2.loss_dice: 0.6067  mix_decode.d3.loss_cls: 0.1034  mix_decode.d3.loss_mask: 0.4269  mix_decode.d3.loss_dice: 0.5824  mix_decode.d4.loss_cls: 0.1110  mix_decode.d4.loss_mask: 0.4141  mix_decode.d4.loss_dice: 0.5871  mix_decode.d5.loss_cls: 0.0773  mix_decode.d5.loss_mask: 0.4313  mix_decode.d5.loss_dice: 0.5840  mix_decode.d6.loss_cls: 0.0847  mix_decode.d6.loss_mask: 0.4313  mix_decode.d6.loss_dice: 0.5910  mix_decode.d7.loss_cls: 0.0702  mix_decode.d7.loss_mask: 0.4390  mix_decode.d7.loss_dice: 0.5925  mix_decode.d8.loss_cls: 0.0505  mix_decode.d8.loss_mask: 0.4398  mix_decode.d8.loss_dice: 0.6154
2025/03/28 15:30:20 - mmengine - INFO - Iter(train) [19650/20000]  base_lr: 2.6227e-06 lr: 2.6227e-06  eta: 0:05:37  time: 1.0785  data_time: 0.0225  memory: 10777  loss: 23.1313  decode.loss_cls: 0.0154  decode.loss_mask: 0.6843  decode.loss_dice: 0.6562  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.6952  decode.d0.loss_dice: 0.6753  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.6942  decode.d1.loss_dice: 0.6736  decode.d2.loss_cls: 0.0142  decode.d2.loss_mask: 0.6896  decode.d2.loss_dice: 0.6728  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.6890  decode.d3.loss_dice: 0.6605  decode.d4.loss_cls: 0.0112  decode.d4.loss_mask: 0.6882  decode.d4.loss_dice: 0.6647  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.6914  decode.d5.loss_dice: 0.6665  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.6843  decode.d6.loss_dice: 0.6575  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.6916  decode.d7.loss_dice: 0.6604  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.6895  decode.d8.loss_dice: 0.6658  mix_decode.loss_cls: 0.1305  mix_decode.loss_mask: 0.3132  mix_decode.loss_dice: 0.4826  mix_decode.d0.loss_cls: 0.0890  mix_decode.d0.loss_mask: 0.3347  mix_decode.d0.loss_dice: 0.5571  mix_decode.d1.loss_cls: 0.1249  mix_decode.d1.loss_mask: 0.3154  mix_decode.d1.loss_dice: 0.4921  mix_decode.d2.loss_cls: 0.1268  mix_decode.d2.loss_mask: 0.3139  mix_decode.d2.loss_dice: 0.4913  mix_decode.d3.loss_cls: 0.1191  mix_decode.d3.loss_mask: 0.3122  mix_decode.d3.loss_dice: 0.5113  mix_decode.d4.loss_cls: 0.1219  mix_decode.d4.loss_mask: 0.3113  mix_decode.d4.loss_dice: 0.4764  mix_decode.d5.loss_cls: 0.1467  mix_decode.d5.loss_mask: 0.3113  mix_decode.d5.loss_dice: 0.4860  mix_decode.d6.loss_cls: 0.1354  mix_decode.d6.loss_mask: 0.3111  mix_decode.d6.loss_dice: 0.4918  mix_decode.d7.loss_cls: 0.1249  mix_decode.d7.loss_mask: 0.3110  mix_decode.d7.loss_dice: 0.4899  mix_decode.d8.loss_cls: 0.1448  mix_decode.d8.loss_mask: 0.3127  mix_decode.d8.loss_dice: 0.4991
2025/03/28 15:31:15 - mmengine - INFO - Iter(train) [19700/20000]  base_lr: 2.2830e-06 lr: 2.2830e-06  eta: 0:04:48  time: 1.0849  data_time: 0.0241  memory: 10774  loss: 27.6580  decode.loss_cls: 0.0618  decode.loss_mask: 0.8266  decode.loss_dice: 0.8812  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.8374  decode.d0.loss_dice: 0.9052  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.8417  decode.d1.loss_dice: 0.9047  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.8336  decode.d2.loss_dice: 0.8780  decode.d3.loss_cls: 0.0181  decode.d3.loss_mask: 0.8337  decode.d3.loss_dice: 0.8843  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.8316  decode.d4.loss_dice: 0.8653  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 0.8321  decode.d5.loss_dice: 0.8943  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.8325  decode.d6.loss_dice: 0.8977  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.8323  decode.d7.loss_dice: 0.9076  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.8330  decode.d8.loss_dice: 0.8842  mix_decode.loss_cls: 0.0812  mix_decode.loss_mask: 0.3646  mix_decode.loss_dice: 0.5370  mix_decode.d0.loss_cls: 0.1279  mix_decode.d0.loss_mask: 0.3715  mix_decode.d0.loss_dice: 0.5677  mix_decode.d1.loss_cls: 0.0897  mix_decode.d1.loss_mask: 0.3695  mix_decode.d1.loss_dice: 0.5551  mix_decode.d2.loss_cls: 0.1068  mix_decode.d2.loss_mask: 0.3696  mix_decode.d2.loss_dice: 0.5314  mix_decode.d3.loss_cls: 0.0831  mix_decode.d3.loss_mask: 0.3626  mix_decode.d3.loss_dice: 0.5466  mix_decode.d4.loss_cls: 0.0920  mix_decode.d4.loss_mask: 0.3649  mix_decode.d4.loss_dice: 0.5303  mix_decode.d5.loss_cls: 0.0867  mix_decode.d5.loss_mask: 0.3664  mix_decode.d5.loss_dice: 0.5565  mix_decode.d6.loss_cls: 0.0923  mix_decode.d6.loss_mask: 0.3617  mix_decode.d6.loss_dice: 0.5225  mix_decode.d7.loss_cls: 0.0997  mix_decode.d7.loss_mask: 0.3640  mix_decode.d7.loss_dice: 0.5225  mix_decode.d8.loss_cls: 0.1003  mix_decode.d8.loss_mask: 0.3653  mix_decode.d8.loss_dice: 0.5356
2025/03/28 15:32:09 - mmengine - INFO - Iter(train) [19750/20000]  base_lr: 1.9375e-06 lr: 1.9375e-06  eta: 0:04:00  time: 1.0783  data_time: 0.0231  memory: 10776  loss: 24.4483  decode.loss_cls: 0.0103  decode.loss_mask: 0.7380  decode.loss_dice: 0.6318  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 0.7403  decode.d0.loss_dice: 0.6303  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.7430  decode.d1.loss_dice: 0.6393  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.7442  decode.d2.loss_dice: 0.6348  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.7404  decode.d3.loss_dice: 0.6401  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.7444  decode.d4.loss_dice: 0.6332  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.7402  decode.d5.loss_dice: 0.6322  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.7400  decode.d6.loss_dice: 0.6300  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.7396  decode.d7.loss_dice: 0.6389  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.7394  decode.d8.loss_dice: 0.6373  mix_decode.loss_cls: 0.0910  mix_decode.loss_mask: 0.4353  mix_decode.loss_dice: 0.5262  mix_decode.d0.loss_cls: 0.0936  mix_decode.d0.loss_mask: 0.4305  mix_decode.d0.loss_dice: 0.5563  mix_decode.d1.loss_cls: 0.0670  mix_decode.d1.loss_mask: 0.4315  mix_decode.d1.loss_dice: 0.5501  mix_decode.d2.loss_cls: 0.0688  mix_decode.d2.loss_mask: 0.4263  mix_decode.d2.loss_dice: 0.5574  mix_decode.d3.loss_cls: 0.1038  mix_decode.d3.loss_mask: 0.4212  mix_decode.d3.loss_dice: 0.5294  mix_decode.d4.loss_cls: 0.0915  mix_decode.d4.loss_mask: 0.4245  mix_decode.d4.loss_dice: 0.5218  mix_decode.d5.loss_cls: 0.0636  mix_decode.d5.loss_mask: 0.4281  mix_decode.d5.loss_dice: 0.5474  mix_decode.d6.loss_cls: 0.0460  mix_decode.d6.loss_mask: 0.4343  mix_decode.d6.loss_dice: 0.5611  mix_decode.d7.loss_cls: 0.0784  mix_decode.d7.loss_mask: 0.4300  mix_decode.d7.loss_dice: 0.5487  mix_decode.d8.loss_cls: 0.0907  mix_decode.d8.loss_mask: 0.4321  mix_decode.d8.loss_dice: 0.5286
2025/03/28 15:33:03 - mmengine - INFO - Iter(train) [19800/20000]  base_lr: 1.5850e-06 lr: 1.5850e-06  eta: 0:03:12  time: 1.0765  data_time: 0.0228  memory: 10772  loss: 25.7381  decode.loss_cls: 0.0063  decode.loss_mask: 0.8001  decode.loss_dice: 0.6920  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.8023  decode.d0.loss_dice: 0.7021  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.8019  decode.d1.loss_dice: 0.6950  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.8013  decode.d2.loss_dice: 0.6944  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.8000  decode.d3.loss_dice: 0.6879  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.7996  decode.d4.loss_dice: 0.6854  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.7979  decode.d5.loss_dice: 0.6856  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.8005  decode.d6.loss_dice: 0.6878  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.8057  decode.d7.loss_dice: 0.6899  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.8003  decode.d8.loss_dice: 0.6827  mix_decode.loss_cls: 0.1385  mix_decode.loss_mask: 0.4193  mix_decode.loss_dice: 0.5168  mix_decode.d0.loss_cls: 0.1467  mix_decode.d0.loss_mask: 0.4212  mix_decode.d0.loss_dice: 0.5361  mix_decode.d1.loss_cls: 0.1463  mix_decode.d1.loss_mask: 0.4193  mix_decode.d1.loss_dice: 0.5160  mix_decode.d2.loss_cls: 0.1268  mix_decode.d2.loss_mask: 0.4161  mix_decode.d2.loss_dice: 0.4999  mix_decode.d3.loss_cls: 0.1187  mix_decode.d3.loss_mask: 0.4140  mix_decode.d3.loss_dice: 0.5234  mix_decode.d4.loss_cls: 0.1302  mix_decode.d4.loss_mask: 0.4147  mix_decode.d4.loss_dice: 0.5220  mix_decode.d5.loss_cls: 0.1113  mix_decode.d5.loss_mask: 0.4140  mix_decode.d5.loss_dice: 0.5243  mix_decode.d6.loss_cls: 0.1187  mix_decode.d6.loss_mask: 0.4167  mix_decode.d6.loss_dice: 0.5113  mix_decode.d7.loss_cls: 0.1564  mix_decode.d7.loss_mask: 0.4176  mix_decode.d7.loss_dice: 0.5149  mix_decode.d8.loss_cls: 0.1271  mix_decode.d8.loss_mask: 0.4200  mix_decode.d8.loss_dice: 0.5242
2025/03/28 15:33:57 - mmengine - INFO - Iter(train) [19850/20000]  base_lr: 1.2234e-06 lr: 1.2234e-06  eta: 0:02:24  time: 1.0744  data_time: 0.0223  memory: 10779  loss: 25.1770  decode.loss_cls: 0.0042  decode.loss_mask: 0.7779  decode.loss_dice: 0.7233  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 0.7717  decode.d0.loss_dice: 0.7138  decode.d1.loss_cls: 0.0664  decode.d1.loss_mask: 0.7666  decode.d1.loss_dice: 0.7127  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.7654  decode.d2.loss_dice: 0.7004  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.7663  decode.d3.loss_dice: 0.7080  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.7752  decode.d4.loss_dice: 0.7197  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.7673  decode.d5.loss_dice: 0.7166  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.7765  decode.d6.loss_dice: 0.7266  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.7730  decode.d7.loss_dice: 0.7261  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.7751  decode.d8.loss_dice: 0.7243  mix_decode.loss_cls: 0.0305  mix_decode.loss_mask: 0.4455  mix_decode.loss_dice: 0.5151  mix_decode.d0.loss_cls: 0.0644  mix_decode.d0.loss_mask: 0.4564  mix_decode.d0.loss_dice: 0.5261  mix_decode.d1.loss_cls: 0.0567  mix_decode.d1.loss_mask: 0.4258  mix_decode.d1.loss_dice: 0.5141  mix_decode.d2.loss_cls: 0.0477  mix_decode.d2.loss_mask: 0.4447  mix_decode.d2.loss_dice: 0.5170  mix_decode.d3.loss_cls: 0.0318  mix_decode.d3.loss_mask: 0.4473  mix_decode.d3.loss_dice: 0.5234  mix_decode.d4.loss_cls: 0.0323  mix_decode.d4.loss_mask: 0.4481  mix_decode.d4.loss_dice: 0.5130  mix_decode.d5.loss_cls: 0.0325  mix_decode.d5.loss_mask: 0.4428  mix_decode.d5.loss_dice: 0.5137  mix_decode.d6.loss_cls: 0.0431  mix_decode.d6.loss_mask: 0.4449  mix_decode.d6.loss_dice: 0.5114  mix_decode.d7.loss_cls: 0.0468  mix_decode.d7.loss_mask: 0.4449  mix_decode.d7.loss_dice: 0.5107  mix_decode.d8.loss_cls: 0.0230  mix_decode.d8.loss_mask: 0.4472  mix_decode.d8.loss_dice: 0.5177
2025/03/28 15:34:51 - mmengine - INFO - Iter(train) [19900/20000]  base_lr: 8.4936e-07 lr: 8.4936e-07  eta: 0:01:36  time: 1.0808  data_time: 0.0236  memory: 10784  loss: 26.2485  decode.loss_cls: 0.0051  decode.loss_mask: 0.8293  decode.loss_dice: 0.7094  decode.d0.loss_cls: 0.0647  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 0.7050  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.8300  decode.d1.loss_dice: 0.7080  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.8441  decode.d2.loss_dice: 0.7208  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.8448  decode.d3.loss_dice: 0.7182  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.8422  decode.d4.loss_dice: 0.7192  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.8426  decode.d5.loss_dice: 0.7112  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.8348  decode.d6.loss_dice: 0.7122  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.8352  decode.d7.loss_dice: 0.7135  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.8371  decode.d8.loss_dice: 0.7154  mix_decode.loss_cls: 0.0464  mix_decode.loss_mask: 0.4300  mix_decode.loss_dice: 0.5623  mix_decode.d0.loss_cls: 0.1175  mix_decode.d0.loss_mask: 0.4431  mix_decode.d0.loss_dice: 0.5891  mix_decode.d1.loss_cls: 0.0841  mix_decode.d1.loss_mask: 0.4344  mix_decode.d1.loss_dice: 0.5590  mix_decode.d2.loss_cls: 0.0888  mix_decode.d2.loss_mask: 0.4279  mix_decode.d2.loss_dice: 0.5624  mix_decode.d3.loss_cls: 0.0467  mix_decode.d3.loss_mask: 0.4302  mix_decode.d3.loss_dice: 0.5560  mix_decode.d4.loss_cls: 0.0491  mix_decode.d4.loss_mask: 0.4243  mix_decode.d4.loss_dice: 0.5585  mix_decode.d5.loss_cls: 0.0617  mix_decode.d5.loss_mask: 0.4251  mix_decode.d5.loss_dice: 0.5599  mix_decode.d6.loss_cls: 0.0534  mix_decode.d6.loss_mask: 0.4309  mix_decode.d6.loss_dice: 0.5571  mix_decode.d7.loss_cls: 0.0666  mix_decode.d7.loss_mask: 0.4308  mix_decode.d7.loss_dice: 0.5681  mix_decode.d8.loss_cls: 0.0720  mix_decode.d8.loss_mask: 0.4305  mix_decode.d8.loss_dice: 0.5543
2025/03/28 15:35:45 - mmengine - INFO - Iter(train) [19950/20000]  base_lr: 4.5516e-07 lr: 4.5516e-07  eta: 0:00:48  time: 1.0788  data_time: 0.0228  memory: 10774  loss: 25.4288  decode.loss_cls: 0.0105  decode.loss_mask: 0.8093  decode.loss_dice: 0.7379  decode.d0.loss_cls: 0.0716  decode.d0.loss_mask: 0.8150  decode.d0.loss_dice: 0.7284  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.8088  decode.d1.loss_dice: 0.7374  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.8088  decode.d2.loss_dice: 0.7365  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.8095  decode.d3.loss_dice: 0.7404  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.8098  decode.d4.loss_dice: 0.7383  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.8116  decode.d5.loss_dice: 0.7320  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.8076  decode.d6.loss_dice: 0.7352  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.8066  decode.d7.loss_dice: 0.7404  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.8090  decode.d8.loss_dice: 0.7355  mix_decode.loss_cls: 0.0740  mix_decode.loss_mask: 0.4005  mix_decode.loss_dice: 0.4886  mix_decode.d0.loss_cls: 0.1302  mix_decode.d0.loss_mask: 0.4187  mix_decode.d0.loss_dice: 0.5256  mix_decode.d1.loss_cls: 0.1054  mix_decode.d1.loss_mask: 0.4212  mix_decode.d1.loss_dice: 0.5054  mix_decode.d2.loss_cls: 0.0912  mix_decode.d2.loss_mask: 0.4198  mix_decode.d2.loss_dice: 0.4951  mix_decode.d3.loss_cls: 0.0946  mix_decode.d3.loss_mask: 0.3973  mix_decode.d3.loss_dice: 0.4811  mix_decode.d4.loss_cls: 0.0790  mix_decode.d4.loss_mask: 0.3850  mix_decode.d4.loss_dice: 0.4807  mix_decode.d5.loss_cls: 0.0853  mix_decode.d5.loss_mask: 0.3868  mix_decode.d5.loss_dice: 0.4830  mix_decode.d6.loss_cls: 0.0611  mix_decode.d6.loss_mask: 0.3969  mix_decode.d6.loss_dice: 0.4913  mix_decode.d7.loss_cls: 0.0802  mix_decode.d7.loss_mask: 0.3900  mix_decode.d7.loss_dice: 0.4918  mix_decode.d8.loss_cls: 0.0826  mix_decode.d8.loss_mask: 0.3864  mix_decode.d8.loss_dice: 0.4828
2025/03/28 15:36:39 - mmengine - INFO - Exp name: vi2pr_20250328_094846
2025/03/28 15:36:39 - mmengine - INFO - Iter(train) [20000/20000]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 1.0862  data_time: 0.0237  memory: 10780  loss: 27.9987  decode.loss_cls: 0.0067  decode.loss_mask: 0.8532  decode.loss_dice: 0.7424  decode.d0.loss_cls: 0.0545  decode.d0.loss_mask: 0.8566  decode.d0.loss_dice: 0.7452  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.8586  decode.d1.loss_dice: 0.7582  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.8585  decode.d2.loss_dice: 0.7470  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.8603  decode.d3.loss_dice: 0.7487  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.8524  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.8569  decode.d5.loss_dice: 0.7494  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.8588  decode.d6.loss_dice: 0.7448  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.8560  decode.d7.loss_dice: 0.7531  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.8555  decode.d8.loss_dice: 0.7380  mix_decode.loss_cls: 0.1119  mix_decode.loss_mask: 0.4725  mix_decode.loss_dice: 0.5876  mix_decode.d0.loss_cls: 0.0781  mix_decode.d0.loss_mask: 0.4792  mix_decode.d0.loss_dice: 0.6262  mix_decode.d1.loss_cls: 0.0927  mix_decode.d1.loss_mask: 0.4678  mix_decode.d1.loss_dice: 0.6314  mix_decode.d2.loss_cls: 0.1262  mix_decode.d2.loss_mask: 0.4702  mix_decode.d2.loss_dice: 0.5985  mix_decode.d3.loss_cls: 0.1126  mix_decode.d3.loss_mask: 0.4668  mix_decode.d3.loss_dice: 0.5912  mix_decode.d4.loss_cls: 0.0999  mix_decode.d4.loss_mask: 0.4664  mix_decode.d4.loss_dice: 0.5815  mix_decode.d5.loss_cls: 0.1343  mix_decode.d5.loss_mask: 0.4686  mix_decode.d5.loss_dice: 0.5931  mix_decode.d6.loss_cls: 0.1288  mix_decode.d6.loss_mask: 0.4737  mix_decode.d6.loss_dice: 0.6148  mix_decode.d7.loss_cls: 0.1482  mix_decode.d7.loss_mask: 0.4675  mix_decode.d7.loss_dice: 0.5843  mix_decode.d8.loss_cls: 0.0894  mix_decode.d8.loss_mask: 0.4721  mix_decode.d8.loss_dice: 0.6080
2025/03/28 15:36:39 - mmengine - INFO - Saving checkpoint at 20000 iterations
2025/03/28 15:36:44 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:02:48  time: 0.0849  data_time: 0.0019  memory: 3067  
2025/03/28 15:36:48 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:43  time: 0.0853  data_time: 0.0019  memory: 3067  
2025/03/28 15:36:53 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:39  time: 0.0849  data_time: 0.0018  memory: 3067  
2025/03/28 15:36:57 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:35  time: 0.0850  data_time: 0.0018  memory: 3067  
2025/03/28 15:37:01 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:30  time: 0.0849  data_time: 0.0018  memory: 3067  
2025/03/28 15:37:05 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:26  time: 0.0848  data_time: 0.0018  memory: 3067  
2025/03/28 15:37:10 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:21  time: 0.0845  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:14 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:17  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:18 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:13  time: 0.0845  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:22 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:09  time: 0.0852  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:27 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:04  time: 0.0847  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:31 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:00  time: 0.0847  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:35 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:01:56  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:39 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:01:51  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:44 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:47  time: 0.0848  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:48 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:43  time: 0.0849  data_time: 0.0017  memory: 3067  
2025/03/28 15:37:52 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:39  time: 0.0850  data_time: 0.0018  memory: 3067  
2025/03/28 15:37:56 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:34  time: 0.0848  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:01 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:30  time: 0.0849  data_time: 0.0018  memory: 3067  
2025/03/28 15:38:05 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:26  time: 0.0849  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:09 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:22  time: 0.0849  data_time: 0.0018  memory: 3067  
2025/03/28 15:38:13 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:17  time: 0.0849  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:18 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:13  time: 0.0873  data_time: 0.0023  memory: 3067  
2025/03/28 15:38:22 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:09  time: 0.0845  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:26 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:05  time: 0.0845  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:30 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:00  time: 0.0845  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:35 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:00:56  time: 0.0847  data_time: 0.0016  memory: 3067  
2025/03/28 15:38:39 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:52  time: 0.0848  data_time: 0.0016  memory: 3067  
2025/03/28 15:38:43 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:48  time: 0.0847  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:47 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:43  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:52 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:39  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:38:56 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:35  time: 0.0847  data_time: 0.0018  memory: 3067  
2025/03/28 15:39:00 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:31  time: 0.0851  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:04 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:26  time: 0.0848  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:09 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:22  time: 0.0847  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:13 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:18  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:17 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:14  time: 0.0846  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:21 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:09  time: 0.0845  data_time: 0.0016  memory: 3067  
2025/03/28 15:39:26 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:05  time: 0.0845  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:30 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0847  data_time: 0.0017  memory: 3067  
2025/03/28 15:39:31 - mmengine - INFO - per class results:
2025/03/28 15:39:31 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 73.14 | 86.82 |
|      building      | 83.97 | 95.83 |
|   low_vegetation   | 59.15 | 91.79 |
|        tree        | 37.74 | 38.89 |
|        car         | 74.44 | 89.09 |
|      clutter       |  6.41 |  6.57 |
+--------------------+-------+-------+
2025/03/28 15:39:31 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 78.1300  mIoU: 55.8100  mAcc: 68.1700  data_time: 0.0018  time: 0.0849
