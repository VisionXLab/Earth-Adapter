2025/03/31 04:26:24 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda-12.1
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
    PyTorch: 2.1.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.1+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 0
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/03/31 04:26:24 - mmengine - INFO - Config:
crop_size = (
    512,
    512,
)
data_root = '/home/face/kaichengyang/xiaoxinghu/data'
dataset_type = 'ISPRSDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=2000,
        max_keep_ckpts=1,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
exp_name = 'DG_spatial_64_cutoff_0.3_fft_pre6'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        adapter_config=dict(
            cutoff_ratio=0.3,
            dim=64,
            fft_layer=[
                0,
                1,
                2,
                3,
                4,
                5,
            ],
            scale=0.1),
        block_chunks=0,
        depth=24,
        embed_dim=1024,
        ffn_bias=True,
        ffn_layer='mlp',
        img_size=512,
        init_cfg=dict(
            checkpoint='checkpoints/dinov2_converted.pth', type='Pretrained'),
        init_values=1e-05,
        mlp_ratio=4,
        moe_adapter_type='earth_adapter',
        num_heads=16,
        patch_size=16,
        proj_bias=True,
        qkv_bias=True,
        type='MOE_Adpter_DinoVisionTransformer'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            1024,
            1024,
            1024,
            1024,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=6,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(crop_size=(
        512,
        512,
    ), mode='slide', stride=(
        341,
        341,
    )),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 19
optim_wrapper = dict(
    constructor='PEFTOptimWrapperConstructor',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'learnable_tokens': dict(decay_mult=0.0, lr_mult=1.0),
            'level_embed': dict(decay_mult=0.0, lr_mult=1.0),
            'norm': dict(decay_mult=0.0),
            'query_embed': dict(decay_mult=0.0, lr_mult=1.0),
            'reins.scale': dict(decay_mult=0.0, lr_mult=1.0)
        }),
        norm_decay_mult=0.0))
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=20000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=0)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='potsdamRGB/img_dir/val',
            seg_map_path='potsdamRGB/ann_dir/val'),
        data_root='/home/face/kaichengyang/xiaoxinghu/data',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                512,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        512,
        512,
    ), type='Resize'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=2000)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        data_prefix=dict(
            img_path='vaihingen/img_dir/train',
            seg_map_path='vaihingen/ann_dir/train'),
        data_root='/home/face/kaichengyang/xiaoxinghu/data',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    512,
                    512,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    512,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            512,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='potsdamRGB/img_dir/val',
            seg_map_path='potsdamRGB/ann_dir/val'),
        data_root='/home/face/kaichengyang/xiaoxinghu/data',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                512,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ISPRSDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
    dict(type='TensorboardVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
        dict(type='TensorboardVisBackend'),
    ])
work_dir = './work_dirs/vi2pr/DG_spatial_64_cutoff_0.3_fft_pre6/3e441_seed0'

2025/03/31 04:26:28 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/03/31 04:26:28 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.scale
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.1.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.1.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.3.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.3.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.4.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.4.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.5.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.5.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.6.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.6.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.7.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.7.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.8.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.8.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.9.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.9.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.10.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.10.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.11.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.11.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.12.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.12.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.13.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.13.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.14.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.14.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.15.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.15.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.16.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.16.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.17.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.17.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.18.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.18.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.19.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.19.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.20.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.20.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.21.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.21.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.22.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.22.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.23.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.layer_norm.23.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.0.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.1.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.2.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.3.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.4.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.5.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.6.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.7.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.8.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.9.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.10.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.11.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.12.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.13.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.14.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.15.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.16.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.17.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.18.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.19.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.20.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.21.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.22.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list1.23.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.0.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.1.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.2.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.3.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.4.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.5.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.6.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.7.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.8.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.9.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.10.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.11.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.12.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.13.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.14.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.15.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.16.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.17.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.18.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.19.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.20.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.21.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.22.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list2.23.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.0.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.1.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.2.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.3.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.4.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.5.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.6.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.7.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.8.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.9.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.10.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.11.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.12.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.13.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.14.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.15.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.16.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.17.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.18.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.19.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.20.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.21.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.22.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.mlp_list3.23.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.0.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.0.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.1.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.1.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.2.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.2.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.3.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.3.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.4.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.4.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.5.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.5.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.6.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.6.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.7.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.7.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.8.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.8.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.9.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.9.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.10.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.10.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.11.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.11.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.12.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.12.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.13.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.13.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.14.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.14.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.15.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.15.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.16.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.16.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.17.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.17.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.18.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.18.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.19.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.19.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.20.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.20.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.21.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.21.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.22.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.22.bias
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.23.weight
2025/03/31 04:26:29 - mmengine - INFO - set_requires_grad----refine_feat.router.23.bias
2025/03/31 04:26:29 - mmengine - INFO - Total trainable params--9638496, All params--313838176, Ratio--3.1%
2025/03/31 04:26:29 - mmengine - INFO - set_train----.refine_feat
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.scale:num of params=24
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.3.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.4.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.5.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.6.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.7.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.8.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.9.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.10.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.11.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.12.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.13.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.14.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.15.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.16.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.17.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.18.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.19.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.20.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.21.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.22.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.layer_norm.23.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.0.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.1.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.2.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.3.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.4.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.5.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.6.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.7.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.8.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.9.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.10.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.11.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.12.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.13.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.14.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.15.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.16.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.17.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.18.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.19.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.20.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.21.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.22.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list1.23.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.0.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.1.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.2.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.3.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.4.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.5.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.6.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.7.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.8.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.9.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.10.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.11.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.12.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.13.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.14.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.15.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.16.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.17.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.18.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.19.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.20.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.21.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.22.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list2.23.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.0.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.1.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.2.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.3.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.4.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.5.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.6.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.7.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.8.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.9.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.10.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.11.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.12.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.13.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.14.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.15.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.16.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.17.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.18.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.19.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.20.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.21.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.22.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.0.bias:num of params=64
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.mlp_list3.23.2.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.0.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.0.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.1.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.1.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.2.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.2.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.3.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.3.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.4.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.4.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.5.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.5.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.6.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.6.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.7.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.7.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.8.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.8.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.9.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.9.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.10.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.10.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.11.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.11.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.12.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.12.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.13.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.13.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.14.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.14.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.15.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.15.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.16.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.16.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.17.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.17.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.18.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.18.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.19.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.19.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.20.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.20.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.21.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.21.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.22.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.22.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.23.weight:num of params=3072
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- backbone.refine_feat.router.23.bias:num of params=3
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.conv.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.conv.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.conv.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.conv.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.conv.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.conv.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight:num of params=49152
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias:num of params=192
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight:num of params=24576
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias:num of params=96
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight:num of params=49152
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias:num of params=192
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight:num of params=24576
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias:num of params=96
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight:num of params=49152
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias:num of params=192
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight:num of params=24576
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias:num of params=96
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight:num of params=49152
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias:num of params=192
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight:num of params=24576
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias:num of params=96
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight:num of params=49152
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias:num of params=192
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight:num of params=24576
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias:num of params=96
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight:num of params=49152
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias:num of params=192
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight:num of params=24576
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias:num of params=96
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias:num of params=1024
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.level_encoding.weight:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.conv.weight:num of params=262144
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.conv.weight:num of params=589824
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.mask_feature.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.mask_feature.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight:num of params=196608
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias:num of params=2048
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.1.weight:num of params=524288
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.ffn.layers.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:num of params=25600
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:num of params=25600
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:num of params=768
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.cls_embed.weight:num of params=1792
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.cls_embed.bias:num of params=7
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.0.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.0.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.2.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.2.bias:num of params=256
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.4.weight:num of params=65536
2025/03/31 04:26:29 - mmengine - INFO - paramwise_options -- decode_head.mask_embed.4.bias:num of params=256
2025/03/31 04:26:30 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
2025/03/31 04:26:30 - mmengine - INFO - load model from: checkpoints/dinov2_converted.pth
2025/03/31 04:26:30 - mmengine - INFO - Loads checkpoint by local backend from path: checkpoints/dinov2_converted.pth
2025/03/31 04:26:31 - mmengine - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: refine_feat.scale, refine_feat.layer_norm.0.weight, refine_feat.layer_norm.0.bias, refine_feat.layer_norm.1.weight, refine_feat.layer_norm.1.bias, refine_feat.layer_norm.2.weight, refine_feat.layer_norm.2.bias, refine_feat.layer_norm.3.weight, refine_feat.layer_norm.3.bias, refine_feat.layer_norm.4.weight, refine_feat.layer_norm.4.bias, refine_feat.layer_norm.5.weight, refine_feat.layer_norm.5.bias, refine_feat.layer_norm.6.weight, refine_feat.layer_norm.6.bias, refine_feat.layer_norm.7.weight, refine_feat.layer_norm.7.bias, refine_feat.layer_norm.8.weight, refine_feat.layer_norm.8.bias, refine_feat.layer_norm.9.weight, refine_feat.layer_norm.9.bias, refine_feat.layer_norm.10.weight, refine_feat.layer_norm.10.bias, refine_feat.layer_norm.11.weight, refine_feat.layer_norm.11.bias, refine_feat.layer_norm.12.weight, refine_feat.layer_norm.12.bias, refine_feat.layer_norm.13.weight, refine_feat.layer_norm.13.bias, refine_feat.layer_norm.14.weight, refine_feat.layer_norm.14.bias, refine_feat.layer_norm.15.weight, refine_feat.layer_norm.15.bias, refine_feat.layer_norm.16.weight, refine_feat.layer_norm.16.bias, refine_feat.layer_norm.17.weight, refine_feat.layer_norm.17.bias, refine_feat.layer_norm.18.weight, refine_feat.layer_norm.18.bias, refine_feat.layer_norm.19.weight, refine_feat.layer_norm.19.bias, refine_feat.layer_norm.20.weight, refine_feat.layer_norm.20.bias, refine_feat.layer_norm.21.weight, refine_feat.layer_norm.21.bias, refine_feat.layer_norm.22.weight, refine_feat.layer_norm.22.bias, refine_feat.layer_norm.23.weight, refine_feat.layer_norm.23.bias, refine_feat.mlp_list1.0.0.weight, refine_feat.mlp_list1.0.0.bias, refine_feat.mlp_list1.0.2.weight, refine_feat.mlp_list1.0.2.bias, refine_feat.mlp_list1.1.0.weight, refine_feat.mlp_list1.1.0.bias, refine_feat.mlp_list1.1.2.weight, refine_feat.mlp_list1.1.2.bias, refine_feat.mlp_list1.2.0.weight, refine_feat.mlp_list1.2.0.bias, refine_feat.mlp_list1.2.2.weight, refine_feat.mlp_list1.2.2.bias, refine_feat.mlp_list1.3.0.weight, refine_feat.mlp_list1.3.0.bias, refine_feat.mlp_list1.3.2.weight, refine_feat.mlp_list1.3.2.bias, refine_feat.mlp_list1.4.0.weight, refine_feat.mlp_list1.4.0.bias, refine_feat.mlp_list1.4.2.weight, refine_feat.mlp_list1.4.2.bias, refine_feat.mlp_list1.5.0.weight, refine_feat.mlp_list1.5.0.bias, refine_feat.mlp_list1.5.2.weight, refine_feat.mlp_list1.5.2.bias, refine_feat.mlp_list1.6.0.weight, refine_feat.mlp_list1.6.0.bias, refine_feat.mlp_list1.6.2.weight, refine_feat.mlp_list1.6.2.bias, refine_feat.mlp_list1.7.0.weight, refine_feat.mlp_list1.7.0.bias, refine_feat.mlp_list1.7.2.weight, refine_feat.mlp_list1.7.2.bias, refine_feat.mlp_list1.8.0.weight, refine_feat.mlp_list1.8.0.bias, refine_feat.mlp_list1.8.2.weight, refine_feat.mlp_list1.8.2.bias, refine_feat.mlp_list1.9.0.weight, refine_feat.mlp_list1.9.0.bias, refine_feat.mlp_list1.9.2.weight, refine_feat.mlp_list1.9.2.bias, refine_feat.mlp_list1.10.0.weight, refine_feat.mlp_list1.10.0.bias, refine_feat.mlp_list1.10.2.weight, refine_feat.mlp_list1.10.2.bias, refine_feat.mlp_list1.11.0.weight, refine_feat.mlp_list1.11.0.bias, refine_feat.mlp_list1.11.2.weight, refine_feat.mlp_list1.11.2.bias, refine_feat.mlp_list1.12.0.weight, refine_feat.mlp_list1.12.0.bias, refine_feat.mlp_list1.12.2.weight, refine_feat.mlp_list1.12.2.bias, refine_feat.mlp_list1.13.0.weight, refine_feat.mlp_list1.13.0.bias, refine_feat.mlp_list1.13.2.weight, refine_feat.mlp_list1.13.2.bias, refine_feat.mlp_list1.14.0.weight, refine_feat.mlp_list1.14.0.bias, refine_feat.mlp_list1.14.2.weight, refine_feat.mlp_list1.14.2.bias, refine_feat.mlp_list1.15.0.weight, refine_feat.mlp_list1.15.0.bias, refine_feat.mlp_list1.15.2.weight, refine_feat.mlp_list1.15.2.bias, refine_feat.mlp_list1.16.0.weight, refine_feat.mlp_list1.16.0.bias, refine_feat.mlp_list1.16.2.weight, refine_feat.mlp_list1.16.2.bias, refine_feat.mlp_list1.17.0.weight, refine_feat.mlp_list1.17.0.bias, refine_feat.mlp_list1.17.2.weight, refine_feat.mlp_list1.17.2.bias, refine_feat.mlp_list1.18.0.weight, refine_feat.mlp_list1.18.0.bias, refine_feat.mlp_list1.18.2.weight, refine_feat.mlp_list1.18.2.bias, refine_feat.mlp_list1.19.0.weight, refine_feat.mlp_list1.19.0.bias, refine_feat.mlp_list1.19.2.weight, refine_feat.mlp_list1.19.2.bias, refine_feat.mlp_list1.20.0.weight, refine_feat.mlp_list1.20.0.bias, refine_feat.mlp_list1.20.2.weight, refine_feat.mlp_list1.20.2.bias, refine_feat.mlp_list1.21.0.weight, refine_feat.mlp_list1.21.0.bias, refine_feat.mlp_list1.21.2.weight, refine_feat.mlp_list1.21.2.bias, refine_feat.mlp_list1.22.0.weight, refine_feat.mlp_list1.22.0.bias, refine_feat.mlp_list1.22.2.weight, refine_feat.mlp_list1.22.2.bias, refine_feat.mlp_list1.23.0.weight, refine_feat.mlp_list1.23.0.bias, refine_feat.mlp_list1.23.2.weight, refine_feat.mlp_list1.23.2.bias, refine_feat.mlp_list2.0.0.weight, refine_feat.mlp_list2.0.0.bias, refine_feat.mlp_list2.0.2.weight, refine_feat.mlp_list2.0.2.bias, refine_feat.mlp_list2.1.0.weight, refine_feat.mlp_list2.1.0.bias, refine_feat.mlp_list2.1.2.weight, refine_feat.mlp_list2.1.2.bias, refine_feat.mlp_list2.2.0.weight, refine_feat.mlp_list2.2.0.bias, refine_feat.mlp_list2.2.2.weight, refine_feat.mlp_list2.2.2.bias, refine_feat.mlp_list2.3.0.weight, refine_feat.mlp_list2.3.0.bias, refine_feat.mlp_list2.3.2.weight, refine_feat.mlp_list2.3.2.bias, refine_feat.mlp_list2.4.0.weight, refine_feat.mlp_list2.4.0.bias, refine_feat.mlp_list2.4.2.weight, refine_feat.mlp_list2.4.2.bias, refine_feat.mlp_list2.5.0.weight, refine_feat.mlp_list2.5.0.bias, refine_feat.mlp_list2.5.2.weight, refine_feat.mlp_list2.5.2.bias, refine_feat.mlp_list2.6.0.weight, refine_feat.mlp_list2.6.0.bias, refine_feat.mlp_list2.6.2.weight, refine_feat.mlp_list2.6.2.bias, refine_feat.mlp_list2.7.0.weight, refine_feat.mlp_list2.7.0.bias, refine_feat.mlp_list2.7.2.weight, refine_feat.mlp_list2.7.2.bias, refine_feat.mlp_list2.8.0.weight, refine_feat.mlp_list2.8.0.bias, refine_feat.mlp_list2.8.2.weight, refine_feat.mlp_list2.8.2.bias, refine_feat.mlp_list2.9.0.weight, refine_feat.mlp_list2.9.0.bias, refine_feat.mlp_list2.9.2.weight, refine_feat.mlp_list2.9.2.bias, refine_feat.mlp_list2.10.0.weight, refine_feat.mlp_list2.10.0.bias, refine_feat.mlp_list2.10.2.weight, refine_feat.mlp_list2.10.2.bias, refine_feat.mlp_list2.11.0.weight, refine_feat.mlp_list2.11.0.bias, refine_feat.mlp_list2.11.2.weight, refine_feat.mlp_list2.11.2.bias, refine_feat.mlp_list2.12.0.weight, refine_feat.mlp_list2.12.0.bias, refine_feat.mlp_list2.12.2.weight, refine_feat.mlp_list2.12.2.bias, refine_feat.mlp_list2.13.0.weight, refine_feat.mlp_list2.13.0.bias, refine_feat.mlp_list2.13.2.weight, refine_feat.mlp_list2.13.2.bias, refine_feat.mlp_list2.14.0.weight, refine_feat.mlp_list2.14.0.bias, refine_feat.mlp_list2.14.2.weight, refine_feat.mlp_list2.14.2.bias, refine_feat.mlp_list2.15.0.weight, refine_feat.mlp_list2.15.0.bias, refine_feat.mlp_list2.15.2.weight, refine_feat.mlp_list2.15.2.bias, refine_feat.mlp_list2.16.0.weight, refine_feat.mlp_list2.16.0.bias, refine_feat.mlp_list2.16.2.weight, refine_feat.mlp_list2.16.2.bias, refine_feat.mlp_list2.17.0.weight, refine_feat.mlp_list2.17.0.bias, refine_feat.mlp_list2.17.2.weight, refine_feat.mlp_list2.17.2.bias, refine_feat.mlp_list2.18.0.weight, refine_feat.mlp_list2.18.0.bias, refine_feat.mlp_list2.18.2.weight, refine_feat.mlp_list2.18.2.bias, refine_feat.mlp_list2.19.0.weight, refine_feat.mlp_list2.19.0.bias, refine_feat.mlp_list2.19.2.weight, refine_feat.mlp_list2.19.2.bias, refine_feat.mlp_list2.20.0.weight, refine_feat.mlp_list2.20.0.bias, refine_feat.mlp_list2.20.2.weight, refine_feat.mlp_list2.20.2.bias, refine_feat.mlp_list2.21.0.weight, refine_feat.mlp_list2.21.0.bias, refine_feat.mlp_list2.21.2.weight, refine_feat.mlp_list2.21.2.bias, refine_feat.mlp_list2.22.0.weight, refine_feat.mlp_list2.22.0.bias, refine_feat.mlp_list2.22.2.weight, refine_feat.mlp_list2.22.2.bias, refine_feat.mlp_list2.23.0.weight, refine_feat.mlp_list2.23.0.bias, refine_feat.mlp_list2.23.2.weight, refine_feat.mlp_list2.23.2.bias, refine_feat.mlp_list3.0.0.weight, refine_feat.mlp_list3.0.0.bias, refine_feat.mlp_list3.0.2.weight, refine_feat.mlp_list3.0.2.bias, refine_feat.mlp_list3.1.0.weight, refine_feat.mlp_list3.1.0.bias, refine_feat.mlp_list3.1.2.weight, refine_feat.mlp_list3.1.2.bias, refine_feat.mlp_list3.2.0.weight, refine_feat.mlp_list3.2.0.bias, refine_feat.mlp_list3.2.2.weight, refine_feat.mlp_list3.2.2.bias, refine_feat.mlp_list3.3.0.weight, refine_feat.mlp_list3.3.0.bias, refine_feat.mlp_list3.3.2.weight, refine_feat.mlp_list3.3.2.bias, refine_feat.mlp_list3.4.0.weight, refine_feat.mlp_list3.4.0.bias, refine_feat.mlp_list3.4.2.weight, refine_feat.mlp_list3.4.2.bias, refine_feat.mlp_list3.5.0.weight, refine_feat.mlp_list3.5.0.bias, refine_feat.mlp_list3.5.2.weight, refine_feat.mlp_list3.5.2.bias, refine_feat.mlp_list3.6.0.weight, refine_feat.mlp_list3.6.0.bias, refine_feat.mlp_list3.6.2.weight, refine_feat.mlp_list3.6.2.bias, refine_feat.mlp_list3.7.0.weight, refine_feat.mlp_list3.7.0.bias, refine_feat.mlp_list3.7.2.weight, refine_feat.mlp_list3.7.2.bias, refine_feat.mlp_list3.8.0.weight, refine_feat.mlp_list3.8.0.bias, refine_feat.mlp_list3.8.2.weight, refine_feat.mlp_list3.8.2.bias, refine_feat.mlp_list3.9.0.weight, refine_feat.mlp_list3.9.0.bias, refine_feat.mlp_list3.9.2.weight, refine_feat.mlp_list3.9.2.bias, refine_feat.mlp_list3.10.0.weight, refine_feat.mlp_list3.10.0.bias, refine_feat.mlp_list3.10.2.weight, refine_feat.mlp_list3.10.2.bias, refine_feat.mlp_list3.11.0.weight, refine_feat.mlp_list3.11.0.bias, refine_feat.mlp_list3.11.2.weight, refine_feat.mlp_list3.11.2.bias, refine_feat.mlp_list3.12.0.weight, refine_feat.mlp_list3.12.0.bias, refine_feat.mlp_list3.12.2.weight, refine_feat.mlp_list3.12.2.bias, refine_feat.mlp_list3.13.0.weight, refine_feat.mlp_list3.13.0.bias, refine_feat.mlp_list3.13.2.weight, refine_feat.mlp_list3.13.2.bias, refine_feat.mlp_list3.14.0.weight, refine_feat.mlp_list3.14.0.bias, refine_feat.mlp_list3.14.2.weight, refine_feat.mlp_list3.14.2.bias, refine_feat.mlp_list3.15.0.weight, refine_feat.mlp_list3.15.0.bias, refine_feat.mlp_list3.15.2.weight, refine_feat.mlp_list3.15.2.bias, refine_feat.mlp_list3.16.0.weight, refine_feat.mlp_list3.16.0.bias, refine_feat.mlp_list3.16.2.weight, refine_feat.mlp_list3.16.2.bias, refine_feat.mlp_list3.17.0.weight, refine_feat.mlp_list3.17.0.bias, refine_feat.mlp_list3.17.2.weight, refine_feat.mlp_list3.17.2.bias, refine_feat.mlp_list3.18.0.weight, refine_feat.mlp_list3.18.0.bias, refine_feat.mlp_list3.18.2.weight, refine_feat.mlp_list3.18.2.bias, refine_feat.mlp_list3.19.0.weight, refine_feat.mlp_list3.19.0.bias, refine_feat.mlp_list3.19.2.weight, refine_feat.mlp_list3.19.2.bias, refine_feat.mlp_list3.20.0.weight, refine_feat.mlp_list3.20.0.bias, refine_feat.mlp_list3.20.2.weight, refine_feat.mlp_list3.20.2.bias, refine_feat.mlp_list3.21.0.weight, refine_feat.mlp_list3.21.0.bias, refine_feat.mlp_list3.21.2.weight, refine_feat.mlp_list3.21.2.bias, refine_feat.mlp_list3.22.0.weight, refine_feat.mlp_list3.22.0.bias, refine_feat.mlp_list3.22.2.weight, refine_feat.mlp_list3.22.2.bias, refine_feat.mlp_list3.23.0.weight, refine_feat.mlp_list3.23.0.bias, refine_feat.mlp_list3.23.2.weight, refine_feat.mlp_list3.23.2.bias, refine_feat.router.0.weight, refine_feat.router.0.bias, refine_feat.router.1.weight, refine_feat.router.1.bias, refine_feat.router.2.weight, refine_feat.router.2.bias, refine_feat.router.3.weight, refine_feat.router.3.bias, refine_feat.router.4.weight, refine_feat.router.4.bias, refine_feat.router.5.weight, refine_feat.router.5.bias, refine_feat.router.6.weight, refine_feat.router.6.bias, refine_feat.router.7.weight, refine_feat.router.7.bias, refine_feat.router.8.weight, refine_feat.router.8.bias, refine_feat.router.9.weight, refine_feat.router.9.bias, refine_feat.router.10.weight, refine_feat.router.10.bias, refine_feat.router.11.weight, refine_feat.router.11.bias, refine_feat.router.12.weight, refine_feat.router.12.bias, refine_feat.router.13.weight, refine_feat.router.13.bias, refine_feat.router.14.weight, refine_feat.router.14.bias, refine_feat.router.15.weight, refine_feat.router.15.bias, refine_feat.router.16.weight, refine_feat.router.16.bias, refine_feat.router.17.weight, refine_feat.router.17.bias, refine_feat.router.18.weight, refine_feat.router.18.bias, refine_feat.router.19.weight, refine_feat.router.19.bias, refine_feat.router.20.weight, refine_feat.router.20.bias, refine_feat.router.21.weight, refine_feat.router.21.bias, refine_feat.router.22.weight, refine_feat.router.22.bias, refine_feat.router.23.weight, refine_feat.router.23.bias

Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.pos_embed - torch.Size([1, 1025, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.mask_token - torch.Size([1, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.patch_embed.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.0.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.1.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.2.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.3.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.4.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.5.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.6.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.7.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.8.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.9.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.10.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.11.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.12.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.13.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.14.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.15.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.16.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.17.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.18.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.19.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.20.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.21.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.22.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm1.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm1.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.qkv.weight - torch.Size([3072, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.qkv.bias - torch.Size([3072]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.attn.proj.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.ls1.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm2.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.norm2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc1.weight - torch.Size([4096, 1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc1.bias - torch.Size([4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc2.weight - torch.Size([1024, 4096]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.mlp.fc2.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.blocks.23.ls2.gamma - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.norm.weight - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.norm.bias - torch.Size([1024]): 
PretrainedInit: load from checkpoints/dinov2_converted.pth 

backbone.refine_feat.scale - torch.Size([24]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.0.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.4.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.4.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.5.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.5.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.6.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.6.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.7.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.7.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.8.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.8.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.9.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.9.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.10.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.10.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.11.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.11.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.12.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.12.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.13.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.13.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.14.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.14.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.15.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.15.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.16.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.16.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.17.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.17.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.18.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.18.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.19.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.19.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.20.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.20.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.21.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.21.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.22.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.22.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.23.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.layer_norm.23.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list1.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list2.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.0.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.1.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.2.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.3.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.4.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.5.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.6.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.7.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.8.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.9.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.10.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.11.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.12.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.13.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.14.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.15.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.16.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.17.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.18.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.19.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.20.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.21.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.22.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.0.weight - torch.Size([64, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.2.weight - torch.Size([1024, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.mlp_list3.23.2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.0.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.1.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.2.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.2.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.3.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.3.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.4.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.4.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.5.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.5.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.6.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.6.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.7.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.7.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.8.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.8.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.9.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.9.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.10.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.10.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.11.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.11.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.12.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.12.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.13.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.13.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.14.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.14.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.15.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.15.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.16.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.16.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.17.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.17.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.18.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.18.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.19.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.19.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.20.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.20.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.21.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.21.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.22.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.22.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.23.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.refine_feat.router.23.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([7, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2025/03/31 04:26:31 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/03/31 04:26:31 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/03/31 04:26:31 - mmengine - INFO - Checkpoints will be saved to /home/face/kaichengyang/xiaoxinghu/Earth_Adapter/work_dirs/vi2pr/DG_spatial_64_cutoff_0.3_fft_pre6/3e441_seed0.
2025/03/31 04:27:16 - mmengine - INFO - Iter(train) [   50/20000]  base_lr: 9.9779e-05 lr: 9.9779e-05  eta: 4:59:25  time: 0.8780  data_time: 0.0196  memory: 10147  loss: 64.0582  decode.loss_cls: 1.7532  decode.loss_mask: 2.3916  decode.loss_dice: 3.1200  decode.d0.loss_cls: 3.4691  decode.d0.loss_mask: 2.1580  decode.d0.loss_dice: 2.9309  decode.d1.loss_cls: 0.9526  decode.d1.loss_mask: 2.1342  decode.d1.loss_dice: 2.7997  decode.d2.loss_cls: 0.8130  decode.d2.loss_mask: 2.1663  decode.d2.loss_dice: 2.7151  decode.d3.loss_cls: 0.7214  decode.d3.loss_mask: 2.2511  decode.d3.loss_dice: 2.7870  decode.d4.loss_cls: 0.7296  decode.d4.loss_mask: 2.2938  decode.d4.loss_dice: 2.8175  decode.d5.loss_cls: 0.7702  decode.d5.loss_mask: 2.3038  decode.d5.loss_dice: 2.8473  decode.d6.loss_cls: 0.8737  decode.d6.loss_mask: 2.3115  decode.d6.loss_dice: 2.8693  decode.d7.loss_cls: 1.0462  decode.d7.loss_mask: 2.3657  decode.d7.loss_dice: 2.9810  decode.d8.loss_cls: 1.3614  decode.d8.loss_mask: 2.3128  decode.d8.loss_dice: 3.0111
2025/03/31 04:27:47 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 04:27:59 - mmengine - INFO - Iter(train) [  100/20000]  base_lr: 9.9554e-05 lr: 9.9554e-05  eta: 4:52:03  time: 0.8577  data_time: 0.0160  memory: 10141  loss: 45.9877  decode.loss_cls: 0.4415  decode.loss_mask: 1.8390  decode.loss_dice: 2.1855  decode.d0.loss_cls: 3.2299  decode.d0.loss_mask: 1.7325  decode.d0.loss_dice: 2.2925  decode.d1.loss_cls: 0.4049  decode.d1.loss_mask: 1.7479  decode.d1.loss_dice: 2.0929  decode.d2.loss_cls: 0.3700  decode.d2.loss_mask: 1.7847  decode.d2.loss_dice: 2.0733  decode.d3.loss_cls: 0.3288  decode.d3.loss_mask: 1.8223  decode.d3.loss_dice: 2.0965  decode.d4.loss_cls: 0.3185  decode.d4.loss_mask: 1.8100  decode.d4.loss_dice: 2.0974  decode.d5.loss_cls: 0.3270  decode.d5.loss_mask: 1.8042  decode.d5.loss_dice: 2.1152  decode.d6.loss_cls: 0.3633  decode.d6.loss_mask: 1.8493  decode.d6.loss_dice: 2.0989  decode.d7.loss_cls: 0.3719  decode.d7.loss_mask: 1.8503  decode.d7.loss_dice: 2.1268  decode.d8.loss_cls: 0.3819  decode.d8.loss_mask: 1.8559  decode.d8.loss_dice: 2.1750
2025/03/31 04:28:43 - mmengine - INFO - Iter(train) [  150/20000]  base_lr: 9.9329e-05 lr: 9.9329e-05  eta: 4:49:48  time: 0.8581  data_time: 0.0162  memory: 10139  loss: 42.1851  decode.loss_cls: 0.2002  decode.loss_mask: 1.8063  decode.loss_dice: 1.9631  decode.d0.loss_cls: 3.0146  decode.d0.loss_mask: 1.6986  decode.d0.loss_dice: 2.0542  decode.d1.loss_cls: 0.2313  decode.d1.loss_mask: 1.7879  decode.d1.loss_dice: 2.0154  decode.d2.loss_cls: 0.2466  decode.d2.loss_mask: 1.7396  decode.d2.loss_dice: 1.9000  decode.d3.loss_cls: 0.2310  decode.d3.loss_mask: 1.7417  decode.d3.loss_dice: 1.8860  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 1.7379  decode.d4.loss_dice: 1.9495  decode.d5.loss_cls: 0.2055  decode.d5.loss_mask: 1.7635  decode.d5.loss_dice: 1.9696  decode.d6.loss_cls: 0.2022  decode.d6.loss_mask: 1.7833  decode.d6.loss_dice: 1.9642  decode.d7.loss_cls: 0.1915  decode.d7.loss_mask: 1.7842  decode.d7.loss_dice: 1.9449  decode.d8.loss_cls: 0.1876  decode.d8.loss_mask: 1.8038  decode.d8.loss_dice: 1.9616
2025/03/31 04:29:26 - mmengine - INFO - Iter(train) [  200/20000]  base_lr: 9.9104e-05 lr: 9.9104e-05  eta: 4:47:52  time: 0.8577  data_time: 0.0162  memory: 10090  loss: 38.2058  decode.loss_cls: 0.2135  decode.loss_mask: 1.6362  decode.loss_dice: 1.7125  decode.d0.loss_cls: 2.9124  decode.d0.loss_mask: 1.5309  decode.d0.loss_dice: 1.7574  decode.d1.loss_cls: 0.2771  decode.d1.loss_mask: 1.5869  decode.d1.loss_dice: 1.7173  decode.d2.loss_cls: 0.2605  decode.d2.loss_mask: 1.6084  decode.d2.loss_dice: 1.6552  decode.d3.loss_cls: 0.2176  decode.d3.loss_mask: 1.6186  decode.d3.loss_dice: 1.6792  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 1.6278  decode.d4.loss_dice: 1.7219  decode.d5.loss_cls: 0.2044  decode.d5.loss_mask: 1.6262  decode.d5.loss_dice: 1.7272  decode.d6.loss_cls: 0.2259  decode.d6.loss_mask: 1.6348  decode.d6.loss_dice: 1.7150  decode.d7.loss_cls: 0.2161  decode.d7.loss_mask: 1.6354  decode.d7.loss_dice: 1.6966  decode.d8.loss_cls: 0.2446  decode.d8.loss_mask: 1.6175  decode.d8.loss_dice: 1.7248
2025/03/31 04:30:09 - mmengine - INFO - Iter(train) [  250/20000]  base_lr: 9.8879e-05 lr: 9.8879e-05  eta: 4:46:21  time: 0.8593  data_time: 0.0160  memory: 10094  loss: 37.4360  decode.loss_cls: 0.1477  decode.loss_mask: 1.5752  decode.loss_dice: 1.8174  decode.d0.loss_cls: 2.6017  decode.d0.loss_mask: 1.5328  decode.d0.loss_dice: 1.7979  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 1.5666  decode.d1.loss_dice: 1.7699  decode.d2.loss_cls: 0.1407  decode.d2.loss_mask: 1.5701  decode.d2.loss_dice: 1.7538  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 1.5842  decode.d3.loss_dice: 1.7875  decode.d4.loss_cls: 0.1166  decode.d4.loss_mask: 1.5833  decode.d4.loss_dice: 1.7973  decode.d5.loss_cls: 0.1102  decode.d5.loss_mask: 1.5723  decode.d5.loss_dice: 1.8028  decode.d6.loss_cls: 0.1048  decode.d6.loss_mask: 1.5919  decode.d6.loss_dice: 1.8068  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 1.5661  decode.d7.loss_dice: 1.8022  decode.d8.loss_cls: 0.1344  decode.d8.loss_mask: 1.5821  decode.d8.loss_dice: 1.8011
2025/03/31 04:30:52 - mmengine - INFO - Iter(train) [  300/20000]  base_lr: 9.8653e-05 lr: 9.8653e-05  eta: 4:45:13  time: 0.8616  data_time: 0.0159  memory: 10095  loss: 35.8404  decode.loss_cls: 0.1154  decode.loss_mask: 1.5650  decode.loss_dice: 1.6639  decode.d0.loss_cls: 2.5067  decode.d0.loss_mask: 1.5131  decode.d0.loss_dice: 1.7092  decode.d1.loss_cls: 0.1867  decode.d1.loss_mask: 1.5480  decode.d1.loss_dice: 1.6565  decode.d2.loss_cls: 0.1545  decode.d2.loss_mask: 1.5656  decode.d2.loss_dice: 1.6371  decode.d3.loss_cls: 0.1239  decode.d3.loss_mask: 1.5598  decode.d3.loss_dice: 1.6500  decode.d4.loss_cls: 0.1123  decode.d4.loss_mask: 1.5565  decode.d4.loss_dice: 1.6620  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 1.5664  decode.d5.loss_dice: 1.6618  decode.d6.loss_cls: 0.1195  decode.d6.loss_mask: 1.5551  decode.d6.loss_dice: 1.6737  decode.d7.loss_cls: 0.1190  decode.d7.loss_mask: 1.5466  decode.d7.loss_dice: 1.6699  decode.d8.loss_cls: 0.1169  decode.d8.loss_mask: 1.5452  decode.d8.loss_dice: 1.6686
2025/03/31 04:31:35 - mmengine - INFO - Iter(train) [  350/20000]  base_lr: 9.8428e-05 lr: 9.8428e-05  eta: 4:44:10  time: 0.8605  data_time: 0.0160  memory: 10140  loss: 36.3467  decode.loss_cls: 0.0627  decode.loss_mask: 1.7164  decode.loss_dice: 1.6352  decode.d0.loss_cls: 2.3475  decode.d0.loss_mask: 1.6654  decode.d0.loss_dice: 1.6406  decode.d1.loss_cls: 0.0982  decode.d1.loss_mask: 1.6930  decode.d1.loss_dice: 1.6478  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 1.7109  decode.d2.loss_dice: 1.6130  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 1.6993  decode.d3.loss_dice: 1.6218  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 1.7119  decode.d4.loss_dice: 1.6277  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 1.7139  decode.d5.loss_dice: 1.6516  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 1.7088  decode.d6.loss_dice: 1.6591  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 1.7106  decode.d7.loss_dice: 1.6528  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 1.7170  decode.d8.loss_dice: 1.6352
2025/03/31 04:32:18 - mmengine - INFO - Iter(train) [  400/20000]  base_lr: 9.8203e-05 lr: 9.8203e-05  eta: 4:43:12  time: 0.8624  data_time: 0.0163  memory: 10147  loss: 34.3877  decode.loss_cls: 0.0956  decode.loss_mask: 1.4973  decode.loss_dice: 1.6164  decode.d0.loss_cls: 2.1960  decode.d0.loss_mask: 1.4411  decode.d0.loss_dice: 1.6712  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 1.4930  decode.d1.loss_dice: 1.6339  decode.d2.loss_cls: 0.1021  decode.d2.loss_mask: 1.5141  decode.d2.loss_dice: 1.6257  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 1.5195  decode.d3.loss_dice: 1.6326  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 1.5181  decode.d4.loss_dice: 1.6400  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 1.5146  decode.d5.loss_dice: 1.6339  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 1.5159  decode.d6.loss_dice: 1.6312  decode.d7.loss_cls: 0.0815  decode.d7.loss_mask: 1.5069  decode.d7.loss_dice: 1.6278  decode.d8.loss_cls: 0.0860  decode.d8.loss_mask: 1.5124  decode.d8.loss_dice: 1.6382
2025/03/31 04:33:01 - mmengine - INFO - Iter(train) [  450/20000]  base_lr: 9.7977e-05 lr: 9.7977e-05  eta: 4:42:12  time: 0.8585  data_time: 0.0160  memory: 10141  loss: 33.7914  decode.loss_cls: 0.0736  decode.loss_mask: 1.5093  decode.loss_dice: 1.6045  decode.d0.loss_cls: 2.0580  decode.d0.loss_mask: 1.4583  decode.d0.loss_dice: 1.5767  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 1.4742  decode.d1.loss_dice: 1.5645  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 1.4973  decode.d2.loss_dice: 1.5800  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 1.5227  decode.d3.loss_dice: 1.5765  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 1.5306  decode.d4.loss_dice: 1.6192  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 1.5272  decode.d5.loss_dice: 1.6162  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 1.5269  decode.d6.loss_dice: 1.5966  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 1.5461  decode.d7.loss_dice: 1.5930  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 1.5340  decode.d8.loss_dice: 1.5883
2025/03/31 04:33:44 - mmengine - INFO - Iter(train) [  500/20000]  base_lr: 9.7752e-05 lr: 9.7752e-05  eta: 4:41:19  time: 0.8617  data_time: 0.0162  memory: 10140  loss: 33.1534  decode.loss_cls: 0.0633  decode.loss_mask: 1.5337  decode.loss_dice: 1.5447  decode.d0.loss_cls: 1.9028  decode.d0.loss_mask: 1.5183  decode.d0.loss_dice: 1.5469  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 1.5336  decode.d1.loss_dice: 1.5141  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 1.5384  decode.d2.loss_dice: 1.5179  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 1.5364  decode.d3.loss_dice: 1.5352  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 1.5310  decode.d4.loss_dice: 1.5597  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 1.5357  decode.d5.loss_dice: 1.5523  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 1.5180  decode.d6.loss_dice: 1.5510  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 1.5297  decode.d7.loss_dice: 1.5587  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 1.5245  decode.d8.loss_dice: 1.5619
2025/03/31 04:34:27 - mmengine - INFO - Iter(train) [  550/20000]  base_lr: 9.7526e-05 lr: 9.7526e-05  eta: 4:40:26  time: 0.8589  data_time: 0.0159  memory: 10148  loss: 31.7295  decode.loss_cls: 0.0683  decode.loss_mask: 1.3584  decode.loss_dice: 1.5886  decode.d0.loss_cls: 1.7757  decode.d0.loss_mask: 1.3277  decode.d0.loss_dice: 1.6108  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 1.3434  decode.d1.loss_dice: 1.5885  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 1.3474  decode.d2.loss_dice: 1.5758  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 1.3533  decode.d3.loss_dice: 1.5811  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 1.3541  decode.d4.loss_dice: 1.5674  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 1.3541  decode.d5.loss_dice: 1.5648  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 1.3607  decode.d6.loss_dice: 1.5617  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 1.3574  decode.d7.loss_dice: 1.5723  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 1.3550  decode.d8.loss_dice: 1.5790
2025/03/31 04:35:10 - mmengine - INFO - Iter(train) [  600/20000]  base_lr: 9.7300e-05 lr: 9.7300e-05  eta: 4:39:35  time: 0.8598  data_time: 0.0160  memory: 10147  loss: 30.1330  decode.loss_cls: 0.0421  decode.loss_mask: 1.3615  decode.loss_dice: 1.4554  decode.d0.loss_cls: 1.6265  decode.d0.loss_mask: 1.3653  decode.d0.loss_dice: 1.4726  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 1.3621  decode.d1.loss_dice: 1.4459  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 1.3566  decode.d2.loss_dice: 1.4369  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 1.3481  decode.d3.loss_dice: 1.4433  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 1.3649  decode.d4.loss_dice: 1.4519  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 1.3686  decode.d5.loss_dice: 1.4391  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 1.3733  decode.d6.loss_dice: 1.4424  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 1.3652  decode.d7.loss_dice: 1.4403  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 1.3675  decode.d8.loss_dice: 1.4637
2025/03/31 04:35:53 - mmengine - INFO - Iter(train) [  650/20000]  base_lr: 9.7075e-05 lr: 9.7075e-05  eta: 4:38:48  time: 0.8621  data_time: 0.0170  memory: 10143  loss: 31.7370  decode.loss_cls: 0.0725  decode.loss_mask: 1.4436  decode.loss_dice: 1.5244  decode.d0.loss_cls: 1.4956  decode.d0.loss_mask: 1.4405  decode.d0.loss_dice: 1.5482  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 1.4447  decode.d1.loss_dice: 1.5297  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 1.4643  decode.d2.loss_dice: 1.5243  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 1.4599  decode.d3.loss_dice: 1.5205  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 1.4511  decode.d4.loss_dice: 1.5223  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 1.4499  decode.d5.loss_dice: 1.5042  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 1.4502  decode.d6.loss_dice: 1.5126  decode.d7.loss_cls: 0.0574  decode.d7.loss_mask: 1.4456  decode.d7.loss_dice: 1.5120  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 1.4524  decode.d8.loss_dice: 1.5121
2025/03/31 04:36:36 - mmengine - INFO - Iter(train) [  700/20000]  base_lr: 9.6849e-05 lr: 9.6849e-05  eta: 4:38:01  time: 0.8651  data_time: 0.0161  memory: 10140  loss: 30.0314  decode.loss_cls: 0.0740  decode.loss_mask: 1.3599  decode.loss_dice: 1.4572  decode.d0.loss_cls: 1.3659  decode.d0.loss_mask: 1.3480  decode.d0.loss_dice: 1.4826  decode.d1.loss_cls: 0.0777  decode.d1.loss_mask: 1.3480  decode.d1.loss_dice: 1.4579  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 1.3483  decode.d2.loss_dice: 1.4230  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 1.3565  decode.d3.loss_dice: 1.4278  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 1.3495  decode.d4.loss_dice: 1.4515  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 1.3530  decode.d5.loss_dice: 1.4546  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 1.3582  decode.d6.loss_dice: 1.4558  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 1.3554  decode.d7.loss_dice: 1.4572  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 1.3583  decode.d8.loss_dice: 1.4483
2025/03/31 04:37:19 - mmengine - INFO - Iter(train) [  750/20000]  base_lr: 9.6623e-05 lr: 9.6623e-05  eta: 4:37:19  time: 0.8608  data_time: 0.0161  memory: 10139  loss: 29.1914  decode.loss_cls: 0.0779  decode.loss_mask: 1.3504  decode.loss_dice: 1.3913  decode.d0.loss_cls: 1.2575  decode.d0.loss_mask: 1.3459  decode.d0.loss_dice: 1.3843  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 1.3460  decode.d1.loss_dice: 1.3620  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 1.3523  decode.d2.loss_dice: 1.3672  decode.d3.loss_cls: 0.0653  decode.d3.loss_mask: 1.3454  decode.d3.loss_dice: 1.3704  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 1.3508  decode.d4.loss_dice: 1.3865  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 1.3493  decode.d5.loss_dice: 1.3800  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 1.3395  decode.d6.loss_dice: 1.3727  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 1.3454  decode.d7.loss_dice: 1.3709  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 1.3469  decode.d8.loss_dice: 1.3655
2025/03/31 04:38:03 - mmengine - INFO - Iter(train) [  800/20000]  base_lr: 9.6397e-05 lr: 9.6397e-05  eta: 4:36:36  time: 0.8682  data_time: 0.0162  memory: 10092  loss: 30.4204  decode.loss_cls: 0.1622  decode.loss_mask: 1.3669  decode.loss_dice: 1.4365  decode.d0.loss_cls: 1.1759  decode.d0.loss_mask: 1.3630  decode.d0.loss_dice: 1.4586  decode.d1.loss_cls: 0.1479  decode.d1.loss_mask: 1.3420  decode.d1.loss_dice: 1.4300  decode.d2.loss_cls: 0.1466  decode.d2.loss_mask: 1.3436  decode.d2.loss_dice: 1.4222  decode.d3.loss_cls: 0.1346  decode.d3.loss_mask: 1.3630  decode.d3.loss_dice: 1.4356  decode.d4.loss_cls: 0.1474  decode.d4.loss_mask: 1.3473  decode.d4.loss_dice: 1.4354  decode.d5.loss_cls: 0.1405  decode.d5.loss_mask: 1.3549  decode.d5.loss_dice: 1.4251  decode.d6.loss_cls: 0.1502  decode.d6.loss_mask: 1.3582  decode.d6.loss_dice: 1.4301  decode.d7.loss_cls: 0.1523  decode.d7.loss_mask: 1.3717  decode.d7.loss_dice: 1.4243  decode.d8.loss_cls: 0.1508  decode.d8.loss_mask: 1.3754  decode.d8.loss_dice: 1.4282
2025/03/31 04:38:46 - mmengine - INFO - Iter(train) [  850/20000]  base_lr: 9.6171e-05 lr: 9.6171e-05  eta: 4:35:51  time: 0.8605  data_time: 0.0158  memory: 10135  loss: 29.9354  decode.loss_cls: 0.0751  decode.loss_mask: 1.3625  decode.loss_dice: 1.4533  decode.d0.loss_cls: 1.0526  decode.d0.loss_mask: 1.3835  decode.d0.loss_dice: 1.5146  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 1.3720  decode.d1.loss_dice: 1.4550  decode.d2.loss_cls: 0.1066  decode.d2.loss_mask: 1.3573  decode.d2.loss_dice: 1.4431  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 1.3593  decode.d3.loss_dice: 1.4392  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 1.3635  decode.d4.loss_dice: 1.4631  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 1.3665  decode.d5.loss_dice: 1.4469  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 1.3742  decode.d6.loss_dice: 1.4478  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 1.3651  decode.d7.loss_dice: 1.4427  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 1.3653  decode.d8.loss_dice: 1.4490
2025/03/31 04:39:29 - mmengine - INFO - Iter(train) [  900/20000]  base_lr: 9.5945e-05 lr: 9.5945e-05  eta: 4:35:08  time: 0.8596  data_time: 0.0157  memory: 10140  loss: 30.5443  decode.loss_cls: 0.1179  decode.loss_mask: 1.3671  decode.loss_dice: 1.4888  decode.d0.loss_cls: 0.9726  decode.d0.loss_mask: 1.3857  decode.d0.loss_dice: 1.4738  decode.d1.loss_cls: 0.1072  decode.d1.loss_mask: 1.3802  decode.d1.loss_dice: 1.4839  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 1.3677  decode.d2.loss_dice: 1.4933  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 1.3715  decode.d3.loss_dice: 1.4786  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 1.3728  decode.d4.loss_dice: 1.5003  decode.d5.loss_cls: 0.1012  decode.d5.loss_mask: 1.3651  decode.d5.loss_dice: 1.5097  decode.d6.loss_cls: 0.1075  decode.d6.loss_mask: 1.3658  decode.d6.loss_dice: 1.4763  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 1.3744  decode.d7.loss_dice: 1.4911  decode.d8.loss_cls: 0.1172  decode.d8.loss_mask: 1.3734  decode.d8.loss_dice: 1.4787
2025/03/31 04:40:12 - mmengine - INFO - Iter(train) [  950/20000]  base_lr: 9.5719e-05 lr: 9.5719e-05  eta: 4:34:23  time: 0.8630  data_time: 0.0158  memory: 10090  loss: 29.4026  decode.loss_cls: 0.0581  decode.loss_mask: 1.3310  decode.loss_dice: 1.4824  decode.d0.loss_cls: 0.8631  decode.d0.loss_mask: 1.3314  decode.d0.loss_dice: 1.4759  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 1.3258  decode.d1.loss_dice: 1.4555  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 1.3245  decode.d2.loss_dice: 1.4733  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 1.3251  decode.d3.loss_dice: 1.4786  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 1.3212  decode.d4.loss_dice: 1.4836  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 1.3205  decode.d5.loss_dice: 1.4685  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 1.3235  decode.d6.loss_dice: 1.4693  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 1.3256  decode.d7.loss_dice: 1.4613  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 1.3203  decode.d8.loss_dice: 1.4740
2025/03/31 04:40:56 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 04:40:56 - mmengine - INFO - Iter(train) [ 1000/20000]  base_lr: 9.5493e-05 lr: 9.5493e-05  eta: 4:33:50  time: 0.8631  data_time: 0.0164  memory: 10096  loss: 26.8275  decode.loss_cls: 0.0991  decode.loss_mask: 1.2974  decode.loss_dice: 1.2424  decode.d0.loss_cls: 0.7892  decode.d0.loss_mask: 1.2700  decode.d0.loss_dice: 1.2464  decode.d1.loss_cls: 0.0839  decode.d1.loss_mask: 1.2898  decode.d1.loss_dice: 1.2348  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 1.2931  decode.d2.loss_dice: 1.2422  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 1.2881  decode.d3.loss_dice: 1.2406  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 1.2960  decode.d4.loss_dice: 1.2457  decode.d5.loss_cls: 0.0869  decode.d5.loss_mask: 1.2910  decode.d5.loss_dice: 1.2275  decode.d6.loss_cls: 0.0933  decode.d6.loss_mask: 1.2942  decode.d6.loss_dice: 1.2226  decode.d7.loss_cls: 0.0888  decode.d7.loss_mask: 1.2942  decode.d7.loss_dice: 1.2287  decode.d8.loss_cls: 0.0957  decode.d8.loss_mask: 1.2940  decode.d8.loss_dice: 1.2189
2025/03/31 04:41:39 - mmengine - INFO - Iter(train) [ 1050/20000]  base_lr: 9.5267e-05 lr: 9.5267e-05  eta: 4:33:03  time: 0.8601  data_time: 0.0158  memory: 10140  loss: 27.5410  decode.loss_cls: 0.0414  decode.loss_mask: 1.3044  decode.loss_dice: 1.3482  decode.d0.loss_cls: 0.7082  decode.d0.loss_mask: 1.2933  decode.d0.loss_dice: 1.3713  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 1.2935  decode.d1.loss_dice: 1.3493  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 1.2963  decode.d2.loss_dice: 1.3273  decode.d3.loss_cls: 0.0301  decode.d3.loss_mask: 1.2991  decode.d3.loss_dice: 1.3443  decode.d4.loss_cls: 0.0323  decode.d4.loss_mask: 1.3073  decode.d4.loss_dice: 1.3574  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 1.3035  decode.d5.loss_dice: 1.3468  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 1.3056  decode.d6.loss_dice: 1.3457  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 1.2982  decode.d7.loss_dice: 1.3494  decode.d8.loss_cls: 0.0329  decode.d8.loss_mask: 1.3022  decode.d8.loss_dice: 1.3525
2025/03/31 04:42:22 - mmengine - INFO - Iter(train) [ 1100/20000]  base_lr: 9.5040e-05 lr: 9.5040e-05  eta: 4:32:16  time: 0.8576  data_time: 0.0158  memory: 10141  loss: 28.0904  decode.loss_cls: 0.0495  decode.loss_mask: 1.3373  decode.loss_dice: 1.3692  decode.d0.loss_cls: 0.6479  decode.d0.loss_mask: 1.3256  decode.d0.loss_dice: 1.3679  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 1.3217  decode.d1.loss_dice: 1.3711  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 1.3178  decode.d2.loss_dice: 1.3687  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 1.3335  decode.d3.loss_dice: 1.3756  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 1.3275  decode.d4.loss_dice: 1.3930  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 1.3363  decode.d5.loss_dice: 1.3856  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 1.3341  decode.d6.loss_dice: 1.3772  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 1.3139  decode.d7.loss_dice: 1.3619  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 1.3196  decode.d8.loss_dice: 1.3566
2025/03/31 04:43:05 - mmengine - INFO - Iter(train) [ 1150/20000]  base_lr: 9.4814e-05 lr: 9.4814e-05  eta: 4:31:33  time: 0.8708  data_time: 0.0176  memory: 10142  loss: 27.7035  decode.loss_cls: 0.1127  decode.loss_mask: 1.2324  decode.loss_dice: 1.4101  decode.d0.loss_cls: 0.6010  decode.d0.loss_mask: 1.2398  decode.d0.loss_dice: 1.4244  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 1.2425  decode.d1.loss_dice: 1.3860  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 1.2403  decode.d2.loss_dice: 1.3845  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 1.2378  decode.d3.loss_dice: 1.3817  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 1.2362  decode.d4.loss_dice: 1.3952  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 1.2307  decode.d5.loss_dice: 1.3901  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 1.2312  decode.d6.loss_dice: 1.3948  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 1.2322  decode.d7.loss_dice: 1.4069  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 1.2325  decode.d8.loss_dice: 1.4041
2025/03/31 04:43:48 - mmengine - INFO - Iter(train) [ 1200/20000]  base_lr: 9.4588e-05 lr: 9.4588e-05  eta: 4:30:46  time: 0.8593  data_time: 0.0160  memory: 10139  loss: 29.1929  decode.loss_cls: 0.0145  decode.loss_mask: 1.4514  decode.loss_dice: 1.4092  decode.d0.loss_cls: 0.4959  decode.d0.loss_mask: 1.4436  decode.d0.loss_dice: 1.4310  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 1.4621  decode.d1.loss_dice: 1.4057  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 1.4517  decode.d2.loss_dice: 1.3917  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 1.4471  decode.d3.loss_dice: 1.3723  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 1.4520  decode.d4.loss_dice: 1.4068  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 1.4516  decode.d5.loss_dice: 1.3975  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 1.4557  decode.d6.loss_dice: 1.4055  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 1.4557  decode.d7.loss_dice: 1.3985  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 1.4529  decode.d8.loss_dice: 1.4020
2025/03/31 04:44:31 - mmengine - INFO - Iter(train) [ 1250/20000]  base_lr: 9.4361e-05 lr: 9.4361e-05  eta: 4:29:59  time: 0.8573  data_time: 0.0161  memory: 10139  loss: 28.5913  decode.loss_cls: 0.0698  decode.loss_mask: 1.3942  decode.loss_dice: 1.3608  decode.d0.loss_cls: 0.4555  decode.d0.loss_mask: 1.4032  decode.d0.loss_dice: 1.3530  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 1.4013  decode.d1.loss_dice: 1.3473  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 1.3779  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 0.0839  decode.d3.loss_mask: 1.3827  decode.d3.loss_dice: 1.3660  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 1.3939  decode.d4.loss_dice: 1.3729  decode.d5.loss_cls: 0.0640  decode.d5.loss_mask: 1.3890  decode.d5.loss_dice: 1.3630  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 1.3967  decode.d6.loss_dice: 1.3622  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 1.3932  decode.d7.loss_dice: 1.3557  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 1.3882  decode.d8.loss_dice: 1.3516
2025/03/31 04:45:14 - mmengine - INFO - Iter(train) [ 1300/20000]  base_lr: 9.4135e-05 lr: 9.4135e-05  eta: 4:29:14  time: 0.8589  data_time: 0.0159  memory: 10140  loss: 28.5183  decode.loss_cls: 0.0351  decode.loss_mask: 1.4074  decode.loss_dice: 1.3861  decode.d0.loss_cls: 0.4202  decode.d0.loss_mask: 1.3903  decode.d0.loss_dice: 1.3951  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 1.3902  decode.d1.loss_dice: 1.3905  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 1.4020  decode.d2.loss_dice: 1.3754  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 1.4002  decode.d3.loss_dice: 1.3755  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 1.4062  decode.d4.loss_dice: 1.3816  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 1.4044  decode.d5.loss_dice: 1.3866  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 1.4060  decode.d6.loss_dice: 1.3794  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 1.4047  decode.d7.loss_dice: 1.3798  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 1.3996  decode.d8.loss_dice: 1.3858
2025/03/31 04:45:58 - mmengine - INFO - Iter(train) [ 1350/20000]  base_lr: 9.3908e-05 lr: 9.3908e-05  eta: 4:28:34  time: 0.8604  data_time: 0.0162  memory: 10095  loss: 27.9926  decode.loss_cls: 0.0917  decode.loss_mask: 1.3495  decode.loss_dice: 1.3569  decode.d0.loss_cls: 0.3981  decode.d0.loss_mask: 1.3693  decode.d0.loss_dice: 1.3622  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 1.3530  decode.d1.loss_dice: 1.3349  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 1.3532  decode.d2.loss_dice: 1.3412  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 1.3489  decode.d3.loss_dice: 1.3458  decode.d4.loss_cls: 0.0560  decode.d4.loss_mask: 1.3521  decode.d4.loss_dice: 1.3463  decode.d5.loss_cls: 0.0564  decode.d5.loss_mask: 1.3482  decode.d5.loss_dice: 1.3420  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 1.3539  decode.d6.loss_dice: 1.3534  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 1.3531  decode.d7.loss_dice: 1.3551  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 1.3488  decode.d8.loss_dice: 1.3588
2025/03/31 04:46:41 - mmengine - INFO - Iter(train) [ 1400/20000]  base_lr: 9.3682e-05 lr: 9.3682e-05  eta: 4:27:50  time: 0.8585  data_time: 0.0162  memory: 10139  loss: 27.9228  decode.loss_cls: 0.0879  decode.loss_mask: 1.3163  decode.loss_dice: 1.3740  decode.d0.loss_cls: 0.3909  decode.d0.loss_mask: 1.3263  decode.d0.loss_dice: 1.3860  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 1.3144  decode.d1.loss_dice: 1.3666  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 1.3234  decode.d2.loss_dice: 1.3707  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 1.3243  decode.d3.loss_dice: 1.3607  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 1.3235  decode.d4.loss_dice: 1.3645  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 1.3175  decode.d5.loss_dice: 1.3565  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 1.3231  decode.d6.loss_dice: 1.3542  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 1.3248  decode.d7.loss_dice: 1.3657  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 1.3291  decode.d8.loss_dice: 1.3800
2025/03/31 04:47:24 - mmengine - INFO - Iter(train) [ 1450/20000]  base_lr: 9.3455e-05 lr: 9.3455e-05  eta: 4:27:05  time: 0.8606  data_time: 0.0166  memory: 10090  loss: 27.0885  decode.loss_cls: 0.0638  decode.loss_mask: 1.3174  decode.loss_dice: 1.3116  decode.d0.loss_cls: 0.3385  decode.d0.loss_mask: 1.3164  decode.d0.loss_dice: 1.3277  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 1.3056  decode.d1.loss_dice: 1.3172  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 1.3151  decode.d2.loss_dice: 1.2857  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 1.3164  decode.d3.loss_dice: 1.2897  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 1.3120  decode.d4.loss_dice: 1.2972  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 1.3289  decode.d5.loss_dice: 1.3019  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 1.3356  decode.d6.loss_dice: 1.3222  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 1.3214  decode.d7.loss_dice: 1.3177  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 1.3245  decode.d8.loss_dice: 1.3307
2025/03/31 04:48:07 - mmengine - INFO - Iter(train) [ 1500/20000]  base_lr: 9.3228e-05 lr: 9.3228e-05  eta: 4:26:19  time: 0.8575  data_time: 0.0159  memory: 10140  loss: 27.8713  decode.loss_cls: 0.0112  decode.loss_mask: 1.4389  decode.loss_dice: 1.2897  decode.d0.loss_cls: 0.3113  decode.d0.loss_mask: 1.4372  decode.d0.loss_dice: 1.3025  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 1.4481  decode.d1.loss_dice: 1.2799  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 1.4363  decode.d2.loss_dice: 1.2958  decode.d3.loss_cls: 0.0433  decode.d3.loss_mask: 1.4362  decode.d3.loss_dice: 1.2809  decode.d4.loss_cls: 0.0412  decode.d4.loss_mask: 1.4381  decode.d4.loss_dice: 1.2910  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 1.4390  decode.d5.loss_dice: 1.2918  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 1.4396  decode.d6.loss_dice: 1.2937  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 1.4428  decode.d7.loss_dice: 1.2995  decode.d8.loss_cls: 0.0399  decode.d8.loss_mask: 1.4314  decode.d8.loss_dice: 1.2832
2025/03/31 04:48:50 - mmengine - INFO - Iter(train) [ 1550/20000]  base_lr: 9.3001e-05 lr: 9.3001e-05  eta: 4:25:33  time: 0.8570  data_time: 0.0158  memory: 10148  loss: 27.4659  decode.loss_cls: 0.0879  decode.loss_mask: 1.4130  decode.loss_dice: 1.2620  decode.d0.loss_cls: 0.2839  decode.d0.loss_mask: 1.3926  decode.d0.loss_dice: 1.2589  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 1.3923  decode.d1.loss_dice: 1.2478  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 1.3889  decode.d2.loss_dice: 1.2606  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 1.4098  decode.d3.loss_dice: 1.2460  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 1.3971  decode.d4.loss_dice: 1.2549  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 1.4066  decode.d5.loss_dice: 1.2750  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 1.4043  decode.d6.loss_dice: 1.2729  decode.d7.loss_cls: 0.0824  decode.d7.loss_mask: 1.4080  decode.d7.loss_dice: 1.2564  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 1.4112  decode.d8.loss_dice: 1.2473
2025/03/31 04:49:33 - mmengine - INFO - Iter(train) [ 1600/20000]  base_lr: 9.2774e-05 lr: 9.2774e-05  eta: 4:24:48  time: 0.8561  data_time: 0.0158  memory: 10136  loss: 24.7784  decode.loss_cls: 0.0229  decode.loss_mask: 1.1523  decode.loss_dice: 1.2660  decode.d0.loss_cls: 0.2609  decode.d0.loss_mask: 1.1543  decode.d0.loss_dice: 1.3113  decode.d1.loss_cls: 0.0294  decode.d1.loss_mask: 1.1458  decode.d1.loss_dice: 1.2707  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 1.1552  decode.d2.loss_dice: 1.2828  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 1.1572  decode.d3.loss_dice: 1.2779  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 1.1499  decode.d4.loss_dice: 1.2834  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 1.1539  decode.d5.loss_dice: 1.2804  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 1.1597  decode.d6.loss_dice: 1.2699  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 1.1626  decode.d7.loss_dice: 1.2787  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 1.1528  decode.d8.loss_dice: 1.2684
2025/03/31 04:50:16 - mmengine - INFO - Iter(train) [ 1650/20000]  base_lr: 9.2548e-05 lr: 9.2548e-05  eta: 4:24:04  time: 0.8623  data_time: 0.0159  memory: 10135  loss: 26.2395  decode.loss_cls: 0.0633  decode.loss_mask: 1.2486  decode.loss_dice: 1.3138  decode.d0.loss_cls: 0.2519  decode.d0.loss_mask: 1.2420  decode.d0.loss_dice: 1.3318  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 1.2402  decode.d1.loss_dice: 1.3094  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 1.2399  decode.d2.loss_dice: 1.2995  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 1.2434  decode.d3.loss_dice: 1.3021  decode.d4.loss_cls: 0.0364  decode.d4.loss_mask: 1.2364  decode.d4.loss_dice: 1.3040  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 1.2441  decode.d5.loss_dice: 1.3012  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 1.2475  decode.d6.loss_dice: 1.3135  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 1.2434  decode.d7.loss_dice: 1.3035  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 1.2411  decode.d8.loss_dice: 1.3143
2025/03/31 04:50:59 - mmengine - INFO - Iter(train) [ 1700/20000]  base_lr: 9.2321e-05 lr: 9.2321e-05  eta: 4:23:19  time: 0.8585  data_time: 0.0158  memory: 10096  loss: 26.2290  decode.loss_cls: 0.0584  decode.loss_mask: 1.3005  decode.loss_dice: 1.2576  decode.d0.loss_cls: 0.2340  decode.d0.loss_mask: 1.3400  decode.d0.loss_dice: 1.2596  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 1.2965  decode.d1.loss_dice: 1.2377  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 1.2904  decode.d2.loss_dice: 1.2516  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 1.2907  decode.d3.loss_dice: 1.2598  decode.d4.loss_cls: 0.0516  decode.d4.loss_mask: 1.2891  decode.d4.loss_dice: 1.2617  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 1.2899  decode.d5.loss_dice: 1.2390  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 1.2950  decode.d6.loss_dice: 1.2427  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 1.2951  decode.d7.loss_dice: 1.2553  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 1.2992  decode.d8.loss_dice: 1.2532
2025/03/31 04:51:42 - mmengine - INFO - Iter(train) [ 1750/20000]  base_lr: 9.2094e-05 lr: 9.2094e-05  eta: 4:22:36  time: 0.8598  data_time: 0.0159  memory: 10146  loss: 24.6215  decode.loss_cls: 0.0186  decode.loss_mask: 1.2828  decode.loss_dice: 1.1334  decode.d0.loss_cls: 0.2072  decode.d0.loss_mask: 1.2998  decode.d0.loss_dice: 1.1367  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 1.2869  decode.d1.loss_dice: 1.1347  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 1.2990  decode.d2.loss_dice: 1.1309  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 1.2895  decode.d3.loss_dice: 1.1343  decode.d4.loss_cls: 0.0193  decode.d4.loss_mask: 1.2874  decode.d4.loss_dice: 1.1305  decode.d5.loss_cls: 0.0214  decode.d5.loss_mask: 1.2890  decode.d5.loss_dice: 1.1376  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 1.2863  decode.d6.loss_dice: 1.1312  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 1.2910  decode.d7.loss_dice: 1.1278  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 1.2916  decode.d8.loss_dice: 1.1257
2025/03/31 04:52:25 - mmengine - INFO - Iter(train) [ 1800/20000]  base_lr: 9.1866e-05 lr: 9.1866e-05  eta: 4:21:51  time: 0.8611  data_time: 0.0159  memory: 10090  loss: 24.6514  decode.loss_cls: 0.0640  decode.loss_mask: 1.2081  decode.loss_dice: 1.1792  decode.d0.loss_cls: 0.2271  decode.d0.loss_mask: 1.2137  decode.d0.loss_dice: 1.1870  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 1.2070  decode.d1.loss_dice: 1.1971  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 1.2076  decode.d2.loss_dice: 1.2009  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 1.2041  decode.d3.loss_dice: 1.2041  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 1.2087  decode.d4.loss_dice: 1.2109  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 1.2067  decode.d5.loss_dice: 1.1870  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 1.2121  decode.d6.loss_dice: 1.1880  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 1.2069  decode.d7.loss_dice: 1.1876  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 1.2070  decode.d8.loss_dice: 1.1806
2025/03/31 04:53:08 - mmengine - INFO - Iter(train) [ 1850/20000]  base_lr: 9.1639e-05 lr: 9.1639e-05  eta: 4:21:06  time: 0.8573  data_time: 0.0161  memory: 10139  loss: 26.3104  decode.loss_cls: 0.0505  decode.loss_mask: 1.2988  decode.loss_dice: 1.2479  decode.d0.loss_cls: 0.1881  decode.d0.loss_mask: 1.3091  decode.d0.loss_dice: 1.2659  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 1.3014  decode.d1.loss_dice: 1.2654  decode.d2.loss_cls: 0.0347  decode.d2.loss_mask: 1.3039  decode.d2.loss_dice: 1.2389  decode.d3.loss_cls: 0.1180  decode.d3.loss_mask: 1.2922  decode.d3.loss_dice: 1.2225  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 1.2879  decode.d4.loss_dice: 1.2218  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 1.2980  decode.d5.loss_dice: 1.2302  decode.d6.loss_cls: 0.1286  decode.d6.loss_mask: 1.2937  decode.d6.loss_dice: 1.2150  decode.d7.loss_cls: 0.1233  decode.d7.loss_mask: 1.2954  decode.d7.loss_dice: 1.2205  decode.d8.loss_cls: 0.1218  decode.d8.loss_mask: 1.2853  decode.d8.loss_dice: 1.2182
2025/03/31 04:53:51 - mmengine - INFO - Iter(train) [ 1900/20000]  base_lr: 9.1412e-05 lr: 9.1412e-05  eta: 4:20:21  time: 0.8570  data_time: 0.0159  memory: 10140  loss: 24.1342  decode.loss_cls: 0.0867  decode.loss_mask: 1.1128  decode.loss_dice: 1.1737  decode.d0.loss_cls: 0.2521  decode.d0.loss_mask: 1.1116  decode.d0.loss_dice: 1.2360  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 1.0962  decode.d1.loss_dice: 1.2001  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 1.1023  decode.d2.loss_dice: 1.1925  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 1.1040  decode.d3.loss_dice: 1.1835  decode.d4.loss_cls: 0.1121  decode.d4.loss_mask: 1.1093  decode.d4.loss_dice: 1.1885  decode.d5.loss_cls: 0.1103  decode.d5.loss_mask: 1.1112  decode.d5.loss_dice: 1.1699  decode.d6.loss_cls: 0.1097  decode.d6.loss_mask: 1.1128  decode.d6.loss_dice: 1.1651  decode.d7.loss_cls: 0.1036  decode.d7.loss_mask: 1.1102  decode.d7.loss_dice: 1.1803  decode.d8.loss_cls: 0.1051  decode.d8.loss_mask: 1.1086  decode.d8.loss_dice: 1.1591
2025/03/31 04:54:34 - mmengine - INFO - Iter(train) [ 1950/20000]  base_lr: 9.1185e-05 lr: 9.1185e-05  eta: 4:19:36  time: 0.8571  data_time: 0.0158  memory: 10096  loss: 20.7984  decode.loss_cls: 0.0262  decode.loss_mask: 0.9515  decode.loss_dice: 1.0707  decode.d0.loss_cls: 0.1662  decode.d0.loss_mask: 0.9482  decode.d0.loss_dice: 1.1021  decode.d1.loss_cls: 0.0201  decode.d1.loss_mask: 0.9572  decode.d1.loss_dice: 1.0754  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.9469  decode.d2.loss_dice: 1.0779  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.9484  decode.d3.loss_dice: 1.0804  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.9577  decode.d4.loss_dice: 1.1029  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.9570  decode.d5.loss_dice: 1.0992  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.9572  decode.d6.loss_dice: 1.0882  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.9538  decode.d7.loss_dice: 1.0781  decode.d8.loss_cls: 0.0247  decode.d8.loss_mask: 0.9631  decode.d8.loss_dice: 1.0890
2025/03/31 04:55:17 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 04:55:17 - mmengine - INFO - Iter(train) [ 2000/20000]  base_lr: 9.0957e-05 lr: 9.0957e-05  eta: 4:18:51  time: 0.8572  data_time: 0.0158  memory: 10140  loss: 22.7969  decode.loss_cls: 0.0809  decode.loss_mask: 1.0659  decode.loss_dice: 1.1307  decode.d0.loss_cls: 0.1799  decode.d0.loss_mask: 1.0589  decode.d0.loss_dice: 1.1966  decode.d1.loss_cls: 0.0419  decode.d1.loss_mask: 1.0606  decode.d1.loss_dice: 1.1590  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 1.0563  decode.d2.loss_dice: 1.1470  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 1.0613  decode.d3.loss_dice: 1.1570  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 1.0613  decode.d4.loss_dice: 1.1539  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 1.0646  decode.d5.loss_dice: 1.1482  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 1.0642  decode.d6.loss_dice: 1.1444  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 1.0666  decode.d7.loss_dice: 1.1438  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 1.0654  decode.d8.loss_dice: 1.1328
2025/03/31 04:55:17 - mmengine - INFO - Saving checkpoint at 2000 iterations
2025/03/31 04:55:24 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:27  time: 0.0940  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:29 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:11  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:33 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:03:03  time: 0.0942  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:38 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:56  time: 0.0945  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:43 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:50  time: 0.0943  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:47 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:45  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:52 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:39  time: 0.0943  data_time: 0.0013  memory: 1854  
2025/03/31 04:55:57 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:34  time: 0.0946  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:02 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:29  time: 0.0943  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:06 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:24  time: 0.0946  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:11 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:19  time: 0.0943  data_time: 0.0014  memory: 1854  
2025/03/31 04:56:16 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:15  time: 0.0945  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:21 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:10  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:25 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:05  time: 0.0946  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:30 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:02:00  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:35 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:55  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:40 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:50  time: 0.0943  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:44 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:46  time: 0.0946  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:49 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:41  time: 0.0946  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:54 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:36  time: 0.0945  data_time: 0.0013  memory: 1854  
2025/03/31 04:56:58 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:31  time: 0.0946  data_time: 0.0014  memory: 1854  
2025/03/31 04:57:03 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:27  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:08 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:22  time: 0.0944  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:13 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:17  time: 0.0947  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:17 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:12  time: 0.0950  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:22 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:08  time: 0.0945  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:27 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:03  time: 0.0945  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:32 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:58  time: 0.0936  data_time: 0.0012  memory: 1854  
2025/03/31 04:57:36 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0937  data_time: 0.0012  memory: 1854  
2025/03/31 04:57:41 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:48  time: 0.0959  data_time: 0.0014  memory: 1854  
2025/03/31 04:57:48 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:44  time: 0.0972  data_time: 0.0016  memory: 1854  
2025/03/31 04:57:53 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:40  time: 0.0948  data_time: 0.0013  memory: 1854  
2025/03/31 04:57:58 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:35  time: 0.0952  data_time: 0.0013  memory: 1854  
2025/03/31 04:58:03 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:30  time: 0.0952  data_time: 0.0014  memory: 1854  
2025/03/31 04:58:07 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0949  data_time: 0.0014  memory: 1854  
2025/03/31 04:58:12 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0947  data_time: 0.0013  memory: 1854  
2025/03/31 04:58:17 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0953  data_time: 0.0014  memory: 1854  
2025/03/31 04:58:22 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:11  time: 0.0954  data_time: 0.0014  memory: 1854  
2025/03/31 04:58:26 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0963  data_time: 0.0014  memory: 1854  
2025/03/31 04:58:31 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0952  data_time: 0.0014  memory: 1854  
2025/03/31 04:58:33 - mmengine - INFO - per class results:
2025/03/31 04:58:33 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 70.86 | 92.55 |
|      building      | 80.45 | 93.96 |
|   low_vegetation   | 58.15 | 86.09 |
|        tree        | 24.06 | 24.48 |
|        car         | 73.71 | 84.07 |
|      clutter       |  3.28 |  3.38 |
+--------------------+-------+-------+
2025/03/31 04:58:33 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 75.5600  mIoU: 51.7500  mAcc: 64.0900  data_time: 0.0026  time: 0.0961
2025/03/31 04:58:33 - mmengine - INFO - The best checkpoint with 51.7500 mIoU at 2000 iter is saved to best_mIoU_iter_2000.pth.
2025/03/31 04:59:18 - mmengine - INFO - Iter(train) [ 2050/20000]  base_lr: 9.0730e-05 lr: 9.0730e-05  eta: 4:18:30  time: 0.8588  data_time: 0.0159  memory: 10144  loss: 25.0658  decode.loss_cls: 0.0462  decode.loss_mask: 1.2281  decode.loss_dice: 1.2208  decode.d0.loss_cls: 0.1808  decode.d0.loss_mask: 1.2395  decode.d0.loss_dice: 1.2297  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 1.2263  decode.d1.loss_dice: 1.2087  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 1.2339  decode.d2.loss_dice: 1.1947  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 1.2396  decode.d3.loss_dice: 1.1978  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 1.2357  decode.d4.loss_dice: 1.1882  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 1.2311  decode.d5.loss_dice: 1.2140  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 1.2276  decode.d6.loss_dice: 1.2022  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 1.2365  decode.d7.loss_dice: 1.2131  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 1.2243  decode.d8.loss_dice: 1.2143
2025/03/31 05:00:01 - mmengine - INFO - Iter(train) [ 2100/20000]  base_lr: 9.0502e-05 lr: 9.0502e-05  eta: 4:17:46  time: 0.8693  data_time: 0.0165  memory: 10145  loss: 23.2734  decode.loss_cls: 0.0449  decode.loss_mask: 1.0879  decode.loss_dice: 1.1697  decode.d0.loss_cls: 0.1795  decode.d0.loss_mask: 1.0785  decode.d0.loss_dice: 1.1956  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 1.0827  decode.d1.loss_dice: 1.1599  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 1.0815  decode.d2.loss_dice: 1.1567  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 1.0872  decode.d3.loss_dice: 1.1639  decode.d4.loss_cls: 0.0691  decode.d4.loss_mask: 1.0865  decode.d4.loss_dice: 1.1670  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 1.0895  decode.d5.loss_dice: 1.1839  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 1.0890  decode.d6.loss_dice: 1.1813  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 1.0766  decode.d7.loss_dice: 1.1756  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 1.0861  decode.d8.loss_dice: 1.1686
2025/03/31 05:00:45 - mmengine - INFO - Iter(train) [ 2150/20000]  base_lr: 9.0275e-05 lr: 9.0275e-05  eta: 4:17:02  time: 0.8598  data_time: 0.0160  memory: 10150  loss: 25.0262  decode.loss_cls: 0.0632  decode.loss_mask: 1.2104  decode.loss_dice: 1.2238  decode.d0.loss_cls: 0.1692  decode.d0.loss_mask: 1.2202  decode.d0.loss_dice: 1.2374  decode.d1.loss_cls: 0.0484  decode.d1.loss_mask: 1.2052  decode.d1.loss_dice: 1.2460  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 1.2216  decode.d2.loss_dice: 1.2369  decode.d3.loss_cls: 0.0376  decode.d3.loss_mask: 1.2218  decode.d3.loss_dice: 1.2290  decode.d4.loss_cls: 0.0406  decode.d4.loss_mask: 1.2210  decode.d4.loss_dice: 1.2317  decode.d5.loss_cls: 0.0353  decode.d5.loss_mask: 1.2080  decode.d5.loss_dice: 1.2264  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 1.2135  decode.d6.loss_dice: 1.2289  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 1.2153  decode.d7.loss_dice: 1.2270  decode.d8.loss_cls: 0.0371  decode.d8.loss_mask: 1.2153  decode.d8.loss_dice: 1.2377
2025/03/31 05:01:28 - mmengine - INFO - Iter(train) [ 2200/20000]  base_lr: 9.0047e-05 lr: 9.0047e-05  eta: 4:16:18  time: 0.8595  data_time: 0.0161  memory: 10142  loss: 24.1954  decode.loss_cls: 0.0687  decode.loss_mask: 1.1431  decode.loss_dice: 1.1837  decode.d0.loss_cls: 0.1360  decode.d0.loss_mask: 1.1649  decode.d0.loss_dice: 1.2134  decode.d1.loss_cls: 0.0495  decode.d1.loss_mask: 1.1489  decode.d1.loss_dice: 1.1975  decode.d2.loss_cls: 0.0479  decode.d2.loss_mask: 1.1513  decode.d2.loss_dice: 1.2013  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 1.1479  decode.d3.loss_dice: 1.1911  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 1.1415  decode.d4.loss_dice: 1.2031  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 1.1455  decode.d5.loss_dice: 1.2058  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 1.1492  decode.d6.loss_dice: 1.1812  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 1.1464  decode.d7.loss_dice: 1.2011  decode.d8.loss_cls: 0.1028  decode.d8.loss_mask: 1.1453  decode.d8.loss_dice: 1.1892
2025/03/31 05:02:12 - mmengine - INFO - Iter(train) [ 2250/20000]  base_lr: 8.9820e-05 lr: 8.9820e-05  eta: 4:15:40  time: 0.8848  data_time: 0.0162  memory: 10150  loss: 24.2867  decode.loss_cls: 0.0279  decode.loss_mask: 1.2596  decode.loss_dice: 1.1298  decode.d0.loss_cls: 0.1346  decode.d0.loss_mask: 1.2665  decode.d0.loss_dice: 1.1322  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 1.2541  decode.d1.loss_dice: 1.1370  decode.d2.loss_cls: 0.0298  decode.d2.loss_mask: 1.2602  decode.d2.loss_dice: 1.1384  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 1.2576  decode.d3.loss_dice: 1.1275  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 1.2560  decode.d4.loss_dice: 1.1269  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 1.2496  decode.d5.loss_dice: 1.1369  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 1.2568  decode.d6.loss_dice: 1.1386  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 1.2628  decode.d7.loss_dice: 1.1405  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 1.2593  decode.d8.loss_dice: 1.1320
2025/03/31 05:02:55 - mmengine - INFO - Iter(train) [ 2300/20000]  base_lr: 8.9592e-05 lr: 8.9592e-05  eta: 4:14:56  time: 0.8601  data_time: 0.0164  memory: 10144  loss: 21.7285  decode.loss_cls: 0.0198  decode.loss_mask: 1.0880  decode.loss_dice: 1.0491  decode.d0.loss_cls: 0.1471  decode.d0.loss_mask: 1.0783  decode.d0.loss_dice: 1.0728  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 1.0896  decode.d1.loss_dice: 1.0663  decode.d2.loss_cls: 0.0275  decode.d2.loss_mask: 1.0772  decode.d2.loss_dice: 1.0641  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 1.0832  decode.d3.loss_dice: 1.0549  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 1.0772  decode.d4.loss_dice: 1.0441  decode.d5.loss_cls: 0.0269  decode.d5.loss_mask: 1.0767  decode.d5.loss_dice: 1.0504  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 1.0891  decode.d6.loss_dice: 1.0461  decode.d7.loss_cls: 0.0204  decode.d7.loss_mask: 1.0802  decode.d7.loss_dice: 1.0395  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 1.0893  decode.d8.loss_dice: 1.0412
2025/03/31 05:03:38 - mmengine - INFO - Iter(train) [ 2350/20000]  base_lr: 8.9364e-05 lr: 8.9364e-05  eta: 4:14:11  time: 0.8606  data_time: 0.0160  memory: 10142  loss: 25.1872  decode.loss_cls: 0.0663  decode.loss_mask: 1.2359  decode.loss_dice: 1.1777  decode.d0.loss_cls: 0.1427  decode.d0.loss_mask: 1.2466  decode.d0.loss_dice: 1.2089  decode.d1.loss_cls: 0.0888  decode.d1.loss_mask: 1.2464  decode.d1.loss_dice: 1.1824  decode.d2.loss_cls: 0.1261  decode.d2.loss_mask: 1.2393  decode.d2.loss_dice: 1.1500  decode.d3.loss_cls: 0.1214  decode.d3.loss_mask: 1.2503  decode.d3.loss_dice: 1.1569  decode.d4.loss_cls: 0.1206  decode.d4.loss_mask: 1.2446  decode.d4.loss_dice: 1.1594  decode.d5.loss_cls: 0.1124  decode.d5.loss_mask: 1.2390  decode.d5.loss_dice: 1.1593  decode.d6.loss_cls: 0.1050  decode.d6.loss_mask: 1.2355  decode.d6.loss_dice: 1.1668  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 1.2349  decode.d7.loss_dice: 1.1645  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 1.2386  decode.d8.loss_dice: 1.1866
2025/03/31 05:04:21 - mmengine - INFO - Iter(train) [ 2400/20000]  base_lr: 8.9136e-05 lr: 8.9136e-05  eta: 4:13:27  time: 0.8593  data_time: 0.0159  memory: 10144  loss: 23.4394  decode.loss_cls: 0.0357  decode.loss_mask: 1.1425  decode.loss_dice: 1.1568  decode.d0.loss_cls: 0.1142  decode.d0.loss_mask: 1.1667  decode.d0.loss_dice: 1.1761  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 1.1632  decode.d1.loss_dice: 1.1600  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 1.1454  decode.d2.loss_dice: 1.1547  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 1.1421  decode.d3.loss_dice: 1.1663  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 1.1436  decode.d4.loss_dice: 1.1610  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 1.1390  decode.d5.loss_dice: 1.1506  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 1.1496  decode.d6.loss_dice: 1.1533  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 1.1427  decode.d7.loss_dice: 1.1673  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 1.1430  decode.d8.loss_dice: 1.1570
2025/03/31 05:05:04 - mmengine - INFO - Iter(train) [ 2450/20000]  base_lr: 8.8908e-05 lr: 8.8908e-05  eta: 4:12:43  time: 0.8602  data_time: 0.0160  memory: 10142  loss: 25.8904  decode.loss_cls: 0.1181  decode.loss_mask: 1.2158  decode.loss_dice: 1.2577  decode.d0.loss_cls: 0.1777  decode.d0.loss_mask: 1.2271  decode.d0.loss_dice: 1.2801  decode.d1.loss_cls: 0.1099  decode.d1.loss_mask: 1.2211  decode.d1.loss_dice: 1.2644  decode.d2.loss_cls: 0.1067  decode.d2.loss_mask: 1.2086  decode.d2.loss_dice: 1.2525  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 1.2070  decode.d3.loss_dice: 1.2429  decode.d4.loss_cls: 0.1141  decode.d4.loss_mask: 1.2092  decode.d4.loss_dice: 1.2492  decode.d5.loss_cls: 0.1687  decode.d5.loss_mask: 1.2097  decode.d5.loss_dice: 1.2452  decode.d6.loss_cls: 0.0988  decode.d6.loss_mask: 1.2149  decode.d6.loss_dice: 1.2555  decode.d7.loss_cls: 0.1045  decode.d7.loss_mask: 1.2160  decode.d7.loss_dice: 1.2562  decode.d8.loss_cls: 0.0941  decode.d8.loss_mask: 1.2149  decode.d8.loss_dice: 1.2406
2025/03/31 05:05:47 - mmengine - INFO - Iter(train) [ 2500/20000]  base_lr: 8.8680e-05 lr: 8.8680e-05  eta: 4:11:59  time: 0.8601  data_time: 0.0156  memory: 10150  loss: 24.7814  decode.loss_cls: 0.0862  decode.loss_mask: 1.1823  decode.loss_dice: 1.2135  decode.d0.loss_cls: 0.1584  decode.d0.loss_mask: 1.1794  decode.d0.loss_dice: 1.2436  decode.d1.loss_cls: 0.1065  decode.d1.loss_mask: 1.1756  decode.d1.loss_dice: 1.2138  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 1.1804  decode.d2.loss_dice: 1.2224  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 1.1690  decode.d3.loss_dice: 1.2137  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 1.1775  decode.d4.loss_dice: 1.2059  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 1.1749  decode.d5.loss_dice: 1.1957  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 1.1755  decode.d6.loss_dice: 1.2026  decode.d7.loss_cls: 0.0796  decode.d7.loss_mask: 1.1777  decode.d7.loss_dice: 1.2083  decode.d8.loss_cls: 0.0426  decode.d8.loss_mask: 1.1869  decode.d8.loss_dice: 1.2086
2025/03/31 05:06:30 - mmengine - INFO - Iter(train) [ 2550/20000]  base_lr: 8.8452e-05 lr: 8.8452e-05  eta: 4:11:16  time: 0.8623  data_time: 0.0156  memory: 10145  loss: 23.9858  decode.loss_cls: 0.1003  decode.loss_mask: 1.1633  decode.loss_dice: 1.1115  decode.d0.loss_cls: 0.1276  decode.d0.loss_mask: 1.1769  decode.d0.loss_dice: 1.1586  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 1.1655  decode.d1.loss_dice: 1.1396  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 1.1611  decode.d2.loss_dice: 1.1351  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 1.1610  decode.d3.loss_dice: 1.1447  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 1.1705  decode.d4.loss_dice: 1.1409  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 1.1741  decode.d5.loss_dice: 1.1345  decode.d6.loss_cls: 0.1064  decode.d6.loss_mask: 1.1668  decode.d6.loss_dice: 1.1316  decode.d7.loss_cls: 0.0994  decode.d7.loss_mask: 1.1595  decode.d7.loss_dice: 1.1347  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 1.1622  decode.d8.loss_dice: 1.1205
2025/03/31 05:07:13 - mmengine - INFO - Iter(train) [ 2600/20000]  base_lr: 8.8224e-05 lr: 8.8224e-05  eta: 4:10:32  time: 0.8608  data_time: 0.0165  memory: 10144  loss: 23.0118  decode.loss_cls: 0.0304  decode.loss_mask: 1.1391  decode.loss_dice: 1.1203  decode.d0.loss_cls: 0.1184  decode.d0.loss_mask: 1.1525  decode.d0.loss_dice: 1.1366  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 1.1368  decode.d1.loss_dice: 1.1378  decode.d2.loss_cls: 0.0264  decode.d2.loss_mask: 1.1304  decode.d2.loss_dice: 1.1293  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 1.1280  decode.d3.loss_dice: 1.1329  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 1.1311  decode.d4.loss_dice: 1.1314  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 1.1372  decode.d5.loss_dice: 1.1237  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 1.1368  decode.d6.loss_dice: 1.1124  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 1.1376  decode.d7.loss_dice: 1.1353  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 1.1325  decode.d8.loss_dice: 1.1286
2025/03/31 05:07:56 - mmengine - INFO - Iter(train) [ 2650/20000]  base_lr: 8.7996e-05 lr: 8.7996e-05  eta: 4:09:49  time: 0.8648  data_time: 0.0166  memory: 10142  loss: 18.5608  decode.loss_cls: 0.0330  decode.loss_mask: 0.8669  decode.loss_dice: 0.9520  decode.d0.loss_cls: 0.1035  decode.d0.loss_mask: 0.8733  decode.d0.loss_dice: 0.9758  decode.d1.loss_cls: 0.0268  decode.d1.loss_mask: 0.8847  decode.d1.loss_dice: 0.9528  decode.d2.loss_cls: 0.0299  decode.d2.loss_mask: 0.8671  decode.d2.loss_dice: 0.9403  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.8699  decode.d3.loss_dice: 0.9461  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.8657  decode.d4.loss_dice: 0.9400  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.8652  decode.d5.loss_dice: 0.9448  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.8713  decode.d6.loss_dice: 0.9567  decode.d7.loss_cls: 0.0254  decode.d7.loss_mask: 0.8692  decode.d7.loss_dice: 0.9579  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.8640  decode.d8.loss_dice: 0.9474
2025/03/31 05:08:40 - mmengine - INFO - Iter(train) [ 2700/20000]  base_lr: 8.7768e-05 lr: 8.7768e-05  eta: 4:09:05  time: 0.8629  data_time: 0.0161  memory: 10093  loss: 21.8916  decode.loss_cls: 0.0580  decode.loss_mask: 1.0175  decode.loss_dice: 1.1004  decode.d0.loss_cls: 0.1217  decode.d0.loss_mask: 1.0039  decode.d0.loss_dice: 1.1456  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 1.0130  decode.d1.loss_dice: 1.1269  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 1.0202  decode.d2.loss_dice: 1.1083  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 1.0116  decode.d3.loss_dice: 1.1159  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 1.0164  decode.d4.loss_dice: 1.0968  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 1.0184  decode.d5.loss_dice: 1.1201  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 1.0202  decode.d6.loss_dice: 1.1146  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 1.0209  decode.d7.loss_dice: 1.1089  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 1.0129  decode.d8.loss_dice: 1.0854
2025/03/31 05:09:23 - mmengine - INFO - Iter(train) [ 2750/20000]  base_lr: 8.7539e-05 lr: 8.7539e-05  eta: 4:08:21  time: 0.8607  data_time: 0.0158  memory: 10093  loss: 23.2150  decode.loss_cls: 0.0492  decode.loss_mask: 1.1120  decode.loss_dice: 1.1423  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 1.1200  decode.d0.loss_dice: 1.1457  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 1.1115  decode.d1.loss_dice: 1.1343  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 1.1173  decode.d2.loss_dice: 1.1257  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 1.1150  decode.d3.loss_dice: 1.1407  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 1.1164  decode.d4.loss_dice: 1.1425  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 1.1118  decode.d5.loss_dice: 1.1374  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 1.1129  decode.d6.loss_dice: 1.1448  decode.d7.loss_cls: 0.0491  decode.d7.loss_mask: 1.1135  decode.d7.loss_dice: 1.1487  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 1.1131  decode.d8.loss_dice: 1.1436
2025/03/31 05:10:06 - mmengine - INFO - Iter(train) [ 2800/20000]  base_lr: 8.7311e-05 lr: 8.7311e-05  eta: 4:07:38  time: 0.8598  data_time: 0.0160  memory: 10145  loss: 22.3205  decode.loss_cls: 0.0680  decode.loss_mask: 1.1094  decode.loss_dice: 1.0511  decode.d0.loss_cls: 0.1229  decode.d0.loss_mask: 1.1243  decode.d0.loss_dice: 1.0694  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 1.1092  decode.d1.loss_dice: 1.0514  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 1.1025  decode.d2.loss_dice: 1.0542  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 1.1047  decode.d3.loss_dice: 1.0512  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 1.1123  decode.d4.loss_dice: 1.0471  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 1.1107  decode.d5.loss_dice: 1.0388  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 1.1088  decode.d6.loss_dice: 1.0421  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 1.1123  decode.d7.loss_dice: 1.0563  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 1.1114  decode.d8.loss_dice: 1.0511
2025/03/31 05:10:49 - mmengine - INFO - Iter(train) [ 2850/20000]  base_lr: 8.7082e-05 lr: 8.7082e-05  eta: 4:06:53  time: 0.8580  data_time: 0.0161  memory: 10150  loss: 22.9932  decode.loss_cls: 0.0470  decode.loss_mask: 1.1769  decode.loss_dice: 1.0788  decode.d0.loss_cls: 0.0921  decode.d0.loss_mask: 1.1685  decode.d0.loss_dice: 1.1073  decode.d1.loss_cls: 0.0179  decode.d1.loss_mask: 1.1679  decode.d1.loss_dice: 1.1101  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 1.1737  decode.d2.loss_dice: 1.0672  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 1.1816  decode.d3.loss_dice: 1.0720  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 1.1811  decode.d4.loss_dice: 1.0850  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 1.1737  decode.d5.loss_dice: 1.0885  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 1.1765  decode.d6.loss_dice: 1.0788  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 1.1706  decode.d7.loss_dice: 1.0649  decode.d8.loss_cls: 0.0252  decode.d8.loss_mask: 1.1751  decode.d8.loss_dice: 1.0827
2025/03/31 05:11:32 - mmengine - INFO - Iter(train) [ 2900/20000]  base_lr: 8.6854e-05 lr: 8.6854e-05  eta: 4:06:09  time: 0.8576  data_time: 0.0159  memory: 10096  loss: 21.1946  decode.loss_cls: 0.0583  decode.loss_mask: 1.0614  decode.loss_dice: 0.9965  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 1.0388  decode.d0.loss_dice: 1.0294  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 1.0510  decode.d1.loss_dice: 0.9976  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 1.0520  decode.d2.loss_dice: 0.9919  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 1.0561  decode.d3.loss_dice: 0.9968  decode.d4.loss_cls: 0.0537  decode.d4.loss_mask: 1.0622  decode.d4.loss_dice: 0.9944  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 1.0694  decode.d5.loss_dice: 0.9961  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 1.0591  decode.d6.loss_dice: 1.0044  decode.d7.loss_cls: 0.0538  decode.d7.loss_mask: 1.0549  decode.d7.loss_dice: 1.0135  decode.d8.loss_cls: 0.0544  decode.d8.loss_mask: 1.0669  decode.d8.loss_dice: 1.0082
2025/03/31 05:12:15 - mmengine - INFO - Iter(train) [ 2950/20000]  base_lr: 8.6625e-05 lr: 8.6625e-05  eta: 4:05:25  time: 0.8569  data_time: 0.0157  memory: 10150  loss: 21.0267  decode.loss_cls: 0.0811  decode.loss_mask: 0.9429  decode.loss_dice: 1.0969  decode.d0.loss_cls: 0.1019  decode.d0.loss_mask: 0.9402  decode.d0.loss_dice: 1.1194  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.9410  decode.d1.loss_dice: 1.0841  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.9432  decode.d2.loss_dice: 1.1020  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.9395  decode.d3.loss_dice: 1.0864  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.9431  decode.d4.loss_dice: 1.1064  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.9417  decode.d5.loss_dice: 1.0979  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.9418  decode.d6.loss_dice: 1.1133  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.9412  decode.d7.loss_dice: 1.0919  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.9383  decode.d8.loss_dice: 1.0950
2025/03/31 05:12:58 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 05:12:58 - mmengine - INFO - Iter(train) [ 3000/20000]  base_lr: 8.6397e-05 lr: 8.6397e-05  eta: 4:04:40  time: 0.8562  data_time: 0.0158  memory: 10096  loss: 24.5623  decode.loss_cls: 0.0651  decode.loss_mask: 1.2150  decode.loss_dice: 1.1518  decode.d0.loss_cls: 0.1015  decode.d0.loss_mask: 1.2329  decode.d0.loss_dice: 1.1769  decode.d1.loss_cls: 0.0386  decode.d1.loss_mask: 1.2245  decode.d1.loss_dice: 1.1654  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 1.2217  decode.d2.loss_dice: 1.1652  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 1.2195  decode.d3.loss_dice: 1.1679  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 1.2183  decode.d4.loss_dice: 1.1584  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 1.2231  decode.d5.loss_dice: 1.1573  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 1.2225  decode.d6.loss_dice: 1.1599  decode.d7.loss_cls: 0.0967  decode.d7.loss_mask: 1.2153  decode.d7.loss_dice: 1.1506  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 1.2193  decode.d8.loss_dice: 1.1653
2025/03/31 05:13:41 - mmengine - INFO - Iter(train) [ 3050/20000]  base_lr: 8.6168e-05 lr: 8.6168e-05  eta: 4:04:00  time: 0.8902  data_time: 0.0157  memory: 10099  loss: 21.9857  decode.loss_cls: 0.0617  decode.loss_mask: 1.0304  decode.loss_dice: 1.0874  decode.d0.loss_cls: 0.1093  decode.d0.loss_mask: 1.0290  decode.d0.loss_dice: 1.1253  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 1.0341  decode.d1.loss_dice: 1.1016  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 1.0292  decode.d2.loss_dice: 1.1041  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 1.0258  decode.d3.loss_dice: 1.1015  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 1.0236  decode.d4.loss_dice: 1.0889  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 1.0286  decode.d5.loss_dice: 1.0887  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 1.0294  decode.d6.loss_dice: 1.0845  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 1.0343  decode.d7.loss_dice: 1.0769  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 1.0335  decode.d8.loss_dice: 1.0921
2025/03/31 05:14:24 - mmengine - INFO - Iter(train) [ 3100/20000]  base_lr: 8.5939e-05 lr: 8.5939e-05  eta: 4:03:16  time: 0.8592  data_time: 0.0161  memory: 10093  loss: 23.0022  decode.loss_cls: 0.0520  decode.loss_mask: 1.1387  decode.loss_dice: 1.1286  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 1.1376  decode.d0.loss_dice: 1.1093  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 1.1285  decode.d1.loss_dice: 1.1121  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 1.1279  decode.d2.loss_dice: 1.1071  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 1.1323  decode.d3.loss_dice: 1.1355  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 1.1303  decode.d4.loss_dice: 1.1123  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 1.1272  decode.d5.loss_dice: 1.1203  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 1.1338  decode.d6.loss_dice: 1.1256  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 1.1355  decode.d7.loss_dice: 1.1229  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 1.1288  decode.d8.loss_dice: 1.1304
2025/03/31 05:15:08 - mmengine - INFO - Iter(train) [ 3150/20000]  base_lr: 8.5710e-05 lr: 8.5710e-05  eta: 4:02:33  time: 0.8581  data_time: 0.0155  memory: 10143  loss: 18.8653  decode.loss_cls: 0.0136  decode.loss_mask: 0.8918  decode.loss_dice: 0.9657  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.8839  decode.d0.loss_dice: 0.9755  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.8835  decode.d1.loss_dice: 0.9768  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.8862  decode.d2.loss_dice: 0.9660  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.8915  decode.d3.loss_dice: 0.9704  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.8931  decode.d4.loss_dice: 0.9741  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.8949  decode.d5.loss_dice: 0.9782  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.8978  decode.d6.loss_dice: 0.9738  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.8985  decode.d7.loss_dice: 0.9734  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.8958  decode.d8.loss_dice: 0.9704
2025/03/31 05:15:51 - mmengine - INFO - Iter(train) [ 3200/20000]  base_lr: 8.5481e-05 lr: 8.5481e-05  eta: 4:01:49  time: 0.8599  data_time: 0.0159  memory: 10143  loss: 21.8499  decode.loss_cls: 0.0453  decode.loss_mask: 1.1337  decode.loss_dice: 1.0106  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 1.1239  decode.d0.loss_dice: 1.0443  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 1.1305  decode.d1.loss_dice: 1.0168  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 1.1328  decode.d2.loss_dice: 1.0075  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 1.1399  decode.d3.loss_dice: 1.0053  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 1.1331  decode.d4.loss_dice: 0.9984  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 1.1381  decode.d5.loss_dice: 1.0074  decode.d6.loss_cls: 0.0461  decode.d6.loss_mask: 1.1339  decode.d6.loss_dice: 1.0021  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 1.1362  decode.d7.loss_dice: 1.0064  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 1.1293  decode.d8.loss_dice: 1.0036
2025/03/31 05:16:34 - mmengine - INFO - Iter(train) [ 3250/20000]  base_lr: 8.5252e-05 lr: 8.5252e-05  eta: 4:01:06  time: 0.8620  data_time: 0.0165  memory: 10144  loss: 22.9990  decode.loss_cls: 0.0999  decode.loss_mask: 1.1017  decode.loss_dice: 1.0964  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 1.1299  decode.d0.loss_dice: 1.1324  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 1.0963  decode.d1.loss_dice: 1.1137  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 1.1039  decode.d2.loss_dice: 1.1009  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 1.1071  decode.d3.loss_dice: 1.1011  decode.d4.loss_cls: 0.0979  decode.d4.loss_mask: 1.1015  decode.d4.loss_dice: 1.0882  decode.d5.loss_cls: 0.1001  decode.d5.loss_mask: 1.1016  decode.d5.loss_dice: 1.0903  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 1.1064  decode.d6.loss_dice: 1.1071  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 1.0999  decode.d7.loss_dice: 1.0814  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 1.1076  decode.d8.loss_dice: 1.0807
2025/03/31 05:17:17 - mmengine - INFO - Iter(train) [ 3300/20000]  base_lr: 8.5023e-05 lr: 8.5023e-05  eta: 4:00:23  time: 0.8604  data_time: 0.0158  memory: 10142  loss: 22.9722  decode.loss_cls: 0.0159  decode.loss_mask: 1.1339  decode.loss_dice: 1.1168  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 1.1512  decode.d0.loss_dice: 1.1289  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 1.1401  decode.d1.loss_dice: 1.1063  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 1.1354  decode.d2.loss_dice: 1.1251  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 1.1305  decode.d3.loss_dice: 1.1194  decode.d4.loss_cls: 0.0392  decode.d4.loss_mask: 1.1362  decode.d4.loss_dice: 1.1148  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 1.1339  decode.d5.loss_dice: 1.1253  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 1.1349  decode.d6.loss_dice: 1.1345  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 1.1404  decode.d7.loss_dice: 1.1280  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 1.1372  decode.d8.loss_dice: 1.1287
2025/03/31 05:18:00 - mmengine - INFO - Iter(train) [ 3350/20000]  base_lr: 8.4794e-05 lr: 8.4794e-05  eta: 3:59:39  time: 0.8595  data_time: 0.0157  memory: 10142  loss: 23.2230  decode.loss_cls: 0.0273  decode.loss_mask: 1.1656  decode.loss_dice: 1.1205  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 1.1712  decode.d0.loss_dice: 1.1093  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 1.1480  decode.d1.loss_dice: 1.1284  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 1.1436  decode.d2.loss_dice: 1.1266  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 1.1453  decode.d3.loss_dice: 1.1303  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 1.1463  decode.d4.loss_dice: 1.1237  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 1.1446  decode.d5.loss_dice: 1.1101  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 1.1426  decode.d6.loss_dice: 1.0974  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 1.1441  decode.d7.loss_dice: 1.1142  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 1.1435  decode.d8.loss_dice: 1.1122
2025/03/31 05:18:43 - mmengine - INFO - Iter(train) [ 3400/20000]  base_lr: 8.4565e-05 lr: 8.4565e-05  eta: 3:58:55  time: 0.8599  data_time: 0.0160  memory: 10144  loss: 21.2169  decode.loss_cls: 0.0300  decode.loss_mask: 1.0666  decode.loss_dice: 1.0086  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 1.0807  decode.d0.loss_dice: 1.0248  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 1.0605  decode.d1.loss_dice: 1.0152  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 1.0626  decode.d2.loss_dice: 1.0108  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 1.0693  decode.d3.loss_dice: 0.9998  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 1.0630  decode.d4.loss_dice: 1.0010  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 1.0635  decode.d5.loss_dice: 1.0029  decode.d6.loss_cls: 0.0302  decode.d6.loss_mask: 1.0639  decode.d6.loss_dice: 1.0109  decode.d7.loss_cls: 0.0410  decode.d7.loss_mask: 1.0654  decode.d7.loss_dice: 1.0062  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 1.0630  decode.d8.loss_dice: 1.0179
2025/03/31 05:19:26 - mmengine - INFO - Iter(train) [ 3450/20000]  base_lr: 8.4336e-05 lr: 8.4336e-05  eta: 3:58:11  time: 0.8589  data_time: 0.0157  memory: 10151  loss: 21.7913  decode.loss_cls: 0.0495  decode.loss_mask: 1.0813  decode.loss_dice: 1.0321  decode.d0.loss_cls: 0.1051  decode.d0.loss_mask: 1.0902  decode.d0.loss_dice: 1.0513  decode.d1.loss_cls: 0.0475  decode.d1.loss_mask: 1.0679  decode.d1.loss_dice: 1.0388  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 1.0731  decode.d2.loss_dice: 1.0301  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 1.0818  decode.d3.loss_dice: 1.0464  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 1.0731  decode.d4.loss_dice: 1.0409  decode.d5.loss_cls: 0.0584  decode.d5.loss_mask: 1.0778  decode.d5.loss_dice: 1.0367  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 1.0847  decode.d6.loss_dice: 1.0412  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 1.0775  decode.d7.loss_dice: 1.0423  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 1.0749  decode.d8.loss_dice: 1.0230
2025/03/31 05:20:09 - mmengine - INFO - Iter(train) [ 3500/20000]  base_lr: 8.4106e-05 lr: 8.4106e-05  eta: 3:57:28  time: 0.8599  data_time: 0.0161  memory: 10099  loss: 21.7143  decode.loss_cls: 0.0434  decode.loss_mask: 1.0875  decode.loss_dice: 1.0339  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 1.1064  decode.d0.loss_dice: 1.0368  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 1.0871  decode.d1.loss_dice: 1.0400  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 1.0851  decode.d2.loss_dice: 1.0512  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 1.0891  decode.d3.loss_dice: 1.0484  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 1.0866  decode.d4.loss_dice: 1.0363  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 1.0880  decode.d5.loss_dice: 1.0402  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 1.0880  decode.d6.loss_dice: 1.0419  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 1.0887  decode.d7.loss_dice: 1.0359  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 1.0869  decode.d8.loss_dice: 1.0404
2025/03/31 05:20:53 - mmengine - INFO - Iter(train) [ 3550/20000]  base_lr: 8.3877e-05 lr: 8.3877e-05  eta: 3:56:47  time: 0.8904  data_time: 0.0170  memory: 10143  loss: 19.1567  decode.loss_cls: 0.0230  decode.loss_mask: 0.9225  decode.loss_dice: 0.9738  decode.d0.loss_cls: 0.0744  decode.d0.loss_mask: 0.9280  decode.d0.loss_dice: 0.9939  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.9229  decode.d1.loss_dice: 0.9767  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.9188  decode.d2.loss_dice: 0.9649  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.9152  decode.d3.loss_dice: 0.9641  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.9172  decode.d4.loss_dice: 0.9748  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.9171  decode.d5.loss_dice: 0.9620  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 0.9223  decode.d6.loss_dice: 0.9669  decode.d7.loss_cls: 0.0223  decode.d7.loss_mask: 0.9199  decode.d7.loss_dice: 0.9577  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.9191  decode.d8.loss_dice: 0.9597
2025/03/31 05:21:36 - mmengine - INFO - Iter(train) [ 3600/20000]  base_lr: 8.3647e-05 lr: 8.3647e-05  eta: 3:56:03  time: 0.8599  data_time: 0.0158  memory: 10139  loss: 20.2763  decode.loss_cls: 0.0535  decode.loss_mask: 0.9761  decode.loss_dice: 0.9848  decode.d0.loss_cls: 0.1259  decode.d0.loss_mask: 0.9923  decode.d0.loss_dice: 0.9990  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.9755  decode.d1.loss_dice: 0.9880  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.9730  decode.d2.loss_dice: 0.9921  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.9785  decode.d3.loss_dice: 0.9839  decode.d4.loss_cls: 0.0559  decode.d4.loss_mask: 0.9666  decode.d4.loss_dice: 0.9882  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.9685  decode.d5.loss_dice: 0.9844  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.9667  decode.d6.loss_dice: 1.0009  decode.d7.loss_cls: 0.0454  decode.d7.loss_mask: 0.9730  decode.d7.loss_dice: 0.9857  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.9803  decode.d8.loss_dice: 0.9829
2025/03/31 05:22:19 - mmengine - INFO - Iter(train) [ 3650/20000]  base_lr: 8.3418e-05 lr: 8.3418e-05  eta: 3:55:19  time: 0.8589  data_time: 0.0156  memory: 10099  loss: 23.1246  decode.loss_cls: 0.0638  decode.loss_mask: 1.1424  decode.loss_dice: 1.0956  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 1.1680  decode.d0.loss_dice: 1.1442  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 1.1494  decode.d1.loss_dice: 1.0891  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 1.1500  decode.d2.loss_dice: 1.0805  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 1.1449  decode.d3.loss_dice: 1.0801  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 1.1442  decode.d4.loss_dice: 1.0906  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 1.1473  decode.d5.loss_dice: 1.0829  decode.d6.loss_cls: 0.0989  decode.d6.loss_mask: 1.1394  decode.d6.loss_dice: 1.0784  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 1.1407  decode.d7.loss_dice: 1.0881  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 1.1431  decode.d8.loss_dice: 1.0896
2025/03/31 05:23:02 - mmengine - INFO - Iter(train) [ 3700/20000]  base_lr: 8.3188e-05 lr: 8.3188e-05  eta: 3:54:35  time: 0.8592  data_time: 0.0157  memory: 10093  loss: 20.6141  decode.loss_cls: 0.0276  decode.loss_mask: 1.0437  decode.loss_dice: 0.9796  decode.d0.loss_cls: 0.0877  decode.d0.loss_mask: 1.0578  decode.d0.loss_dice: 0.9585  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 1.0442  decode.d1.loss_dice: 0.9791  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 1.0432  decode.d2.loss_dice: 0.9882  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 1.0424  decode.d3.loss_dice: 0.9739  decode.d4.loss_cls: 0.0281  decode.d4.loss_mask: 1.0535  decode.d4.loss_dice: 0.9837  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 1.0480  decode.d5.loss_dice: 0.9834  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 1.0489  decode.d6.loss_dice: 0.9783  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 1.0518  decode.d7.loss_dice: 0.9815  decode.d8.loss_cls: 0.0286  decode.d8.loss_mask: 1.0540  decode.d8.loss_dice: 0.9815
2025/03/31 05:23:45 - mmengine - INFO - Iter(train) [ 3750/20000]  base_lr: 8.2958e-05 lr: 8.2958e-05  eta: 3:53:52  time: 0.8613  data_time: 0.0158  memory: 10099  loss: 21.5611  decode.loss_cls: 0.0386  decode.loss_mask: 1.0854  decode.loss_dice: 1.0260  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 1.0998  decode.d0.loss_dice: 1.0400  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 1.0934  decode.d1.loss_dice: 1.0279  decode.d2.loss_cls: 0.0300  decode.d2.loss_mask: 1.0945  decode.d2.loss_dice: 1.0124  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 1.0920  decode.d3.loss_dice: 1.0182  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 1.0921  decode.d4.loss_dice: 1.0229  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 1.0922  decode.d5.loss_dice: 1.0248  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 1.0894  decode.d6.loss_dice: 1.0413  decode.d7.loss_cls: 0.0313  decode.d7.loss_mask: 1.0947  decode.d7.loss_dice: 1.0327  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 1.0859  decode.d8.loss_dice: 1.0190
2025/03/31 05:24:28 - mmengine - INFO - Iter(train) [ 3800/20000]  base_lr: 8.2729e-05 lr: 8.2729e-05  eta: 3:53:08  time: 0.8587  data_time: 0.0157  memory: 10139  loss: 17.6464  decode.loss_cls: 0.0140  decode.loss_mask: 0.8966  decode.loss_dice: 0.8547  decode.d0.loss_cls: 0.0654  decode.d0.loss_mask: 0.8842  decode.d0.loss_dice: 0.8686  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.8845  decode.d1.loss_dice: 0.8644  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.8938  decode.d2.loss_dice: 0.8531  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.8953  decode.d3.loss_dice: 0.8488  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.8996  decode.d4.loss_dice: 0.8502  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.8986  decode.d5.loss_dice: 0.8450  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.8946  decode.d6.loss_dice: 0.8411  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.8966  decode.d7.loss_dice: 0.8520  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.8944  decode.d8.loss_dice: 0.8400
2025/03/31 05:25:11 - mmengine - INFO - Iter(train) [ 3850/20000]  base_lr: 8.2499e-05 lr: 8.2499e-05  eta: 3:52:24  time: 0.8594  data_time: 0.0158  memory: 10145  loss: 21.1356  decode.loss_cls: 0.0277  decode.loss_mask: 1.0481  decode.loss_dice: 1.0216  decode.d0.loss_cls: 0.0842  decode.d0.loss_mask: 1.0592  decode.d0.loss_dice: 1.0145  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 1.0583  decode.d1.loss_dice: 1.0167  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 1.0528  decode.d2.loss_dice: 1.0287  decode.d3.loss_cls: 0.0404  decode.d3.loss_mask: 1.0462  decode.d3.loss_dice: 1.0218  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 1.0468  decode.d4.loss_dice: 1.0250  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 1.0442  decode.d5.loss_dice: 1.0311  decode.d6.loss_cls: 0.0294  decode.d6.loss_mask: 1.0474  decode.d6.loss_dice: 1.0172  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 1.0525  decode.d7.loss_dice: 1.0190  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 1.0536  decode.d8.loss_dice: 1.0109
2025/03/31 05:25:54 - mmengine - INFO - Iter(train) [ 3900/20000]  base_lr: 8.2269e-05 lr: 8.2269e-05  eta: 3:51:41  time: 0.8630  data_time: 0.0158  memory: 10142  loss: 18.4411  decode.loss_cls: 0.0337  decode.loss_mask: 0.9135  decode.loss_dice: 0.8869  decode.d0.loss_cls: 0.1130  decode.d0.loss_mask: 0.9181  decode.d0.loss_dice: 0.9040  decode.d1.loss_cls: 0.0264  decode.d1.loss_mask: 0.9184  decode.d1.loss_dice: 0.8933  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.9066  decode.d2.loss_dice: 0.9000  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.9055  decode.d3.loss_dice: 0.8875  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.9073  decode.d4.loss_dice: 0.8950  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.9025  decode.d5.loss_dice: 0.8956  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 0.9102  decode.d6.loss_dice: 0.8901  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.9087  decode.d7.loss_dice: 0.8988  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.9099  decode.d8.loss_dice: 0.8926
2025/03/31 05:26:39 - mmengine - INFO - Iter(train) [ 3950/20000]  base_lr: 8.2039e-05 lr: 8.2039e-05  eta: 3:51:02  time: 0.9074  data_time: 0.0159  memory: 10099  loss: 19.4524  decode.loss_cls: 0.0591  decode.loss_mask: 0.9674  decode.loss_dice: 0.9045  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.9788  decode.d0.loss_dice: 0.9306  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.9691  decode.d1.loss_dice: 0.9109  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.9627  decode.d2.loss_dice: 0.9149  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.9659  decode.d3.loss_dice: 0.9027  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.9703  decode.d4.loss_dice: 0.9067  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.9655  decode.d5.loss_dice: 0.9084  decode.d6.loss_cls: 0.0981  decode.d6.loss_mask: 0.9652  decode.d6.loss_dice: 0.9100  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.9638  decode.d7.loss_dice: 0.9144  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.9688  decode.d8.loss_dice: 0.9151
2025/03/31 05:27:23 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 05:27:23 - mmengine - INFO - Iter(train) [ 4000/20000]  base_lr: 8.1809e-05 lr: 8.1809e-05  eta: 3:50:22  time: 0.8603  data_time: 0.0158  memory: 10143  loss: 18.8885  decode.loss_cls: 0.0122  decode.loss_mask: 0.9982  decode.loss_dice: 0.8680  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 0.9925  decode.d0.loss_dice: 0.8963  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 1.0053  decode.d1.loss_dice: 0.8713  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 1.0053  decode.d2.loss_dice: 0.8871  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 1.0016  decode.d3.loss_dice: 0.8649  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.9963  decode.d4.loss_dice: 0.8676  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 1.0039  decode.d5.loss_dice: 0.8581  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.9964  decode.d6.loss_dice: 0.8598  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.9982  decode.d7.loss_dice: 0.8592  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.9959  decode.d8.loss_dice: 0.8658
2025/03/31 05:27:23 - mmengine - INFO - Saving checkpoint at 4000 iterations
2025/03/31 05:27:29 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:07  time: 0.0955  data_time: 0.0015  memory: 1853  
2025/03/31 05:27:34 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:02  time: 0.0948  data_time: 0.0014  memory: 1853  
2025/03/31 05:27:39 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:57  time: 0.0960  data_time: 0.0014  memory: 1853  
2025/03/31 05:27:43 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:53  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:27:48 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:48  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 05:27:53 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:43  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 05:27:58 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:38  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:02 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:33  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:07 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:28  time: 0.0951  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:12 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:24  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:17 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:19  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:21 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:14  time: 0.0951  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:26 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:09  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:31 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:05  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:36 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:02:00  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:40 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:55  time: 0.0951  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:45 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:50  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:50 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:46  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:55 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:41  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 05:28:59 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:36  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:04 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:31  time: 0.0951  data_time: 0.0014  memory: 1853  
2025/03/31 05:29:09 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:26  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:14 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:22  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:18 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:17  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:23 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:12  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:28 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:07  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:33 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:03  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:37 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:58  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:42 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0946  data_time: 0.0012  memory: 1853  
2025/03/31 05:29:47 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:48  time: 0.0948  data_time: 0.0012  memory: 1853  
2025/03/31 05:29:52 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:44  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 05:29:56 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:30:01 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 05:30:06 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:30  time: 0.0950  data_time: 0.0014  memory: 1853  
2025/03/31 05:30:11 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:30:16 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0950  data_time: 0.0014  memory: 1853  
2025/03/31 05:30:20 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 05:30:25 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:11  time: 0.0951  data_time: 0.0014  memory: 1853  
2025/03/31 05:30:30 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 05:30:35 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 05:30:36 - mmengine - INFO - per class results:
2025/03/31 05:30:36 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 69.12 | 92.57 |
|      building      | 84.09 | 94.37 |
|   low_vegetation   | 58.43 | 78.59 |
|        tree        | 42.61 | 45.74 |
|        car         | 74.34 | 83.85 |
|      clutter       |  1.76 |  1.77 |
+--------------------+-------+-------+
2025/03/31 05:30:36 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 77.6600  mIoU: 55.0600  mAcc: 66.1500  data_time: 0.0013  time: 0.0949
2025/03/31 05:30:36 - mmengine - INFO - The previous best checkpoint /home/face/kaichengyang/xiaoxinghu/Earth_Adapter/work_dirs/vi2pr/DG_spatial_64_cutoff_0.3_fft_pre6/3e441_seed0/best_mIoU_iter_2000.pth is removed
2025/03/31 05:30:37 - mmengine - INFO - The best checkpoint with 55.0600 mIoU at 4000 iter is saved to best_mIoU_iter_4000.pth.
2025/03/31 05:31:21 - mmengine - INFO - Iter(train) [ 4050/20000]  base_lr: 8.1579e-05 lr: 8.1579e-05  eta: 3:49:47  time: 0.8589  data_time: 0.0159  memory: 10094  loss: 22.1468  decode.loss_cls: 0.0253  decode.loss_mask: 1.1183  decode.loss_dice: 1.0509  decode.d0.loss_cls: 0.1055  decode.d0.loss_mask: 1.1424  decode.d0.loss_dice: 1.0253  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 1.1142  decode.d1.loss_dice: 1.0304  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 1.1201  decode.d2.loss_dice: 1.0426  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 1.1210  decode.d3.loss_dice: 1.0515  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 1.1184  decode.d4.loss_dice: 1.0565  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 1.1183  decode.d5.loss_dice: 1.0464  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 1.1248  decode.d6.loss_dice: 1.0512  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 1.1162  decode.d7.loss_dice: 1.0552  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 1.1175  decode.d8.loss_dice: 1.0458
2025/03/31 05:32:05 - mmengine - INFO - Iter(train) [ 4100/20000]  base_lr: 8.1349e-05 lr: 8.1349e-05  eta: 3:49:04  time: 0.8656  data_time: 0.0161  memory: 10155  loss: 20.7471  decode.loss_cls: 0.0417  decode.loss_mask: 1.0596  decode.loss_dice: 0.9700  decode.d0.loss_cls: 0.1060  decode.d0.loss_mask: 1.0688  decode.d0.loss_dice: 0.9605  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 1.0615  decode.d1.loss_dice: 0.9566  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 1.0632  decode.d2.loss_dice: 0.9569  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 1.0591  decode.d3.loss_dice: 0.9784  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 1.0592  decode.d4.loss_dice: 0.9649  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 1.0663  decode.d5.loss_dice: 0.9695  decode.d6.loss_cls: 0.0400  decode.d6.loss_mask: 1.0664  decode.d6.loss_dice: 0.9552  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 1.0640  decode.d7.loss_dice: 0.9650  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 1.0636  decode.d8.loss_dice: 0.9504
2025/03/31 05:32:48 - mmengine - INFO - Iter(train) [ 4150/20000]  base_lr: 8.1118e-05 lr: 8.1118e-05  eta: 3:48:20  time: 0.8600  data_time: 0.0160  memory: 10145  loss: 19.4942  decode.loss_cls: 0.0319  decode.loss_mask: 0.9730  decode.loss_dice: 0.9331  decode.d0.loss_cls: 0.0745  decode.d0.loss_mask: 0.9812  decode.d0.loss_dice: 0.9457  decode.d1.loss_cls: 0.0309  decode.d1.loss_mask: 0.9673  decode.d1.loss_dice: 0.9395  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.9699  decode.d2.loss_dice: 0.9340  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.9790  decode.d3.loss_dice: 0.9333  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 0.9821  decode.d4.loss_dice: 0.9371  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.9784  decode.d5.loss_dice: 0.9323  decode.d6.loss_cls: 0.0326  decode.d6.loss_mask: 0.9747  decode.d6.loss_dice: 0.9310  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.9726  decode.d7.loss_dice: 0.9358  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.9767  decode.d8.loss_dice: 0.9369
2025/03/31 05:33:31 - mmengine - INFO - Iter(train) [ 4200/20000]  base_lr: 8.0888e-05 lr: 8.0888e-05  eta: 3:47:37  time: 0.8610  data_time: 0.0169  memory: 10092  loss: 19.8018  decode.loss_cls: 0.0152  decode.loss_mask: 1.0290  decode.loss_dice: 0.9339  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 1.0385  decode.d0.loss_dice: 0.9451  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 1.0316  decode.d1.loss_dice: 0.9309  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 1.0220  decode.d2.loss_dice: 0.9264  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 1.0184  decode.d3.loss_dice: 0.9361  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 1.0154  decode.d4.loss_dice: 0.9269  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 1.0180  decode.d5.loss_dice: 0.9234  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 1.0281  decode.d6.loss_dice: 0.9239  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 1.0235  decode.d7.loss_dice: 0.9297  decode.d8.loss_cls: 0.0181  decode.d8.loss_mask: 1.0278  decode.d8.loss_dice: 0.9300
2025/03/31 05:34:14 - mmengine - INFO - Iter(train) [ 4250/20000]  base_lr: 8.0658e-05 lr: 8.0658e-05  eta: 3:46:53  time: 0.8601  data_time: 0.0158  memory: 10094  loss: 19.2292  decode.loss_cls: 0.0358  decode.loss_mask: 0.9696  decode.loss_dice: 0.9050  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.9765  decode.d0.loss_dice: 0.9080  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.9649  decode.d1.loss_dice: 0.9148  decode.d2.loss_cls: 0.0565  decode.d2.loss_mask: 0.9608  decode.d2.loss_dice: 0.9229  decode.d3.loss_cls: 0.0391  decode.d3.loss_mask: 0.9582  decode.d3.loss_dice: 0.9222  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.9635  decode.d4.loss_dice: 0.9196  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.9651  decode.d5.loss_dice: 0.9008  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.9702  decode.d6.loss_dice: 0.9077  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.9752  decode.d7.loss_dice: 0.9170  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.9687  decode.d8.loss_dice: 0.9034
2025/03/31 05:34:57 - mmengine - INFO - Iter(train) [ 4300/20000]  base_lr: 8.0427e-05 lr: 8.0427e-05  eta: 3:46:09  time: 0.8576  data_time: 0.0160  memory: 10140  loss: 19.6039  decode.loss_cls: 0.0289  decode.loss_mask: 0.9875  decode.loss_dice: 0.9075  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 1.0046  decode.d0.loss_dice: 0.9315  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.9964  decode.d1.loss_dice: 0.9365  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.9923  decode.d2.loss_dice: 0.9344  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.9906  decode.d3.loss_dice: 0.9311  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.9866  decode.d4.loss_dice: 0.9149  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.9894  decode.d5.loss_dice: 0.9236  decode.d6.loss_cls: 0.0388  decode.d6.loss_mask: 0.9892  decode.d6.loss_dice: 0.9258  decode.d7.loss_cls: 0.0515  decode.d7.loss_mask: 0.9896  decode.d7.loss_dice: 0.9261  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.9911  decode.d8.loss_dice: 0.9246
2025/03/31 05:35:40 - mmengine - INFO - Iter(train) [ 4350/20000]  base_lr: 8.0197e-05 lr: 8.0197e-05  eta: 3:45:25  time: 0.8589  data_time: 0.0157  memory: 10145  loss: 19.6365  decode.loss_cls: 0.0389  decode.loss_mask: 0.9963  decode.loss_dice: 0.9291  decode.d0.loss_cls: 0.0953  decode.d0.loss_mask: 0.9762  decode.d0.loss_dice: 0.9383  decode.d1.loss_cls: 0.0398  decode.d1.loss_mask: 0.9718  decode.d1.loss_dice: 0.9353  decode.d2.loss_cls: 0.0508  decode.d2.loss_mask: 0.9681  decode.d2.loss_dice: 0.9207  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.9974  decode.d3.loss_dice: 0.9349  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.9964  decode.d4.loss_dice: 0.9396  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.9965  decode.d5.loss_dice: 0.9365  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.9676  decode.d6.loss_dice: 0.9343  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 0.9784  decode.d7.loss_dice: 0.9426  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.9728  decode.d8.loss_dice: 0.9295
2025/03/31 05:36:23 - mmengine - INFO - Iter(train) [ 4400/20000]  base_lr: 7.9966e-05 lr: 7.9966e-05  eta: 3:44:41  time: 0.8579  data_time: 0.0159  memory: 10139  loss: 20.5108  decode.loss_cls: 0.0225  decode.loss_mask: 1.0108  decode.loss_dice: 1.0149  decode.d0.loss_cls: 0.0702  decode.d0.loss_mask: 1.0247  decode.d0.loss_dice: 0.9981  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 1.0073  decode.d1.loss_dice: 1.0170  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 1.0168  decode.d2.loss_dice: 0.9982  decode.d3.loss_cls: 0.0205  decode.d3.loss_mask: 1.0152  decode.d3.loss_dice: 1.0102  decode.d4.loss_cls: 0.0233  decode.d4.loss_mask: 1.0082  decode.d4.loss_dice: 1.0114  decode.d5.loss_cls: 0.0243  decode.d5.loss_mask: 1.0110  decode.d5.loss_dice: 1.0107  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 1.0186  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 1.0155  decode.d7.loss_dice: 1.0101  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 1.0162  decode.d8.loss_dice: 1.0132
2025/03/31 05:37:06 - mmengine - INFO - Iter(train) [ 4450/20000]  base_lr: 7.9735e-05 lr: 7.9735e-05  eta: 3:43:58  time: 0.8601  data_time: 0.0159  memory: 10145  loss: 19.9167  decode.loss_cls: 0.0440  decode.loss_mask: 0.9630  decode.loss_dice: 0.9796  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.9749  decode.d0.loss_dice: 0.9885  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.9679  decode.d1.loss_dice: 0.9742  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.9659  decode.d2.loss_dice: 0.9764  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.9638  decode.d3.loss_dice: 0.9779  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.9692  decode.d4.loss_dice: 0.9915  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.9639  decode.d5.loss_dice: 0.9909  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.9663  decode.d6.loss_dice: 0.9847  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.9663  decode.d7.loss_dice: 0.9963  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.9675  decode.d8.loss_dice: 0.9758
2025/03/31 05:37:49 - mmengine - INFO - Iter(train) [ 4500/20000]  base_lr: 7.9504e-05 lr: 7.9504e-05  eta: 3:43:14  time: 0.8625  data_time: 0.0159  memory: 10094  loss: 19.6553  decode.loss_cls: 0.0432  decode.loss_mask: 0.9922  decode.loss_dice: 0.9471  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 1.0006  decode.d0.loss_dice: 0.9457  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.9895  decode.d1.loss_dice: 0.9417  decode.d2.loss_cls: 0.0281  decode.d2.loss_mask: 0.9903  decode.d2.loss_dice: 0.9201  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.9944  decode.d3.loss_dice: 0.9375  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 0.9925  decode.d4.loss_dice: 0.9432  decode.d5.loss_cls: 0.0258  decode.d5.loss_mask: 0.9863  decode.d5.loss_dice: 0.9426  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.9887  decode.d6.loss_dice: 0.9316  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.9916  decode.d7.loss_dice: 0.9377  decode.d8.loss_cls: 0.0202  decode.d8.loss_mask: 0.9898  decode.d8.loss_dice: 0.9456
2025/03/31 05:38:32 - mmengine - INFO - Iter(train) [ 4550/20000]  base_lr: 7.9274e-05 lr: 7.9274e-05  eta: 3:42:30  time: 0.8581  data_time: 0.0161  memory: 10093  loss: 18.1691  decode.loss_cls: 0.0493  decode.loss_mask: 0.8763  decode.loss_dice: 0.8911  decode.d0.loss_cls: 0.0569  decode.d0.loss_mask: 0.8922  decode.d0.loss_dice: 0.8921  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.8794  decode.d1.loss_dice: 0.8908  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.8792  decode.d2.loss_dice: 0.8763  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.8767  decode.d3.loss_dice: 0.8771  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.8721  decode.d4.loss_dice: 0.8832  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.8817  decode.d5.loss_dice: 0.8766  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.8781  decode.d6.loss_dice: 0.8825  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.8792  decode.d7.loss_dice: 0.8961  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.8781  decode.d8.loss_dice: 0.8851
2025/03/31 05:39:16 - mmengine - INFO - Iter(train) [ 4600/20000]  base_lr: 7.9043e-05 lr: 7.9043e-05  eta: 3:41:47  time: 0.8595  data_time: 0.0158  memory: 10144  loss: 21.4160  decode.loss_cls: 0.0307  decode.loss_mask: 1.0955  decode.loss_dice: 1.0218  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 1.1137  decode.d0.loss_dice: 0.9976  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 1.1084  decode.d1.loss_dice: 1.0037  decode.d2.loss_cls: 0.0230  decode.d2.loss_mask: 1.1014  decode.d2.loss_dice: 1.0162  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 1.0921  decode.d3.loss_dice: 1.0144  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 1.0895  decode.d4.loss_dice: 1.0129  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 1.0904  decode.d5.loss_dice: 1.0154  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 1.0912  decode.d6.loss_dice: 1.0106  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 1.0918  decode.d7.loss_dice: 1.0214  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 1.0930  decode.d8.loss_dice: 1.0179
2025/03/31 05:39:59 - mmengine - INFO - Iter(train) [ 4650/20000]  base_lr: 7.8812e-05 lr: 7.8812e-05  eta: 3:41:04  time: 0.8603  data_time: 0.0163  memory: 10097  loss: 17.2179  decode.loss_cls: 0.0482  decode.loss_mask: 0.7793  decode.loss_dice: 0.8566  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.7771  decode.d0.loss_dice: 0.9056  decode.d1.loss_cls: 0.1040  decode.d1.loss_mask: 0.7726  decode.d1.loss_dice: 0.8444  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.7728  decode.d2.loss_dice: 0.8512  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 0.7754  decode.d3.loss_dice: 0.8260  decode.d4.loss_cls: 0.1169  decode.d4.loss_mask: 0.7723  decode.d4.loss_dice: 0.8391  decode.d5.loss_cls: 0.0956  decode.d5.loss_mask: 0.7761  decode.d5.loss_dice: 0.8579  decode.d6.loss_cls: 0.1314  decode.d6.loss_mask: 0.7774  decode.d6.loss_dice: 0.8439  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.7840  decode.d7.loss_dice: 0.8620  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.7772  decode.d8.loss_dice: 0.8587
2025/03/31 05:40:42 - mmengine - INFO - Iter(train) [ 4700/20000]  base_lr: 7.8581e-05 lr: 7.8581e-05  eta: 3:40:20  time: 0.8589  data_time: 0.0159  memory: 10144  loss: 19.6331  decode.loss_cls: 0.0231  decode.loss_mask: 0.9912  decode.loss_dice: 0.9375  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 1.0090  decode.d0.loss_dice: 0.9693  decode.d1.loss_cls: 0.0235  decode.d1.loss_mask: 0.9952  decode.d1.loss_dice: 0.9424  decode.d2.loss_cls: 0.0258  decode.d2.loss_mask: 0.9963  decode.d2.loss_dice: 0.9356  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.9871  decode.d3.loss_dice: 0.9449  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.9860  decode.d4.loss_dice: 0.9443  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.9870  decode.d5.loss_dice: 0.9438  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.9872  decode.d6.loss_dice: 0.9430  decode.d7.loss_cls: 0.0253  decode.d7.loss_mask: 0.9939  decode.d7.loss_dice: 0.9300  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.9939  decode.d8.loss_dice: 0.9284
2025/03/31 05:41:25 - mmengine - INFO - Iter(train) [ 4750/20000]  base_lr: 7.8349e-05 lr: 7.8349e-05  eta: 3:39:37  time: 0.8588  data_time: 0.0160  memory: 10098  loss: 20.0231  decode.loss_cls: 0.0078  decode.loss_mask: 1.0129  decode.loss_dice: 0.9659  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 1.0244  decode.d0.loss_dice: 0.9612  decode.d1.loss_cls: 0.0371  decode.d1.loss_mask: 1.0171  decode.d1.loss_dice: 0.9595  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 1.0202  decode.d2.loss_dice: 0.9592  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 1.0160  decode.d3.loss_dice: 0.9729  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 1.0175  decode.d4.loss_dice: 0.9727  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 1.0183  decode.d5.loss_dice: 0.9724  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 1.0143  decode.d6.loss_dice: 0.9676  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 1.0143  decode.d7.loss_dice: 0.9626  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 1.0130  decode.d8.loss_dice: 0.9692
2025/03/31 05:42:08 - mmengine - INFO - Iter(train) [ 4800/20000]  base_lr: 7.8118e-05 lr: 7.8118e-05  eta: 3:38:53  time: 0.8613  data_time: 0.0164  memory: 10099  loss: 20.3772  decode.loss_cls: 0.0490  decode.loss_mask: 1.0411  decode.loss_dice: 0.9347  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 1.0728  decode.d0.loss_dice: 0.9409  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 1.0470  decode.d1.loss_dice: 0.9597  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 1.0364  decode.d2.loss_dice: 0.9643  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 1.0418  decode.d3.loss_dice: 0.9513  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 1.0404  decode.d4.loss_dice: 0.9388  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 1.0399  decode.d5.loss_dice: 0.9488  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 1.0400  decode.d6.loss_dice: 0.9500  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 1.0413  decode.d7.loss_dice: 0.9569  decode.d8.loss_cls: 0.0474  decode.d8.loss_mask: 1.0488  decode.d8.loss_dice: 0.9535
2025/03/31 05:42:51 - mmengine - INFO - Iter(train) [ 4850/20000]  base_lr: 7.7887e-05 lr: 7.7887e-05  eta: 3:38:10  time: 0.8595  data_time: 0.0159  memory: 10154  loss: 18.1270  decode.loss_cls: 0.0371  decode.loss_mask: 0.9153  decode.loss_dice: 0.8560  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.9248  decode.d0.loss_dice: 0.8548  decode.d1.loss_cls: 0.0320  decode.d1.loss_mask: 0.9236  decode.d1.loss_dice: 0.8552  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.9216  decode.d2.loss_dice: 0.8649  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.9215  decode.d3.loss_dice: 0.8523  decode.d4.loss_cls: 0.0369  decode.d4.loss_mask: 0.9164  decode.d4.loss_dice: 0.8317  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.9190  decode.d5.loss_dice: 0.8464  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.9195  decode.d6.loss_dice: 0.8566  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.9155  decode.d7.loss_dice: 0.8553  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.9212  decode.d8.loss_dice: 0.8588
2025/03/31 05:43:34 - mmengine - INFO - Iter(train) [ 4900/20000]  base_lr: 7.7655e-05 lr: 7.7655e-05  eta: 3:37:27  time: 0.8655  data_time: 0.0161  memory: 10145  loss: 18.9990  decode.loss_cls: 0.0242  decode.loss_mask: 0.9769  decode.loss_dice: 0.8784  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.9813  decode.d0.loss_dice: 0.8990  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.9708  decode.d1.loss_dice: 0.8945  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.9704  decode.d2.loss_dice: 0.8829  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.9724  decode.d3.loss_dice: 0.8808  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.9761  decode.d4.loss_dice: 0.8857  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.9790  decode.d5.loss_dice: 0.8831  decode.d6.loss_cls: 0.0273  decode.d6.loss_mask: 0.9825  decode.d6.loss_dice: 0.8820  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.9821  decode.d7.loss_dice: 0.8772  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.9747  decode.d8.loss_dice: 0.8762
2025/03/31 05:44:17 - mmengine - INFO - Iter(train) [ 4950/20000]  base_lr: 7.7424e-05 lr: 7.7424e-05  eta: 3:36:43  time: 0.8606  data_time: 0.0163  memory: 10095  loss: 17.9418  decode.loss_cls: 0.0518  decode.loss_mask: 0.8674  decode.loss_dice: 0.8461  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.8728  decode.d0.loss_dice: 0.9169  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.8670  decode.d1.loss_dice: 0.8667  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.8666  decode.d2.loss_dice: 0.8596  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.8710  decode.d3.loss_dice: 0.8508  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.8676  decode.d4.loss_dice: 0.8480  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.8706  decode.d5.loss_dice: 0.8536  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.8733  decode.d6.loss_dice: 0.8455  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.8736  decode.d7.loss_dice: 0.8618  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.8747  decode.d8.loss_dice: 0.8619
2025/03/31 05:45:01 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 05:45:01 - mmengine - INFO - Iter(train) [ 5000/20000]  base_lr: 7.7192e-05 lr: 7.7192e-05  eta: 3:35:59  time: 0.8595  data_time: 0.0158  memory: 10142  loss: 19.2482  decode.loss_cls: 0.0562  decode.loss_mask: 0.9311  decode.loss_dice: 0.9437  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.9335  decode.d0.loss_dice: 0.9256  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.9311  decode.d1.loss_dice: 0.9286  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.9239  decode.d2.loss_dice: 0.9221  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.9270  decode.d3.loss_dice: 0.9086  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.9317  decode.d4.loss_dice: 0.9166  decode.d5.loss_cls: 0.0768  decode.d5.loss_mask: 0.9215  decode.d5.loss_dice: 0.9234  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.9303  decode.d6.loss_dice: 0.9280  decode.d7.loss_cls: 0.0720  decode.d7.loss_mask: 0.9240  decode.d7.loss_dice: 0.9332  decode.d8.loss_cls: 0.0585  decode.d8.loss_mask: 0.9227  decode.d8.loss_dice: 0.9413
2025/03/31 05:45:44 - mmengine - INFO - Iter(train) [ 5050/20000]  base_lr: 7.6961e-05 lr: 7.6961e-05  eta: 3:35:16  time: 0.8622  data_time: 0.0160  memory: 10142  loss: 17.2882  decode.loss_cls: 0.0146  decode.loss_mask: 0.8878  decode.loss_dice: 0.8137  decode.d0.loss_cls: 0.0646  decode.d0.loss_mask: 0.8801  decode.d0.loss_dice: 0.8330  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.8741  decode.d1.loss_dice: 0.8339  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.8822  decode.d2.loss_dice: 0.8358  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.8875  decode.d3.loss_dice: 0.8246  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.8842  decode.d4.loss_dice: 0.8275  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.8821  decode.d5.loss_dice: 0.8244  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.8852  decode.d6.loss_dice: 0.8301  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.8823  decode.d7.loss_dice: 0.8250  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.8813  decode.d8.loss_dice: 0.8241
2025/03/31 05:46:27 - mmengine - INFO - Iter(train) [ 5100/20000]  base_lr: 7.6729e-05 lr: 7.6729e-05  eta: 3:34:33  time: 0.8637  data_time: 0.0162  memory: 10093  loss: 19.0606  decode.loss_cls: 0.0098  decode.loss_mask: 0.9754  decode.loss_dice: 0.9107  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.9883  decode.d0.loss_dice: 0.9119  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.9799  decode.d1.loss_dice: 0.9152  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 0.9190  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.9675  decode.d3.loss_dice: 0.9132  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.9703  decode.d4.loss_dice: 0.9176  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.9732  decode.d5.loss_dice: 0.9150  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.9696  decode.d6.loss_dice: 0.9142  decode.d7.loss_cls: 0.0099  decode.d7.loss_mask: 0.9624  decode.d7.loss_dice: 0.9141  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.9694  decode.d8.loss_dice: 0.9134
2025/03/31 05:47:10 - mmengine - INFO - Iter(train) [ 5150/20000]  base_lr: 7.6497e-05 lr: 7.6497e-05  eta: 3:33:49  time: 0.8611  data_time: 0.0160  memory: 10145  loss: 19.5352  decode.loss_cls: 0.0473  decode.loss_mask: 1.0016  decode.loss_dice: 0.8960  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 1.0096  decode.d0.loss_dice: 0.8708  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 1.0035  decode.d1.loss_dice: 0.8949  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 1.0018  decode.d2.loss_dice: 0.8898  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.9995  decode.d3.loss_dice: 0.8911  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.9992  decode.d4.loss_dice: 0.8858  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 1.0040  decode.d5.loss_dice: 0.8972  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.9948  decode.d6.loss_dice: 0.8966  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 1.0012  decode.d7.loss_dice: 0.8870  decode.d8.loss_cls: 0.0729  decode.d8.loss_mask: 0.9973  decode.d8.loss_dice: 0.8873
2025/03/31 05:47:53 - mmengine - INFO - Iter(train) [ 5200/20000]  base_lr: 7.6265e-05 lr: 7.6265e-05  eta: 3:33:06  time: 0.8601  data_time: 0.0161  memory: 10142  loss: 17.1675  decode.loss_cls: 0.0354  decode.loss_mask: 0.8272  decode.loss_dice: 0.8561  decode.d0.loss_cls: 0.0555  decode.d0.loss_mask: 0.8392  decode.d0.loss_dice: 0.8527  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.8286  decode.d1.loss_dice: 0.8405  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.8289  decode.d2.loss_dice: 0.8668  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.8215  decode.d3.loss_dice: 0.8457  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.8205  decode.d4.loss_dice: 0.8386  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.8262  decode.d5.loss_dice: 0.8313  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.8230  decode.d6.loss_dice: 0.8378  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.8238  decode.d7.loss_dice: 0.8364  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.8247  decode.d8.loss_dice: 0.8384
2025/03/31 05:48:36 - mmengine - INFO - Iter(train) [ 5250/20000]  base_lr: 7.6034e-05 lr: 7.6034e-05  eta: 3:32:23  time: 0.8582  data_time: 0.0166  memory: 10099  loss: 17.1832  decode.loss_cls: 0.0038  decode.loss_mask: 0.9011  decode.loss_dice: 0.8120  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.9002  decode.d0.loss_dice: 0.7936  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.9009  decode.d1.loss_dice: 0.8033  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.8962  decode.d2.loss_dice: 0.8006  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 0.8067  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.8973  decode.d4.loss_dice: 0.7983  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.8993  decode.d5.loss_dice: 0.8056  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.8974  decode.d6.loss_dice: 0.8117  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.8981  decode.d7.loss_dice: 0.8085  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.8973  decode.d8.loss_dice: 0.8174
2025/03/31 05:49:19 - mmengine - INFO - Iter(train) [ 5300/20000]  base_lr: 7.5802e-05 lr: 7.5802e-05  eta: 3:31:39  time: 0.8585  data_time: 0.0158  memory: 10139  loss: 19.8845  decode.loss_cls: 0.0682  decode.loss_mask: 1.0079  decode.loss_dice: 0.9313  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 1.0116  decode.d0.loss_dice: 0.9396  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 1.0099  decode.d1.loss_dice: 0.9104  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 1.0036  decode.d2.loss_dice: 0.8991  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 1.0132  decode.d3.loss_dice: 0.9181  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 1.0082  decode.d4.loss_dice: 0.9045  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 1.0070  decode.d5.loss_dice: 0.8982  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 1.0070  decode.d6.loss_dice: 0.8972  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 1.0110  decode.d7.loss_dice: 0.9058  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 1.0062  decode.d8.loss_dice: 0.9330
2025/03/31 05:50:02 - mmengine - INFO - Iter(train) [ 5350/20000]  base_lr: 7.5569e-05 lr: 7.5569e-05  eta: 3:30:55  time: 0.8593  data_time: 0.0159  memory: 10142  loss: 17.3329  decode.loss_cls: 0.0212  decode.loss_mask: 0.8689  decode.loss_dice: 0.8313  decode.d0.loss_cls: 0.0663  decode.d0.loss_mask: 0.8936  decode.d0.loss_dice: 0.8164  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.8776  decode.d1.loss_dice: 0.8323  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.8790  decode.d2.loss_dice: 0.8418  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.8710  decode.d3.loss_dice: 0.8391  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.8688  decode.d4.loss_dice: 0.8370  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.8686  decode.d5.loss_dice: 0.8428  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.8730  decode.d6.loss_dice: 0.8291  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.8715  decode.d7.loss_dice: 0.8341  decode.d8.loss_cls: 0.0181  decode.d8.loss_mask: 0.8752  decode.d8.loss_dice: 0.8336
2025/03/31 05:50:45 - mmengine - INFO - Iter(train) [ 5400/20000]  base_lr: 7.5337e-05 lr: 7.5337e-05  eta: 3:30:12  time: 0.8587  data_time: 0.0157  memory: 10145  loss: 18.4860  decode.loss_cls: 0.0333  decode.loss_mask: 0.9503  decode.loss_dice: 0.8468  decode.d0.loss_cls: 0.0691  decode.d0.loss_mask: 0.9517  decode.d0.loss_dice: 0.8467  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.9529  decode.d1.loss_dice: 0.8381  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.9514  decode.d2.loss_dice: 0.8521  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.9429  decode.d3.loss_dice: 0.8661  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.9452  decode.d4.loss_dice: 0.8445  decode.d5.loss_cls: 0.0405  decode.d5.loss_mask: 0.9438  decode.d5.loss_dice: 0.8554  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.9508  decode.d6.loss_dice: 0.8547  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.9516  decode.d7.loss_dice: 0.8487  decode.d8.loss_cls: 0.0900  decode.d8.loss_mask: 0.9485  decode.d8.loss_dice: 0.8383
2025/03/31 05:51:28 - mmengine - INFO - Iter(train) [ 5450/20000]  base_lr: 7.5105e-05 lr: 7.5105e-05  eta: 3:29:28  time: 0.8583  data_time: 0.0156  memory: 10144  loss: 17.6343  decode.loss_cls: 0.0188  decode.loss_mask: 0.9016  decode.loss_dice: 0.8321  decode.d0.loss_cls: 0.0722  decode.d0.loss_mask: 0.9019  decode.d0.loss_dice: 0.8419  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.8950  decode.d1.loss_dice: 0.8403  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.9005  decode.d2.loss_dice: 0.8296  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.9021  decode.d3.loss_dice: 0.8423  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.8971  decode.d4.loss_dice: 0.8327  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.9026  decode.d5.loss_dice: 0.8401  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.9049  decode.d6.loss_dice: 0.8336  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.8986  decode.d7.loss_dice: 0.8401  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.9023  decode.d8.loss_dice: 0.8241
2025/03/31 05:52:12 - mmengine - INFO - Iter(train) [ 5500/20000]  base_lr: 7.4873e-05 lr: 7.4873e-05  eta: 3:28:45  time: 0.8724  data_time: 0.0161  memory: 10098  loss: 18.1578  decode.loss_cls: 0.0293  decode.loss_mask: 0.9075  decode.loss_dice: 0.8624  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.9245  decode.d0.loss_dice: 0.8728  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.9224  decode.d1.loss_dice: 0.8598  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.9075  decode.d2.loss_dice: 0.8609  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.9127  decode.d3.loss_dice: 0.8641  decode.d4.loss_cls: 0.0513  decode.d4.loss_mask: 0.9067  decode.d4.loss_dice: 0.8614  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.9038  decode.d5.loss_dice: 0.8791  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.9090  decode.d6.loss_dice: 0.8669  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.9120  decode.d7.loss_dice: 0.8583  decode.d8.loss_cls: 0.0310  decode.d8.loss_mask: 0.9122  decode.d8.loss_dice: 0.8668
2025/03/31 05:52:54 - mmengine - INFO - Iter(train) [ 5550/20000]  base_lr: 7.4640e-05 lr: 7.4640e-05  eta: 3:28:01  time: 0.8569  data_time: 0.0156  memory: 10093  loss: 18.0482  decode.loss_cls: 0.0063  decode.loss_mask: 0.9501  decode.loss_dice: 0.8469  decode.d0.loss_cls: 0.0552  decode.d0.loss_mask: 0.9639  decode.d0.loss_dice: 0.8312  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.9520  decode.d1.loss_dice: 0.8404  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.9482  decode.d2.loss_dice: 0.8363  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.9394  decode.d3.loss_dice: 0.8355  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.9440  decode.d4.loss_dice: 0.8325  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.9453  decode.d5.loss_dice: 0.8458  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.9417  decode.d6.loss_dice: 0.8552  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.9445  decode.d7.loss_dice: 0.8511  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.9506  decode.d8.loss_dice: 0.8513
2025/03/31 05:53:37 - mmengine - INFO - Iter(train) [ 5600/20000]  base_lr: 7.4408e-05 lr: 7.4408e-05  eta: 3:27:17  time: 0.8562  data_time: 0.0157  memory: 10099  loss: 18.8202  decode.loss_cls: 0.0549  decode.loss_mask: 0.9476  decode.loss_dice: 0.8904  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.9553  decode.d0.loss_dice: 0.9082  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.9423  decode.d1.loss_dice: 0.9073  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.9444  decode.d2.loss_dice: 0.8934  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.9440  decode.d3.loss_dice: 0.8968  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.9406  decode.d4.loss_dice: 0.8969  decode.d5.loss_cls: 0.0216  decode.d5.loss_mask: 0.9488  decode.d5.loss_dice: 0.9115  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.9496  decode.d6.loss_dice: 0.9039  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.9462  decode.d7.loss_dice: 0.9094  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.9499  decode.d8.loss_dice: 0.8986
2025/03/31 05:54:20 - mmengine - INFO - Iter(train) [ 5650/20000]  base_lr: 7.4175e-05 lr: 7.4175e-05  eta: 3:26:33  time: 0.8571  data_time: 0.0156  memory: 10144  loss: 17.3728  decode.loss_cls: 0.0630  decode.loss_mask: 0.8566  decode.loss_dice: 0.8080  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.8824  decode.d0.loss_dice: 0.8060  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.8746  decode.d1.loss_dice: 0.8178  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.8667  decode.d2.loss_dice: 0.8185  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.8653  decode.d3.loss_dice: 0.8080  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.8592  decode.d4.loss_dice: 0.8149  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.8600  decode.d5.loss_dice: 0.7976  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.8590  decode.d6.loss_dice: 0.8123  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.8598  decode.d7.loss_dice: 0.8056  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.8565  decode.d8.loss_dice: 0.8216
2025/03/31 05:55:03 - mmengine - INFO - Iter(train) [ 5700/20000]  base_lr: 7.3943e-05 lr: 7.3943e-05  eta: 3:25:49  time: 0.8567  data_time: 0.0154  memory: 10142  loss: 18.6810  decode.loss_cls: 0.0108  decode.loss_mask: 0.9558  decode.loss_dice: 0.8888  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.9573  decode.d0.loss_dice: 0.8968  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.9531  decode.d1.loss_dice: 0.8900  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.9518  decode.d2.loss_dice: 0.8951  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.9543  decode.d3.loss_dice: 0.8859  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.9562  decode.d4.loss_dice: 0.8854  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.9558  decode.d5.loss_dice: 0.8803  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.9530  decode.d6.loss_dice: 0.8892  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.9533  decode.d7.loss_dice: 0.8888  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.9555  decode.d8.loss_dice: 0.8817
2025/03/31 05:55:46 - mmengine - INFO - Iter(train) [ 5750/20000]  base_lr: 7.3710e-05 lr: 7.3710e-05  eta: 3:25:05  time: 0.8586  data_time: 0.0156  memory: 10144  loss: 17.3543  decode.loss_cls: 0.0367  decode.loss_mask: 0.9030  decode.loss_dice: 0.7915  decode.d0.loss_cls: 0.0672  decode.d0.loss_mask: 0.9129  decode.d0.loss_dice: 0.7994  decode.d1.loss_cls: 0.0403  decode.d1.loss_mask: 0.9056  decode.d1.loss_dice: 0.7929  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.9006  decode.d2.loss_dice: 0.7859  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.9002  decode.d3.loss_dice: 0.7813  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.9094  decode.d4.loss_dice: 0.7946  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.9027  decode.d5.loss_dice: 0.8060  decode.d6.loss_cls: 0.0365  decode.d6.loss_mask: 0.9050  decode.d6.loss_dice: 0.7978  decode.d7.loss_cls: 0.0413  decode.d7.loss_mask: 0.9011  decode.d7.loss_dice: 0.7810  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.9026  decode.d8.loss_dice: 0.7801
2025/03/31 05:56:29 - mmengine - INFO - Iter(train) [ 5800/20000]  base_lr: 7.3477e-05 lr: 7.3477e-05  eta: 3:24:21  time: 0.8564  data_time: 0.0157  memory: 10143  loss: 17.1384  decode.loss_cls: 0.0104  decode.loss_mask: 0.8166  decode.loss_dice: 0.8783  decode.d0.loss_cls: 0.0628  decode.d0.loss_mask: 0.8311  decode.d0.loss_dice: 0.8981  decode.d1.loss_cls: 0.0346  decode.d1.loss_mask: 0.8133  decode.d1.loss_dice: 0.8815  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.8162  decode.d2.loss_dice: 0.8813  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.8094  decode.d3.loss_dice: 0.8689  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.8070  decode.d4.loss_dice: 0.8726  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.8161  decode.d5.loss_dice: 0.8761  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.8092  decode.d6.loss_dice: 0.8784  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.8088  decode.d7.loss_dice: 0.8678  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.8059  decode.d8.loss_dice: 0.8608
2025/03/31 05:57:12 - mmengine - INFO - Iter(train) [ 5850/20000]  base_lr: 7.3244e-05 lr: 7.3244e-05  eta: 3:23:37  time: 0.8560  data_time: 0.0155  memory: 10139  loss: 18.5599  decode.loss_cls: 0.0589  decode.loss_mask: 0.9183  decode.loss_dice: 0.8729  decode.d0.loss_cls: 0.0616  decode.d0.loss_mask: 0.9380  decode.d0.loss_dice: 0.8655  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.9304  decode.d1.loss_dice: 0.8717  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.9246  decode.d2.loss_dice: 0.8657  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.9190  decode.d3.loss_dice: 0.8917  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 0.9230  decode.d4.loss_dice: 0.8849  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.9180  decode.d5.loss_dice: 0.8918  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.9131  decode.d6.loss_dice: 0.8802  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.9187  decode.d7.loss_dice: 0.8957  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.9232  decode.d8.loss_dice: 0.8950
2025/03/31 05:57:55 - mmengine - INFO - Iter(train) [ 5900/20000]  base_lr: 7.3011e-05 lr: 7.3011e-05  eta: 3:22:54  time: 0.8569  data_time: 0.0154  memory: 10139  loss: 16.6799  decode.loss_cls: 0.0095  decode.loss_mask: 0.8535  decode.loss_dice: 0.7904  decode.d0.loss_cls: 0.0517  decode.d0.loss_mask: 0.8687  decode.d0.loss_dice: 0.7934  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.8540  decode.d1.loss_dice: 0.7926  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.8548  decode.d2.loss_dice: 0.8053  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.8491  decode.d3.loss_dice: 0.8091  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.8470  decode.d4.loss_dice: 0.8079  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.8536  decode.d5.loss_dice: 0.8010  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.8540  decode.d6.loss_dice: 0.7952  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.8519  decode.d7.loss_dice: 0.7994  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.8537  decode.d8.loss_dice: 0.7942
2025/03/31 05:58:38 - mmengine - INFO - Iter(train) [ 5950/20000]  base_lr: 7.2778e-05 lr: 7.2778e-05  eta: 3:22:10  time: 0.8594  data_time: 0.0165  memory: 10093  loss: 16.4512  decode.loss_cls: 0.0190  decode.loss_mask: 0.8214  decode.loss_dice: 0.7868  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.8263  decode.d0.loss_dice: 0.8268  decode.d1.loss_cls: 0.0203  decode.d1.loss_mask: 0.8289  decode.d1.loss_dice: 0.8040  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.8291  decode.d2.loss_dice: 0.8008  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.8261  decode.d3.loss_dice: 0.7938  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.8282  decode.d4.loss_dice: 0.7924  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.8189  decode.d5.loss_dice: 0.7877  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.8213  decode.d6.loss_dice: 0.7895  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.8248  decode.d7.loss_dice: 0.7794  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.8231  decode.d8.loss_dice: 0.7877
2025/03/31 05:59:21 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 05:59:21 - mmengine - INFO - Iter(train) [ 6000/20000]  base_lr: 7.2545e-05 lr: 7.2545e-05  eta: 3:21:27  time: 0.8553  data_time: 0.0156  memory: 10143  loss: 16.7783  decode.loss_cls: 0.0091  decode.loss_mask: 0.8585  decode.loss_dice: 0.8070  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.8549  decode.d0.loss_dice: 0.8068  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.8435  decode.d1.loss_dice: 0.8157  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.8519  decode.d2.loss_dice: 0.8025  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.8540  decode.d3.loss_dice: 0.7984  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.8550  decode.d4.loss_dice: 0.8010  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.8506  decode.d5.loss_dice: 0.7960  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.8570  decode.d6.loss_dice: 0.8016  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.8606  decode.d7.loss_dice: 0.8011  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.8586  decode.d8.loss_dice: 0.8046
2025/03/31 05:59:21 - mmengine - INFO - Saving checkpoint at 6000 iterations
2025/03/31 05:59:27 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:05  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 05:59:32 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:00  time: 0.0940  data_time: 0.0011  memory: 1853  
2025/03/31 05:59:36 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:55  time: 0.0934  data_time: 0.0012  memory: 1853  
2025/03/31 05:59:41 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:50  time: 0.0934  data_time: 0.0011  memory: 1853  
2025/03/31 05:59:46 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:45  time: 0.0934  data_time: 0.0011  memory: 1853  
2025/03/31 05:59:51 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:41  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 05:59:55 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:36  time: 0.0935  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:00 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:31  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:05 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:26  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:09 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:22  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:14 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:17  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:19 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:12  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:23 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:08  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:28 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:03  time: 0.0935  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:33 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:58  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 06:00:37 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:54  time: 0.0933  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:42 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:49  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:47 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:44  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:52 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:39  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 06:00:56 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:35  time: 0.0932  data_time: 0.0011  memory: 1853  
2025/03/31 06:01:01 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:30  time: 0.0934  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:06 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:25  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:10 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:21  time: 0.0934  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:15 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:16  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:20 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:11  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:24 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:07  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:29 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:02  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:34 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:57  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 06:01:38 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:43 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:48  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:48 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:43  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 06:01:53 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:01:57 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:02 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:29  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:07 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:24  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:11 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:16 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:21 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:10  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:26 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:30 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 06:02:32 - mmengine - INFO - per class results:
2025/03/31 06:02:32 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 71.79 | 90.88 |
|      building      | 83.17 | 92.92 |
|   low_vegetation   | 59.04 | 87.03 |
|        tree        | 37.75 |  39.6 |
|        car         |  75.5 | 89.85 |
|      clutter       |  1.69 |  1.72 |
+--------------------+-------+-------+
2025/03/31 06:02:32 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 77.6200  mIoU: 54.8200  mAcc: 67.0000  data_time: 0.0012  time: 0.0939
2025/03/31 06:03:15 - mmengine - INFO - Iter(train) [ 6050/20000]  base_lr: 7.2312e-05 lr: 7.2312e-05  eta: 3:20:43  time: 0.8563  data_time: 0.0156  memory: 10142  loss: 15.8581  decode.loss_cls: 0.0432  decode.loss_mask: 0.7781  decode.loss_dice: 0.7677  decode.d0.loss_cls: 0.0611  decode.d0.loss_mask: 0.7840  decode.d0.loss_dice: 0.7707  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.7844  decode.d1.loss_dice: 0.7723  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 0.7513  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.7788  decode.d3.loss_dice: 0.7597  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.7832  decode.d4.loss_dice: 0.7633  decode.d5.loss_cls: 0.0434  decode.d5.loss_mask: 0.7819  decode.d5.loss_dice: 0.7662  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.7767  decode.d6.loss_dice: 0.7398  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.7793  decode.d7.loss_dice: 0.7590  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.7801  decode.d8.loss_dice: 0.7719
2025/03/31 06:03:58 - mmengine - INFO - Iter(train) [ 6100/20000]  base_lr: 7.2079e-05 lr: 7.2079e-05  eta: 3:19:59  time: 0.8584  data_time: 0.0156  memory: 10144  loss: 17.8892  decode.loss_cls: 0.0362  decode.loss_mask: 0.8924  decode.loss_dice: 0.8499  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.9108  decode.d0.loss_dice: 0.8447  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.8971  decode.d1.loss_dice: 0.8417  decode.d2.loss_cls: 0.0354  decode.d2.loss_mask: 0.8977  decode.d2.loss_dice: 0.8417  decode.d3.loss_cls: 0.0282  decode.d3.loss_mask: 0.9026  decode.d3.loss_dice: 0.8570  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.8981  decode.d4.loss_dice: 0.8489  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.8986  decode.d5.loss_dice: 0.8599  decode.d6.loss_cls: 0.0251  decode.d6.loss_mask: 0.8979  decode.d6.loss_dice: 0.8544  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.8931  decode.d7.loss_dice: 0.8522  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.8978  decode.d8.loss_dice: 0.8519
2025/03/31 06:04:41 - mmengine - INFO - Iter(train) [ 6150/20000]  base_lr: 7.1845e-05 lr: 7.1845e-05  eta: 3:19:17  time: 0.9040  data_time: 0.0157  memory: 10142  loss: 15.5475  decode.loss_cls: 0.0354  decode.loss_mask: 0.7927  decode.loss_dice: 0.7317  decode.d0.loss_cls: 0.0584  decode.d0.loss_mask: 0.8134  decode.d0.loss_dice: 0.7591  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.7986  decode.d1.loss_dice: 0.7375  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.7947  decode.d2.loss_dice: 0.7389  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.7945  decode.d3.loss_dice: 0.7245  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.7931  decode.d4.loss_dice: 0.7313  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.7914  decode.d5.loss_dice: 0.7354  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.8010  decode.d6.loss_dice: 0.7370  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.7951  decode.d7.loss_dice: 0.7336  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.7997  decode.d8.loss_dice: 0.7333
2025/03/31 06:05:25 - mmengine - INFO - Iter(train) [ 6200/20000]  base_lr: 7.1612e-05 lr: 7.1612e-05  eta: 3:18:35  time: 0.8573  data_time: 0.0156  memory: 10144  loss: 17.9920  decode.loss_cls: 0.0504  decode.loss_mask: 0.9556  decode.loss_dice: 0.7949  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 0.9522  decode.d0.loss_dice: 0.8194  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.9517  decode.d1.loss_dice: 0.7972  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.9522  decode.d2.loss_dice: 0.7976  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.9576  decode.d3.loss_dice: 0.8002  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.9621  decode.d4.loss_dice: 0.8026  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.9584  decode.d5.loss_dice: 0.8019  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.9574  decode.d6.loss_dice: 0.8066  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.9556  decode.d7.loss_dice: 0.8090  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.9571  decode.d8.loss_dice: 0.8088
2025/03/31 06:06:08 - mmengine - INFO - Iter(train) [ 6250/20000]  base_lr: 7.1378e-05 lr: 7.1378e-05  eta: 3:17:51  time: 0.8566  data_time: 0.0153  memory: 10143  loss: 16.5676  decode.loss_cls: 0.0344  decode.loss_mask: 0.8040  decode.loss_dice: 0.8014  decode.d0.loss_cls: 0.0614  decode.d0.loss_mask: 0.8137  decode.d0.loss_dice: 0.8310  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.8099  decode.d1.loss_dice: 0.8199  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.8087  decode.d2.loss_dice: 0.8058  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.8044  decode.d3.loss_dice: 0.8075  decode.d4.loss_cls: 0.0340  decode.d4.loss_mask: 0.8074  decode.d4.loss_dice: 0.8074  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.8063  decode.d5.loss_dice: 0.7967  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.8050  decode.d6.loss_dice: 0.8313  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.8051  decode.d7.loss_dice: 0.8238  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.8095  decode.d8.loss_dice: 0.7926
2025/03/31 06:06:51 - mmengine - INFO - Iter(train) [ 6300/20000]  base_lr: 7.1144e-05 lr: 7.1144e-05  eta: 3:17:08  time: 0.8555  data_time: 0.0155  memory: 10098  loss: 17.3975  decode.loss_cls: 0.0101  decode.loss_mask: 0.8862  decode.loss_dice: 0.8290  decode.d0.loss_cls: 0.0572  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 0.8283  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.8942  decode.d1.loss_dice: 0.8288  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.8917  decode.d2.loss_dice: 0.8375  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.8879  decode.d3.loss_dice: 0.8327  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.8894  decode.d4.loss_dice: 0.8423  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.8890  decode.d5.loss_dice: 0.8377  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.8899  decode.d6.loss_dice: 0.8325  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.8908  decode.d7.loss_dice: 0.8373  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.8919  decode.d8.loss_dice: 0.8415
2025/03/31 06:07:34 - mmengine - INFO - Iter(train) [ 6350/20000]  base_lr: 7.0911e-05 lr: 7.0911e-05  eta: 3:16:24  time: 0.8608  data_time: 0.0157  memory: 10145  loss: 16.4577  decode.loss_cls: 0.0111  decode.loss_mask: 0.8579  decode.loss_dice: 0.7691  decode.d0.loss_cls: 0.0539  decode.d0.loss_mask: 0.8772  decode.d0.loss_dice: 0.7535  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.8618  decode.d1.loss_dice: 0.7743  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.8647  decode.d2.loss_dice: 0.7683  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.8586  decode.d3.loss_dice: 0.7678  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.8545  decode.d4.loss_dice: 0.7687  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.8587  decode.d5.loss_dice: 0.7706  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.8544  decode.d6.loss_dice: 0.7744  decode.d7.loss_cls: 0.0125  decode.d7.loss_mask: 0.8595  decode.d7.loss_dice: 0.7755  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.8539  decode.d8.loss_dice: 0.7702
2025/03/31 06:08:17 - mmengine - INFO - Iter(train) [ 6400/20000]  base_lr: 7.0677e-05 lr: 7.0677e-05  eta: 3:15:40  time: 0.8569  data_time: 0.0155  memory: 10144  loss: 21.0031  decode.loss_cls: 0.0576  decode.loss_mask: 1.0981  decode.loss_dice: 0.9421  decode.d0.loss_cls: 0.0976  decode.d0.loss_mask: 1.1342  decode.d0.loss_dice: 0.9412  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 1.1051  decode.d1.loss_dice: 0.9466  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 1.0922  decode.d2.loss_dice: 0.9212  decode.d3.loss_cls: 0.0414  decode.d3.loss_mask: 1.1003  decode.d3.loss_dice: 0.9344  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 1.0921  decode.d4.loss_dice: 0.9578  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 1.0920  decode.d5.loss_dice: 0.9722  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 1.0854  decode.d6.loss_dice: 0.9591  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 1.0840  decode.d7.loss_dice: 0.9297  decode.d8.loss_cls: 0.0480  decode.d8.loss_mask: 1.0962  decode.d8.loss_dice: 0.9687
2025/03/31 06:09:00 - mmengine - INFO - Iter(train) [ 6450/20000]  base_lr: 7.0443e-05 lr: 7.0443e-05  eta: 3:14:56  time: 0.8576  data_time: 0.0156  memory: 10142  loss: 18.3842  decode.loss_cls: 0.0127  decode.loss_mask: 0.9390  decode.loss_dice: 0.8845  decode.d0.loss_cls: 0.0448  decode.d0.loss_mask: 0.9470  decode.d0.loss_dice: 0.8776  decode.d1.loss_cls: 0.0230  decode.d1.loss_mask: 0.9398  decode.d1.loss_dice: 0.8759  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.9325  decode.d2.loss_dice: 0.8825  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.9231  decode.d3.loss_dice: 0.9009  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.9218  decode.d4.loss_dice: 0.8883  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.9229  decode.d5.loss_dice: 0.8966  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.9257  decode.d6.loss_dice: 0.8886  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.9267  decode.d7.loss_dice: 0.8874  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.9227  decode.d8.loss_dice: 0.9071
2025/03/31 06:09:43 - mmengine - INFO - Iter(train) [ 6500/20000]  base_lr: 7.0209e-05 lr: 7.0209e-05  eta: 3:14:13  time: 0.8572  data_time: 0.0157  memory: 10143  loss: 16.9916  decode.loss_cls: 0.0037  decode.loss_mask: 0.8634  decode.loss_dice: 0.8236  decode.d0.loss_cls: 0.0453  decode.d0.loss_mask: 0.8663  decode.d0.loss_dice: 0.7924  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.8692  decode.d1.loss_dice: 0.8332  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 0.8638  decode.d2.loss_dice: 0.8187  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.8667  decode.d3.loss_dice: 0.8240  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.8704  decode.d4.loss_dice: 0.8206  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.8696  decode.d5.loss_dice: 0.8144  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.8663  decode.d6.loss_dice: 0.8120  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.8658  decode.d7.loss_dice: 0.8156  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.8663  decode.d8.loss_dice: 0.8208
2025/03/31 06:10:25 - mmengine - INFO - Iter(train) [ 6550/20000]  base_lr: 6.9975e-05 lr: 6.9975e-05  eta: 3:13:29  time: 0.8563  data_time: 0.0157  memory: 10142  loss: 18.2413  decode.loss_cls: 0.0318  decode.loss_mask: 0.9162  decode.loss_dice: 0.8632  decode.d0.loss_cls: 0.0588  decode.d0.loss_mask: 0.9232  decode.d0.loss_dice: 0.8717  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.9164  decode.d1.loss_dice: 0.8864  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.9174  decode.d2.loss_dice: 0.8796  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.9096  decode.d3.loss_dice: 0.8891  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.9096  decode.d4.loss_dice: 0.8813  decode.d5.loss_cls: 0.0316  decode.d5.loss_mask: 0.9097  decode.d5.loss_dice: 0.8744  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.9025  decode.d6.loss_dice: 0.8607  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.9115  decode.d7.loss_dice: 0.8573  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.9134  decode.d8.loss_dice: 0.8727
2025/03/31 06:11:08 - mmengine - INFO - Iter(train) [ 6600/20000]  base_lr: 6.9741e-05 lr: 6.9741e-05  eta: 3:12:45  time: 0.8563  data_time: 0.0154  memory: 10143  loss: 17.6606  decode.loss_cls: 0.0411  decode.loss_mask: 0.9161  decode.loss_dice: 0.8201  decode.d0.loss_cls: 0.0558  decode.d0.loss_mask: 0.9391  decode.d0.loss_dice: 0.8069  decode.d1.loss_cls: 0.0261  decode.d1.loss_mask: 0.9205  decode.d1.loss_dice: 0.8276  decode.d2.loss_cls: 0.0398  decode.d2.loss_mask: 0.9220  decode.d2.loss_dice: 0.8130  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.9132  decode.d3.loss_dice: 0.8119  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.9113  decode.d4.loss_dice: 0.8096  decode.d5.loss_cls: 0.0309  decode.d5.loss_mask: 0.9174  decode.d5.loss_dice: 0.8173  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.9143  decode.d6.loss_dice: 0.8174  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.9134  decode.d7.loss_dice: 0.8104  decode.d8.loss_cls: 0.0325  decode.d8.loss_mask: 0.9140  decode.d8.loss_dice: 0.8131
2025/03/31 06:11:51 - mmengine - INFO - Iter(train) [ 6650/20000]  base_lr: 6.9507e-05 lr: 6.9507e-05  eta: 3:12:02  time: 0.8565  data_time: 0.0154  memory: 10144  loss: 16.5075  decode.loss_cls: 0.0570  decode.loss_mask: 0.8152  decode.loss_dice: 0.7898  decode.d0.loss_cls: 0.0659  decode.d0.loss_mask: 0.8255  decode.d0.loss_dice: 0.8107  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.8202  decode.d1.loss_dice: 0.8069  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.8248  decode.d2.loss_dice: 0.8139  decode.d3.loss_cls: 0.0262  decode.d3.loss_mask: 0.8212  decode.d3.loss_dice: 0.7961  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.8190  decode.d4.loss_dice: 0.7926  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.8231  decode.d5.loss_dice: 0.7891  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.8185  decode.d6.loss_dice: 0.7824  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.8202  decode.d7.loss_dice: 0.8025  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.8203  decode.d8.loss_dice: 0.8013
2025/03/31 06:12:34 - mmengine - INFO - Iter(train) [ 6700/20000]  base_lr: 6.9272e-05 lr: 6.9272e-05  eta: 3:11:18  time: 0.8568  data_time: 0.0159  memory: 10093  loss: 16.5411  decode.loss_cls: 0.0098  decode.loss_mask: 0.8726  decode.loss_dice: 0.7608  decode.d0.loss_cls: 0.0597  decode.d0.loss_mask: 0.8645  decode.d0.loss_dice: 0.7667  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.8763  decode.d1.loss_dice: 0.7642  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.8704  decode.d2.loss_dice: 0.7549  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.8720  decode.d3.loss_dice: 0.7604  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.8806  decode.d4.loss_dice: 0.7566  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.8791  decode.d5.loss_dice: 0.7493  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.8714  decode.d6.loss_dice: 0.7596  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.8826  decode.d7.loss_dice: 0.7566  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.8797  decode.d8.loss_dice: 0.7534
2025/03/31 06:13:17 - mmengine - INFO - Iter(train) [ 6750/20000]  base_lr: 6.9038e-05 lr: 6.9038e-05  eta: 3:10:34  time: 0.8557  data_time: 0.0152  memory: 10142  loss: 16.8815  decode.loss_cls: 0.0162  decode.loss_mask: 0.8559  decode.loss_dice: 0.8167  decode.d0.loss_cls: 0.0783  decode.d0.loss_mask: 0.8719  decode.d0.loss_dice: 0.8008  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.8606  decode.d1.loss_dice: 0.8098  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.8554  decode.d2.loss_dice: 0.8061  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.8606  decode.d3.loss_dice: 0.8013  decode.d4.loss_cls: 0.0508  decode.d4.loss_mask: 0.8538  decode.d4.loss_dice: 0.8109  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.8595  decode.d5.loss_dice: 0.8051  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.8591  decode.d6.loss_dice: 0.8021  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.8542  decode.d7.loss_dice: 0.7992  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.8537  decode.d8.loss_dice: 0.7960
2025/03/31 06:14:00 - mmengine - INFO - Iter(train) [ 6800/20000]  base_lr: 6.8803e-05 lr: 6.8803e-05  eta: 3:09:51  time: 0.8760  data_time: 0.0163  memory: 10095  loss: 16.1333  decode.loss_cls: 0.0114  decode.loss_mask: 0.8256  decode.loss_dice: 0.7701  decode.d0.loss_cls: 0.0572  decode.d0.loss_mask: 0.8362  decode.d0.loss_dice: 0.7713  decode.d1.loss_cls: 0.0239  decode.d1.loss_mask: 0.8267  decode.d1.loss_dice: 0.7668  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.8259  decode.d2.loss_dice: 0.7716  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.8277  decode.d3.loss_dice: 0.7626  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.8271  decode.d4.loss_dice: 0.7745  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.8199  decode.d5.loss_dice: 0.7622  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.8312  decode.d6.loss_dice: 0.7758  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.8269  decode.d7.loss_dice: 0.7714  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.8302  decode.d8.loss_dice: 0.7706
2025/03/31 06:14:43 - mmengine - INFO - Iter(train) [ 6850/20000]  base_lr: 6.8569e-05 lr: 6.8569e-05  eta: 3:09:08  time: 0.8653  data_time: 0.0159  memory: 10093  loss: 16.0969  decode.loss_cls: 0.0090  decode.loss_mask: 0.8306  decode.loss_dice: 0.7566  decode.d0.loss_cls: 0.0508  decode.d0.loss_mask: 0.8434  decode.d0.loss_dice: 0.7660  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.8327  decode.d1.loss_dice: 0.7586  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.8284  decode.d2.loss_dice: 0.7569  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 0.7583  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.8375  decode.d4.loss_dice: 0.7544  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.8337  decode.d5.loss_dice: 0.7565  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.8383  decode.d6.loss_dice: 0.7584  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.8353  decode.d7.loss_dice: 0.7515  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.8312  decode.d8.loss_dice: 0.7566
2025/03/31 06:15:27 - mmengine - INFO - Iter(train) [ 6900/20000]  base_lr: 6.8334e-05 lr: 6.8334e-05  eta: 3:08:27  time: 0.8576  data_time: 0.0158  memory: 10143  loss: 14.1334  decode.loss_cls: 0.0238  decode.loss_mask: 0.6817  decode.loss_dice: 0.7160  decode.d0.loss_cls: 0.0588  decode.d0.loss_mask: 0.6792  decode.d0.loss_dice: 0.7234  decode.d1.loss_cls: 0.0371  decode.d1.loss_mask: 0.6793  decode.d1.loss_dice: 0.7273  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.6785  decode.d2.loss_dice: 0.7094  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.6818  decode.d3.loss_dice: 0.7045  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.6811  decode.d4.loss_dice: 0.7072  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.6865  decode.d5.loss_dice: 0.7103  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.6834  decode.d6.loss_dice: 0.7172  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.6802  decode.d7.loss_dice: 0.7084  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.6831  decode.d8.loss_dice: 0.7059
2025/03/31 06:16:10 - mmengine - INFO - Iter(train) [ 6950/20000]  base_lr: 6.8099e-05 lr: 6.8099e-05  eta: 3:07:43  time: 0.8601  data_time: 0.0158  memory: 10144  loss: 17.2478  decode.loss_cls: 0.0566  decode.loss_mask: 0.8204  decode.loss_dice: 0.8127  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.8240  decode.d0.loss_dice: 0.8504  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.8254  decode.d1.loss_dice: 0.8168  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.8302  decode.d2.loss_dice: 0.8174  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.8294  decode.d3.loss_dice: 0.8222  decode.d4.loss_cls: 0.1071  decode.d4.loss_mask: 0.8317  decode.d4.loss_dice: 0.8227  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.8207  decode.d5.loss_dice: 0.8107  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.8263  decode.d6.loss_dice: 0.8068  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 0.8182  decode.d7.loss_dice: 0.8153  decode.d8.loss_cls: 0.0805  decode.d8.loss_mask: 0.8207  decode.d8.loss_dice: 0.8243
2025/03/31 06:16:53 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 06:16:53 - mmengine - INFO - Iter(train) [ 7000/20000]  base_lr: 6.7864e-05 lr: 6.7864e-05  eta: 3:07:00  time: 0.8577  data_time: 0.0157  memory: 10142  loss: 15.9751  decode.loss_cls: 0.0057  decode.loss_mask: 0.8634  decode.loss_dice: 0.7261  decode.d0.loss_cls: 0.0608  decode.d0.loss_mask: 0.8652  decode.d0.loss_dice: 0.7187  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.8664  decode.d1.loss_dice: 0.7204  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.8623  decode.d2.loss_dice: 0.7132  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.8594  decode.d3.loss_dice: 0.7141  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.8564  decode.d4.loss_dice: 0.7145  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.8640  decode.d5.loss_dice: 0.7217  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.8668  decode.d6.loss_dice: 0.7247  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.8669  decode.d7.loss_dice: 0.7235  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.8657  decode.d8.loss_dice: 0.7214
2025/03/31 06:17:36 - mmengine - INFO - Iter(train) [ 7050/20000]  base_lr: 6.7629e-05 lr: 6.7629e-05  eta: 3:06:16  time: 0.8579  data_time: 0.0159  memory: 10145  loss: 16.8652  decode.loss_cls: 0.0078  decode.loss_mask: 0.8709  decode.loss_dice: 0.7835  decode.d0.loss_cls: 0.0620  decode.d0.loss_mask: 0.8905  decode.d0.loss_dice: 0.7951  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.8712  decode.d1.loss_dice: 0.7863  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.8759  decode.d2.loss_dice: 0.7874  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.8767  decode.d3.loss_dice: 0.7863  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.8761  decode.d4.loss_dice: 0.7914  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.8823  decode.d5.loss_dice: 0.8007  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.8771  decode.d6.loss_dice: 0.7839  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.8766  decode.d7.loss_dice: 0.7892  decode.d8.loss_cls: 0.0293  decode.d8.loss_mask: 0.8735  decode.d8.loss_dice: 0.7790
2025/03/31 06:18:19 - mmengine - INFO - Iter(train) [ 7100/20000]  base_lr: 6.7394e-05 lr: 6.7394e-05  eta: 3:05:33  time: 0.8561  data_time: 0.0157  memory: 10143  loss: 16.4316  decode.loss_cls: 0.0580  decode.loss_mask: 0.8070  decode.loss_dice: 0.7953  decode.d0.loss_cls: 0.0576  decode.d0.loss_mask: 0.8106  decode.d0.loss_dice: 0.8063  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.8055  decode.d1.loss_dice: 0.7929  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.8009  decode.d2.loss_dice: 0.7973  decode.d3.loss_cls: 0.0310  decode.d3.loss_mask: 0.7985  decode.d3.loss_dice: 0.7895  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.8010  decode.d4.loss_dice: 0.7955  decode.d5.loss_cls: 0.0331  decode.d5.loss_mask: 0.8060  decode.d5.loss_dice: 0.7967  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.8095  decode.d6.loss_dice: 0.7964  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.8062  decode.d7.loss_dice: 0.7832  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.8028  decode.d8.loss_dice: 0.7922
2025/03/31 06:19:02 - mmengine - INFO - Iter(train) [ 7150/20000]  base_lr: 6.7159e-05 lr: 6.7159e-05  eta: 3:04:49  time: 0.8561  data_time: 0.0156  memory: 10093  loss: 15.6908  decode.loss_cls: 0.0135  decode.loss_mask: 0.8113  decode.loss_dice: 0.7447  decode.d0.loss_cls: 0.0426  decode.d0.loss_mask: 0.8108  decode.d0.loss_dice: 0.7395  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.8098  decode.d1.loss_dice: 0.7466  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.8075  decode.d2.loss_dice: 0.7456  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.8083  decode.d3.loss_dice: 0.7409  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.8074  decode.d4.loss_dice: 0.7342  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.8051  decode.d5.loss_dice: 0.7340  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.8118  decode.d6.loss_dice: 0.7419  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.8084  decode.d7.loss_dice: 0.7429  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.8105  decode.d8.loss_dice: 0.7392
2025/03/31 06:19:45 - mmengine - INFO - Iter(train) [ 7200/20000]  base_lr: 6.6924e-05 lr: 6.6924e-05  eta: 3:04:05  time: 0.8562  data_time: 0.0156  memory: 10093  loss: 15.4212  decode.loss_cls: 0.0429  decode.loss_mask: 0.7605  decode.loss_dice: 0.7284  decode.d0.loss_cls: 0.0532  decode.d0.loss_mask: 0.7798  decode.d0.loss_dice: 0.7789  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.7647  decode.d1.loss_dice: 0.7406  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.7616  decode.d2.loss_dice: 0.7511  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.7619  decode.d3.loss_dice: 0.7395  decode.d4.loss_cls: 0.0177  decode.d4.loss_mask: 0.7596  decode.d4.loss_dice: 0.7466  decode.d5.loss_cls: 0.0270  decode.d5.loss_mask: 0.7628  decode.d5.loss_dice: 0.7409  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.7625  decode.d6.loss_dice: 0.7326  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.7669  decode.d7.loss_dice: 0.7315  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.7639  decode.d8.loss_dice: 0.7321
2025/03/31 06:20:28 - mmengine - INFO - Iter(train) [ 7250/20000]  base_lr: 6.6689e-05 lr: 6.6689e-05  eta: 3:03:22  time: 0.8605  data_time: 0.0161  memory: 10142  loss: 15.3015  decode.loss_cls: 0.0053  decode.loss_mask: 0.8303  decode.loss_dice: 0.6803  decode.d0.loss_cls: 0.0554  decode.d0.loss_mask: 0.8311  decode.d0.loss_dice: 0.6865  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.8276  decode.d1.loss_dice: 0.7074  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.8288  decode.d2.loss_dice: 0.6927  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.8251  decode.d3.loss_dice: 0.6836  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.8265  decode.d4.loss_dice: 0.6851  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.8270  decode.d5.loss_dice: 0.6914  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.8309  decode.d6.loss_dice: 0.6883  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.8348  decode.d7.loss_dice: 0.7025  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.8299  decode.d8.loss_dice: 0.6850
2025/03/31 06:21:11 - mmengine - INFO - Iter(train) [ 7300/20000]  base_lr: 6.6453e-05 lr: 6.6453e-05  eta: 3:02:39  time: 0.8593  data_time: 0.0157  memory: 10143  loss: 16.0030  decode.loss_cls: 0.0120  decode.loss_mask: 0.8222  decode.loss_dice: 0.7563  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 0.8264  decode.d0.loss_dice: 0.7472  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.8217  decode.d1.loss_dice: 0.7482  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.8220  decode.d2.loss_dice: 0.7707  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.8236  decode.d3.loss_dice: 0.7725  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.8203  decode.d4.loss_dice: 0.7585  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.8219  decode.d5.loss_dice: 0.7676  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.8189  decode.d6.loss_dice: 0.7690  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.8234  decode.d7.loss_dice: 0.7789  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.8254  decode.d8.loss_dice: 0.7579
2025/03/31 06:21:54 - mmengine - INFO - Iter(train) [ 7350/20000]  base_lr: 6.6218e-05 lr: 6.6218e-05  eta: 3:01:56  time: 0.8693  data_time: 0.0165  memory: 10145  loss: 16.3739  decode.loss_cls: 0.0037  decode.loss_mask: 0.8750  decode.loss_dice: 0.7466  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.8772  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.8756  decode.d1.loss_dice: 0.7572  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.8726  decode.d2.loss_dice: 0.7482  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.8696  decode.d3.loss_dice: 0.7507  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.8721  decode.d4.loss_dice: 0.7682  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.8704  decode.d5.loss_dice: 0.7438  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.8737  decode.d6.loss_dice: 0.7503  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.8780  decode.d7.loss_dice: 0.7508  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.8760  decode.d8.loss_dice: 0.7465
2025/03/31 06:22:37 - mmengine - INFO - Iter(train) [ 7400/20000]  base_lr: 6.5982e-05 lr: 6.5982e-05  eta: 3:01:12  time: 0.8569  data_time: 0.0154  memory: 10144  loss: 15.4549  decode.loss_cls: 0.0134  decode.loss_mask: 0.7790  decode.loss_dice: 0.7396  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.7846  decode.d0.loss_dice: 0.7284  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.7822  decode.d1.loss_dice: 0.7507  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.7802  decode.d2.loss_dice: 0.7325  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.7744  decode.d3.loss_dice: 0.7347  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.7819  decode.d4.loss_dice: 0.7367  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.7818  decode.d5.loss_dice: 0.7341  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.7805  decode.d6.loss_dice: 0.7408  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.7778  decode.d7.loss_dice: 0.7423  decode.d8.loss_cls: 0.0351  decode.d8.loss_mask: 0.7840  decode.d8.loss_dice: 0.7386
2025/03/31 06:23:20 - mmengine - INFO - Iter(train) [ 7450/20000]  base_lr: 6.5746e-05 lr: 6.5746e-05  eta: 3:00:28  time: 0.8564  data_time: 0.0155  memory: 10144  loss: 16.4114  decode.loss_cls: 0.0140  decode.loss_mask: 0.8112  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.0534  decode.d0.loss_mask: 0.8241  decode.d0.loss_dice: 0.7943  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.8210  decode.d1.loss_dice: 0.8048  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.8135  decode.d2.loss_dice: 0.8081  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.8135  decode.d3.loss_dice: 0.8077  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.8128  decode.d4.loss_dice: 0.8026  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.8158  decode.d5.loss_dice: 0.7965  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.8153  decode.d6.loss_dice: 0.8058  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.8151  decode.d7.loss_dice: 0.8010  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.8165  decode.d8.loss_dice: 0.8093
2025/03/31 06:24:03 - mmengine - INFO - Iter(train) [ 7500/20000]  base_lr: 6.5511e-05 lr: 6.5511e-05  eta: 2:59:45  time: 0.8569  data_time: 0.0155  memory: 10139  loss: 15.0266  decode.loss_cls: 0.0253  decode.loss_mask: 0.7571  decode.loss_dice: 0.7061  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.7594  decode.d0.loss_dice: 0.7188  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.7633  decode.d1.loss_dice: 0.7196  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.7616  decode.d2.loss_dice: 0.7162  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.7624  decode.d3.loss_dice: 0.7051  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 0.7067  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.7578  decode.d5.loss_dice: 0.7033  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.7590  decode.d6.loss_dice: 0.7141  decode.d7.loss_cls: 0.0197  decode.d7.loss_mask: 0.7577  decode.d7.loss_dice: 0.7293  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.7556  decode.d8.loss_dice: 0.7060
2025/03/31 06:24:46 - mmengine - INFO - Iter(train) [ 7550/20000]  base_lr: 6.5275e-05 lr: 6.5275e-05  eta: 2:59:01  time: 0.8569  data_time: 0.0156  memory: 10143  loss: 16.8106  decode.loss_cls: 0.0603  decode.loss_mask: 0.8177  decode.loss_dice: 0.7923  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.8220  decode.d0.loss_dice: 0.8397  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.8186  decode.d1.loss_dice: 0.7925  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.8271  decode.d2.loss_dice: 0.8070  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.8216  decode.d3.loss_dice: 0.8088  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.8195  decode.d4.loss_dice: 0.7934  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.8135  decode.d5.loss_dice: 0.7996  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.8119  decode.d6.loss_dice: 0.8044  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.8178  decode.d7.loss_dice: 0.8165  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.8209  decode.d8.loss_dice: 0.8204
2025/03/31 06:25:29 - mmengine - INFO - Iter(train) [ 7600/20000]  base_lr: 6.5039e-05 lr: 6.5039e-05  eta: 2:58:18  time: 0.8561  data_time: 0.0153  memory: 10144  loss: 16.4914  decode.loss_cls: 0.0401  decode.loss_mask: 0.8328  decode.loss_dice: 0.7700  decode.d0.loss_cls: 0.0639  decode.d0.loss_mask: 0.8372  decode.d0.loss_dice: 0.7811  decode.d1.loss_cls: 0.0296  decode.d1.loss_mask: 0.8322  decode.d1.loss_dice: 0.7658  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.8295  decode.d2.loss_dice: 0.7855  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.8277  decode.d3.loss_dice: 0.7972  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.8327  decode.d4.loss_dice: 0.7604  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.8298  decode.d5.loss_dice: 0.7661  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.8250  decode.d6.loss_dice: 0.7586  decode.d7.loss_cls: 0.0398  decode.d7.loss_mask: 0.8259  decode.d7.loss_dice: 0.7687  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.8291  decode.d8.loss_dice: 0.7915
2025/03/31 06:26:12 - mmengine - INFO - Iter(train) [ 7650/20000]  base_lr: 6.4803e-05 lr: 6.4803e-05  eta: 2:57:35  time: 0.8572  data_time: 0.0156  memory: 10094  loss: 15.7477  decode.loss_cls: 0.0214  decode.loss_mask: 0.7919  decode.loss_dice: 0.7484  decode.d0.loss_cls: 0.0646  decode.d0.loss_mask: 0.8063  decode.d0.loss_dice: 0.7688  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.8002  decode.d1.loss_dice: 0.7579  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.7930  decode.d2.loss_dice: 0.7553  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.7955  decode.d3.loss_dice: 0.7512  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.7964  decode.d4.loss_dice: 0.7550  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.7960  decode.d5.loss_dice: 0.7469  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.7914  decode.d6.loss_dice: 0.7510  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 0.7533  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.7944  decode.d8.loss_dice: 0.7552
2025/03/31 06:26:55 - mmengine - INFO - Iter(train) [ 7700/20000]  base_lr: 6.4566e-05 lr: 6.4566e-05  eta: 2:56:51  time: 0.8556  data_time: 0.0153  memory: 10144  loss: 15.4809  decode.loss_cls: 0.0401  decode.loss_mask: 0.7803  decode.loss_dice: 0.7209  decode.d0.loss_cls: 0.0447  decode.d0.loss_mask: 0.7855  decode.d0.loss_dice: 0.7257  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.7814  decode.d1.loss_dice: 0.7266  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.7765  decode.d2.loss_dice: 0.7219  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.7737  decode.d3.loss_dice: 0.7326  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 0.7753  decode.d4.loss_dice: 0.7237  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.7762  decode.d5.loss_dice: 0.7292  decode.d6.loss_cls: 0.0414  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 0.7166  decode.d7.loss_cls: 0.0461  decode.d7.loss_mask: 0.7789  decode.d7.loss_dice: 0.7166  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.7753  decode.d8.loss_dice: 0.7257
2025/03/31 06:27:38 - mmengine - INFO - Iter(train) [ 7750/20000]  base_lr: 6.4330e-05 lr: 6.4330e-05  eta: 2:56:08  time: 0.8552  data_time: 0.0157  memory: 10092  loss: 16.2075  decode.loss_cls: 0.0103  decode.loss_mask: 0.8107  decode.loss_dice: 0.7642  decode.d0.loss_cls: 0.0498  decode.d0.loss_mask: 0.8123  decode.d0.loss_dice: 0.7905  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.8063  decode.d1.loss_dice: 0.7659  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.8070  decode.d2.loss_dice: 0.7798  decode.d3.loss_cls: 0.0383  decode.d3.loss_mask: 0.8060  decode.d3.loss_dice: 0.7695  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.8074  decode.d4.loss_dice: 0.7944  decode.d5.loss_cls: 0.0336  decode.d5.loss_mask: 0.8070  decode.d5.loss_dice: 0.7879  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.8055  decode.d6.loss_dice: 0.7779  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.8098  decode.d7.loss_dice: 0.7749  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.8089  decode.d8.loss_dice: 0.7652
2025/03/31 06:28:20 - mmengine - INFO - Iter(train) [ 7800/20000]  base_lr: 6.4094e-05 lr: 6.4094e-05  eta: 2:55:24  time: 0.8554  data_time: 0.0155  memory: 10140  loss: 16.9274  decode.loss_cls: 0.0071  decode.loss_mask: 0.9029  decode.loss_dice: 0.7749  decode.d0.loss_cls: 0.0591  decode.d0.loss_mask: 0.9131  decode.d0.loss_dice: 0.7721  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.9011  decode.d1.loss_dice: 0.7734  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.9035  decode.d2.loss_dice: 0.7809  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.9049  decode.d3.loss_dice: 0.7730  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.9034  decode.d4.loss_dice: 0.7798  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.9031  decode.d5.loss_dice: 0.7807  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.9019  decode.d6.loss_dice: 0.7681  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.9001  decode.d7.loss_dice: 0.7701  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.8994  decode.d8.loss_dice: 0.7790
2025/03/31 06:29:03 - mmengine - INFO - Iter(train) [ 7850/20000]  base_lr: 6.3857e-05 lr: 6.3857e-05  eta: 2:54:40  time: 0.8568  data_time: 0.0156  memory: 10142  loss: 14.9587  decode.loss_cls: 0.0109  decode.loss_mask: 0.7377  decode.loss_dice: 0.7302  decode.d0.loss_cls: 0.0485  decode.d0.loss_mask: 0.7458  decode.d0.loss_dice: 0.7358  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.7460  decode.d1.loss_dice: 0.7440  decode.d2.loss_cls: 0.0202  decode.d2.loss_mask: 0.7423  decode.d2.loss_dice: 0.7442  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.7367  decode.d3.loss_dice: 0.7263  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.7402  decode.d4.loss_dice: 0.7346  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.7379  decode.d5.loss_dice: 0.7293  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.7395  decode.d6.loss_dice: 0.7320  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.7413  decode.d7.loss_dice: 0.7396  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.7412  decode.d8.loss_dice: 0.7360
2025/03/31 06:29:46 - mmengine - INFO - Iter(train) [ 7900/20000]  base_lr: 6.3621e-05 lr: 6.3621e-05  eta: 2:53:57  time: 0.8569  data_time: 0.0156  memory: 10139  loss: 16.2961  decode.loss_cls: 0.0088  decode.loss_mask: 0.8416  decode.loss_dice: 0.7629  decode.d0.loss_cls: 0.0498  decode.d0.loss_mask: 0.8612  decode.d0.loss_dice: 0.7568  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.8475  decode.d1.loss_dice: 0.7619  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.8435  decode.d2.loss_dice: 0.7659  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.8392  decode.d3.loss_dice: 0.7696  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.8397  decode.d4.loss_dice: 0.7712  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.8435  decode.d5.loss_dice: 0.7804  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.8386  decode.d6.loss_dice: 0.7711  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.8434  decode.d7.loss_dice: 0.7791  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.8416  decode.d8.loss_dice: 0.7702
2025/03/31 06:30:29 - mmengine - INFO - Iter(train) [ 7950/20000]  base_lr: 6.3384e-05 lr: 6.3384e-05  eta: 2:53:14  time: 0.8570  data_time: 0.0154  memory: 10144  loss: 15.6584  decode.loss_cls: 0.0091  decode.loss_mask: 0.8313  decode.loss_dice: 0.7104  decode.d0.loss_cls: 0.0565  decode.d0.loss_mask: 0.8406  decode.d0.loss_dice: 0.7305  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.8354  decode.d1.loss_dice: 0.7238  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.8336  decode.d2.loss_dice: 0.7273  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.8342  decode.d3.loss_dice: 0.7164  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.8342  decode.d4.loss_dice: 0.7223  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.8273  decode.d5.loss_dice: 0.7150  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.8272  decode.d6.loss_dice: 0.7069  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.8280  decode.d7.loss_dice: 0.7168  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.8287  decode.d8.loss_dice: 0.7197
2025/03/31 06:31:12 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 06:31:12 - mmengine - INFO - Iter(train) [ 8000/20000]  base_lr: 6.3147e-05 lr: 6.3147e-05  eta: 2:52:30  time: 0.8548  data_time: 0.0155  memory: 10144  loss: 15.1707  decode.loss_cls: 0.0289  decode.loss_mask: 0.7596  decode.loss_dice: 0.7115  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.7583  decode.d0.loss_dice: 0.7108  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.7667  decode.d1.loss_dice: 0.7055  decode.d2.loss_cls: 0.0768  decode.d2.loss_mask: 0.7621  decode.d2.loss_dice: 0.7014  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.7668  decode.d3.loss_dice: 0.7164  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.7630  decode.d4.loss_dice: 0.7042  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.7591  decode.d5.loss_dice: 0.7070  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.7626  decode.d6.loss_dice: 0.7082  decode.d7.loss_cls: 0.0368  decode.d7.loss_mask: 0.7635  decode.d7.loss_dice: 0.7075  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.7628  decode.d8.loss_dice: 0.7037
2025/03/31 06:31:12 - mmengine - INFO - Saving checkpoint at 8000 iterations
2025/03/31 06:31:18 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:06  time: 0.0942  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:23 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:00  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:28 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:55  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:32 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:50  time: 0.0937  data_time: 0.0013  memory: 1853  
2025/03/31 06:31:37 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:46  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:42 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:41  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:47 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:36  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:51 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:31  time: 0.0934  data_time: 0.0012  memory: 1853  
2025/03/31 06:31:56 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:27  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 06:32:01 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:22  time: 0.0935  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:05 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:17  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:10 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:12  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:15 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:08  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 06:32:19 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:03  time: 0.0931  data_time: 0.0011  memory: 1853  
2025/03/31 06:32:24 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:58  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:29 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:54  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:33 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:49  time: 0.0935  data_time: 0.0011  memory: 1853  
2025/03/31 06:32:38 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:44  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 06:32:43 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:40  time: 0.0936  data_time: 0.0011  memory: 1853  
2025/03/31 06:32:48 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:35  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:52 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:30  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 06:32:57 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:25  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 06:33:02 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:21  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 06:33:06 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:16  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 06:33:11 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:11  time: 0.0939  data_time: 0.0013  memory: 1853  
2025/03/31 06:33:16 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:07  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:33:20 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:02  time: 0.0939  data_time: 0.0013  memory: 1853  
2025/03/31 06:33:25 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:57  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 06:33:30 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0935  data_time: 0.0012  memory: 1853  
2025/03/31 06:33:35 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:48  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 06:33:39 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:43  time: 0.0949  data_time: 0.0014  memory: 1853  
2025/03/31 06:33:44 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0939  data_time: 0.0013  memory: 1853  
2025/03/31 06:33:49 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 06:33:53 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:29  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 06:33:58 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:24  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 06:34:03 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 06:34:08 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 06:34:12 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:10  time: 0.0939  data_time: 0.0013  memory: 1853  
2025/03/31 06:34:17 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 06:34:22 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0953  data_time: 0.0013  memory: 1853  
2025/03/31 06:34:23 - mmengine - INFO - per class results:
2025/03/31 06:34:23 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 69.49 | 92.99 |
|      building      | 81.31 | 90.76 |
|   low_vegetation   | 59.71 | 86.56 |
|        tree        | 31.11 | 31.95 |
|        car         | 75.26 |  87.5 |
|      clutter       |  2.15 |  2.17 |
+--------------------+-------+-------+
2025/03/31 06:34:23 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.3300  mIoU: 53.1700  mAcc: 65.3200  data_time: 0.0013  time: 0.0939
2025/03/31 06:35:06 - mmengine - INFO - Iter(train) [ 8050/20000]  base_lr: 6.2911e-05 lr: 6.2911e-05  eta: 2:51:47  time: 0.8575  data_time: 0.0158  memory: 10142  loss: 16.1005  decode.loss_cls: 0.0069  decode.loss_mask: 0.8538  decode.loss_dice: 0.7376  decode.d0.loss_cls: 0.0597  decode.d0.loss_mask: 0.8655  decode.d0.loss_dice: 0.7348  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.8531  decode.d1.loss_dice: 0.7454  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.8480  decode.d2.loss_dice: 0.7417  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.8533  decode.d3.loss_dice: 0.7490  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.8576  decode.d4.loss_dice: 0.7414  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.8585  decode.d5.loss_dice: 0.7399  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.8604  decode.d6.loss_dice: 0.7486  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.8559  decode.d7.loss_dice: 0.7421  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.8559  decode.d8.loss_dice: 0.7410
2025/03/31 06:35:49 - mmengine - INFO - Iter(train) [ 8100/20000]  base_lr: 6.2674e-05 lr: 6.2674e-05  eta: 2:51:03  time: 0.8566  data_time: 0.0157  memory: 10099  loss: 15.8966  decode.loss_cls: 0.0493  decode.loss_mask: 0.7865  decode.loss_dice: 0.7482  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.7897  decode.d0.loss_dice: 0.7615  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.7829  decode.d1.loss_dice: 0.7597  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.7861  decode.d2.loss_dice: 0.7548  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.7831  decode.d3.loss_dice: 0.7469  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.7828  decode.d4.loss_dice: 0.7554  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 0.7404  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.7847  decode.d6.loss_dice: 0.7547  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.7825  decode.d7.loss_dice: 0.7457  decode.d8.loss_cls: 0.0502  decode.d8.loss_mask: 0.7826  decode.d8.loss_dice: 0.7416
2025/03/31 06:36:32 - mmengine - INFO - Iter(train) [ 8150/20000]  base_lr: 6.2437e-05 lr: 6.2437e-05  eta: 2:50:20  time: 0.8564  data_time: 0.0158  memory: 10143  loss: 14.9841  decode.loss_cls: 0.0536  decode.loss_mask: 0.7198  decode.loss_dice: 0.7017  decode.d0.loss_cls: 0.0569  decode.d0.loss_mask: 0.7259  decode.d0.loss_dice: 0.7120  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.7206  decode.d1.loss_dice: 0.7083  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.7231  decode.d2.loss_dice: 0.7064  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.7219  decode.d3.loss_dice: 0.7017  decode.d4.loss_cls: 0.1030  decode.d4.loss_mask: 0.7220  decode.d4.loss_dice: 0.7170  decode.d5.loss_cls: 0.0784  decode.d5.loss_mask: 0.7215  decode.d5.loss_dice: 0.6937  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.7242  decode.d6.loss_dice: 0.7117  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.7215  decode.d7.loss_dice: 0.6980  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.7221  decode.d8.loss_dice: 0.7106
2025/03/31 06:37:15 - mmengine - INFO - Iter(train) [ 8200/20000]  base_lr: 6.2199e-05 lr: 6.2199e-05  eta: 2:49:37  time: 0.8580  data_time: 0.0158  memory: 10145  loss: 15.6989  decode.loss_cls: 0.0158  decode.loss_mask: 0.7941  decode.loss_dice: 0.7530  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.8225  decode.d0.loss_dice: 0.7525  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.8031  decode.d1.loss_dice: 0.7302  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.7986  decode.d2.loss_dice: 0.7511  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.7925  decode.d3.loss_dice: 0.7480  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.7973  decode.d4.loss_dice: 0.7495  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.7982  decode.d5.loss_dice: 0.7504  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.7977  decode.d6.loss_dice: 0.7424  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.8030  decode.d7.loss_dice: 0.7630  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.7987  decode.d8.loss_dice: 0.7467
2025/03/31 06:37:58 - mmengine - INFO - Iter(train) [ 8250/20000]  base_lr: 6.1962e-05 lr: 6.1962e-05  eta: 2:48:54  time: 0.8585  data_time: 0.0155  memory: 10151  loss: 14.8882  decode.loss_cls: 0.0090  decode.loss_mask: 0.7623  decode.loss_dice: 0.7139  decode.d0.loss_cls: 0.0571  decode.d0.loss_mask: 0.7640  decode.d0.loss_dice: 0.7281  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.7644  decode.d1.loss_dice: 0.7267  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.7652  decode.d2.loss_dice: 0.7155  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.7605  decode.d3.loss_dice: 0.7100  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.7644  decode.d4.loss_dice: 0.7018  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.7604  decode.d5.loss_dice: 0.7107  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.7639  decode.d6.loss_dice: 0.7173  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.7616  decode.d7.loss_dice: 0.7019  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.7624  decode.d8.loss_dice: 0.7002
2025/03/31 06:38:41 - mmengine - INFO - Iter(train) [ 8300/20000]  base_lr: 6.1725e-05 lr: 6.1725e-05  eta: 2:48:10  time: 0.8577  data_time: 0.0155  memory: 10095  loss: 15.5598  decode.loss_cls: 0.0770  decode.loss_mask: 0.7379  decode.loss_dice: 0.7368  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.7398  decode.d0.loss_dice: 0.7561  decode.d1.loss_cls: 0.1009  decode.d1.loss_mask: 0.7363  decode.d1.loss_dice: 0.7170  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.7427  decode.d2.loss_dice: 0.7252  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.7457  decode.d3.loss_dice: 0.7423  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 0.7466  decode.d4.loss_dice: 0.7432  decode.d5.loss_cls: 0.1022  decode.d5.loss_mask: 0.7416  decode.d5.loss_dice: 0.7287  decode.d6.loss_cls: 0.0970  decode.d6.loss_mask: 0.7382  decode.d6.loss_dice: 0.7290  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.7404  decode.d7.loss_dice: 0.7169  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.7403  decode.d8.loss_dice: 0.7421
2025/03/31 06:39:24 - mmengine - INFO - Iter(train) [ 8350/20000]  base_lr: 6.1487e-05 lr: 6.1487e-05  eta: 2:47:27  time: 0.8579  data_time: 0.0155  memory: 10145  loss: 15.2081  decode.loss_cls: 0.0215  decode.loss_mask: 0.7520  decode.loss_dice: 0.7429  decode.d0.loss_cls: 0.0461  decode.d0.loss_mask: 0.7580  decode.d0.loss_dice: 0.7544  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.7584  decode.d1.loss_dice: 0.7416  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.7562  decode.d2.loss_dice: 0.7473  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.7564  decode.d3.loss_dice: 0.7373  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.7533  decode.d4.loss_dice: 0.7378  decode.d5.loss_cls: 0.0275  decode.d5.loss_mask: 0.7548  decode.d5.loss_dice: 0.7551  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.7535  decode.d6.loss_dice: 0.7428  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.7531  decode.d7.loss_dice: 0.7376  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.7536  decode.d8.loss_dice: 0.7407
2025/03/31 06:40:07 - mmengine - INFO - Iter(train) [ 8400/20000]  base_lr: 6.1250e-05 lr: 6.1250e-05  eta: 2:46:43  time: 0.8573  data_time: 0.0154  memory: 10143  loss: 15.4004  decode.loss_cls: 0.0327  decode.loss_mask: 0.7716  decode.loss_dice: 0.7250  decode.d0.loss_cls: 0.1167  decode.d0.loss_mask: 0.7702  decode.d0.loss_dice: 0.7212  decode.d1.loss_cls: 0.0403  decode.d1.loss_mask: 0.7777  decode.d1.loss_dice: 0.7013  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.7811  decode.d2.loss_dice: 0.7330  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.7673  decode.d3.loss_dice: 0.7280  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.7648  decode.d4.loss_dice: 0.7235  decode.d5.loss_cls: 0.0312  decode.d5.loss_mask: 0.7652  decode.d5.loss_dice: 0.7363  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.7636  decode.d6.loss_dice: 0.7158  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.7725  decode.d7.loss_dice: 0.7431  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.7688  decode.d8.loss_dice: 0.7140
2025/03/31 06:40:50 - mmengine - INFO - Iter(train) [ 8450/20000]  base_lr: 6.1012e-05 lr: 6.1012e-05  eta: 2:46:00  time: 0.8573  data_time: 0.0155  memory: 10145  loss: 14.9421  decode.loss_cls: 0.0115  decode.loss_mask: 0.7536  decode.loss_dice: 0.7022  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.7654  decode.d0.loss_dice: 0.7050  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.7591  decode.d1.loss_dice: 0.7083  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.7572  decode.d2.loss_dice: 0.7030  decode.d3.loss_cls: 0.0199  decode.d3.loss_mask: 0.7599  decode.d3.loss_dice: 0.6989  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.7581  decode.d4.loss_dice: 0.6972  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.7541  decode.d5.loss_dice: 0.6970  decode.d6.loss_cls: 0.0345  decode.d6.loss_mask: 0.7543  decode.d6.loss_dice: 0.6907  decode.d7.loss_cls: 0.0204  decode.d7.loss_mask: 0.7536  decode.d7.loss_dice: 0.6969  decode.d8.loss_cls: 0.0452  decode.d8.loss_mask: 0.7523  decode.d8.loss_dice: 0.6984
2025/03/31 06:41:33 - mmengine - INFO - Iter(train) [ 8500/20000]  base_lr: 6.0774e-05 lr: 6.0774e-05  eta: 2:45:17  time: 0.8587  data_time: 0.0160  memory: 10098  loss: 14.9781  decode.loss_cls: 0.0128  decode.loss_mask: 0.7311  decode.loss_dice: 0.7442  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 0.7316  decode.d0.loss_dice: 0.7403  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.7351  decode.d1.loss_dice: 0.7509  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.7293  decode.d2.loss_dice: 0.7366  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 0.7270  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.7362  decode.d4.loss_dice: 0.7285  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.7312  decode.d5.loss_dice: 0.7405  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.7293  decode.d6.loss_dice: 0.7359  decode.d7.loss_cls: 0.0194  decode.d7.loss_mask: 0.7296  decode.d7.loss_dice: 0.7273  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.7285  decode.d8.loss_dice: 0.7400
2025/03/31 06:42:16 - mmengine - INFO - Iter(train) [ 8550/20000]  base_lr: 6.0537e-05 lr: 6.0537e-05  eta: 2:44:34  time: 0.8573  data_time: 0.0155  memory: 10096  loss: 15.3060  decode.loss_cls: 0.0075  decode.loss_mask: 0.7634  decode.loss_dice: 0.7371  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.7764  decode.d0.loss_dice: 0.7449  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.7670  decode.d1.loss_dice: 0.7377  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.7621  decode.d2.loss_dice: 0.7424  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.7649  decode.d3.loss_dice: 0.7430  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.7662  decode.d4.loss_dice: 0.7455  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.7667  decode.d5.loss_dice: 0.7454  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.7664  decode.d6.loss_dice: 0.7439  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.7706  decode.d7.loss_dice: 0.7412  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.7660  decode.d8.loss_dice: 0.7343
2025/03/31 06:42:59 - mmengine - INFO - Iter(train) [ 8600/20000]  base_lr: 6.0299e-05 lr: 6.0299e-05  eta: 2:43:50  time: 0.8562  data_time: 0.0153  memory: 10144  loss: 15.1151  decode.loss_cls: 0.0331  decode.loss_mask: 0.7254  decode.loss_dice: 0.7291  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 0.7392  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.7247  decode.d1.loss_dice: 0.7389  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.7301  decode.d2.loss_dice: 0.7251  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.7336  decode.d3.loss_dice: 0.7349  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.7335  decode.d4.loss_dice: 0.7190  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 0.7300  decode.d5.loss_dice: 0.7232  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.7272  decode.d6.loss_dice: 0.7176  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.7247  decode.d7.loss_dice: 0.7224  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.7278  decode.d8.loss_dice: 0.7241
2025/03/31 06:43:42 - mmengine - INFO - Iter(train) [ 8650/20000]  base_lr: 6.0060e-05 lr: 6.0060e-05  eta: 2:43:07  time: 0.8563  data_time: 0.0156  memory: 10097  loss: 15.7941  decode.loss_cls: 0.0473  decode.loss_mask: 0.7786  decode.loss_dice: 0.7342  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.7931  decode.d0.loss_dice: 0.7552  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.7754  decode.d1.loss_dice: 0.7495  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.7770  decode.d2.loss_dice: 0.7557  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.7810  decode.d3.loss_dice: 0.7290  decode.d4.loss_cls: 0.0374  decode.d4.loss_mask: 0.7827  decode.d4.loss_dice: 0.7487  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.7805  decode.d5.loss_dice: 0.7286  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.7827  decode.d6.loss_dice: 0.7424  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.7799  decode.d7.loss_dice: 0.7344  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.7817  decode.d8.loss_dice: 0.7384
2025/03/31 06:44:25 - mmengine - INFO - Iter(train) [ 8700/20000]  base_lr: 5.9822e-05 lr: 5.9822e-05  eta: 2:42:23  time: 0.8555  data_time: 0.0155  memory: 10096  loss: 12.9607  decode.loss_cls: 0.0284  decode.loss_mask: 0.6325  decode.loss_dice: 0.6378  decode.d0.loss_cls: 0.0610  decode.d0.loss_mask: 0.6357  decode.d0.loss_dice: 0.6446  decode.d1.loss_cls: 0.0388  decode.d1.loss_mask: 0.6313  decode.d1.loss_dice: 0.6463  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.6262  decode.d2.loss_dice: 0.6401  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.6322  decode.d3.loss_dice: 0.6407  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.6281  decode.d4.loss_dice: 0.6452  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.6309  decode.d5.loss_dice: 0.6297  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.6316  decode.d6.loss_dice: 0.6381  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.6285  decode.d7.loss_dice: 0.6325  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.6318  decode.d8.loss_dice: 0.6322
2025/03/31 06:45:08 - mmengine - INFO - Iter(train) [ 8750/20000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 2:41:40  time: 0.8567  data_time: 0.0154  memory: 10093  loss: 14.9413  decode.loss_cls: 0.0266  decode.loss_mask: 0.7173  decode.loss_dice: 0.7256  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.7231  decode.d0.loss_dice: 0.7199  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.7085  decode.d1.loss_dice: 0.7315  decode.d2.loss_cls: 0.0388  decode.d2.loss_mask: 0.7174  decode.d2.loss_dice: 0.7201  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.7086  decode.d3.loss_dice: 0.7251  decode.d4.loss_cls: 0.0344  decode.d4.loss_mask: 0.7227  decode.d4.loss_dice: 0.7239  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.7607  decode.d5.loss_dice: 0.7345  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.7261  decode.d6.loss_dice: 0.7223  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.7549  decode.d7.loss_dice: 0.7416  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.7346  decode.d8.loss_dice: 0.7310
2025/03/31 06:45:51 - mmengine - INFO - Iter(train) [ 8800/20000]  base_lr: 5.9346e-05 lr: 5.9346e-05  eta: 2:40:57  time: 0.8572  data_time: 0.0154  memory: 10144  loss: 14.0761  decode.loss_cls: 0.0084  decode.loss_mask: 0.6942  decode.loss_dice: 0.6925  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.7093  decode.d0.loss_dice: 0.6893  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 0.6970  decode.d1.loss_dice: 0.6767  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.6990  decode.d2.loss_dice: 0.6784  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.6980  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.6989  decode.d4.loss_dice: 0.7010  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.6929  decode.d5.loss_dice: 0.6819  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 0.6931  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.6999  decode.d7.loss_dice: 0.6981  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.6967  decode.d8.loss_dice: 0.6906
2025/03/31 06:46:34 - mmengine - INFO - Iter(train) [ 8850/20000]  base_lr: 5.9107e-05 lr: 5.9107e-05  eta: 2:40:13  time: 0.8606  data_time: 0.0155  memory: 10142  loss: 14.4386  decode.loss_cls: 0.0251  decode.loss_mask: 0.7227  decode.loss_dice: 0.6871  decode.d0.loss_cls: 0.0474  decode.d0.loss_mask: 0.7208  decode.d0.loss_dice: 0.6969  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.7223  decode.d1.loss_dice: 0.6893  decode.d2.loss_cls: 0.0149  decode.d2.loss_mask: 0.7188  decode.d2.loss_dice: 0.6972  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.7217  decode.d3.loss_dice: 0.6975  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.7222  decode.d4.loss_dice: 0.6899  decode.d5.loss_cls: 0.0213  decode.d5.loss_mask: 0.7192  decode.d5.loss_dice: 0.6967  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.7227  decode.d6.loss_dice: 0.6941  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.7227  decode.d7.loss_dice: 0.6914  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.7254  decode.d8.loss_dice: 0.6898
2025/03/31 06:47:17 - mmengine - INFO - Iter(train) [ 8900/20000]  base_lr: 5.8869e-05 lr: 5.8869e-05  eta: 2:39:30  time: 0.8569  data_time: 0.0153  memory: 10145  loss: 14.0265  decode.loss_cls: 0.0378  decode.loss_mask: 0.6722  decode.loss_dice: 0.7094  decode.d0.loss_cls: 0.0554  decode.d0.loss_mask: 0.6658  decode.d0.loss_dice: 0.7035  decode.d1.loss_cls: 0.0370  decode.d1.loss_mask: 0.6686  decode.d1.loss_dice: 0.6901  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.6679  decode.d2.loss_dice: 0.6727  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.6724  decode.d3.loss_dice: 0.6835  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.6682  decode.d4.loss_dice: 0.6810  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 0.6941  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.6692  decode.d6.loss_dice: 0.6863  decode.d7.loss_cls: 0.0350  decode.d7.loss_mask: 0.6736  decode.d7.loss_dice: 0.6939  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.6742  decode.d8.loss_dice: 0.6757
2025/03/31 06:48:00 - mmengine - INFO - Iter(train) [ 8950/20000]  base_lr: 5.8630e-05 lr: 5.8630e-05  eta: 2:38:47  time: 0.8589  data_time: 0.0155  memory: 10142  loss: 15.8907  decode.loss_cls: 0.0370  decode.loss_mask: 0.8290  decode.loss_dice: 0.7037  decode.d0.loss_cls: 0.0513  decode.d0.loss_mask: 0.8450  decode.d0.loss_dice: 0.7429  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.8274  decode.d1.loss_dice: 0.7227  decode.d2.loss_cls: 0.0350  decode.d2.loss_mask: 0.8316  decode.d2.loss_dice: 0.7161  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.8299  decode.d3.loss_dice: 0.7166  decode.d4.loss_cls: 0.0361  decode.d4.loss_mask: 0.8341  decode.d4.loss_dice: 0.7113  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.8341  decode.d5.loss_dice: 0.7126  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.8284  decode.d6.loss_dice: 0.7142  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.8310  decode.d7.loss_dice: 0.7151  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.8294  decode.d8.loss_dice: 0.7143
2025/03/31 06:48:43 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 06:48:43 - mmengine - INFO - Iter(train) [ 9000/20000]  base_lr: 5.8391e-05 lr: 5.8391e-05  eta: 2:38:04  time: 0.8584  data_time: 0.0155  memory: 10098  loss: 15.2423  decode.loss_cls: 0.0382  decode.loss_mask: 0.7414  decode.loss_dice: 0.7450  decode.d0.loss_cls: 0.0524  decode.d0.loss_mask: 0.7570  decode.d0.loss_dice: 0.7465  decode.d1.loss_cls: 0.0446  decode.d1.loss_mask: 0.7442  decode.d1.loss_dice: 0.7400  decode.d2.loss_cls: 0.0477  decode.d2.loss_mask: 0.7445  decode.d2.loss_dice: 0.7483  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.7396  decode.d3.loss_dice: 0.7493  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.7413  decode.d4.loss_dice: 0.7540  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.7413  decode.d5.loss_dice: 0.7478  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.7385  decode.d6.loss_dice: 0.7538  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.7439  decode.d7.loss_dice: 0.7351  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.7415  decode.d8.loss_dice: 0.7440
2025/03/31 06:49:26 - mmengine - INFO - Iter(train) [ 9050/20000]  base_lr: 5.8152e-05 lr: 5.8152e-05  eta: 2:37:20  time: 0.8570  data_time: 0.0157  memory: 10144  loss: 14.1705  decode.loss_cls: 0.0435  decode.loss_mask: 0.7287  decode.loss_dice: 0.6357  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.7331  decode.d0.loss_dice: 0.6330  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.7313  decode.d1.loss_dice: 0.6441  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.7347  decode.d2.loss_dice: 0.6241  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.7343  decode.d3.loss_dice: 0.6411  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.7367  decode.d4.loss_dice: 0.6438  decode.d5.loss_cls: 0.0416  decode.d5.loss_mask: 0.7330  decode.d5.loss_dice: 0.6454  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 0.7325  decode.d6.loss_dice: 0.6451  decode.d7.loss_cls: 0.0348  decode.d7.loss_mask: 0.7328  decode.d7.loss_dice: 0.6234  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.7326  decode.d8.loss_dice: 0.6380
2025/03/31 06:50:09 - mmengine - INFO - Iter(train) [ 9100/20000]  base_lr: 5.7913e-05 lr: 5.7913e-05  eta: 2:36:37  time: 0.8578  data_time: 0.0155  memory: 10095  loss: 14.3864  decode.loss_cls: 0.0526  decode.loss_mask: 0.7460  decode.loss_dice: 0.6462  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.7657  decode.d0.loss_dice: 0.6497  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.7551  decode.d1.loss_dice: 0.6529  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.7506  decode.d2.loss_dice: 0.6448  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.7503  decode.d3.loss_dice: 0.6422  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.7536  decode.d4.loss_dice: 0.6453  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.7485  decode.d5.loss_dice: 0.6462  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.7487  decode.d6.loss_dice: 0.6432  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.7489  decode.d7.loss_dice: 0.6557  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.7503  decode.d8.loss_dice: 0.6510
2025/03/31 06:50:52 - mmengine - INFO - Iter(train) [ 9150/20000]  base_lr: 5.7674e-05 lr: 5.7674e-05  eta: 2:35:54  time: 0.8571  data_time: 0.0157  memory: 10151  loss: 14.8618  decode.loss_cls: 0.0308  decode.loss_mask: 0.7527  decode.loss_dice: 0.6980  decode.d0.loss_cls: 0.0469  decode.d0.loss_mask: 0.7584  decode.d0.loss_dice: 0.7145  decode.d1.loss_cls: 0.0692  decode.d1.loss_mask: 0.7549  decode.d1.loss_dice: 0.7022  decode.d2.loss_cls: 0.0368  decode.d2.loss_mask: 0.7530  decode.d2.loss_dice: 0.6924  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.7524  decode.d3.loss_dice: 0.6991  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.7507  decode.d4.loss_dice: 0.6893  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.7530  decode.d5.loss_dice: 0.7042  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.7490  decode.d6.loss_dice: 0.6903  decode.d7.loss_cls: 0.0284  decode.d7.loss_mask: 0.7533  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.7525  decode.d8.loss_dice: 0.6916
2025/03/31 06:51:35 - mmengine - INFO - Iter(train) [ 9200/20000]  base_lr: 5.7435e-05 lr: 5.7435e-05  eta: 2:35:11  time: 0.8575  data_time: 0.0156  memory: 10147  loss: 14.6538  decode.loss_cls: 0.0107  decode.loss_mask: 0.7487  decode.loss_dice: 0.6896  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.7735  decode.d0.loss_dice: 0.6797  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.7499  decode.d1.loss_dice: 0.6844  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.7493  decode.d2.loss_dice: 0.6810  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.7500  decode.d3.loss_dice: 0.6772  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.7492  decode.d4.loss_dice: 0.6853  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.7541  decode.d5.loss_dice: 0.6854  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.7545  decode.d6.loss_dice: 0.6872  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.7531  decode.d7.loss_dice: 0.6863  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.7549  decode.d8.loss_dice: 0.7069
2025/03/31 06:52:18 - mmengine - INFO - Iter(train) [ 9250/20000]  base_lr: 5.7195e-05 lr: 5.7195e-05  eta: 2:34:27  time: 0.8594  data_time: 0.0155  memory: 10144  loss: 15.4861  decode.loss_cls: 0.0097  decode.loss_mask: 0.7977  decode.loss_dice: 0.7316  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.7984  decode.d0.loss_dice: 0.7337  decode.d1.loss_cls: 0.0313  decode.d1.loss_mask: 0.7973  decode.d1.loss_dice: 0.7264  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.7969  decode.d2.loss_dice: 0.7240  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.7993  decode.d3.loss_dice: 0.7359  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.7993  decode.d4.loss_dice: 0.7321  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.8025  decode.d5.loss_dice: 0.7267  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.7986  decode.d6.loss_dice: 0.7408  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.7980  decode.d7.loss_dice: 0.7272  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.7991  decode.d8.loss_dice: 0.7210
2025/03/31 06:53:01 - mmengine - INFO - Iter(train) [ 9300/20000]  base_lr: 5.6956e-05 lr: 5.6956e-05  eta: 2:33:44  time: 0.8578  data_time: 0.0156  memory: 10139  loss: 13.9682  decode.loss_cls: 0.0075  decode.loss_mask: 0.7261  decode.loss_dice: 0.6440  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.7346  decode.d0.loss_dice: 0.6573  decode.d1.loss_cls: 0.0409  decode.d1.loss_mask: 0.7260  decode.d1.loss_dice: 0.6456  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.7235  decode.d2.loss_dice: 0.6506  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.7247  decode.d3.loss_dice: 0.6455  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.7278  decode.d4.loss_dice: 0.6549  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.7268  decode.d5.loss_dice: 0.6472  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.7232  decode.d6.loss_dice: 0.6474  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.7267  decode.d7.loss_dice: 0.6463  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.7255  decode.d8.loss_dice: 0.6553
2025/03/31 06:53:44 - mmengine - INFO - Iter(train) [ 9350/20000]  base_lr: 5.6716e-05 lr: 5.6716e-05  eta: 2:33:01  time: 0.8592  data_time: 0.0156  memory: 10145  loss: 14.8452  decode.loss_cls: 0.0065  decode.loss_mask: 0.7893  decode.loss_dice: 0.6706  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.8006  decode.d0.loss_dice: 0.6727  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.7923  decode.d1.loss_dice: 0.6708  decode.d2.loss_cls: 0.0259  decode.d2.loss_mask: 0.7864  decode.d2.loss_dice: 0.6835  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.7889  decode.d3.loss_dice: 0.6807  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.7910  decode.d4.loss_dice: 0.6777  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.7878  decode.d5.loss_dice: 0.6763  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.7896  decode.d6.loss_dice: 0.6852  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.7873  decode.d7.loss_dice: 0.6784  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.7877  decode.d8.loss_dice: 0.6695
2025/03/31 06:54:27 - mmengine - INFO - Iter(train) [ 9400/20000]  base_lr: 5.6477e-05 lr: 5.6477e-05  eta: 2:32:18  time: 0.8591  data_time: 0.0165  memory: 10140  loss: 14.8042  decode.loss_cls: 0.0382  decode.loss_mask: 0.7356  decode.loss_dice: 0.6648  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.7485  decode.d0.loss_dice: 0.6812  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.7424  decode.d1.loss_dice: 0.6916  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.7418  decode.d2.loss_dice: 0.7004  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 0.7401  decode.d3.loss_dice: 0.6975  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 0.7046  decode.d5.loss_cls: 0.0308  decode.d5.loss_mask: 0.7471  decode.d5.loss_dice: 0.6885  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 0.7454  decode.d6.loss_dice: 0.6954  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.7443  decode.d7.loss_dice: 0.6828  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.7423  decode.d8.loss_dice: 0.6633
2025/03/31 06:55:10 - mmengine - INFO - Iter(train) [ 9450/20000]  base_lr: 5.6237e-05 lr: 5.6237e-05  eta: 2:31:35  time: 0.8570  data_time: 0.0159  memory: 10144  loss: 14.5595  decode.loss_cls: 0.0173  decode.loss_mask: 0.7518  decode.loss_dice: 0.6813  decode.d0.loss_cls: 0.0544  decode.d0.loss_mask: 0.7622  decode.d0.loss_dice: 0.6800  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.7523  decode.d1.loss_dice: 0.6910  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.7512  decode.d2.loss_dice: 0.6821  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.7499  decode.d3.loss_dice: 0.6897  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.7493  decode.d4.loss_dice: 0.6836  decode.d5.loss_cls: 0.0193  decode.d5.loss_mask: 0.7470  decode.d5.loss_dice: 0.6852  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.7471  decode.d6.loss_dice: 0.6870  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 0.7536  decode.d7.loss_dice: 0.6808  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.7512  decode.d8.loss_dice: 0.6858
2025/03/31 06:55:53 - mmengine - INFO - Iter(train) [ 9500/20000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 2:30:51  time: 0.8563  data_time: 0.0155  memory: 10139  loss: 15.1296  decode.loss_cls: 0.0535  decode.loss_mask: 0.7222  decode.loss_dice: 0.7216  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.7347  decode.d0.loss_dice: 0.7561  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.7269  decode.d1.loss_dice: 0.7126  decode.d2.loss_cls: 0.1106  decode.d2.loss_mask: 0.7259  decode.d2.loss_dice: 0.7068  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.7237  decode.d3.loss_dice: 0.7154  decode.d4.loss_cls: 0.0705  decode.d4.loss_mask: 0.7253  decode.d4.loss_dice: 0.7188  decode.d5.loss_cls: 0.0560  decode.d5.loss_mask: 0.7237  decode.d5.loss_dice: 0.7137  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.7199  decode.d6.loss_dice: 0.7071  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.7205  decode.d7.loss_dice: 0.7037  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.7228  decode.d8.loss_dice: 0.7090
2025/03/31 06:56:36 - mmengine - INFO - Iter(train) [ 9550/20000]  base_lr: 5.5757e-05 lr: 5.5757e-05  eta: 2:30:08  time: 0.8716  data_time: 0.0157  memory: 10144  loss: 13.7981  decode.loss_cls: 0.0038  decode.loss_mask: 0.7077  decode.loss_dice: 0.6616  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.7194  decode.d0.loss_dice: 0.6577  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.7145  decode.d1.loss_dice: 0.6604  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.7095  decode.d2.loss_dice: 0.6608  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 0.6574  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.7084  decode.d4.loss_dice: 0.6517  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.7078  decode.d5.loss_dice: 0.6618  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.7058  decode.d6.loss_dice: 0.6582  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.7066  decode.d7.loss_dice: 0.6601  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.7088  decode.d8.loss_dice: 0.6571
2025/03/31 06:57:19 - mmengine - INFO - Iter(train) [ 9600/20000]  base_lr: 5.5517e-05 lr: 5.5517e-05  eta: 2:29:25  time: 0.8595  data_time: 0.0155  memory: 10142  loss: 13.2528  decode.loss_cls: 0.0153  decode.loss_mask: 0.6352  decode.loss_dice: 0.6642  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.6448  decode.d0.loss_dice: 0.6888  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.6355  decode.d1.loss_dice: 0.6715  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.6367  decode.d2.loss_dice: 0.6573  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.6360  decode.d3.loss_dice: 0.6495  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.6398  decode.d4.loss_dice: 0.6653  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.6368  decode.d5.loss_dice: 0.6666  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.6368  decode.d6.loss_dice: 0.6552  decode.d7.loss_cls: 0.0407  decode.d7.loss_mask: 0.6392  decode.d7.loss_dice: 0.6598  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.6365  decode.d8.loss_dice: 0.6662
2025/03/31 06:58:02 - mmengine - INFO - Iter(train) [ 9650/20000]  base_lr: 5.5276e-05 lr: 5.5276e-05  eta: 2:28:42  time: 0.8568  data_time: 0.0155  memory: 10144  loss: 14.2661  decode.loss_cls: 0.0183  decode.loss_mask: 0.7426  decode.loss_dice: 0.6573  decode.d0.loss_cls: 0.0537  decode.d0.loss_mask: 0.7468  decode.d0.loss_dice: 0.6613  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.7393  decode.d1.loss_dice: 0.6677  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.7395  decode.d2.loss_dice: 0.6544  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.7420  decode.d3.loss_dice: 0.6519  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.7400  decode.d4.loss_dice: 0.6575  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.7393  decode.d5.loss_dice: 0.6573  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.7399  decode.d6.loss_dice: 0.6542  decode.d7.loss_cls: 0.0491  decode.d7.loss_mask: 0.7391  decode.d7.loss_dice: 0.6597  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.7395  decode.d8.loss_dice: 0.6620
2025/03/31 06:58:45 - mmengine - INFO - Iter(train) [ 9700/20000]  base_lr: 5.5036e-05 lr: 5.5036e-05  eta: 2:27:59  time: 0.8638  data_time: 0.0165  memory: 10143  loss: 14.4070  decode.loss_cls: 0.0402  decode.loss_mask: 0.7406  decode.loss_dice: 0.6783  decode.d0.loss_cls: 0.0538  decode.d0.loss_mask: 0.7511  decode.d0.loss_dice: 0.6772  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.7424  decode.d1.loss_dice: 0.6870  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.7432  decode.d2.loss_dice: 0.6809  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.7441  decode.d3.loss_dice: 0.6862  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.7418  decode.d4.loss_dice: 0.6727  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.7461  decode.d5.loss_dice: 0.6749  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.7411  decode.d6.loss_dice: 0.6800  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.7429  decode.d7.loss_dice: 0.6753  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.7376  decode.d8.loss_dice: 0.6824
2025/03/31 06:59:28 - mmengine - INFO - Iter(train) [ 9750/20000]  base_lr: 5.4795e-05 lr: 5.4795e-05  eta: 2:27:15  time: 0.8570  data_time: 0.0154  memory: 10098  loss: 14.4600  decode.loss_cls: 0.0350  decode.loss_mask: 0.7268  decode.loss_dice: 0.6796  decode.d0.loss_cls: 0.0530  decode.d0.loss_mask: 0.7385  decode.d0.loss_dice: 0.6890  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.7329  decode.d1.loss_dice: 0.6864  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.7332  decode.d2.loss_dice: 0.6805  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.7314  decode.d3.loss_dice: 0.6711  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.7324  decode.d4.loss_dice: 0.6927  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.7301  decode.d5.loss_dice: 0.6719  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.7297  decode.d6.loss_dice: 0.6743  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.7317  decode.d7.loss_dice: 0.6794  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.7288  decode.d8.loss_dice: 0.6776
2025/03/31 07:00:11 - mmengine - INFO - Iter(train) [ 9800/20000]  base_lr: 5.4555e-05 lr: 5.4555e-05  eta: 2:26:32  time: 0.8563  data_time: 0.0155  memory: 10098  loss: 12.8573  decode.loss_cls: 0.0036  decode.loss_mask: 0.6549  decode.loss_dice: 0.6164  decode.d0.loss_cls: 0.0601  decode.d0.loss_mask: 0.6626  decode.d0.loss_dice: 0.6113  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.6546  decode.d1.loss_dice: 0.6206  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.6555  decode.d2.loss_dice: 0.6229  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.6513  decode.d3.loss_dice: 0.6201  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.6523  decode.d4.loss_dice: 0.6269  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.6508  decode.d5.loss_dice: 0.6206  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.6534  decode.d6.loss_dice: 0.6275  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.6469  decode.d7.loss_dice: 0.6141  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.6507  decode.d8.loss_dice: 0.6209
2025/03/31 07:00:54 - mmengine - INFO - Iter(train) [ 9850/20000]  base_lr: 5.4314e-05 lr: 5.4314e-05  eta: 2:25:49  time: 0.8583  data_time: 0.0157  memory: 10150  loss: 14.4668  decode.loss_cls: 0.0392  decode.loss_mask: 0.7132  decode.loss_dice: 0.6880  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.7164  decode.d0.loss_dice: 0.6976  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.7112  decode.d1.loss_dice: 0.6933  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.7123  decode.d2.loss_dice: 0.6934  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.7149  decode.d3.loss_dice: 0.6768  decode.d4.loss_cls: 0.0329  decode.d4.loss_mask: 0.7137  decode.d4.loss_dice: 0.6771  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.7120  decode.d5.loss_dice: 0.6767  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.7213  decode.d6.loss_dice: 0.6990  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.7159  decode.d7.loss_dice: 0.6900  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.7140  decode.d8.loss_dice: 0.6784
2025/03/31 07:01:37 - mmengine - INFO - Iter(train) [ 9900/20000]  base_lr: 5.4073e-05 lr: 5.4073e-05  eta: 2:25:06  time: 0.8576  data_time: 0.0156  memory: 10093  loss: 13.5880  decode.loss_cls: 0.0263  decode.loss_mask: 0.6944  decode.loss_dice: 0.6360  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.7061  decode.d0.loss_dice: 0.6451  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.6936  decode.d1.loss_dice: 0.6463  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.6964  decode.d2.loss_dice: 0.6371  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.6940  decode.d3.loss_dice: 0.6274  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.6939  decode.d4.loss_dice: 0.6376  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.6923  decode.d5.loss_dice: 0.6256  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.6943  decode.d6.loss_dice: 0.6543  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.6952  decode.d7.loss_dice: 0.6257  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 0.6944  decode.d8.loss_dice: 0.6508
2025/03/31 07:02:20 - mmengine - INFO - Iter(train) [ 9950/20000]  base_lr: 5.3832e-05 lr: 5.3832e-05  eta: 2:24:22  time: 0.8575  data_time: 0.0153  memory: 10140  loss: 13.8525  decode.loss_cls: 0.0485  decode.loss_mask: 0.7014  decode.loss_dice: 0.6476  decode.d0.loss_cls: 0.0596  decode.d0.loss_mask: 0.7133  decode.d0.loss_dice: 0.6646  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.7045  decode.d1.loss_dice: 0.6414  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.7051  decode.d2.loss_dice: 0.6334  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.7053  decode.d3.loss_dice: 0.6411  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.7034  decode.d4.loss_dice: 0.6521  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.7008  decode.d5.loss_dice: 0.6356  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.7038  decode.d6.loss_dice: 0.6439  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.7014  decode.d7.loss_dice: 0.6439  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.7052  decode.d8.loss_dice: 0.6316
2025/03/31 07:03:03 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 07:03:03 - mmengine - INFO - Iter(train) [10000/20000]  base_lr: 5.3591e-05 lr: 5.3591e-05  eta: 2:23:39  time: 0.8582  data_time: 0.0157  memory: 10142  loss: 13.3268  decode.loss_cls: 0.0085  decode.loss_mask: 0.7013  decode.loss_dice: 0.6045  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.7049  decode.d0.loss_dice: 0.6173  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.7017  decode.d1.loss_dice: 0.6132  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.7040  decode.d2.loss_dice: 0.6182  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.7074  decode.d3.loss_dice: 0.6197  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.7066  decode.d4.loss_dice: 0.6123  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.7072  decode.d5.loss_dice: 0.6190  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.7025  decode.d6.loss_dice: 0.6163  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.7023  decode.d7.loss_dice: 0.6133  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.7074  decode.d8.loss_dice: 0.6157
2025/03/31 07:03:03 - mmengine - INFO - Saving checkpoint at 10000 iterations
2025/03/31 07:03:09 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:05  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:03:14 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:02:59  time: 0.0936  data_time: 0.0011  memory: 1853  
2025/03/31 07:03:18 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:55  time: 0.0937  data_time: 0.0011  memory: 1853  
2025/03/31 07:03:23 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:50  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:03:28 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:45  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:03:32 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:41  time: 0.0935  data_time: 0.0011  memory: 1853  
2025/03/31 07:03:37 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:36  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:03:42 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:31  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 07:03:47 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:27  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 07:03:51 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:22  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 07:03:56 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:17  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:01 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:13  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 07:04:05 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:08  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 07:04:10 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:03  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:15 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:59  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:20 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:54  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:24 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:49  time: 0.0948  data_time: 0.0014  memory: 1853  
2025/03/31 07:04:29 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:44  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 07:04:34 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:40  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 07:04:38 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:35  time: 0.0937  data_time: 0.0011  memory: 1853  
2025/03/31 07:04:43 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:30  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:48 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:26  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:53 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:21  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:04:57 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:16  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:05:02 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:12  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:05:07 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:07  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:11 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:02  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:16 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:57  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:21 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:05:26 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:48  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:30 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:43  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:05:35 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 07:05:40 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:44 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:29  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:05:49 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:54 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 07:05:59 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 07:06:03 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:10  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:06:08 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 07:06:13 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 07:06:14 - mmengine - INFO - per class results:
2025/03/31 07:06:14 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 68.33 | 92.55 |
|      building      | 84.07 | 94.53 |
|   low_vegetation   | 58.88 |  83.1 |
|        tree        | 32.27 |  33.2 |
|        car         | 75.06 | 84.38 |
|      clutter       |  1.47 |  1.48 |
+--------------------+-------+-------+
2025/03/31 07:06:14 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.4900  mIoU: 53.3500  mAcc: 64.8700  data_time: 0.0013  time: 0.0941
2025/03/31 07:06:58 - mmengine - INFO - Iter(train) [10050/20000]  base_lr: 5.3350e-05 lr: 5.3350e-05  eta: 2:22:56  time: 0.8751  data_time: 0.0158  memory: 10142  loss: 13.5137  decode.loss_cls: 0.0051  decode.loss_mask: 0.6715  decode.loss_dice: 0.6818  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.6784  decode.d0.loss_dice: 0.6617  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.6723  decode.d1.loss_dice: 0.6770  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.6735  decode.d2.loss_dice: 0.6638  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.6695  decode.d3.loss_dice: 0.6741  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.6687  decode.d4.loss_dice: 0.6627  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.6722  decode.d5.loss_dice: 0.6723  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.6652  decode.d6.loss_dice: 0.6560  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.6702  decode.d7.loss_dice: 0.6631  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 0.6641
2025/03/31 07:07:41 - mmengine - INFO - Iter(train) [10100/20000]  base_lr: 5.3109e-05 lr: 5.3109e-05  eta: 2:22:13  time: 0.8582  data_time: 0.0159  memory: 10140  loss: 14.1494  decode.loss_cls: 0.0377  decode.loss_mask: 0.7132  decode.loss_dice: 0.6651  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.7116  decode.d0.loss_dice: 0.6723  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.7147  decode.d1.loss_dice: 0.6649  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.7119  decode.d2.loss_dice: 0.6759  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.7189  decode.d3.loss_dice: 0.6733  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.7149  decode.d4.loss_dice: 0.6599  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.7183  decode.d5.loss_dice: 0.6661  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.7170  decode.d6.loss_dice: 0.6798  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.7157  decode.d7.loss_dice: 0.6624  decode.d8.loss_cls: 0.0392  decode.d8.loss_mask: 0.7184  decode.d8.loss_dice: 0.6688
2025/03/31 07:08:24 - mmengine - INFO - Iter(train) [10150/20000]  base_lr: 5.2867e-05 lr: 5.2867e-05  eta: 2:21:30  time: 0.8575  data_time: 0.0155  memory: 10144  loss: 13.4987  decode.loss_cls: 0.0080  decode.loss_mask: 0.7004  decode.loss_dice: 0.6372  decode.d0.loss_cls: 0.0563  decode.d0.loss_mask: 0.7041  decode.d0.loss_dice: 0.6356  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.7035  decode.d1.loss_dice: 0.6412  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.6995  decode.d2.loss_dice: 0.6478  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.6960  decode.d3.loss_dice: 0.6375  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.6930  decode.d4.loss_dice: 0.6368  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.6972  decode.d5.loss_dice: 0.6376  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.6954  decode.d6.loss_dice: 0.6389  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.6957  decode.d7.loss_dice: 0.6344  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.6969  decode.d8.loss_dice: 0.6327
2025/03/31 07:09:06 - mmengine - INFO - Iter(train) [10200/20000]  base_lr: 5.2625e-05 lr: 5.2625e-05  eta: 2:20:46  time: 0.8589  data_time: 0.0159  memory: 10150  loss: 14.1293  decode.loss_cls: 0.0036  decode.loss_mask: 0.7517  decode.loss_dice: 0.6446  decode.d0.loss_cls: 0.0567  decode.d0.loss_mask: 0.7679  decode.d0.loss_dice: 0.6404  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.7546  decode.d1.loss_dice: 0.6591  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.7565  decode.d2.loss_dice: 0.6498  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.7527  decode.d3.loss_dice: 0.6501  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.7539  decode.d4.loss_dice: 0.6461  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.7539  decode.d5.loss_dice: 0.6498  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.7500  decode.d6.loss_dice: 0.6496  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.7540  decode.d7.loss_dice: 0.6516  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.7508  decode.d8.loss_dice: 0.6438
2025/03/31 07:09:49 - mmengine - INFO - Iter(train) [10250/20000]  base_lr: 5.2384e-05 lr: 5.2384e-05  eta: 2:20:03  time: 0.8587  data_time: 0.0158  memory: 10139  loss: 14.1493  decode.loss_cls: 0.0464  decode.loss_mask: 0.7046  decode.loss_dice: 0.6423  decode.d0.loss_cls: 0.1125  decode.d0.loss_mask: 0.7128  decode.d0.loss_dice: 0.6570  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.7028  decode.d1.loss_dice: 0.6399  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.7046  decode.d2.loss_dice: 0.6423  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.7079  decode.d3.loss_dice: 0.6310  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.7095  decode.d4.loss_dice: 0.6410  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.7080  decode.d5.loss_dice: 0.6398  decode.d6.loss_cls: 0.0303  decode.d6.loss_mask: 0.7094  decode.d6.loss_dice: 0.6524  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.7054  decode.d7.loss_dice: 0.6513  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.7050  decode.d8.loss_dice: 0.6416
2025/03/31 07:10:32 - mmengine - INFO - Iter(train) [10300/20000]  base_lr: 5.2142e-05 lr: 5.2142e-05  eta: 2:19:20  time: 0.8585  data_time: 0.0157  memory: 10142  loss: 13.8783  decode.loss_cls: 0.0136  decode.loss_mask: 0.7118  decode.loss_dice: 0.6540  decode.d0.loss_cls: 0.0496  decode.d0.loss_mask: 0.7153  decode.d0.loss_dice: 0.6490  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.7091  decode.d1.loss_dice: 0.6543  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.7124  decode.d2.loss_dice: 0.6528  decode.d3.loss_cls: 0.0295  decode.d3.loss_mask: 0.7131  decode.d3.loss_dice: 0.6530  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.7102  decode.d4.loss_dice: 0.6523  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.7159  decode.d5.loss_dice: 0.6516  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.7096  decode.d6.loss_dice: 0.6492  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.7164  decode.d7.loss_dice: 0.6572  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.7138  decode.d8.loss_dice: 0.6502
2025/03/31 07:11:15 - mmengine - INFO - Iter(train) [10350/20000]  base_lr: 5.1900e-05 lr: 5.1900e-05  eta: 2:18:37  time: 0.8595  data_time: 0.0161  memory: 10142  loss: 13.9127  decode.loss_cls: 0.0478  decode.loss_mask: 0.6498  decode.loss_dice: 0.7176  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.6631  decode.d0.loss_dice: 0.7270  decode.d1.loss_cls: 0.0340  decode.d1.loss_mask: 0.6499  decode.d1.loss_dice: 0.7105  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.6524  decode.d2.loss_dice: 0.7207  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.6493  decode.d3.loss_dice: 0.7065  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 0.7129  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.6491  decode.d5.loss_dice: 0.7191  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.6513  decode.d6.loss_dice: 0.7256  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.6537  decode.d7.loss_dice: 0.7145  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.6511  decode.d8.loss_dice: 0.7190
2025/03/31 07:11:58 - mmengine - INFO - Iter(train) [10400/20000]  base_lr: 5.1658e-05 lr: 5.1658e-05  eta: 2:17:54  time: 0.8577  data_time: 0.0155  memory: 10144  loss: 14.7781  decode.loss_cls: 0.0441  decode.loss_mask: 0.7381  decode.loss_dice: 0.6906  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.7476  decode.d0.loss_dice: 0.6788  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.7451  decode.d1.loss_dice: 0.6989  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.7406  decode.d2.loss_dice: 0.6941  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.7380  decode.d3.loss_dice: 0.6976  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.7387  decode.d4.loss_dice: 0.6903  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.7366  decode.d5.loss_dice: 0.6958  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.7376  decode.d6.loss_dice: 0.6912  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.7366  decode.d7.loss_dice: 0.6967  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.7391  decode.d8.loss_dice: 0.7032
2025/03/31 07:12:41 - mmengine - INFO - Iter(train) [10450/20000]  base_lr: 5.1416e-05 lr: 5.1416e-05  eta: 2:17:10  time: 0.8560  data_time: 0.0155  memory: 10144  loss: 15.0772  decode.loss_cls: 0.0457  decode.loss_mask: 0.7859  decode.loss_dice: 0.6703  decode.d0.loss_cls: 0.0768  decode.d0.loss_mask: 0.7951  decode.d0.loss_dice: 0.6958  decode.d1.loss_cls: 0.0399  decode.d1.loss_mask: 0.7906  decode.d1.loss_dice: 0.6848  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.7905  decode.d2.loss_dice: 0.6753  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.7914  decode.d3.loss_dice: 0.6662  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.7930  decode.d4.loss_dice: 0.6753  decode.d5.loss_cls: 0.0331  decode.d5.loss_mask: 0.7885  decode.d5.loss_dice: 0.6762  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.7877  decode.d6.loss_dice: 0.6846  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.7932  decode.d7.loss_dice: 0.6807  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.7930  decode.d8.loss_dice: 0.6662
2025/03/31 07:13:24 - mmengine - INFO - Iter(train) [10500/20000]  base_lr: 5.1173e-05 lr: 5.1173e-05  eta: 2:16:27  time: 0.8565  data_time: 0.0156  memory: 10142  loss: 13.0595  decode.loss_cls: 0.0234  decode.loss_mask: 0.6597  decode.loss_dice: 0.6261  decode.d0.loss_cls: 0.0400  decode.d0.loss_mask: 0.6692  decode.d0.loss_dice: 0.6419  decode.d1.loss_cls: 0.0205  decode.d1.loss_mask: 0.6640  decode.d1.loss_dice: 0.6283  decode.d2.loss_cls: 0.0290  decode.d2.loss_mask: 0.6668  decode.d2.loss_dice: 0.6214  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.6613  decode.d3.loss_dice: 0.6234  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.6633  decode.d4.loss_dice: 0.6220  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.6673  decode.d5.loss_dice: 0.6206  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.6621  decode.d6.loss_dice: 0.6395  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.6626  decode.d7.loss_dice: 0.6152  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.6618  decode.d8.loss_dice: 0.6200
2025/03/31 07:14:07 - mmengine - INFO - Iter(train) [10550/20000]  base_lr: 5.0931e-05 lr: 5.0931e-05  eta: 2:15:44  time: 0.8565  data_time: 0.0154  memory: 10144  loss: 13.2457  decode.loss_cls: 0.0038  decode.loss_mask: 0.6745  decode.loss_dice: 0.6284  decode.d0.loss_cls: 0.0563  decode.d0.loss_mask: 0.6808  decode.d0.loss_dice: 0.6339  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.6777  decode.d1.loss_dice: 0.6352  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.6796  decode.d2.loss_dice: 0.6411  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.6764  decode.d3.loss_dice: 0.6380  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.6765  decode.d4.loss_dice: 0.6322  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.6776  decode.d5.loss_dice: 0.6407  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.6810  decode.d6.loss_dice: 0.6361  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.6786  decode.d7.loss_dice: 0.6362  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.6752  decode.d8.loss_dice: 0.6267
2025/03/31 07:14:50 - mmengine - INFO - Iter(train) [10600/20000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 2:15:01  time: 0.8571  data_time: 0.0156  memory: 10093  loss: 14.4528  decode.loss_cls: 0.0053  decode.loss_mask: 0.7773  decode.loss_dice: 0.6572  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.7775  decode.d0.loss_dice: 0.6466  decode.d1.loss_cls: 0.0395  decode.d1.loss_mask: 0.7670  decode.d1.loss_dice: 0.6637  decode.d2.loss_cls: 0.0180  decode.d2.loss_mask: 0.7653  decode.d2.loss_dice: 0.6539  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.7743  decode.d3.loss_dice: 0.6594  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.7718  decode.d4.loss_dice: 0.6558  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.7701  decode.d5.loss_dice: 0.6498  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.7727  decode.d6.loss_dice: 0.6616  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.7715  decode.d7.loss_dice: 0.6578  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.7730  decode.d8.loss_dice: 0.6576
2025/03/31 07:15:33 - mmengine - INFO - Iter(train) [10650/20000]  base_lr: 5.0446e-05 lr: 5.0446e-05  eta: 2:14:18  time: 0.8571  data_time: 0.0153  memory: 10143  loss: 12.2576  decode.loss_cls: 0.0034  decode.loss_mask: 0.6446  decode.loss_dice: 0.5701  decode.d0.loss_cls: 0.0467  decode.d0.loss_mask: 0.6444  decode.d0.loss_dice: 0.5794  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.6454  decode.d1.loss_dice: 0.5753  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.6443  decode.d2.loss_dice: 0.5761  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.6397  decode.d3.loss_dice: 0.5720  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.6458  decode.d4.loss_dice: 0.5759  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.6470  decode.d5.loss_dice: 0.5735  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.6458  decode.d6.loss_dice: 0.5689  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.6420  decode.d7.loss_dice: 0.5735  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.6479  decode.d8.loss_dice: 0.5698
2025/03/31 07:16:16 - mmengine - INFO - Iter(train) [10700/20000]  base_lr: 5.0203e-05 lr: 5.0203e-05  eta: 2:13:34  time: 0.8568  data_time: 0.0157  memory: 10140  loss: 12.9855  decode.loss_cls: 0.0030  decode.loss_mask: 0.6415  decode.loss_dice: 0.6437  decode.d0.loss_cls: 0.0538  decode.d0.loss_mask: 0.6370  decode.d0.loss_dice: 0.6472  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.6435  decode.d1.loss_dice: 0.6458  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.6420  decode.d2.loss_dice: 0.6443  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.6395  decode.d3.loss_dice: 0.6404  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.6368  decode.d4.loss_dice: 0.6392  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.6409  decode.d5.loss_dice: 0.6445  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.6401  decode.d6.loss_dice: 0.6532  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.6409  decode.d7.loss_dice: 0.6470  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.6402  decode.d8.loss_dice: 0.6366
2025/03/31 07:16:59 - mmengine - INFO - Iter(train) [10750/20000]  base_lr: 4.9960e-05 lr: 4.9960e-05  eta: 2:12:51  time: 0.8592  data_time: 0.0158  memory: 10144  loss: 13.6803  decode.loss_cls: 0.0118  decode.loss_mask: 0.6933  decode.loss_dice: 0.6546  decode.d0.loss_cls: 0.0489  decode.d0.loss_mask: 0.7030  decode.d0.loss_dice: 0.6699  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.6912  decode.d1.loss_dice: 0.6553  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.6906  decode.d2.loss_dice: 0.6486  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.6926  decode.d3.loss_dice: 0.6566  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.6888  decode.d4.loss_dice: 0.6630  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.6911  decode.d5.loss_dice: 0.6531  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.6939  decode.d6.loss_dice: 0.6530  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.6947  decode.d7.loss_dice: 0.6614  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.6929  decode.d8.loss_dice: 0.6606
2025/03/31 07:17:42 - mmengine - INFO - Iter(train) [10800/20000]  base_lr: 4.9717e-05 lr: 4.9717e-05  eta: 2:12:08  time: 0.8591  data_time: 0.0158  memory: 10097  loss: 13.3941  decode.loss_cls: 0.0323  decode.loss_mask: 0.6777  decode.loss_dice: 0.6366  decode.d0.loss_cls: 0.0431  decode.d0.loss_mask: 0.6870  decode.d0.loss_dice: 0.6420  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.6833  decode.d1.loss_dice: 0.6216  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.6801  decode.d2.loss_dice: 0.6480  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.6756  decode.d3.loss_dice: 0.6342  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.6785  decode.d4.loss_dice: 0.6379  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.6813  decode.d5.loss_dice: 0.6246  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.6804  decode.d6.loss_dice: 0.6480  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.6780  decode.d7.loss_dice: 0.6367  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.6780  decode.d8.loss_dice: 0.6407
2025/03/31 07:18:25 - mmengine - INFO - Iter(train) [10850/20000]  base_lr: 4.9473e-05 lr: 4.9473e-05  eta: 2:11:25  time: 0.8578  data_time: 0.0155  memory: 10142  loss: 12.6087  decode.loss_cls: 0.0100  decode.loss_mask: 0.6271  decode.loss_dice: 0.6121  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.6267  decode.d0.loss_dice: 0.6160  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.6283  decode.d1.loss_dice: 0.6158  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.6283  decode.d2.loss_dice: 0.6021  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.6278  decode.d3.loss_dice: 0.6044  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.6258  decode.d4.loss_dice: 0.5915  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.6250  decode.d5.loss_dice: 0.5941  decode.d6.loss_cls: 0.0366  decode.d6.loss_mask: 0.6242  decode.d6.loss_dice: 0.5984  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.6270  decode.d7.loss_dice: 0.6089  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.6278  decode.d8.loss_dice: 0.5926
2025/03/31 07:19:08 - mmengine - INFO - Iter(train) [10900/20000]  base_lr: 4.9230e-05 lr: 4.9230e-05  eta: 2:10:42  time: 0.8579  data_time: 0.0158  memory: 10097  loss: 12.6813  decode.loss_cls: 0.0300  decode.loss_mask: 0.6206  decode.loss_dice: 0.6157  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.6256  decode.d0.loss_dice: 0.6341  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.6230  decode.d1.loss_dice: 0.6307  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.6191  decode.d2.loss_dice: 0.6309  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.6180  decode.d3.loss_dice: 0.6127  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.6234  decode.d4.loss_dice: 0.6272  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.6218  decode.d5.loss_dice: 0.6345  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.6236  decode.d6.loss_dice: 0.6099  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.6220  decode.d7.loss_dice: 0.6077  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.6192  decode.d8.loss_dice: 0.6420
2025/03/31 07:19:51 - mmengine - INFO - Iter(train) [10950/20000]  base_lr: 4.8986e-05 lr: 4.8986e-05  eta: 2:09:58  time: 0.8604  data_time: 0.0161  memory: 10139  loss: 13.3138  decode.loss_cls: 0.0341  decode.loss_mask: 0.6743  decode.loss_dice: 0.6141  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.6893  decode.d0.loss_dice: 0.6467  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.6801  decode.d1.loss_dice: 0.6252  decode.d2.loss_cls: 0.0172  decode.d2.loss_mask: 0.6763  decode.d2.loss_dice: 0.6297  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.6780  decode.d3.loss_dice: 0.6300  decode.d4.loss_cls: 0.0304  decode.d4.loss_mask: 0.6744  decode.d4.loss_dice: 0.6177  decode.d5.loss_cls: 0.0263  decode.d5.loss_mask: 0.6798  decode.d5.loss_dice: 0.6145  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.6773  decode.d6.loss_dice: 0.6217  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.6800  decode.d7.loss_dice: 0.6165  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.6796  decode.d8.loss_dice: 0.6123
2025/03/31 07:20:34 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 07:20:34 - mmengine - INFO - Iter(train) [11000/20000]  base_lr: 4.8743e-05 lr: 4.8743e-05  eta: 2:09:15  time: 0.8609  data_time: 0.0159  memory: 10139  loss: 13.0849  decode.loss_cls: 0.0073  decode.loss_mask: 0.6728  decode.loss_dice: 0.6082  decode.d0.loss_cls: 0.0682  decode.d0.loss_mask: 0.6912  decode.d0.loss_dice: 0.6189  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.6843  decode.d1.loss_dice: 0.6020  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.6820  decode.d2.loss_dice: 0.6140  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.6840  decode.d3.loss_dice: 0.6093  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.6781  decode.d4.loss_dice: 0.6133  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.6820  decode.d5.loss_dice: 0.6080  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.6782  decode.d6.loss_dice: 0.6085  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.6792  decode.d7.loss_dice: 0.6135  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.6781  decode.d8.loss_dice: 0.6175
2025/03/31 07:21:17 - mmengine - INFO - Iter(train) [11050/20000]  base_lr: 4.8499e-05 lr: 4.8499e-05  eta: 2:08:32  time: 0.8598  data_time: 0.0161  memory: 10142  loss: 13.1258  decode.loss_cls: 0.0367  decode.loss_mask: 0.6676  decode.loss_dice: 0.5956  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.6664  decode.d0.loss_dice: 0.6175  decode.d1.loss_cls: 0.0452  decode.d1.loss_mask: 0.6630  decode.d1.loss_dice: 0.6064  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.6645  decode.d2.loss_dice: 0.5993  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.6661  decode.d3.loss_dice: 0.5995  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.6643  decode.d4.loss_dice: 0.6145  decode.d5.loss_cls: 0.0197  decode.d5.loss_mask: 0.6681  decode.d5.loss_dice: 0.6138  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.6663  decode.d6.loss_dice: 0.6097  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.6672  decode.d7.loss_dice: 0.6145  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.6665  decode.d8.loss_dice: 0.6052
2025/03/31 07:22:00 - mmengine - INFO - Iter(train) [11100/20000]  base_lr: 4.8255e-05 lr: 4.8255e-05  eta: 2:07:49  time: 0.8581  data_time: 0.0160  memory: 10146  loss: 13.6646  decode.loss_cls: 0.0056  decode.loss_mask: 0.7101  decode.loss_dice: 0.6344  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.7131  decode.d0.loss_dice: 0.6355  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.7113  decode.d1.loss_dice: 0.6392  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.7156  decode.d2.loss_dice: 0.6365  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.7100  decode.d3.loss_dice: 0.6276  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.7158  decode.d4.loss_dice: 0.6326  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.7145  decode.d5.loss_dice: 0.6386  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.7147  decode.d6.loss_dice: 0.6364  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.7134  decode.d7.loss_dice: 0.6332  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.7070  decode.d8.loss_dice: 0.6359
2025/03/31 07:22:43 - mmengine - INFO - Iter(train) [11150/20000]  base_lr: 4.8011e-05 lr: 4.8011e-05  eta: 2:07:06  time: 0.8569  data_time: 0.0158  memory: 10145  loss: 14.5194  decode.loss_cls: 0.0588  decode.loss_mask: 0.6968  decode.loss_dice: 0.6963  decode.d0.loss_cls: 0.1027  decode.d0.loss_mask: 0.6977  decode.d0.loss_dice: 0.6872  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.6936  decode.d1.loss_dice: 0.6846  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.6931  decode.d2.loss_dice: 0.6829  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.6959  decode.d3.loss_dice: 0.6813  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.6971  decode.d4.loss_dice: 0.6855  decode.d5.loss_cls: 0.0373  decode.d5.loss_mask: 0.6993  decode.d5.loss_dice: 0.7048  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.6977  decode.d6.loss_dice: 0.6906  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.6995  decode.d7.loss_dice: 0.6757  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.6962  decode.d8.loss_dice: 0.6915
2025/03/31 07:23:26 - mmengine - INFO - Iter(train) [11200/20000]  base_lr: 4.7767e-05 lr: 4.7767e-05  eta: 2:06:22  time: 0.8562  data_time: 0.0157  memory: 10145  loss: 12.8500  decode.loss_cls: 0.0247  decode.loss_mask: 0.6591  decode.loss_dice: 0.6030  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.6626  decode.d0.loss_dice: 0.6068  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.6656  decode.d1.loss_dice: 0.6084  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.6620  decode.d2.loss_dice: 0.6022  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.6615  decode.d3.loss_dice: 0.6042  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.6618  decode.d4.loss_dice: 0.6018  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.6572  decode.d5.loss_dice: 0.5857  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.6600  decode.d6.loss_dice: 0.5944  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.6566  decode.d7.loss_dice: 0.5928  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.6577  decode.d8.loss_dice: 0.5990
2025/03/31 07:24:09 - mmengine - INFO - Iter(train) [11250/20000]  base_lr: 4.7523e-05 lr: 4.7523e-05  eta: 2:05:39  time: 0.8581  data_time: 0.0157  memory: 10145  loss: 12.2490  decode.loss_cls: 0.0262  decode.loss_mask: 0.6113  decode.loss_dice: 0.5799  decode.d0.loss_cls: 0.0495  decode.d0.loss_mask: 0.6177  decode.d0.loss_dice: 0.5986  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.6114  decode.d1.loss_dice: 0.5817  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 0.6128  decode.d2.loss_dice: 0.5838  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.6122  decode.d3.loss_dice: 0.5781  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 0.6083  decode.d4.loss_dice: 0.5862  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 0.6129  decode.d5.loss_dice: 0.5838  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.6094  decode.d6.loss_dice: 0.5858  decode.d7.loss_cls: 0.0169  decode.d7.loss_mask: 0.6120  decode.d7.loss_dice: 0.5845  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.6144  decode.d8.loss_dice: 0.5824
2025/03/31 07:24:52 - mmengine - INFO - Iter(train) [11300/20000]  base_lr: 4.7278e-05 lr: 4.7278e-05  eta: 2:04:56  time: 0.8566  data_time: 0.0155  memory: 10144  loss: 13.2438  decode.loss_cls: 0.0483  decode.loss_mask: 0.6931  decode.loss_dice: 0.6093  decode.d0.loss_cls: 0.0654  decode.d0.loss_mask: 0.6955  decode.d0.loss_dice: 0.6189  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.6880  decode.d1.loss_dice: 0.6296  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.6866  decode.d2.loss_dice: 0.6110  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 0.6129  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.6882  decode.d4.loss_dice: 0.6004  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.6917  decode.d5.loss_dice: 0.6159  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.6913  decode.d6.loss_dice: 0.6123  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.6884  decode.d7.loss_dice: 0.6104  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.6912  decode.d8.loss_dice: 0.5973
2025/03/31 07:25:35 - mmengine - INFO - Iter(train) [11350/20000]  base_lr: 4.7033e-05 lr: 4.7033e-05  eta: 2:04:13  time: 0.8569  data_time: 0.0156  memory: 10143  loss: 12.0304  decode.loss_cls: 0.0152  decode.loss_mask: 0.5908  decode.loss_dice: 0.5758  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.5861  decode.d0.loss_dice: 0.5926  decode.d1.loss_cls: 0.0478  decode.d1.loss_mask: 0.5884  decode.d1.loss_dice: 0.5752  decode.d2.loss_cls: 0.0131  decode.d2.loss_mask: 0.5915  decode.d2.loss_dice: 0.5848  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 0.5882  decode.d3.loss_dice: 0.5623  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.5939  decode.d4.loss_dice: 0.5727  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.5919  decode.d5.loss_dice: 0.5743  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.5915  decode.d6.loss_dice: 0.5710  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.5872  decode.d7.loss_dice: 0.5791  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.5907  decode.d8.loss_dice: 0.5792
2025/03/31 07:26:18 - mmengine - INFO - Iter(train) [11400/20000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 2:03:30  time: 0.8580  data_time: 0.0157  memory: 10094  loss: 12.4611  decode.loss_cls: 0.0065  decode.loss_mask: 0.6544  decode.loss_dice: 0.5804  decode.d0.loss_cls: 0.0577  decode.d0.loss_mask: 0.6548  decode.d0.loss_dice: 0.6008  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.6534  decode.d1.loss_dice: 0.5840  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.6536  decode.d2.loss_dice: 0.5743  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.6538  decode.d3.loss_dice: 0.5731  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.6549  decode.d4.loss_dice: 0.5713  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.6538  decode.d5.loss_dice: 0.5787  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.6499  decode.d6.loss_dice: 0.5820  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.6543  decode.d7.loss_dice: 0.5787  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.6535  decode.d8.loss_dice: 0.5786
2025/03/31 07:27:01 - mmengine - INFO - Iter(train) [11450/20000]  base_lr: 4.6544e-05 lr: 4.6544e-05  eta: 2:02:47  time: 0.8579  data_time: 0.0157  memory: 10097  loss: 15.6486  decode.loss_cls: 0.0070  decode.loss_mask: 0.8400  decode.loss_dice: 0.6985  decode.d0.loss_cls: 0.0508  decode.d0.loss_mask: 0.8564  decode.d0.loss_dice: 0.7062  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.8463  decode.d1.loss_dice: 0.7125  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.8449  decode.d2.loss_dice: 0.7091  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.8382  decode.d3.loss_dice: 0.7024  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.8436  decode.d4.loss_dice: 0.7053  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.8404  decode.d5.loss_dice: 0.7067  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.8280  decode.d6.loss_dice: 0.6970  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.8283  decode.d7.loss_dice: 0.6946  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.8347  decode.d8.loss_dice: 0.6919
2025/03/31 07:27:43 - mmengine - INFO - Iter(train) [11500/20000]  base_lr: 4.6299e-05 lr: 4.6299e-05  eta: 2:02:03  time: 0.8563  data_time: 0.0156  memory: 10145  loss: 12.5580  decode.loss_cls: 0.0150  decode.loss_mask: 0.6101  decode.loss_dice: 0.6143  decode.d0.loss_cls: 0.0616  decode.d0.loss_mask: 0.6250  decode.d0.loss_dice: 0.6122  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.6126  decode.d1.loss_dice: 0.6273  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.6096  decode.d2.loss_dice: 0.6015  decode.d3.loss_cls: 0.0359  decode.d3.loss_mask: 0.6114  decode.d3.loss_dice: 0.6076  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.6106  decode.d4.loss_dice: 0.6195  decode.d5.loss_cls: 0.0416  decode.d5.loss_mask: 0.6123  decode.d5.loss_dice: 0.6106  decode.d6.loss_cls: 0.0303  decode.d6.loss_mask: 0.6152  decode.d6.loss_dice: 0.6096  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.6118  decode.d7.loss_dice: 0.6082  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.6128  decode.d8.loss_dice: 0.6054
2025/03/31 07:28:26 - mmengine - INFO - Iter(train) [11550/20000]  base_lr: 4.6054e-05 lr: 4.6054e-05  eta: 2:01:20  time: 0.8570  data_time: 0.0158  memory: 10142  loss: 14.5151  decode.loss_cls: 0.0350  decode.loss_mask: 0.7544  decode.loss_dice: 0.6512  decode.d0.loss_cls: 0.1496  decode.d0.loss_mask: 0.7558  decode.d0.loss_dice: 0.6362  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.7540  decode.d1.loss_dice: 0.6712  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.7556  decode.d2.loss_dice: 0.6464  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 0.7580  decode.d3.loss_dice: 0.6347  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 0.7612  decode.d4.loss_dice: 0.6665  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.7567  decode.d5.loss_dice: 0.6768  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.7565  decode.d6.loss_dice: 0.6676  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.7509  decode.d7.loss_dice: 0.6511  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.7516  decode.d8.loss_dice: 0.6631
2025/03/31 07:29:09 - mmengine - INFO - Iter(train) [11600/20000]  base_lr: 4.5808e-05 lr: 4.5808e-05  eta: 2:00:37  time: 0.8572  data_time: 0.0161  memory: 10156  loss: 13.6847  decode.loss_cls: 0.0049  decode.loss_mask: 0.7333  decode.loss_dice: 0.6191  decode.d0.loss_cls: 0.0424  decode.d0.loss_mask: 0.7414  decode.d0.loss_dice: 0.6250  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.7298  decode.d1.loss_dice: 0.6252  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.7364  decode.d2.loss_dice: 0.6202  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 0.6279  decode.d4.loss_cls: 0.0278  decode.d4.loss_mask: 0.7325  decode.d4.loss_dice: 0.6238  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.7337  decode.d5.loss_dice: 0.6199  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.7320  decode.d6.loss_dice: 0.6258  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.7338  decode.d7.loss_dice: 0.6263  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.7336  decode.d8.loss_dice: 0.6222
2025/03/31 07:29:52 - mmengine - INFO - Iter(train) [11650/20000]  base_lr: 4.5563e-05 lr: 4.5563e-05  eta: 1:59:54  time: 0.8582  data_time: 0.0156  memory: 10145  loss: 13.2652  decode.loss_cls: 0.0208  decode.loss_mask: 0.6447  decode.loss_dice: 0.6485  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.6377  decode.d0.loss_dice: 0.6544  decode.d1.loss_cls: 0.0827  decode.d1.loss_mask: 0.6379  decode.d1.loss_dice: 0.6445  decode.d2.loss_cls: 0.0498  decode.d2.loss_mask: 0.6361  decode.d2.loss_dice: 0.6395  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.6383  decode.d3.loss_dice: 0.6354  decode.d4.loss_cls: 0.0684  decode.d4.loss_mask: 0.6368  decode.d4.loss_dice: 0.6326  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.6430  decode.d5.loss_dice: 0.6394  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.6417  decode.d6.loss_dice: 0.6418  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.6364  decode.d7.loss_dice: 0.6318  decode.d8.loss_cls: 0.0205  decode.d8.loss_mask: 0.6441  decode.d8.loss_dice: 0.6411
2025/03/31 07:30:35 - mmengine - INFO - Iter(train) [11700/20000]  base_lr: 4.5317e-05 lr: 4.5317e-05  eta: 1:59:11  time: 0.8606  data_time: 0.0156  memory: 10143  loss: 13.3144  decode.loss_cls: 0.0144  decode.loss_mask: 0.6828  decode.loss_dice: 0.6243  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.6885  decode.d0.loss_dice: 0.6330  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.6862  decode.d1.loss_dice: 0.6256  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.6842  decode.d2.loss_dice: 0.6308  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.6832  decode.d3.loss_dice: 0.6385  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.6868  decode.d4.loss_dice: 0.6322  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.6793  decode.d5.loss_dice: 0.6226  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.6816  decode.d6.loss_dice: 0.6223  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.6784  decode.d7.loss_dice: 0.6168  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.6820  decode.d8.loss_dice: 0.6164
2025/03/31 07:31:18 - mmengine - INFO - Iter(train) [11750/20000]  base_lr: 4.5071e-05 lr: 4.5071e-05  eta: 1:58:28  time: 0.8576  data_time: 0.0159  memory: 10142  loss: 12.0140  decode.loss_cls: 0.0121  decode.loss_mask: 0.6073  decode.loss_dice: 0.5783  decode.d0.loss_cls: 0.0522  decode.d0.loss_mask: 0.6139  decode.d0.loss_dice: 0.5837  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.6106  decode.d1.loss_dice: 0.5842  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.6076  decode.d2.loss_dice: 0.5760  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.6076  decode.d3.loss_dice: 0.5797  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.6054  decode.d4.loss_dice: 0.5779  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.6044  decode.d5.loss_dice: 0.5785  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.6075  decode.d6.loss_dice: 0.5770  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.6037  decode.d7.loss_dice: 0.5711  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.6044  decode.d8.loss_dice: 0.5701
2025/03/31 07:32:01 - mmengine - INFO - Iter(train) [11800/20000]  base_lr: 4.4825e-05 lr: 4.4825e-05  eta: 1:57:44  time: 0.8579  data_time: 0.0160  memory: 10093  loss: 12.9082  decode.loss_cls: 0.0150  decode.loss_mask: 0.6478  decode.loss_dice: 0.6289  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.6474  decode.d0.loss_dice: 0.6292  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.6504  decode.d1.loss_dice: 0.6271  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.6484  decode.d2.loss_dice: 0.6232  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.6500  decode.d3.loss_dice: 0.6235  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.6504  decode.d4.loss_dice: 0.6304  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.6521  decode.d5.loss_dice: 0.6275  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.6492  decode.d6.loss_dice: 0.6259  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.6493  decode.d7.loss_dice: 0.6234  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.6438  decode.d8.loss_dice: 0.6239
2025/03/31 07:32:44 - mmengine - INFO - Iter(train) [11850/20000]  base_lr: 4.4579e-05 lr: 4.4579e-05  eta: 1:57:01  time: 0.8576  data_time: 0.0159  memory: 10140  loss: 11.6281  decode.loss_cls: 0.0208  decode.loss_mask: 0.5922  decode.loss_dice: 0.5393  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.6033  decode.d0.loss_dice: 0.5466  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.5942  decode.d1.loss_dice: 0.5350  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.5981  decode.d2.loss_dice: 0.5366  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.5927  decode.d3.loss_dice: 0.5335  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.5962  decode.d4.loss_dice: 0.5386  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.5946  decode.d5.loss_dice: 0.5231  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.5939  decode.d6.loss_dice: 0.5438  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.5923  decode.d7.loss_dice: 0.5229  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.5934  decode.d8.loss_dice: 0.5366
2025/03/31 07:33:27 - mmengine - INFO - Iter(train) [11900/20000]  base_lr: 4.4333e-05 lr: 4.4333e-05  eta: 1:56:18  time: 0.8577  data_time: 0.0157  memory: 10139  loss: 13.2520  decode.loss_cls: 0.0190  decode.loss_mask: 0.6498  decode.loss_dice: 0.6513  decode.d0.loss_cls: 0.0776  decode.d0.loss_mask: 0.6557  decode.d0.loss_dice: 0.6467  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.6506  decode.d1.loss_dice: 0.6533  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.6518  decode.d2.loss_dice: 0.6502  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.6551  decode.d3.loss_dice: 0.6435  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.6533  decode.d4.loss_dice: 0.6498  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.6525  decode.d5.loss_dice: 0.6438  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.6503  decode.d6.loss_dice: 0.6400  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.6488  decode.d7.loss_dice: 0.6519  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.6527  decode.d8.loss_dice: 0.6502
2025/03/31 07:34:11 - mmengine - INFO - Iter(train) [11950/20000]  base_lr: 4.4087e-05 lr: 4.4087e-05  eta: 1:55:35  time: 0.8811  data_time: 0.0165  memory: 10143  loss: 12.6972  decode.loss_cls: 0.0057  decode.loss_mask: 0.6602  decode.loss_dice: 0.5939  decode.d0.loss_cls: 0.0602  decode.d0.loss_mask: 0.6703  decode.d0.loss_dice: 0.5966  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.6545  decode.d1.loss_dice: 0.6014  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.6612  decode.d2.loss_dice: 0.5925  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.6583  decode.d3.loss_dice: 0.6046  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.6587  decode.d4.loss_dice: 0.6066  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.6580  decode.d5.loss_dice: 0.5963  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.6605  decode.d6.loss_dice: 0.5935  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.6615  decode.d7.loss_dice: 0.5974  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.6626  decode.d8.loss_dice: 0.6050
2025/03/31 07:34:54 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 07:34:54 - mmengine - INFO - Iter(train) [12000/20000]  base_lr: 4.3840e-05 lr: 4.3840e-05  eta: 1:54:52  time: 0.8569  data_time: 0.0155  memory: 10100  loss: 12.0415  decode.loss_cls: 0.0222  decode.loss_mask: 0.6098  decode.loss_dice: 0.5721  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 0.6163  decode.d0.loss_dice: 0.5740  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.6119  decode.d1.loss_dice: 0.5597  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.6115  decode.d2.loss_dice: 0.5654  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.6125  decode.d3.loss_dice: 0.5540  decode.d4.loss_cls: 0.0193  decode.d4.loss_mask: 0.6124  decode.d4.loss_dice: 0.5680  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.6166  decode.d5.loss_dice: 0.5750  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.6107  decode.d6.loss_dice: 0.5652  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.6116  decode.d7.loss_dice: 0.5647  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.6095  decode.d8.loss_dice: 0.5523
2025/03/31 07:34:54 - mmengine - INFO - Saving checkpoint at 12000 iterations
2025/03/31 07:35:00 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:06  time: 0.0938  data_time: 0.0013  memory: 1853  
2025/03/31 07:35:05 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:00  time: 0.0939  data_time: 0.0013  memory: 1853  
2025/03/31 07:35:09 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:55  time: 0.0947  data_time: 0.0014  memory: 1853  
2025/03/31 07:35:14 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:51  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 07:35:19 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:46  time: 0.0939  data_time: 0.0013  memory: 1853  
2025/03/31 07:35:23 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:41  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:35:28 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:36  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 07:35:33 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:32  time: 0.0937  data_time: 0.0013  memory: 1853  
2025/03/31 07:35:38 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:27  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:35:42 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:22  time: 0.0935  data_time: 0.0012  memory: 1853  
2025/03/31 07:35:47 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:17  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:35:52 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:13  time: 0.0947  data_time: 0.0014  memory: 1853  
2025/03/31 07:35:56 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:08  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:01 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:03  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:06 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:01:59  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:11 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:54  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 07:36:15 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:49  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:20 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:44  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:25 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:40  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:29 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:35  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:34 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:30  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:39 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:26  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 07:36:44 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:21  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 07:36:48 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:16  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 07:36:53 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:12  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 07:36:58 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:07  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:02 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:02  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:07 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:57  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:12 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:17 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:48  time: 0.0942  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:21 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:43  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:26 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:31 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0935  data_time: 0.0011  memory: 1853  
2025/03/31 07:37:35 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:29  time: 0.0935  data_time: 0.0011  memory: 1853  
2025/03/31 07:37:40 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0942  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:45 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 07:37:49 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 07:37:54 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:10  time: 0.0962  data_time: 0.0013  memory: 1853  
2025/03/31 07:37:59 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0950  data_time: 0.0015  memory: 1853  
2025/03/31 07:38:04 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 07:38:05 - mmengine - INFO - per class results:
2025/03/31 07:38:05 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 69.15 | 93.01 |
|      building      | 82.88 | 92.57 |
|   low_vegetation   | 59.35 | 85.44 |
|        tree        | 30.96 | 31.78 |
|        car         | 75.02 | 85.19 |
|      clutter       |  1.24 |  1.24 |
+--------------------+-------+-------+
2025/03/31 07:38:05 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.4100  mIoU: 53.1000  mAcc: 64.8700  data_time: 0.0013  time: 0.0941
2025/03/31 07:38:49 - mmengine - INFO - Iter(train) [12050/20000]  base_lr: 4.3594e-05 lr: 4.3594e-05  eta: 1:54:09  time: 0.8915  data_time: 0.0159  memory: 10144  loss: 11.5896  decode.loss_cls: 0.0075  decode.loss_mask: 0.5958  decode.loss_dice: 0.5378  decode.d0.loss_cls: 0.0617  decode.d0.loss_mask: 0.6020  decode.d0.loss_dice: 0.5423  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.6009  decode.d1.loss_dice: 0.5505  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.5999  decode.d2.loss_dice: 0.5543  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.5997  decode.d3.loss_dice: 0.5501  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5975  decode.d4.loss_dice: 0.5457  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.6005  decode.d5.loss_dice: 0.5392  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.6013  decode.d6.loss_dice: 0.5457  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.6013  decode.d7.loss_dice: 0.5473  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.6007  decode.d8.loss_dice: 0.5490
2025/03/31 07:39:32 - mmengine - INFO - Iter(train) [12100/20000]  base_lr: 4.3347e-05 lr: 4.3347e-05  eta: 1:53:26  time: 0.8588  data_time: 0.0156  memory: 10142  loss: 12.2649  decode.loss_cls: 0.0325  decode.loss_mask: 0.6045  decode.loss_dice: 0.5783  decode.d0.loss_cls: 0.0545  decode.d0.loss_mask: 0.6129  decode.d0.loss_dice: 0.5835  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.6085  decode.d1.loss_dice: 0.5904  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.6058  decode.d2.loss_dice: 0.5814  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.6070  decode.d3.loss_dice: 0.5855  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.6032  decode.d4.loss_dice: 0.5836  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.6037  decode.d5.loss_dice: 0.5838  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.6059  decode.d6.loss_dice: 0.5875  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.6050  decode.d7.loss_dice: 0.5918  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.6050  decode.d8.loss_dice: 0.5861
2025/03/31 07:40:15 - mmengine - INFO - Iter(train) [12150/20000]  base_lr: 4.3100e-05 lr: 4.3100e-05  eta: 1:52:43  time: 0.8578  data_time: 0.0158  memory: 10099  loss: 13.6530  decode.loss_cls: 0.0137  decode.loss_mask: 0.7154  decode.loss_dice: 0.6130  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.7260  decode.d0.loss_dice: 0.6387  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.7175  decode.d1.loss_dice: 0.6254  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.7152  decode.d2.loss_dice: 0.6376  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.7183  decode.d3.loss_dice: 0.6158  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.7136  decode.d4.loss_dice: 0.6244  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.7174  decode.d5.loss_dice: 0.6371  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.7145  decode.d6.loss_dice: 0.6226  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.7153  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.7168  decode.d8.loss_dice: 0.6093
2025/03/31 07:40:58 - mmengine - INFO - Iter(train) [12200/20000]  base_lr: 4.2853e-05 lr: 4.2853e-05  eta: 1:52:00  time: 0.8586  data_time: 0.0158  memory: 10142  loss: 12.4090  decode.loss_cls: 0.0286  decode.loss_mask: 0.6296  decode.loss_dice: 0.5820  decode.d0.loss_cls: 0.0585  decode.d0.loss_mask: 0.6397  decode.d0.loss_dice: 0.5869  decode.d1.loss_cls: 0.0409  decode.d1.loss_mask: 0.6287  decode.d1.loss_dice: 0.5871  decode.d2.loss_cls: 0.0378  decode.d2.loss_mask: 0.6323  decode.d2.loss_dice: 0.5787  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.6300  decode.d3.loss_dice: 0.5780  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.6269  decode.d4.loss_dice: 0.5748  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.6269  decode.d5.loss_dice: 0.5909  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.6285  decode.d6.loss_dice: 0.5856  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.6260  decode.d7.loss_dice: 0.5868  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.6281  decode.d8.loss_dice: 0.5695
2025/03/31 07:41:41 - mmengine - INFO - Iter(train) [12250/20000]  base_lr: 4.2605e-05 lr: 4.2605e-05  eta: 1:51:17  time: 0.8577  data_time: 0.0157  memory: 10099  loss: 13.0034  decode.loss_cls: 0.0326  decode.loss_mask: 0.6775  decode.loss_dice: 0.5983  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.6876  decode.d0.loss_dice: 0.6061  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.6842  decode.d1.loss_dice: 0.6135  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.6768  decode.d2.loss_dice: 0.6152  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.6810  decode.d3.loss_dice: 0.6066  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.6831  decode.d4.loss_dice: 0.5961  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.6815  decode.d5.loss_dice: 0.6039  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.6829  decode.d6.loss_dice: 0.6005  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.6811  decode.d7.loss_dice: 0.5938  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.6806  decode.d8.loss_dice: 0.6081
2025/03/31 07:42:24 - mmengine - INFO - Iter(train) [12300/20000]  base_lr: 4.2358e-05 lr: 4.2358e-05  eta: 1:50:34  time: 0.8597  data_time: 0.0156  memory: 10144  loss: 13.2678  decode.loss_cls: 0.0075  decode.loss_mask: 0.7092  decode.loss_dice: 0.5983  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.7081  decode.d0.loss_dice: 0.6012  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.6994  decode.d1.loss_dice: 0.6093  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.7062  decode.d2.loss_dice: 0.6140  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.7070  decode.d3.loss_dice: 0.6082  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.7064  decode.d4.loss_dice: 0.6011  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.7076  decode.d5.loss_dice: 0.5976  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.7047  decode.d6.loss_dice: 0.6008  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.7064  decode.d7.loss_dice: 0.6025  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.7115  decode.d8.loss_dice: 0.6023
2025/03/31 07:43:07 - mmengine - INFO - Iter(train) [12350/20000]  base_lr: 4.2110e-05 lr: 4.2110e-05  eta: 1:49:51  time: 0.8580  data_time: 0.0157  memory: 10099  loss: 12.0365  decode.loss_cls: 0.0083  decode.loss_mask: 0.6247  decode.loss_dice: 0.5567  decode.d0.loss_cls: 0.0523  decode.d0.loss_mask: 0.6262  decode.d0.loss_dice: 0.5694  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.6281  decode.d1.loss_dice: 0.5600  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.6273  decode.d2.loss_dice: 0.5667  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.6253  decode.d3.loss_dice: 0.5754  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.6267  decode.d4.loss_dice: 0.5589  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.6258  decode.d5.loss_dice: 0.5571  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.6233  decode.d6.loss_dice: 0.5647  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.6229  decode.d7.loss_dice: 0.5517  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.6247  decode.d8.loss_dice: 0.5684
2025/03/31 07:43:50 - mmengine - INFO - Iter(train) [12400/20000]  base_lr: 4.1862e-05 lr: 4.1862e-05  eta: 1:49:07  time: 0.8588  data_time: 0.0157  memory: 10100  loss: 12.2155  decode.loss_cls: 0.0092  decode.loss_mask: 0.5972  decode.loss_dice: 0.6048  decode.d0.loss_cls: 0.0737  decode.d0.loss_mask: 0.5911  decode.d0.loss_dice: 0.6139  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.5949  decode.d1.loss_dice: 0.6166  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.5932  decode.d2.loss_dice: 0.6062  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.5957  decode.d3.loss_dice: 0.6090  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.5943  decode.d4.loss_dice: 0.6042  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.5909  decode.d5.loss_dice: 0.6008  decode.d6.loss_cls: 0.0096  decode.d6.loss_mask: 0.5933  decode.d6.loss_dice: 0.6049  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.5934  decode.d7.loss_dice: 0.6031  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.5905  decode.d8.loss_dice: 0.6040
2025/03/31 07:44:33 - mmengine - INFO - Iter(train) [12450/20000]  base_lr: 4.1615e-05 lr: 4.1615e-05  eta: 1:48:24  time: 0.8572  data_time: 0.0157  memory: 10093  loss: 13.3841  decode.loss_cls: 0.0813  decode.loss_mask: 0.6201  decode.loss_dice: 0.6368  decode.d0.loss_cls: 0.1057  decode.d0.loss_mask: 0.6300  decode.d0.loss_dice: 0.6781  decode.d1.loss_cls: 0.0928  decode.d1.loss_mask: 0.6233  decode.d1.loss_dice: 0.6513  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.6219  decode.d2.loss_dice: 0.6455  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.6225  decode.d3.loss_dice: 0.6482  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.6203  decode.d4.loss_dice: 0.6261  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.6177  decode.d5.loss_dice: 0.6333  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.6194  decode.d6.loss_dice: 0.6344  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.6222  decode.d7.loss_dice: 0.6356  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.6210  decode.d8.loss_dice: 0.6455
2025/03/31 07:45:16 - mmengine - INFO - Iter(train) [12500/20000]  base_lr: 4.1366e-05 lr: 4.1366e-05  eta: 1:47:41  time: 0.8573  data_time: 0.0156  memory: 10144  loss: 12.8982  decode.loss_cls: 0.0043  decode.loss_mask: 0.6654  decode.loss_dice: 0.6107  decode.d0.loss_cls: 0.0718  decode.d0.loss_mask: 0.6744  decode.d0.loss_dice: 0.6153  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.6692  decode.d1.loss_dice: 0.6166  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.6666  decode.d2.loss_dice: 0.6050  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.6658  decode.d3.loss_dice: 0.6148  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.6646  decode.d4.loss_dice: 0.6028  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.6639  decode.d5.loss_dice: 0.6104  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.6689  decode.d6.loss_dice: 0.6207  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.6631  decode.d7.loss_dice: 0.6170  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.6665  decode.d8.loss_dice: 0.5999
2025/03/31 07:45:59 - mmengine - INFO - Iter(train) [12550/20000]  base_lr: 4.1118e-05 lr: 4.1118e-05  eta: 1:46:58  time: 0.8574  data_time: 0.0158  memory: 10097  loss: 13.2998  decode.loss_cls: 0.0187  decode.loss_mask: 0.6493  decode.loss_dice: 0.6569  decode.d0.loss_cls: 0.0611  decode.d0.loss_mask: 0.6583  decode.d0.loss_dice: 0.6619  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.6517  decode.d1.loss_dice: 0.6510  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.6505  decode.d2.loss_dice: 0.6645  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.6530  decode.d3.loss_dice: 0.6513  decode.d4.loss_cls: 0.0241  decode.d4.loss_mask: 0.6505  decode.d4.loss_dice: 0.6609  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.6512  decode.d5.loss_dice: 0.6617  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.6488  decode.d6.loss_dice: 0.6654  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.6532  decode.d7.loss_dice: 0.6586  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.6529  decode.d8.loss_dice: 0.6572
2025/03/31 07:46:42 - mmengine - INFO - Iter(train) [12600/20000]  base_lr: 4.0870e-05 lr: 4.0870e-05  eta: 1:46:15  time: 0.8574  data_time: 0.0156  memory: 10149  loss: 12.9546  decode.loss_cls: 0.0135  decode.loss_mask: 0.6543  decode.loss_dice: 0.6228  decode.d0.loss_cls: 0.0502  decode.d0.loss_mask: 0.6657  decode.d0.loss_dice: 0.6106  decode.d1.loss_cls: 0.0284  decode.d1.loss_mask: 0.6574  decode.d1.loss_dice: 0.6123  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.6548  decode.d2.loss_dice: 0.6061  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.6604  decode.d3.loss_dice: 0.6180  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.6582  decode.d4.loss_dice: 0.6236  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.6549  decode.d5.loss_dice: 0.6168  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.6552  decode.d6.loss_dice: 0.6242  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.6558  decode.d7.loss_dice: 0.6171  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.6574  decode.d8.loss_dice: 0.6226
2025/03/31 07:47:25 - mmengine - INFO - Iter(train) [12650/20000]  base_lr: 4.0621e-05 lr: 4.0621e-05  eta: 1:45:32  time: 0.8572  data_time: 0.0156  memory: 10142  loss: 12.4920  decode.loss_cls: 0.0149  decode.loss_mask: 0.6677  decode.loss_dice: 0.5541  decode.d0.loss_cls: 0.0856  decode.d0.loss_mask: 0.6715  decode.d0.loss_dice: 0.5683  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.6657  decode.d1.loss_dice: 0.5596  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.6699  decode.d2.loss_dice: 0.5571  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.6668  decode.d3.loss_dice: 0.5631  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.6654  decode.d4.loss_dice: 0.5536  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.6673  decode.d5.loss_dice: 0.5518  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.6707  decode.d6.loss_dice: 0.5616  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.6685  decode.d7.loss_dice: 0.5606  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.6667  decode.d8.loss_dice: 0.5649
2025/03/31 07:48:09 - mmengine - INFO - Iter(train) [12700/20000]  base_lr: 4.0372e-05 lr: 4.0372e-05  eta: 1:44:49  time: 0.9059  data_time: 0.0163  memory: 10142  loss: 12.1471  decode.loss_cls: 0.0835  decode.loss_mask: 0.5343  decode.loss_dice: 0.6065  decode.d0.loss_cls: 0.0611  decode.d0.loss_mask: 0.5329  decode.d0.loss_dice: 0.6482  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.5340  decode.d1.loss_dice: 0.6553  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.5324  decode.d2.loss_dice: 0.6353  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.5331  decode.d3.loss_dice: 0.5842  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.5312  decode.d4.loss_dice: 0.6149  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.5319  decode.d5.loss_dice: 0.6533  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.5385  decode.d6.loss_dice: 0.6108  decode.d7.loss_cls: 0.0560  decode.d7.loss_mask: 0.5356  decode.d7.loss_dice: 0.6218  decode.d8.loss_cls: 0.0498  decode.d8.loss_mask: 0.5345  decode.d8.loss_dice: 0.6355
2025/03/31 07:48:54 - mmengine - INFO - Iter(train) [12750/20000]  base_lr: 4.0123e-05 lr: 4.0123e-05  eta: 1:44:07  time: 0.9108  data_time: 0.0159  memory: 10100  loss: 12.9762  decode.loss_cls: 0.0070  decode.loss_mask: 0.6839  decode.loss_dice: 0.5990  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 0.6866  decode.d0.loss_dice: 0.6026  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.6885  decode.d1.loss_dice: 0.6037  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.6881  decode.d2.loss_dice: 0.6005  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.6827  decode.d3.loss_dice: 0.5976  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.6823  decode.d4.loss_dice: 0.5942  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.6845  decode.d5.loss_dice: 0.6017  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.6827  decode.d6.loss_dice: 0.5992  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.6864  decode.d7.loss_dice: 0.6028  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.6865  decode.d8.loss_dice: 0.6038
2025/03/31 07:49:38 - mmengine - INFO - Iter(train) [12800/20000]  base_lr: 3.9874e-05 lr: 3.9874e-05  eta: 1:43:25  time: 0.8579  data_time: 0.0158  memory: 10145  loss: 10.9511  decode.loss_cls: 0.0070  decode.loss_mask: 0.5489  decode.loss_dice: 0.5434  decode.d0.loss_cls: 0.0478  decode.d0.loss_mask: 0.5531  decode.d0.loss_dice: 0.5423  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.5497  decode.d1.loss_dice: 0.5371  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.5506  decode.d2.loss_dice: 0.5358  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.5465  decode.d3.loss_dice: 0.5275  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.5442  decode.d4.loss_dice: 0.5277  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.5480  decode.d5.loss_dice: 0.5341  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.5510  decode.d6.loss_dice: 0.5320  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.5447  decode.d7.loss_dice: 0.5382  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.5480  decode.d8.loss_dice: 0.5408
2025/03/31 07:50:21 - mmengine - INFO - Iter(train) [12850/20000]  base_lr: 3.9625e-05 lr: 3.9625e-05  eta: 1:42:42  time: 0.8589  data_time: 0.0157  memory: 10144  loss: 13.3977  decode.loss_cls: 0.0426  decode.loss_mask: 0.7025  decode.loss_dice: 0.5973  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 0.7151  decode.d0.loss_dice: 0.5878  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.7017  decode.d1.loss_dice: 0.6063  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.7016  decode.d2.loss_dice: 0.5933  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.6962  decode.d3.loss_dice: 0.5969  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.6980  decode.d4.loss_dice: 0.5945  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.7010  decode.d5.loss_dice: 0.5992  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.7024  decode.d6.loss_dice: 0.6011  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.7009  decode.d7.loss_dice: 0.5920  decode.d8.loss_cls: 0.0451  decode.d8.loss_mask: 0.7022  decode.d8.loss_dice: 0.5887
2025/03/31 07:51:04 - mmengine - INFO - Iter(train) [12900/20000]  base_lr: 3.9375e-05 lr: 3.9375e-05  eta: 1:41:59  time: 0.8665  data_time: 0.0181  memory: 10092  loss: 11.6759  decode.loss_cls: 0.0050  decode.loss_mask: 0.5916  decode.loss_dice: 0.5679  decode.d0.loss_cls: 0.0517  decode.d0.loss_mask: 0.5957  decode.d0.loss_dice: 0.5703  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.5895  decode.d1.loss_dice: 0.5597  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.5929  decode.d2.loss_dice: 0.5596  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.5871  decode.d3.loss_dice: 0.5688  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.5874  decode.d4.loss_dice: 0.5765  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.5890  decode.d5.loss_dice: 0.5691  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.5889  decode.d6.loss_dice: 0.5669  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.5917  decode.d7.loss_dice: 0.5749  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.5866  decode.d8.loss_dice: 0.5607
2025/03/31 07:51:48 - mmengine - INFO - Iter(train) [12950/20000]  base_lr: 3.9126e-05 lr: 3.9126e-05  eta: 1:41:16  time: 0.8654  data_time: 0.0170  memory: 10144  loss: 10.4678  decode.loss_cls: 0.0089  decode.loss_mask: 0.4982  decode.loss_dice: 0.5348  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 0.4990  decode.d0.loss_dice: 0.5549  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.4973  decode.d1.loss_dice: 0.5336  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.4997  decode.d2.loss_dice: 0.5369  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.4986  decode.d3.loss_dice: 0.5351  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.5019  decode.d4.loss_dice: 0.5359  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.5001  decode.d5.loss_dice: 0.5350  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.4982  decode.d6.loss_dice: 0.5299  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.5002  decode.d7.loss_dice: 0.5222  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.5016  decode.d8.loss_dice: 0.5380
2025/03/31 07:52:32 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 07:52:32 - mmengine - INFO - Iter(train) [13000/20000]  base_lr: 3.8876e-05 lr: 3.8876e-05  eta: 1:40:33  time: 0.8690  data_time: 0.0176  memory: 10142  loss: 11.7542  decode.loss_cls: 0.0142  decode.loss_mask: 0.5677  decode.loss_dice: 0.5816  decode.d0.loss_cls: 0.0528  decode.d0.loss_mask: 0.5769  decode.d0.loss_dice: 0.5894  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.5684  decode.d1.loss_dice: 0.5880  decode.d2.loss_cls: 0.0312  decode.d2.loss_mask: 0.5724  decode.d2.loss_dice: 0.5927  decode.d3.loss_cls: 0.0205  decode.d3.loss_mask: 0.5706  decode.d3.loss_dice: 0.6020  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.5708  decode.d4.loss_dice: 0.5920  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.5708  decode.d5.loss_dice: 0.5864  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.5667  decode.d6.loss_dice: 0.5806  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.5675  decode.d7.loss_dice: 0.5763  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.5674  decode.d8.loss_dice: 0.5858
2025/03/31 07:53:15 - mmengine - INFO - Iter(train) [13050/20000]  base_lr: 3.8626e-05 lr: 3.8626e-05  eta: 1:39:50  time: 0.8687  data_time: 0.0177  memory: 10145  loss: 12.1681  decode.loss_cls: 0.0042  decode.loss_mask: 0.6458  decode.loss_dice: 0.5571  decode.d0.loss_cls: 0.0537  decode.d0.loss_mask: 0.6395  decode.d0.loss_dice: 0.5625  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.6396  decode.d1.loss_dice: 0.5590  decode.d2.loss_cls: 0.0247  decode.d2.loss_mask: 0.6331  decode.d2.loss_dice: 0.5509  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.6309  decode.d3.loss_dice: 0.5507  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.6504  decode.d4.loss_dice: 0.5586  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.6511  decode.d5.loss_dice: 0.5647  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.6465  decode.d6.loss_dice: 0.5675  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.6442  decode.d7.loss_dice: 0.5617  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.6492  decode.d8.loss_dice: 0.5603
2025/03/31 07:53:59 - mmengine - INFO - Iter(train) [13100/20000]  base_lr: 3.8376e-05 lr: 3.8376e-05  eta: 1:39:07  time: 0.8685  data_time: 0.0166  memory: 10144  loss: 12.4548  decode.loss_cls: 0.0170  decode.loss_mask: 0.6379  decode.loss_dice: 0.5628  decode.d0.loss_cls: 0.0486  decode.d0.loss_mask: 0.6430  decode.d0.loss_dice: 0.5787  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.6430  decode.d1.loss_dice: 0.5842  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.6429  decode.d2.loss_dice: 0.5792  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.6418  decode.d3.loss_dice: 0.5664  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.6396  decode.d4.loss_dice: 0.5677  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.6432  decode.d5.loss_dice: 0.5731  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.6402  decode.d6.loss_dice: 0.5764  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.6406  decode.d7.loss_dice: 0.5668  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.6433  decode.d8.loss_dice: 0.5750
2025/03/31 07:54:42 - mmengine - INFO - Iter(train) [13150/20000]  base_lr: 3.8125e-05 lr: 3.8125e-05  eta: 1:38:24  time: 0.8632  data_time: 0.0164  memory: 10143  loss: 12.9003  decode.loss_cls: 0.0080  decode.loss_mask: 0.6625  decode.loss_dice: 0.6045  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.6696  decode.d0.loss_dice: 0.6094  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.6644  decode.d1.loss_dice: 0.6114  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.6611  decode.d2.loss_dice: 0.6084  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.6634  decode.d3.loss_dice: 0.5886  decode.d4.loss_cls: 0.0241  decode.d4.loss_mask: 0.6637  decode.d4.loss_dice: 0.6088  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.6642  decode.d5.loss_dice: 0.6066  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.6608  decode.d6.loss_dice: 0.6174  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.6601  decode.d7.loss_dice: 0.5966  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.6620  decode.d8.loss_dice: 0.6104
2025/03/31 07:55:25 - mmengine - INFO - Iter(train) [13200/20000]  base_lr: 3.7875e-05 lr: 3.7875e-05  eta: 1:37:41  time: 0.8648  data_time: 0.0163  memory: 10144  loss: 12.4971  decode.loss_cls: 0.0132  decode.loss_mask: 0.6390  decode.loss_dice: 0.5836  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.6483  decode.d0.loss_dice: 0.5933  decode.d1.loss_cls: 0.0352  decode.d1.loss_mask: 0.6432  decode.d1.loss_dice: 0.5849  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.6430  decode.d2.loss_dice: 0.5958  decode.d3.loss_cls: 0.0207  decode.d3.loss_mask: 0.6405  decode.d3.loss_dice: 0.5913  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.6411  decode.d4.loss_dice: 0.5742  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.6394  decode.d5.loss_dice: 0.5948  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 0.6424  decode.d6.loss_dice: 0.5728  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.6439  decode.d7.loss_dice: 0.5930  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 0.6421  decode.d8.loss_dice: 0.5744
2025/03/31 07:56:08 - mmengine - INFO - Iter(train) [13250/20000]  base_lr: 3.7624e-05 lr: 3.7624e-05  eta: 1:36:58  time: 0.8653  data_time: 0.0167  memory: 10141  loss: 12.9035  decode.loss_cls: 0.0119  decode.loss_mask: 0.6638  decode.loss_dice: 0.6056  decode.d0.loss_cls: 0.0583  decode.d0.loss_mask: 0.6749  decode.d0.loss_dice: 0.6060  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.6661  decode.d1.loss_dice: 0.6094  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.6675  decode.d2.loss_dice: 0.6044  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.6663  decode.d3.loss_dice: 0.5983  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.6665  decode.d4.loss_dice: 0.6057  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.6678  decode.d5.loss_dice: 0.6073  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.6639  decode.d6.loss_dice: 0.6036  decode.d7.loss_cls: 0.0275  decode.d7.loss_mask: 0.6679  decode.d7.loss_dice: 0.6009  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.6636  decode.d8.loss_dice: 0.5922
2025/03/31 07:56:52 - mmengine - INFO - Iter(train) [13300/20000]  base_lr: 3.7373e-05 lr: 3.7373e-05  eta: 1:36:15  time: 0.8680  data_time: 0.0168  memory: 10142  loss: 12.9095  decode.loss_cls: 0.0173  decode.loss_mask: 0.6391  decode.loss_dice: 0.6132  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.6517  decode.d0.loss_dice: 0.6592  decode.d1.loss_cls: 0.0407  decode.d1.loss_mask: 0.6456  decode.d1.loss_dice: 0.6057  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.6428  decode.d2.loss_dice: 0.6127  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.6402  decode.d3.loss_dice: 0.6242  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.6384  decode.d4.loss_dice: 0.6221  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.6453  decode.d5.loss_dice: 0.6287  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 0.6170  decode.d7.loss_cls: 0.0187  decode.d7.loss_mask: 0.6443  decode.d7.loss_dice: 0.6311  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.6423  decode.d8.loss_dice: 0.6071
2025/03/31 07:57:35 - mmengine - INFO - Iter(train) [13350/20000]  base_lr: 3.7122e-05 lr: 3.7122e-05  eta: 1:35:32  time: 0.8648  data_time: 0.0164  memory: 10144  loss: 12.0428  decode.loss_cls: 0.0122  decode.loss_mask: 0.6290  decode.loss_dice: 0.5595  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.6330  decode.d0.loss_dice: 0.5749  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.6317  decode.d1.loss_dice: 0.5729  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.6307  decode.d2.loss_dice: 0.5718  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.6289  decode.d3.loss_dice: 0.5513  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.6321  decode.d4.loss_dice: 0.5620  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.6306  decode.d5.loss_dice: 0.5690  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.6284  decode.d6.loss_dice: 0.5618  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.6306  decode.d7.loss_dice: 0.5623  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.6277  decode.d8.loss_dice: 0.5508
2025/03/31 07:58:18 - mmengine - INFO - Iter(train) [13400/20000]  base_lr: 3.6871e-05 lr: 3.6871e-05  eta: 1:34:49  time: 0.8649  data_time: 0.0167  memory: 10142  loss: 11.6168  decode.loss_cls: 0.0032  decode.loss_mask: 0.5730  decode.loss_dice: 0.5735  decode.d0.loss_cls: 0.0326  decode.d0.loss_mask: 0.5802  decode.d0.loss_dice: 0.5809  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.5744  decode.d1.loss_dice: 0.5799  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.5773  decode.d2.loss_dice: 0.5840  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.5736  decode.d3.loss_dice: 0.5788  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 0.5748  decode.d4.loss_dice: 0.5766  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.5714  decode.d5.loss_dice: 0.5752  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.5724  decode.d6.loss_dice: 0.5768  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.5695  decode.d7.loss_dice: 0.5773  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.5725  decode.d8.loss_dice: 0.5729
2025/03/31 07:59:02 - mmengine - INFO - Iter(train) [13450/20000]  base_lr: 3.6619e-05 lr: 3.6619e-05  eta: 1:34:06  time: 0.8655  data_time: 0.0163  memory: 10142  loss: 11.3286  decode.loss_cls: 0.0025  decode.loss_mask: 0.5777  decode.loss_dice: 0.5356  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.5894  decode.d0.loss_dice: 0.5363  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.5825  decode.d1.loss_dice: 0.5428  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.5804  decode.d2.loss_dice: 0.5471  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.5771  decode.d3.loss_dice: 0.5430  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.5795  decode.d4.loss_dice: 0.5395  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.5787  decode.d5.loss_dice: 0.5415  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.5796  decode.d6.loss_dice: 0.5425  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.5793  decode.d7.loss_dice: 0.5363  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.5791  decode.d8.loss_dice: 0.5354
2025/03/31 07:59:45 - mmengine - INFO - Iter(train) [13500/20000]  base_lr: 3.6368e-05 lr: 3.6368e-05  eta: 1:33:23  time: 0.8872  data_time: 0.0163  memory: 10143  loss: 11.9564  decode.loss_cls: 0.0182  decode.loss_mask: 0.6066  decode.loss_dice: 0.5611  decode.d0.loss_cls: 0.0515  decode.d0.loss_mask: 0.6169  decode.d0.loss_dice: 0.5688  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.6134  decode.d1.loss_dice: 0.5700  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.6117  decode.d2.loss_dice: 0.5763  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.6075  decode.d3.loss_dice: 0.5605  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.6100  decode.d4.loss_dice: 0.5861  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.6098  decode.d5.loss_dice: 0.5589  decode.d6.loss_cls: 0.0252  decode.d6.loss_mask: 0.6099  decode.d6.loss_dice: 0.5548  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.6107  decode.d7.loss_dice: 0.5644  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.6096  decode.d8.loss_dice: 0.5648
2025/03/31 08:00:29 - mmengine - INFO - Iter(train) [13550/20000]  base_lr: 3.6116e-05 lr: 3.6116e-05  eta: 1:32:40  time: 0.8652  data_time: 0.0165  memory: 10143  loss: 13.4574  decode.loss_cls: 0.0060  decode.loss_mask: 0.7142  decode.loss_dice: 0.6080  decode.d0.loss_cls: 0.1005  decode.d0.loss_mask: 0.7234  decode.d0.loss_dice: 0.5987  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.7238  decode.d1.loss_dice: 0.6129  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.7179  decode.d2.loss_dice: 0.6074  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.7170  decode.d3.loss_dice: 0.6105  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.7157  decode.d4.loss_dice: 0.6052  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.7131  decode.d5.loss_dice: 0.6074  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.7186  decode.d6.loss_dice: 0.6087  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.7194  decode.d7.loss_dice: 0.6064  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.7127  decode.d8.loss_dice: 0.6035
2025/03/31 08:01:12 - mmengine - INFO - Iter(train) [13600/20000]  base_lr: 3.5864e-05 lr: 3.5864e-05  eta: 1:31:57  time: 0.8674  data_time: 0.0165  memory: 10099  loss: 12.1922  decode.loss_cls: 0.0085  decode.loss_mask: 0.6387  decode.loss_dice: 0.5590  decode.d0.loss_cls: 0.0389  decode.d0.loss_mask: 0.6458  decode.d0.loss_dice: 0.5808  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.6436  decode.d1.loss_dice: 0.5667  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.6436  decode.d2.loss_dice: 0.5595  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.6430  decode.d3.loss_dice: 0.5561  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.6438  decode.d4.loss_dice: 0.5659  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.6391  decode.d5.loss_dice: 0.5530  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.6412  decode.d6.loss_dice: 0.5679  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.6363  decode.d7.loss_dice: 0.5585  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.6385  decode.d8.loss_dice: 0.5710
2025/03/31 08:01:55 - mmengine - INFO - Iter(train) [13650/20000]  base_lr: 3.5611e-05 lr: 3.5611e-05  eta: 1:31:14  time: 0.8671  data_time: 0.0164  memory: 10143  loss: 12.0823  decode.loss_cls: 0.0211  decode.loss_mask: 0.5952  decode.loss_dice: 0.5589  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.5980  decode.d0.loss_dice: 0.5858  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.5957  decode.d1.loss_dice: 0.6041  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.5949  decode.d2.loss_dice: 0.5791  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.5981  decode.d3.loss_dice: 0.5679  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.5994  decode.d4.loss_dice: 0.5817  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.5958  decode.d5.loss_dice: 0.5864  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.5947  decode.d6.loss_dice: 0.5611  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.5981  decode.d7.loss_dice: 0.5746  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.5956  decode.d8.loss_dice: 0.5846
2025/03/31 08:02:39 - mmengine - INFO - Iter(train) [13700/20000]  base_lr: 3.5359e-05 lr: 3.5359e-05  eta: 1:30:31  time: 0.8633  data_time: 0.0170  memory: 10150  loss: 12.0207  decode.loss_cls: 0.0504  decode.loss_mask: 0.5980  decode.loss_dice: 0.5503  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.6088  decode.d0.loss_dice: 0.5669  decode.d1.loss_cls: 0.0388  decode.d1.loss_mask: 0.5998  decode.d1.loss_dice: 0.5509  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.6017  decode.d2.loss_dice: 0.5447  decode.d3.loss_cls: 0.0484  decode.d3.loss_mask: 0.6023  decode.d3.loss_dice: 0.5510  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.5969  decode.d4.loss_dice: 0.5462  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.5983  decode.d5.loss_dice: 0.5473  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.5984  decode.d6.loss_dice: 0.5430  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.5970  decode.d7.loss_dice: 0.5572  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.5977  decode.d8.loss_dice: 0.5490
2025/03/31 08:03:22 - mmengine - INFO - Iter(train) [13750/20000]  base_lr: 3.5106e-05 lr: 3.5106e-05  eta: 1:29:48  time: 0.8598  data_time: 0.0165  memory: 10098  loss: 12.1124  decode.loss_cls: 0.0078  decode.loss_mask: 0.6371  decode.loss_dice: 0.5655  decode.d0.loss_cls: 0.0461  decode.d0.loss_mask: 0.6471  decode.d0.loss_dice: 0.5546  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.6460  decode.d1.loss_dice: 0.5616  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.6439  decode.d2.loss_dice: 0.5583  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.6397  decode.d3.loss_dice: 0.5741  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.6356  decode.d4.loss_dice: 0.5590  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.6379  decode.d5.loss_dice: 0.5640  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.6398  decode.d6.loss_dice: 0.5619  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.6395  decode.d7.loss_dice: 0.5584  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.6408  decode.d8.loss_dice: 0.5645
2025/03/31 08:04:05 - mmengine - INFO - Iter(train) [13800/20000]  base_lr: 3.4853e-05 lr: 3.4853e-05  eta: 1:29:05  time: 0.8608  data_time: 0.0166  memory: 10142  loss: 11.2135  decode.loss_cls: 0.0343  decode.loss_mask: 0.5773  decode.loss_dice: 0.5059  decode.d0.loss_cls: 0.0639  decode.d0.loss_mask: 0.5763  decode.d0.loss_dice: 0.5125  decode.d1.loss_cls: 0.0594  decode.d1.loss_mask: 0.5762  decode.d1.loss_dice: 0.5107  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.5709  decode.d2.loss_dice: 0.5033  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.5738  decode.d3.loss_dice: 0.5090  decode.d4.loss_cls: 0.0329  decode.d4.loss_mask: 0.5773  decode.d4.loss_dice: 0.5131  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.5745  decode.d5.loss_dice: 0.5046  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.5731  decode.d6.loss_dice: 0.5113  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.5746  decode.d7.loss_dice: 0.5041  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.5722  decode.d8.loss_dice: 0.4997
2025/03/31 08:04:48 - mmengine - INFO - Iter(train) [13850/20000]  base_lr: 3.4600e-05 lr: 3.4600e-05  eta: 1:28:22  time: 0.8608  data_time: 0.0163  memory: 10096  loss: 12.1154  decode.loss_cls: 0.0053  decode.loss_mask: 0.6292  decode.loss_dice: 0.5625  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.6317  decode.d0.loss_dice: 0.5593  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.6278  decode.d1.loss_dice: 0.5620  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.6265  decode.d2.loss_dice: 0.5606  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.6288  decode.d3.loss_dice: 0.5530  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.6299  decode.d4.loss_dice: 0.5599  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.6283  decode.d5.loss_dice: 0.5641  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.6297  decode.d6.loss_dice: 0.5596  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.6284  decode.d7.loss_dice: 0.5600  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.6300  decode.d8.loss_dice: 0.5540
2025/03/31 08:05:32 - mmengine - INFO - Iter(train) [13900/20000]  base_lr: 3.4347e-05 lr: 3.4347e-05  eta: 1:27:39  time: 0.8656  data_time: 0.0173  memory: 10144  loss: 12.1536  decode.loss_cls: 0.0262  decode.loss_mask: 0.6156  decode.loss_dice: 0.5624  decode.d0.loss_cls: 0.0430  decode.d0.loss_mask: 0.6217  decode.d0.loss_dice: 0.5743  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.6191  decode.d1.loss_dice: 0.5764  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.6172  decode.d2.loss_dice: 0.5694  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.6174  decode.d3.loss_dice: 0.5697  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.6138  decode.d4.loss_dice: 0.5731  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.6131  decode.d5.loss_dice: 0.5668  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.6138  decode.d6.loss_dice: 0.5690  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.6153  decode.d7.loss_dice: 0.5658  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.6107  decode.d8.loss_dice: 0.5600
2025/03/31 08:06:15 - mmengine - INFO - Iter(train) [13950/20000]  base_lr: 3.4094e-05 lr: 3.4094e-05  eta: 1:26:56  time: 0.8621  data_time: 0.0168  memory: 10142  loss: 11.5912  decode.loss_cls: 0.0207  decode.loss_mask: 0.5761  decode.loss_dice: 0.5591  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.5798  decode.d0.loss_dice: 0.5468  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.5767  decode.d1.loss_dice: 0.5582  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.5751  decode.d2.loss_dice: 0.5600  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.5728  decode.d3.loss_dice: 0.5514  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.5737  decode.d4.loss_dice: 0.5517  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.5718  decode.d5.loss_dice: 0.5526  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.5719  decode.d6.loss_dice: 0.5534  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.5780  decode.d7.loss_dice: 0.5630  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.5746  decode.d8.loss_dice: 0.5580
2025/03/31 08:06:58 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 08:06:58 - mmengine - INFO - Iter(train) [14000/20000]  base_lr: 3.3840e-05 lr: 3.3840e-05  eta: 1:26:13  time: 0.8643  data_time: 0.0173  memory: 10143  loss: 12.0979  decode.loss_cls: 0.0106  decode.loss_mask: 0.5890  decode.loss_dice: 0.6017  decode.d0.loss_cls: 0.0536  decode.d0.loss_mask: 0.5955  decode.d0.loss_dice: 0.6001  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.5938  decode.d1.loss_dice: 0.6241  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.5858  decode.d2.loss_dice: 0.6237  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.5911  decode.d3.loss_dice: 0.6019  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.5912  decode.d4.loss_dice: 0.6044  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.5865  decode.d5.loss_dice: 0.6001  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.5867  decode.d6.loss_dice: 0.6048  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.5889  decode.d7.loss_dice: 0.5810  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.5871  decode.d8.loss_dice: 0.5830
2025/03/31 08:06:58 - mmengine - INFO - Saving checkpoint at 14000 iterations
2025/03/31 08:07:05 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:12  time: 0.1003  data_time: 0.0013  memory: 1853  
2025/03/31 08:07:10 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:11  time: 0.1012  data_time: 0.0015  memory: 1853  
2025/03/31 08:07:15 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:03:05  time: 0.0960  data_time: 0.0015  memory: 1853  
2025/03/31 08:07:19 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:58  time: 0.0961  data_time: 0.0019  memory: 1853  
2025/03/31 08:07:24 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:52  time: 0.0954  data_time: 0.0016  memory: 1853  
2025/03/31 08:07:29 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:47  time: 0.0959  data_time: 0.0019  memory: 1853  
2025/03/31 08:07:34 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:41  time: 0.0958  data_time: 0.0015  memory: 1853  
2025/03/31 08:07:39 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:36  time: 0.0957  data_time: 0.0014  memory: 1853  
2025/03/31 08:07:43 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:31  time: 0.0964  data_time: 0.0015  memory: 1853  
2025/03/31 08:07:48 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:26  time: 0.0966  data_time: 0.0014  memory: 1853  
2025/03/31 08:07:53 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:21  time: 0.0950  data_time: 0.0014  memory: 1853  
2025/03/31 08:07:58 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:16  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 08:08:02 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:11  time: 0.0962  data_time: 0.0014  memory: 1853  
2025/03/31 08:08:07 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:06  time: 0.0947  data_time: 0.0012  memory: 1853  
2025/03/31 08:08:12 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:02:01  time: 0.0944  data_time: 0.0012  memory: 1853  
2025/03/31 08:08:17 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:56  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 08:08:22 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:52  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 08:08:26 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:47  time: 0.0964  data_time: 0.0021  memory: 1853  
2025/03/31 08:08:31 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:42  time: 0.0960  data_time: 0.0018  memory: 1853  
2025/03/31 08:08:36 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:37  time: 0.0954  data_time: 0.0014  memory: 1853  
2025/03/31 08:08:41 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:32  time: 0.0959  data_time: 0.0014  memory: 1853  
2025/03/31 08:08:45 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:27  time: 0.0950  data_time: 0.0014  memory: 1853  
2025/03/31 08:08:50 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:23  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 08:08:55 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:18  time: 0.0956  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:00 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:13  time: 0.0951  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:05 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:08  time: 0.0953  data_time: 0.0014  memory: 1853  
2025/03/31 08:09:09 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:03  time: 0.0951  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:14 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:59  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:19 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:54  time: 0.0957  data_time: 0.0017  memory: 1853  
2025/03/31 08:09:24 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:49  time: 0.0955  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:28 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:44  time: 0.0963  data_time: 0.0017  memory: 1853  
2025/03/31 08:09:33 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0968  data_time: 0.0015  memory: 1853  
2025/03/31 08:09:38 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:35  time: 0.0957  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:43 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:30  time: 0.0949  data_time: 0.0012  memory: 1853  
2025/03/31 08:09:48 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0955  data_time: 0.0014  memory: 1853  
2025/03/31 08:09:52 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0948  data_time: 0.0013  memory: 1853  
2025/03/31 08:09:57 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 08:10:02 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:11  time: 0.0956  data_time: 0.0017  memory: 1853  
2025/03/31 08:10:07 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 08:10:12 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0963  data_time: 0.0015  memory: 1853  
2025/03/31 08:10:13 - mmengine - INFO - per class results:
2025/03/31 08:10:13 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 68.74 | 92.98 |
|      building      | 83.76 | 94.38 |
|   low_vegetation   | 59.52 | 82.72 |
|        tree        | 33.69 | 34.88 |
|        car         | 74.63 | 84.92 |
|      clutter       |  1.5  |  1.51 |
+--------------------+-------+-------+
2025/03/31 08:10:13 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.8000  mIoU: 53.6400  mAcc: 65.2300  data_time: 0.0014  time: 0.0957
2025/03/31 08:10:57 - mmengine - INFO - Iter(train) [14050/20000]  base_lr: 3.3586e-05 lr: 3.3586e-05  eta: 1:25:30  time: 0.8643  data_time: 0.0163  memory: 10145  loss: 11.5160  decode.loss_cls: 0.0110  decode.loss_mask: 0.5716  decode.loss_dice: 0.5605  decode.d0.loss_cls: 0.0522  decode.d0.loss_mask: 0.5799  decode.d0.loss_dice: 0.5730  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.5738  decode.d1.loss_dice: 0.5647  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.5779  decode.d2.loss_dice: 0.5646  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.5756  decode.d3.loss_dice: 0.5625  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.5758  decode.d4.loss_dice: 0.5570  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.5762  decode.d5.loss_dice: 0.5636  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.5748  decode.d6.loss_dice: 0.5612  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.5751  decode.d7.loss_dice: 0.5691  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.5770  decode.d8.loss_dice: 0.5699
2025/03/31 08:11:40 - mmengine - INFO - Iter(train) [14100/20000]  base_lr: 3.3332e-05 lr: 3.3332e-05  eta: 1:24:47  time: 0.8642  data_time: 0.0161  memory: 10142  loss: 10.7406  decode.loss_cls: 0.0016  decode.loss_mask: 0.5370  decode.loss_dice: 0.5248  decode.d0.loss_cls: 0.0618  decode.d0.loss_mask: 0.5414  decode.d0.loss_dice: 0.5301  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.5386  decode.d1.loss_dice: 0.5282  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.5402  decode.d2.loss_dice: 0.5370  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.5346  decode.d3.loss_dice: 0.5277  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.5353  decode.d4.loss_dice: 0.5237  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.5392  decode.d5.loss_dice: 0.5334  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.5361  decode.d6.loss_dice: 0.5226  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.5375  decode.d7.loss_dice: 0.5202  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.5383  decode.d8.loss_dice: 0.5268
2025/03/31 08:12:23 - mmengine - INFO - Iter(train) [14150/20000]  base_lr: 3.3078e-05 lr: 3.3078e-05  eta: 1:24:04  time: 0.8662  data_time: 0.0169  memory: 10155  loss: 11.0405  decode.loss_cls: 0.0395  decode.loss_mask: 0.5249  decode.loss_dice: 0.5440  decode.d0.loss_cls: 0.0622  decode.d0.loss_mask: 0.5245  decode.d0.loss_dice: 0.5758  decode.d1.loss_cls: 0.0407  decode.d1.loss_mask: 0.5245  decode.d1.loss_dice: 0.5479  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.5267  decode.d2.loss_dice: 0.5432  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 0.5268  decode.d3.loss_dice: 0.5377  decode.d4.loss_cls: 0.0393  decode.d4.loss_mask: 0.5293  decode.d4.loss_dice: 0.5471  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.5244  decode.d5.loss_dice: 0.5469  decode.d6.loss_cls: 0.0107  decode.d6.loss_mask: 0.5282  decode.d6.loss_dice: 0.5496  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 0.5266  decode.d7.loss_dice: 0.5393  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.5275  decode.d8.loss_dice: 0.5470
2025/03/31 08:13:07 - mmengine - INFO - Iter(train) [14200/20000]  base_lr: 3.2823e-05 lr: 3.2823e-05  eta: 1:23:21  time: 0.8656  data_time: 0.0164  memory: 10144  loss: 11.2779  decode.loss_cls: 0.0472  decode.loss_mask: 0.5625  decode.loss_dice: 0.5183  decode.d0.loss_cls: 0.0472  decode.d0.loss_mask: 0.5689  decode.d0.loss_dice: 0.5410  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 0.5671  decode.d1.loss_dice: 0.5143  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.5612  decode.d2.loss_dice: 0.5142  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.5609  decode.d3.loss_dice: 0.5297  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.5642  decode.d4.loss_dice: 0.5278  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.5591  decode.d5.loss_dice: 0.5255  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.5626  decode.d6.loss_dice: 0.5221  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.5610  decode.d7.loss_dice: 0.5237  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.5612  decode.d8.loss_dice: 0.5277
2025/03/31 08:13:50 - mmengine - INFO - Iter(train) [14250/20000]  base_lr: 3.2568e-05 lr: 3.2568e-05  eta: 1:22:38  time: 0.8664  data_time: 0.0167  memory: 10096  loss: 10.5712  decode.loss_cls: 0.0178  decode.loss_mask: 0.5301  decode.loss_dice: 0.4938  decode.d0.loss_cls: 0.0589  decode.d0.loss_mask: 0.5268  decode.d0.loss_dice: 0.5076  decode.d1.loss_cls: 0.0167  decode.d1.loss_mask: 0.5325  decode.d1.loss_dice: 0.5046  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.5325  decode.d2.loss_dice: 0.5110  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.5327  decode.d3.loss_dice: 0.4986  decode.d4.loss_cls: 0.0378  decode.d4.loss_mask: 0.5332  decode.d4.loss_dice: 0.5002  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.5323  decode.d5.loss_dice: 0.5012  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.5318  decode.d6.loss_dice: 0.5066  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.5327  decode.d7.loss_dice: 0.4950  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.5336  decode.d8.loss_dice: 0.5004
2025/03/31 08:14:33 - mmengine - INFO - Iter(train) [14300/20000]  base_lr: 3.2313e-05 lr: 3.2313e-05  eta: 1:21:55  time: 0.8633  data_time: 0.0166  memory: 10100  loss: 11.1129  decode.loss_cls: 0.0076  decode.loss_mask: 0.5591  decode.loss_dice: 0.5356  decode.d0.loss_cls: 0.0556  decode.d0.loss_mask: 0.5671  decode.d0.loss_dice: 0.5515  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.5620  decode.d1.loss_dice: 0.5319  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.5636  decode.d2.loss_dice: 0.5384  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.5635  decode.d3.loss_dice: 0.5293  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.5623  decode.d4.loss_dice: 0.5324  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.5626  decode.d5.loss_dice: 0.5395  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.5582  decode.d6.loss_dice: 0.5362  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.5595  decode.d7.loss_dice: 0.5360  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.5619  decode.d8.loss_dice: 0.5458
2025/03/31 08:15:17 - mmengine - INFO - Iter(train) [14350/20000]  base_lr: 3.2058e-05 lr: 3.2058e-05  eta: 1:21:12  time: 0.8652  data_time: 0.0164  memory: 10142  loss: 11.7289  decode.loss_cls: 0.0068  decode.loss_mask: 0.5990  decode.loss_dice: 0.5578  decode.d0.loss_cls: 0.0493  decode.d0.loss_mask: 0.6007  decode.d0.loss_dice: 0.5551  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.6031  decode.d1.loss_dice: 0.5563  decode.d2.loss_cls: 0.0377  decode.d2.loss_mask: 0.5968  decode.d2.loss_dice: 0.5524  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.5980  decode.d3.loss_dice: 0.5527  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.5992  decode.d4.loss_dice: 0.5601  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.5951  decode.d5.loss_dice: 0.5525  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.5954  decode.d6.loss_dice: 0.5549  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.5960  decode.d7.loss_dice: 0.5543  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.5982  decode.d8.loss_dice: 0.5597
2025/03/31 08:16:00 - mmengine - INFO - Iter(train) [14400/20000]  base_lr: 3.1803e-05 lr: 3.1803e-05  eta: 1:20:29  time: 0.8941  data_time: 0.0172  memory: 10145  loss: 11.8734  decode.loss_cls: 0.0066  decode.loss_mask: 0.6229  decode.loss_dice: 0.5459  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.6358  decode.d0.loss_dice: 0.5526  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.6259  decode.d1.loss_dice: 0.5508  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.6248  decode.d2.loss_dice: 0.5481  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.6261  decode.d3.loss_dice: 0.5511  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.6213  decode.d4.loss_dice: 0.5476  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.6275  decode.d5.loss_dice: 0.5472  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.6256  decode.d6.loss_dice: 0.5467  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.6259  decode.d7.loss_dice: 0.5507  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.6232  decode.d8.loss_dice: 0.5491
2025/03/31 08:16:44 - mmengine - INFO - Iter(train) [14450/20000]  base_lr: 3.1547e-05 lr: 3.1547e-05  eta: 1:19:46  time: 0.8627  data_time: 0.0163  memory: 10097  loss: 11.4459  decode.loss_cls: 0.0170  decode.loss_mask: 0.5765  decode.loss_dice: 0.5496  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.5809  decode.d0.loss_dice: 0.5510  decode.d1.loss_cls: 0.0235  decode.d1.loss_mask: 0.5747  decode.d1.loss_dice: 0.5439  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.5739  decode.d2.loss_dice: 0.5496  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.5736  decode.d3.loss_dice: 0.5464  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.5739  decode.d4.loss_dice: 0.5494  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.5705  decode.d5.loss_dice: 0.5414  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.5739  decode.d6.loss_dice: 0.5426  decode.d7.loss_cls: 0.0266  decode.d7.loss_mask: 0.5757  decode.d7.loss_dice: 0.5457  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.5774  decode.d8.loss_dice: 0.5517
2025/03/31 08:17:29 - mmengine - INFO - Iter(train) [14500/20000]  base_lr: 3.1291e-05 lr: 3.1291e-05  eta: 1:19:04  time: 0.8956  data_time: 0.0173  memory: 10150  loss: 11.2958  decode.loss_cls: 0.0137  decode.loss_mask: 0.5498  decode.loss_dice: 0.5448  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.5605  decode.d0.loss_dice: 0.5672  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.5528  decode.d1.loss_dice: 0.5511  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.5509  decode.d2.loss_dice: 0.5609  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.5503  decode.d3.loss_dice: 0.5588  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 0.5489  decode.d4.loss_dice: 0.5503  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.5461  decode.d5.loss_dice: 0.5678  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.5516  decode.d6.loss_dice: 0.5461  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.5518  decode.d7.loss_dice: 0.5487  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.5543  decode.d8.loss_dice: 0.5584
2025/03/31 08:18:12 - mmengine - INFO - Iter(train) [14550/20000]  base_lr: 3.1035e-05 lr: 3.1035e-05  eta: 1:18:21  time: 0.8632  data_time: 0.0165  memory: 10148  loss: 10.6512  decode.loss_cls: 0.0180  decode.loss_mask: 0.5203  decode.loss_dice: 0.5246  decode.d0.loss_cls: 0.0457  decode.d0.loss_mask: 0.5213  decode.d0.loss_dice: 0.5372  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.5230  decode.d1.loss_dice: 0.5275  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.5189  decode.d2.loss_dice: 0.5199  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.5233  decode.d3.loss_dice: 0.5299  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.5198  decode.d4.loss_dice: 0.5172  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.5180  decode.d5.loss_dice: 0.5123  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.5166  decode.d6.loss_dice: 0.5312  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.5210  decode.d7.loss_dice: 0.5161  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.5204  decode.d8.loss_dice: 0.5091
2025/03/31 08:18:56 - mmengine - INFO - Iter(train) [14600/20000]  base_lr: 3.0778e-05 lr: 3.0778e-05  eta: 1:17:38  time: 0.8686  data_time: 0.0165  memory: 10142  loss: 12.5601  decode.loss_cls: 0.0167  decode.loss_mask: 0.6282  decode.loss_dice: 0.6111  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.6352  decode.d0.loss_dice: 0.6084  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.6302  decode.d1.loss_dice: 0.6000  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.6279  decode.d2.loss_dice: 0.6058  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.6287  decode.d3.loss_dice: 0.5955  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.6296  decode.d4.loss_dice: 0.6089  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.6314  decode.d5.loss_dice: 0.5896  decode.d6.loss_cls: 0.0215  decode.d6.loss_mask: 0.6277  decode.d6.loss_dice: 0.6085  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.6241  decode.d7.loss_dice: 0.6098  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.6278  decode.d8.loss_dice: 0.6130
2025/03/31 08:19:39 - mmengine - INFO - Iter(train) [14650/20000]  base_lr: 3.0522e-05 lr: 3.0522e-05  eta: 1:16:54  time: 0.8646  data_time: 0.0163  memory: 10144  loss: 10.8231  decode.loss_cls: 0.0041  decode.loss_mask: 0.5698  decode.loss_dice: 0.5045  decode.d0.loss_cls: 0.0336  decode.d0.loss_mask: 0.5684  decode.d0.loss_dice: 0.5075  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.5682  decode.d1.loss_dice: 0.5096  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.5663  decode.d2.loss_dice: 0.5064  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.5715  decode.d3.loss_dice: 0.5051  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.5713  decode.d4.loss_dice: 0.5013  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.5711  decode.d5.loss_dice: 0.5049  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.5729  decode.d6.loss_dice: 0.5090  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.5701  decode.d7.loss_dice: 0.4995  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.5702  decode.d8.loss_dice: 0.5059
2025/03/31 08:20:22 - mmengine - INFO - Iter(train) [14700/20000]  base_lr: 3.0265e-05 lr: 3.0265e-05  eta: 1:16:11  time: 0.8657  data_time: 0.0169  memory: 10098  loss: 10.5398  decode.loss_cls: 0.0014  decode.loss_mask: 0.5507  decode.loss_dice: 0.4958  decode.d0.loss_cls: 0.0587  decode.d0.loss_mask: 0.5537  decode.d0.loss_dice: 0.4906  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.5467  decode.d1.loss_dice: 0.4957  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.5517  decode.d2.loss_dice: 0.4899  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.5483  decode.d3.loss_dice: 0.4948  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.5471  decode.d4.loss_dice: 0.4940  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.5500  decode.d5.loss_dice: 0.4957  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.5495  decode.d6.loss_dice: 0.4978  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.5515  decode.d7.loss_dice: 0.5042  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.5505  decode.d8.loss_dice: 0.4997
2025/03/31 08:21:06 - mmengine - INFO - Iter(train) [14750/20000]  base_lr: 3.0008e-05 lr: 3.0008e-05  eta: 1:15:28  time: 0.8644  data_time: 0.0162  memory: 10142  loss: 10.2708  decode.loss_cls: 0.0041  decode.loss_mask: 0.4852  decode.loss_dice: 0.5221  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.4909  decode.d0.loss_dice: 0.5313  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.4861  decode.d1.loss_dice: 0.5277  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.4886  decode.d2.loss_dice: 0.5210  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.4854  decode.d3.loss_dice: 0.5257  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.4854  decode.d4.loss_dice: 0.5319  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.4861  decode.d5.loss_dice: 0.5311  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.4890  decode.d6.loss_dice: 0.5297  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.4859  decode.d7.loss_dice: 0.5193  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.4857  decode.d8.loss_dice: 0.5199
2025/03/31 08:21:49 - mmengine - INFO - Iter(train) [14800/20000]  base_lr: 2.9751e-05 lr: 2.9751e-05  eta: 1:14:45  time: 0.8672  data_time: 0.0164  memory: 10142  loss: 12.6548  decode.loss_cls: 0.0231  decode.loss_mask: 0.6249  decode.loss_dice: 0.5943  decode.d0.loss_cls: 0.0500  decode.d0.loss_mask: 0.6284  decode.d0.loss_dice: 0.5885  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.6240  decode.d1.loss_dice: 0.5922  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.6239  decode.d2.loss_dice: 0.5767  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.6235  decode.d3.loss_dice: 0.5716  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.6244  decode.d4.loss_dice: 0.5778  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.6221  decode.d5.loss_dice: 0.5716  decode.d6.loss_cls: 0.0763  decode.d6.loss_mask: 0.6222  decode.d6.loss_dice: 0.5783  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.6240  decode.d7.loss_dice: 0.5821  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.6266  decode.d8.loss_dice: 0.5912
2025/03/31 08:22:33 - mmengine - INFO - Iter(train) [14850/20000]  base_lr: 2.9493e-05 lr: 2.9493e-05  eta: 1:14:02  time: 0.8633  data_time: 0.0162  memory: 10144  loss: 10.6242  decode.loss_cls: 0.0052  decode.loss_mask: 0.5368  decode.loss_dice: 0.4988  decode.d0.loss_cls: 0.0439  decode.d0.loss_mask: 0.5433  decode.d0.loss_dice: 0.5155  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.5416  decode.d1.loss_dice: 0.5080  decode.d2.loss_cls: 0.0258  decode.d2.loss_mask: 0.5406  decode.d2.loss_dice: 0.5198  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.5425  decode.d3.loss_dice: 0.5012  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.5420  decode.d4.loss_dice: 0.5048  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.5391  decode.d5.loss_dice: 0.4976  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.5392  decode.d6.loss_dice: 0.5045  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.5381  decode.d7.loss_dice: 0.5130  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.5369  decode.d8.loss_dice: 0.4998
2025/03/31 08:23:16 - mmengine - INFO - Iter(train) [14900/20000]  base_lr: 2.9235e-05 lr: 2.9235e-05  eta: 1:13:19  time: 0.8645  data_time: 0.0162  memory: 10142  loss: 11.5687  decode.loss_cls: 0.0058  decode.loss_mask: 0.5950  decode.loss_dice: 0.5288  decode.d0.loss_cls: 0.0611  decode.d0.loss_mask: 0.6071  decode.d0.loss_dice: 0.5457  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.6004  decode.d1.loss_dice: 0.5337  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.5956  decode.d2.loss_dice: 0.5543  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.5968  decode.d3.loss_dice: 0.5340  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.5983  decode.d4.loss_dice: 0.5373  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.5964  decode.d5.loss_dice: 0.5302  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.5981  decode.d6.loss_dice: 0.5386  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.6003  decode.d7.loss_dice: 0.5499  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.5967  decode.d8.loss_dice: 0.5288
2025/03/31 08:24:00 - mmengine - INFO - Iter(train) [14950/20000]  base_lr: 2.8977e-05 lr: 2.8977e-05  eta: 1:12:36  time: 0.8635  data_time: 0.0165  memory: 10139  loss: 11.0256  decode.loss_cls: 0.0138  decode.loss_mask: 0.5453  decode.loss_dice: 0.5363  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.5493  decode.d0.loss_dice: 0.5350  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.5506  decode.d1.loss_dice: 0.5359  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.5446  decode.d2.loss_dice: 0.5403  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.5459  decode.d3.loss_dice: 0.5473  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.5463  decode.d4.loss_dice: 0.5435  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.5414  decode.d5.loss_dice: 0.5438  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.5433  decode.d6.loss_dice: 0.5451  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.5445  decode.d7.loss_dice: 0.5361  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.5444  decode.d8.loss_dice: 0.5468
2025/03/31 08:24:43 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 08:24:43 - mmengine - INFO - Iter(train) [15000/20000]  base_lr: 2.8719e-05 lr: 2.8719e-05  eta: 1:11:53  time: 0.8647  data_time: 0.0163  memory: 10098  loss: 11.0675  decode.loss_cls: 0.0059  decode.loss_mask: 0.5938  decode.loss_dice: 0.4987  decode.d0.loss_cls: 0.0590  decode.d0.loss_mask: 0.6136  decode.d0.loss_dice: 0.4952  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.5999  decode.d1.loss_dice: 0.4912  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.5982  decode.d2.loss_dice: 0.4960  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.5984  decode.d3.loss_dice: 0.4976  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.5949  decode.d4.loss_dice: 0.5003  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.4980  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.5965  decode.d6.loss_dice: 0.4973  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.5967  decode.d7.loss_dice: 0.4940  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.5947  decode.d8.loss_dice: 0.4999
2025/03/31 08:25:27 - mmengine - INFO - Iter(train) [15050/20000]  base_lr: 2.8460e-05 lr: 2.8460e-05  eta: 1:11:10  time: 0.8695  data_time: 0.0163  memory: 10093  loss: 13.0561  decode.loss_cls: 0.0197  decode.loss_mask: 0.6333  decode.loss_dice: 0.6438  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 0.6439  decode.d0.loss_dice: 0.6480  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.6371  decode.d1.loss_dice: 0.6487  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.6354  decode.d2.loss_dice: 0.6402  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.6367  decode.d3.loss_dice: 0.6315  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.6332  decode.d4.loss_dice: 0.6436  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.6312  decode.d5.loss_dice: 0.6390  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.6295  decode.d6.loss_dice: 0.6301  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.6356  decode.d7.loss_dice: 0.6572  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.6318  decode.d8.loss_dice: 0.6412
2025/03/31 08:26:10 - mmengine - INFO - Iter(train) [15100/20000]  base_lr: 2.8201e-05 lr: 2.8201e-05  eta: 1:10:27  time: 0.8648  data_time: 0.0161  memory: 10092  loss: 11.9259  decode.loss_cls: 0.0075  decode.loss_mask: 0.6294  decode.loss_dice: 0.5465  decode.d0.loss_cls: 0.0523  decode.d0.loss_mask: 0.6272  decode.d0.loss_dice: 0.5616  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.6287  decode.d1.loss_dice: 0.5554  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.6297  decode.d2.loss_dice: 0.5520  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.6323  decode.d3.loss_dice: 0.5568  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.6315  decode.d4.loss_dice: 0.5559  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.6314  decode.d5.loss_dice: 0.5484  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.6317  decode.d6.loss_dice: 0.5435  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.6323  decode.d7.loss_dice: 0.5479  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.6291  decode.d8.loss_dice: 0.5354
2025/03/31 08:26:53 - mmengine - INFO - Iter(train) [15150/20000]  base_lr: 2.7942e-05 lr: 2.7942e-05  eta: 1:09:44  time: 0.8647  data_time: 0.0160  memory: 10144  loss: 11.2562  decode.loss_cls: 0.0341  decode.loss_mask: 0.5896  decode.loss_dice: 0.5169  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.5953  decode.d0.loss_dice: 0.5309  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.5883  decode.d1.loss_dice: 0.5232  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.5871  decode.d2.loss_dice: 0.5261  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.5895  decode.d3.loss_dice: 0.5188  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.5876  decode.d4.loss_dice: 0.5199  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.5860  decode.d5.loss_dice: 0.5250  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.5916  decode.d6.loss_dice: 0.5204  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.5889  decode.d7.loss_dice: 0.5396  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.5917  decode.d8.loss_dice: 0.5169
2025/03/31 08:27:37 - mmengine - INFO - Iter(train) [15200/20000]  base_lr: 2.7683e-05 lr: 2.7683e-05  eta: 1:09:01  time: 0.8695  data_time: 0.0165  memory: 10145  loss: 12.4653  decode.loss_cls: 0.0194  decode.loss_mask: 0.6174  decode.loss_dice: 0.5967  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.6250  decode.d0.loss_dice: 0.6203  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.6194  decode.d1.loss_dice: 0.5782  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.6167  decode.d2.loss_dice: 0.6011  decode.d3.loss_cls: 0.0404  decode.d3.loss_mask: 0.6160  decode.d3.loss_dice: 0.5844  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.6184  decode.d4.loss_dice: 0.6057  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.6119  decode.d5.loss_dice: 0.5937  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.6152  decode.d6.loss_dice: 0.6102  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.6118  decode.d7.loss_dice: 0.5836  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.6158  decode.d8.loss_dice: 0.5992
2025/03/31 08:28:20 - mmengine - INFO - Iter(train) [15250/20000]  base_lr: 2.7423e-05 lr: 2.7423e-05  eta: 1:08:18  time: 0.8705  data_time: 0.0162  memory: 10100  loss: 10.8863  decode.loss_cls: 0.0047  decode.loss_mask: 0.5508  decode.loss_dice: 0.5233  decode.d0.loss_cls: 0.0490  decode.d0.loss_mask: 0.5541  decode.d0.loss_dice: 0.5263  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.5513  decode.d1.loss_dice: 0.5257  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.5502  decode.d2.loss_dice: 0.5333  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.5540  decode.d3.loss_dice: 0.5227  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5548  decode.d4.loss_dice: 0.5235  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.5535  decode.d5.loss_dice: 0.5215  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.5524  decode.d6.loss_dice: 0.5224  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.5531  decode.d7.loss_dice: 0.5245  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.5536  decode.d8.loss_dice: 0.5285
2025/03/31 08:29:03 - mmengine - INFO - Iter(train) [15300/20000]  base_lr: 2.7163e-05 lr: 2.7163e-05  eta: 1:07:35  time: 0.8674  data_time: 0.0161  memory: 10151  loss: 10.0367  decode.loss_cls: 0.0060  decode.loss_mask: 0.4890  decode.loss_dice: 0.4930  decode.d0.loss_cls: 0.0836  decode.d0.loss_mask: 0.4932  decode.d0.loss_dice: 0.5093  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.4892  decode.d1.loss_dice: 0.5113  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.4888  decode.d2.loss_dice: 0.5053  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.4871  decode.d3.loss_dice: 0.4996  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.4885  decode.d4.loss_dice: 0.5014  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.4883  decode.d5.loss_dice: 0.4929  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.4904  decode.d6.loss_dice: 0.4987  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.4921  decode.d7.loss_dice: 0.5039  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.4866  decode.d8.loss_dice: 0.4971
2025/03/31 08:29:47 - mmengine - INFO - Iter(train) [15350/20000]  base_lr: 2.6903e-05 lr: 2.6903e-05  eta: 1:06:52  time: 0.8636  data_time: 0.0162  memory: 10097  loss: 11.5137  decode.loss_cls: 0.0131  decode.loss_mask: 0.5799  decode.loss_dice: 0.5531  decode.d0.loss_cls: 0.0479  decode.d0.loss_mask: 0.5897  decode.d0.loss_dice: 0.5582  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.5845  decode.d1.loss_dice: 0.5531  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.5835  decode.d2.loss_dice: 0.5557  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.5831  decode.d3.loss_dice: 0.5570  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.5801  decode.d4.loss_dice: 0.5571  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.5820  decode.d5.loss_dice: 0.5591  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.5789  decode.d6.loss_dice: 0.5592  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.5793  decode.d7.loss_dice: 0.5572  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.5782  decode.d8.loss_dice: 0.5571
2025/03/31 08:30:30 - mmengine - INFO - Iter(train) [15400/20000]  base_lr: 2.6642e-05 lr: 2.6642e-05  eta: 1:06:09  time: 0.8681  data_time: 0.0163  memory: 10096  loss: 9.6491  decode.loss_cls: 0.0023  decode.loss_mask: 0.4908  decode.loss_dice: 0.4631  decode.d0.loss_cls: 0.0412  decode.d0.loss_mask: 0.4896  decode.d0.loss_dice: 0.4624  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.4875  decode.d1.loss_dice: 0.4681  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.4917  decode.d2.loss_dice: 0.4644  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.4878  decode.d3.loss_dice: 0.4614  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.4874  decode.d4.loss_dice: 0.4653  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.4901  decode.d5.loss_dice: 0.4610  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.4896  decode.d6.loss_dice: 0.4622  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.4907  decode.d7.loss_dice: 0.4645  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.4922  decode.d8.loss_dice: 0.4689
2025/03/31 08:31:13 - mmengine - INFO - Iter(train) [15450/20000]  base_lr: 2.6382e-05 lr: 2.6382e-05  eta: 1:05:26  time: 0.8709  data_time: 0.0165  memory: 10144  loss: 10.8637  decode.loss_cls: 0.0028  decode.loss_mask: 0.5541  decode.loss_dice: 0.5083  decode.d0.loss_cls: 0.0675  decode.d0.loss_mask: 0.5581  decode.d0.loss_dice: 0.5153  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.5589  decode.d1.loss_dice: 0.5161  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.5546  decode.d2.loss_dice: 0.5184  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.5545  decode.d3.loss_dice: 0.5242  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.5523  decode.d4.loss_dice: 0.5158  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.5539  decode.d5.loss_dice: 0.5344  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.5510  decode.d6.loss_dice: 0.5170  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.5546  decode.d7.loss_dice: 0.5233  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.5559  decode.d8.loss_dice: 0.5143
2025/03/31 08:31:57 - mmengine - INFO - Iter(train) [15500/20000]  base_lr: 2.6121e-05 lr: 2.6121e-05  eta: 1:04:43  time: 0.8787  data_time: 0.0161  memory: 10144  loss: 10.7650  decode.loss_cls: 0.0024  decode.loss_mask: 0.5490  decode.loss_dice: 0.5135  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.5521  decode.d0.loss_dice: 0.5234  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.5467  decode.d1.loss_dice: 0.5029  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.5506  decode.d2.loss_dice: 0.5147  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.5480  decode.d3.loss_dice: 0.5079  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5466  decode.d4.loss_dice: 0.5078  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.5487  decode.d5.loss_dice: 0.5159  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 0.5119  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.5506  decode.d7.loss_dice: 0.5175  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.5482  decode.d8.loss_dice: 0.5132
2025/03/31 08:32:40 - mmengine - INFO - Iter(train) [15550/20000]  base_lr: 2.5859e-05 lr: 2.5859e-05  eta: 1:04:00  time: 0.8640  data_time: 0.0162  memory: 10150  loss: 10.5821  decode.loss_cls: 0.0345  decode.loss_mask: 0.5360  decode.loss_dice: 0.5006  decode.d0.loss_cls: 0.0437  decode.d0.loss_mask: 0.5390  decode.d0.loss_dice: 0.5142  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.5345  decode.d1.loss_dice: 0.5141  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.5352  decode.d2.loss_dice: 0.5029  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.5329  decode.d3.loss_dice: 0.5049  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.5345  decode.d4.loss_dice: 0.5036  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.5359  decode.d5.loss_dice: 0.4949  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.5350  decode.d6.loss_dice: 0.4972  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.5358  decode.d7.loss_dice: 0.5029  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.5342  decode.d8.loss_dice: 0.5119
2025/03/31 08:33:23 - mmengine - INFO - Iter(train) [15600/20000]  base_lr: 2.5598e-05 lr: 2.5598e-05  eta: 1:03:16  time: 0.8641  data_time: 0.0163  memory: 10143  loss: 11.3831  decode.loss_cls: 0.0035  decode.loss_mask: 0.5594  decode.loss_dice: 0.5681  decode.d0.loss_cls: 0.0491  decode.d0.loss_mask: 0.5693  decode.d0.loss_dice: 0.5686  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.5611  decode.d1.loss_dice: 0.5755  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.5645  decode.d2.loss_dice: 0.5740  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.5634  decode.d3.loss_dice: 0.5647  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.5629  decode.d4.loss_dice: 0.5687  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.5591  decode.d5.loss_dice: 0.5720  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.5623  decode.d6.loss_dice: 0.5632  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.5603  decode.d7.loss_dice: 0.5590  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.5582  decode.d8.loss_dice: 0.5626
2025/03/31 08:34:07 - mmengine - INFO - Iter(train) [15650/20000]  base_lr: 2.5336e-05 lr: 2.5336e-05  eta: 1:02:33  time: 0.8647  data_time: 0.0164  memory: 10142  loss: 11.1136  decode.loss_cls: 0.0110  decode.loss_mask: 0.5531  decode.loss_dice: 0.5371  decode.d0.loss_cls: 0.0590  decode.d0.loss_mask: 0.5652  decode.d0.loss_dice: 0.5392  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.5574  decode.d1.loss_dice: 0.5398  decode.d2.loss_cls: 0.0094  decode.d2.loss_mask: 0.5584  decode.d2.loss_dice: 0.5390  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.5547  decode.d3.loss_dice: 0.5390  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.5510  decode.d4.loss_dice: 0.5399  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.5524  decode.d5.loss_dice: 0.5477  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.5536  decode.d6.loss_dice: 0.5379  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.5520  decode.d7.loss_dice: 0.5292  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.5554  decode.d8.loss_dice: 0.5421
2025/03/31 08:34:50 - mmengine - INFO - Iter(train) [15700/20000]  base_lr: 2.5073e-05 lr: 2.5073e-05  eta: 1:01:50  time: 0.8644  data_time: 0.0165  memory: 10140  loss: 10.3236  decode.loss_cls: 0.0022  decode.loss_mask: 0.5335  decode.loss_dice: 0.4907  decode.d0.loss_cls: 0.0542  decode.d0.loss_mask: 0.5308  decode.d0.loss_dice: 0.5002  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.5299  decode.d1.loss_dice: 0.4903  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.5294  decode.d2.loss_dice: 0.4925  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.5312  decode.d3.loss_dice: 0.4941  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.5307  decode.d4.loss_dice: 0.4936  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.5316  decode.d5.loss_dice: 0.4950  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.5319  decode.d6.loss_dice: 0.4911  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.5317  decode.d7.loss_dice: 0.4930  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.5307  decode.d8.loss_dice: 0.4942
2025/03/31 08:35:33 - mmengine - INFO - Iter(train) [15750/20000]  base_lr: 2.4811e-05 lr: 2.4811e-05  eta: 1:01:07  time: 0.8663  data_time: 0.0165  memory: 10151  loss: 10.3452  decode.loss_cls: 0.0059  decode.loss_mask: 0.5284  decode.loss_dice: 0.4972  decode.d0.loss_cls: 0.0580  decode.d0.loss_mask: 0.5285  decode.d0.loss_dice: 0.5004  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.5250  decode.d1.loss_dice: 0.5023  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.5244  decode.d2.loss_dice: 0.5090  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.5222  decode.d3.loss_dice: 0.4900  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.5245  decode.d4.loss_dice: 0.4967  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.5276  decode.d5.loss_dice: 0.4916  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.5274  decode.d6.loss_dice: 0.4939  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.5269  decode.d7.loss_dice: 0.4965  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.5283  decode.d8.loss_dice: 0.4912
2025/03/31 08:36:17 - mmengine - INFO - Iter(train) [15800/20000]  base_lr: 2.4548e-05 lr: 2.4548e-05  eta: 1:00:24  time: 0.8646  data_time: 0.0163  memory: 10139  loss: 12.1567  decode.loss_cls: 0.0228  decode.loss_mask: 0.6030  decode.loss_dice: 0.5810  decode.d0.loss_cls: 0.0495  decode.d0.loss_mask: 0.6122  decode.d0.loss_dice: 0.5824  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.6085  decode.d1.loss_dice: 0.5869  decode.d2.loss_cls: 0.0255  decode.d2.loss_mask: 0.6055  decode.d2.loss_dice: 0.5833  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.6050  decode.d3.loss_dice: 0.5815  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 0.6022  decode.d4.loss_dice: 0.5817  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.6006  decode.d5.loss_dice: 0.5772  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.5994  decode.d6.loss_dice: 0.5786  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.6057  decode.d7.loss_dice: 0.5878  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.6014  decode.d8.loss_dice: 0.5854
2025/03/31 08:37:00 - mmengine - INFO - Iter(train) [15850/20000]  base_lr: 2.4285e-05 lr: 2.4285e-05  eta: 0:59:41  time: 0.8647  data_time: 0.0161  memory: 10142  loss: 11.0590  decode.loss_cls: 0.0368  decode.loss_mask: 0.5334  decode.loss_dice: 0.5423  decode.d0.loss_cls: 0.0501  decode.d0.loss_mask: 0.5291  decode.d0.loss_dice: 0.5565  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.5349  decode.d1.loss_dice: 0.5588  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.5372  decode.d2.loss_dice: 0.5565  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.5320  decode.d3.loss_dice: 0.5555  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.5306  decode.d4.loss_dice: 0.5451  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.5333  decode.d5.loss_dice: 0.5499  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.5336  decode.d6.loss_dice: 0.5551  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.5314  decode.d7.loss_dice: 0.5618  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.5303  decode.d8.loss_dice: 0.5445
2025/03/31 08:37:44 - mmengine - INFO - Iter(train) [15900/20000]  base_lr: 2.4021e-05 lr: 2.4021e-05  eta: 0:58:58  time: 0.8722  data_time: 0.0175  memory: 10150  loss: 10.8454  decode.loss_cls: 0.0090  decode.loss_mask: 0.5606  decode.loss_dice: 0.5069  decode.d0.loss_cls: 0.0539  decode.d0.loss_mask: 0.5683  decode.d0.loss_dice: 0.5208  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.5648  decode.d1.loss_dice: 0.5092  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.5638  decode.d2.loss_dice: 0.5127  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.5645  decode.d3.loss_dice: 0.5077  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.5609  decode.d4.loss_dice: 0.5093  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.5603  decode.d5.loss_dice: 0.5103  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.5621  decode.d6.loss_dice: 0.5089  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5596  decode.d7.loss_dice: 0.5063  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.5601  decode.d8.loss_dice: 0.5072
2025/03/31 08:38:27 - mmengine - INFO - Iter(train) [15950/20000]  base_lr: 2.3758e-05 lr: 2.3758e-05  eta: 0:58:15  time: 0.8643  data_time: 0.0163  memory: 10099  loss: 10.9613  decode.loss_cls: 0.0084  decode.loss_mask: 0.5202  decode.loss_dice: 0.5574  decode.d0.loss_cls: 0.0570  decode.d0.loss_mask: 0.5241  decode.d0.loss_dice: 0.5683  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.5222  decode.d1.loss_dice: 0.5611  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.5232  decode.d2.loss_dice: 0.5530  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.5216  decode.d3.loss_dice: 0.5513  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.5234  decode.d4.loss_dice: 0.5573  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.5238  decode.d5.loss_dice: 0.5631  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.5196  decode.d6.loss_dice: 0.5500  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.5192  decode.d7.loss_dice: 0.5543  decode.d8.loss_cls: 0.0106  decode.d8.loss_mask: 0.5194  decode.d8.loss_dice: 0.5652
2025/03/31 08:39:10 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 08:39:10 - mmengine - INFO - Iter(train) [16000/20000]  base_lr: 2.3493e-05 lr: 2.3493e-05  eta: 0:57:32  time: 0.8648  data_time: 0.0162  memory: 10093  loss: 10.7846  decode.loss_cls: 0.0045  decode.loss_mask: 0.5874  decode.loss_dice: 0.4806  decode.d0.loss_cls: 0.0481  decode.d0.loss_mask: 0.5979  decode.d0.loss_dice: 0.4835  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.5874  decode.d1.loss_dice: 0.4838  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.5836  decode.d2.loss_dice: 0.4857  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.5814  decode.d3.loss_dice: 0.4836  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.5870  decode.d4.loss_dice: 0.4854  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.5857  decode.d5.loss_dice: 0.4789  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.5852  decode.d6.loss_dice: 0.4825  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.5883  decode.d7.loss_dice: 0.4835  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.5868  decode.d8.loss_dice: 0.4840
2025/03/31 08:39:10 - mmengine - INFO - Saving checkpoint at 16000 iterations
2025/03/31 08:39:17 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:10  time: 0.0957  data_time: 0.0014  memory: 1853  
2025/03/31 08:39:21 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:04  time: 0.0954  data_time: 0.0014  memory: 1853  
2025/03/31 08:39:26 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:58  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 08:39:31 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:53  time: 0.0954  data_time: 0.0014  memory: 1853  
2025/03/31 08:39:36 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:48  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 08:39:41 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:43  time: 0.0952  data_time: 0.0014  memory: 1853  
2025/03/31 08:39:45 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:39  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 08:39:50 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:34  time: 0.0962  data_time: 0.0013  memory: 1853  
2025/03/31 08:39:55 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:29  time: 0.0963  data_time: 0.0015  memory: 1853  
2025/03/31 08:40:00 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:24  time: 0.0965  data_time: 0.0014  memory: 1853  
2025/03/31 08:40:04 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:19  time: 0.0951  data_time: 0.0014  memory: 1853  
2025/03/31 08:40:09 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:14  time: 0.0947  data_time: 0.0012  memory: 1853  
2025/03/31 08:40:14 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:10  time: 0.0953  data_time: 0.0014  memory: 1853  
2025/03/31 08:40:19 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:05  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 08:40:23 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:02:00  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 08:40:28 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:55  time: 0.0963  data_time: 0.0018  memory: 1853  
2025/03/31 08:40:33 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:51  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 08:40:38 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:46  time: 0.0962  data_time: 0.0015  memory: 1853  
2025/03/31 08:40:43 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:41  time: 0.0949  data_time: 0.0012  memory: 1853  
2025/03/31 08:40:47 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:36  time: 0.0956  data_time: 0.0014  memory: 1853  
2025/03/31 08:40:52 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:32  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 08:40:57 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:27  time: 0.0973  data_time: 0.0019  memory: 1853  
2025/03/31 08:41:02 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:22  time: 0.0957  data_time: 0.0012  memory: 1853  
2025/03/31 08:41:07 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:17  time: 0.0956  data_time: 0.0017  memory: 1853  
2025/03/31 08:41:11 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:13  time: 0.0956  data_time: 0.0013  memory: 1853  
2025/03/31 08:41:16 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:08  time: 0.0948  data_time: 0.0012  memory: 1853  
2025/03/31 08:41:21 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:03  time: 0.0961  data_time: 0.0014  memory: 1853  
2025/03/31 08:41:26 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:58  time: 0.0959  data_time: 0.0015  memory: 1853  
2025/03/31 08:41:30 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0947  data_time: 0.0012  memory: 1853  
2025/03/31 08:41:35 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:49  time: 0.0954  data_time: 0.0016  memory: 1853  
2025/03/31 08:41:40 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:44  time: 0.0959  data_time: 0.0015  memory: 1853  
2025/03/31 08:41:45 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0949  data_time: 0.0012  memory: 1853  
2025/03/31 08:41:50 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0956  data_time: 0.0013  memory: 1853  
2025/03/31 08:41:54 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:30  time: 0.0949  data_time: 0.0012  memory: 1853  
2025/03/31 08:41:59 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0954  data_time: 0.0013  memory: 1853  
2025/03/31 08:42:04 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0948  data_time: 0.0014  memory: 1853  
2025/03/31 08:42:09 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0949  data_time: 0.0012  memory: 1853  
2025/03/31 08:42:13 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:11  time: 0.0960  data_time: 0.0014  memory: 1853  
2025/03/31 08:42:18 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0950  data_time: 0.0012  memory: 1853  
2025/03/31 08:42:23 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0954  data_time: 0.0013  memory: 1853  
2025/03/31 08:42:25 - mmengine - INFO - per class results:
2025/03/31 08:42:25 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 68.41 | 93.46 |
|      building      | 81.67 | 93.92 |
|   low_vegetation   | 59.57 | 82.48 |
|        tree        | 29.91 | 30.79 |
|        car         | 74.58 | 84.05 |
|      clutter       |  1.4  |  1.41 |
+--------------------+-------+-------+
2025/03/31 08:42:25 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.0700  mIoU: 52.5900  mAcc: 64.3500  data_time: 0.0014  time: 0.0954
2025/03/31 08:43:08 - mmengine - INFO - Iter(train) [16050/20000]  base_lr: 2.3229e-05 lr: 2.3229e-05  eta: 0:56:49  time: 0.8674  data_time: 0.0167  memory: 10139  loss: 10.5375  decode.loss_cls: 0.0169  decode.loss_mask: 0.5217  decode.loss_dice: 0.4999  decode.d0.loss_cls: 0.0675  decode.d0.loss_mask: 0.5239  decode.d0.loss_dice: 0.5166  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.5239  decode.d1.loss_dice: 0.5121  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.5198  decode.d2.loss_dice: 0.4954  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.5238  decode.d3.loss_dice: 0.5202  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.5230  decode.d4.loss_dice: 0.5205  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.5199  decode.d5.loss_dice: 0.4935  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.5227  decode.d6.loss_dice: 0.4990  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.5197  decode.d7.loss_dice: 0.4870  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.5195  decode.d8.loss_dice: 0.4856
2025/03/31 08:43:51 - mmengine - INFO - Iter(train) [16100/20000]  base_lr: 2.2964e-05 lr: 2.2964e-05  eta: 0:56:05  time: 0.8641  data_time: 0.0163  memory: 10144  loss: 12.4366  decode.loss_cls: 0.0369  decode.loss_mask: 0.6349  decode.loss_dice: 0.5708  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.6386  decode.d0.loss_dice: 0.5881  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.6374  decode.d1.loss_dice: 0.5715  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.6333  decode.d2.loss_dice: 0.5609  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.6359  decode.d3.loss_dice: 0.5605  decode.d4.loss_cls: 0.0327  decode.d4.loss_mask: 0.6394  decode.d4.loss_dice: 0.5574  decode.d5.loss_cls: 0.0304  decode.d5.loss_mask: 0.6383  decode.d5.loss_dice: 0.5614  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.6381  decode.d6.loss_dice: 0.5649  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.6394  decode.d7.loss_dice: 0.5560  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.6366  decode.d8.loss_dice: 0.5519
2025/03/31 08:44:35 - mmengine - INFO - Iter(train) [16150/20000]  base_lr: 2.2699e-05 lr: 2.2699e-05  eta: 0:55:22  time: 0.8645  data_time: 0.0160  memory: 10147  loss: 9.8993  decode.loss_cls: 0.0335  decode.loss_mask: 0.4848  decode.loss_dice: 0.4667  decode.d0.loss_cls: 0.0493  decode.d0.loss_mask: 0.4847  decode.d0.loss_dice: 0.5090  decode.d1.loss_cls: 0.0489  decode.d1.loss_mask: 0.4833  decode.d1.loss_dice: 0.4785  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.4809  decode.d2.loss_dice: 0.4928  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.4831  decode.d3.loss_dice: 0.4737  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.4847  decode.d4.loss_dice: 0.4723  decode.d5.loss_cls: 0.0183  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.4639  decode.d6.loss_cls: 0.0290  decode.d6.loss_mask: 0.4857  decode.d6.loss_dice: 0.4753  decode.d7.loss_cls: 0.0199  decode.d7.loss_mask: 0.4849  decode.d7.loss_dice: 0.4771  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.4872  decode.d8.loss_dice: 0.4786
2025/03/31 08:45:18 - mmengine - INFO - Iter(train) [16200/20000]  base_lr: 2.2434e-05 lr: 2.2434e-05  eta: 0:54:39  time: 0.8658  data_time: 0.0166  memory: 10145  loss: 10.0800  decode.loss_cls: 0.0066  decode.loss_mask: 0.5143  decode.loss_dice: 0.4797  decode.d0.loss_cls: 0.0661  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 0.4677  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.5166  decode.d1.loss_dice: 0.4731  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.5131  decode.d2.loss_dice: 0.4794  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.5194  decode.d3.loss_dice: 0.4803  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5173  decode.d4.loss_dice: 0.4885  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.5170  decode.d5.loss_dice: 0.4746  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.5151  decode.d6.loss_dice: 0.4787  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.5159  decode.d7.loss_dice: 0.4758  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.5138  decode.d8.loss_dice: 0.4788
2025/03/31 08:46:01 - mmengine - INFO - Iter(train) [16250/20000]  base_lr: 2.2168e-05 lr: 2.2168e-05  eta: 0:53:56  time: 0.8867  data_time: 0.0171  memory: 10100  loss: 10.4555  decode.loss_cls: 0.0137  decode.loss_mask: 0.5301  decode.loss_dice: 0.4942  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.5369  decode.d0.loss_dice: 0.5019  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.5325  decode.d1.loss_dice: 0.4923  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.5319  decode.d2.loss_dice: 0.4902  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.5307  decode.d3.loss_dice: 0.4895  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.5286  decode.d4.loss_dice: 0.4887  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.5276  decode.d5.loss_dice: 0.4857  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.5260  decode.d6.loss_dice: 0.4872  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.5274  decode.d7.loss_dice: 0.4896  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.5319  decode.d8.loss_dice: 0.4915
2025/03/31 08:46:45 - mmengine - INFO - Iter(train) [16300/20000]  base_lr: 2.1902e-05 lr: 2.1902e-05  eta: 0:53:13  time: 0.8690  data_time: 0.0165  memory: 10142  loss: 10.8820  decode.loss_cls: 0.0064  decode.loss_mask: 0.5651  decode.loss_dice: 0.5144  decode.d0.loss_cls: 0.0319  decode.d0.loss_mask: 0.5649  decode.d0.loss_dice: 0.5160  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.5580  decode.d1.loss_dice: 0.5076  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.5638  decode.d2.loss_dice: 0.5138  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.5633  decode.d3.loss_dice: 0.5142  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.5609  decode.d4.loss_dice: 0.5214  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.5609  decode.d5.loss_dice: 0.5163  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.5625  decode.d6.loss_dice: 0.5263  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.5647  decode.d7.loss_dice: 0.5158  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.5625  decode.d8.loss_dice: 0.5181
2025/03/31 08:47:28 - mmengine - INFO - Iter(train) [16350/20000]  base_lr: 2.1635e-05 lr: 2.1635e-05  eta: 0:52:30  time: 0.8656  data_time: 0.0171  memory: 10151  loss: 10.7712  decode.loss_cls: 0.0102  decode.loss_mask: 0.5418  decode.loss_dice: 0.5208  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.5500  decode.d0.loss_dice: 0.5241  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.5438  decode.d1.loss_dice: 0.5226  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.5411  decode.d2.loss_dice: 0.5205  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.5477  decode.d3.loss_dice: 0.5172  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.5449  decode.d4.loss_dice: 0.5097  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.5457  decode.d5.loss_dice: 0.5163  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.5458  decode.d6.loss_dice: 0.5187  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.5444  decode.d7.loss_dice: 0.5182  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.5423  decode.d8.loss_dice: 0.5136
2025/03/31 08:48:11 - mmengine - INFO - Iter(train) [16400/20000]  base_lr: 2.1368e-05 lr: 2.1368e-05  eta: 0:51:47  time: 0.8594  data_time: 0.0157  memory: 10144  loss: 10.7140  decode.loss_cls: 0.0387  decode.loss_mask: 0.5519  decode.loss_dice: 0.4803  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.5560  decode.d0.loss_dice: 0.4909  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.5548  decode.d1.loss_dice: 0.4770  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.5488  decode.d2.loss_dice: 0.4807  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.5528  decode.d3.loss_dice: 0.4895  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.5508  decode.d4.loss_dice: 0.4894  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.5529  decode.d5.loss_dice: 0.4972  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.5514  decode.d6.loss_dice: 0.4907  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.5523  decode.d7.loss_dice: 0.4836  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.5485  decode.d8.loss_dice: 0.5062
2025/03/31 08:48:55 - mmengine - INFO - Iter(train) [16450/20000]  base_lr: 2.1101e-05 lr: 2.1101e-05  eta: 0:51:04  time: 0.8642  data_time: 0.0163  memory: 10146  loss: 10.5953  decode.loss_cls: 0.0219  decode.loss_mask: 0.5052  decode.loss_dice: 0.5288  decode.d0.loss_cls: 0.0644  decode.d0.loss_mask: 0.5113  decode.d0.loss_dice: 0.5500  decode.d1.loss_cls: 0.0494  decode.d1.loss_mask: 0.5086  decode.d1.loss_dice: 0.5371  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.5097  decode.d2.loss_dice: 0.5262  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.5095  decode.d3.loss_dice: 0.5164  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.5050  decode.d4.loss_dice: 0.5150  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.5105  decode.d5.loss_dice: 0.5397  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.5072  decode.d6.loss_dice: 0.5209  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.5084  decode.d7.loss_dice: 0.5146  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.5080  decode.d8.loss_dice: 0.5273
2025/03/31 08:49:38 - mmengine - INFO - Iter(train) [16500/20000]  base_lr: 2.0833e-05 lr: 2.0833e-05  eta: 0:50:21  time: 0.8639  data_time: 0.0163  memory: 10140  loss: 10.8350  decode.loss_cls: 0.0057  decode.loss_mask: 0.5741  decode.loss_dice: 0.5115  decode.d0.loss_cls: 0.0536  decode.d0.loss_mask: 0.5747  decode.d0.loss_dice: 0.4878  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.5774  decode.d1.loss_dice: 0.5086  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.5732  decode.d2.loss_dice: 0.5009  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.5747  decode.d3.loss_dice: 0.4904  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5749  decode.d4.loss_dice: 0.5163  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.5764  decode.d5.loss_dice: 0.5027  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.5771  decode.d6.loss_dice: 0.4889  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.5770  decode.d7.loss_dice: 0.4902  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.5719  decode.d8.loss_dice: 0.4877
2025/03/31 08:50:22 - mmengine - INFO - Iter(train) [16550/20000]  base_lr: 2.0565e-05 lr: 2.0565e-05  eta: 0:49:38  time: 0.8630  data_time: 0.0160  memory: 10146  loss: 10.0278  decode.loss_cls: 0.0033  decode.loss_mask: 0.5115  decode.loss_dice: 0.4740  decode.d0.loss_cls: 0.0467  decode.d0.loss_mask: 0.5176  decode.d0.loss_dice: 0.4727  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.5121  decode.d1.loss_dice: 0.4749  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.5159  decode.d2.loss_dice: 0.4802  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.5152  decode.d3.loss_dice: 0.4810  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.5143  decode.d4.loss_dice: 0.4682  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.5150  decode.d5.loss_dice: 0.4772  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.5146  decode.d6.loss_dice: 0.4798  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.5143  decode.d7.loss_dice: 0.4722  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.5140  decode.d8.loss_dice: 0.4966
2025/03/31 08:51:07 - mmengine - INFO - Iter(train) [16600/20000]  base_lr: 2.0297e-05 lr: 2.0297e-05  eta: 0:48:55  time: 0.8886  data_time: 0.0179  memory: 10142  loss: 10.3530  decode.loss_cls: 0.0030  decode.loss_mask: 0.5363  decode.loss_dice: 0.4870  decode.d0.loss_cls: 0.0617  decode.d0.loss_mask: 0.5423  decode.d0.loss_dice: 0.4917  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.5363  decode.d1.loss_dice: 0.4928  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.5358  decode.d2.loss_dice: 0.4875  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.5323  decode.d3.loss_dice: 0.4854  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5372  decode.d4.loss_dice: 0.4889  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.5377  decode.d5.loss_dice: 0.4878  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.5374  decode.d6.loss_dice: 0.4883  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.5389  decode.d7.loss_dice: 0.4916  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.5359  decode.d8.loss_dice: 0.4855
2025/03/31 08:51:50 - mmengine - INFO - Iter(train) [16650/20000]  base_lr: 2.0028e-05 lr: 2.0028e-05  eta: 0:48:12  time: 0.8685  data_time: 0.0175  memory: 10143  loss: 10.5326  decode.loss_cls: 0.0074  decode.loss_mask: 0.5457  decode.loss_dice: 0.4922  decode.d0.loss_cls: 0.0577  decode.d0.loss_mask: 0.5564  decode.d0.loss_dice: 0.4954  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.5520  decode.d1.loss_dice: 0.4972  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.5500  decode.d2.loss_dice: 0.4936  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.5494  decode.d3.loss_dice: 0.4971  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.5486  decode.d4.loss_dice: 0.4951  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 0.4914  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.5474  decode.d6.loss_dice: 0.4916  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.5476  decode.d7.loss_dice: 0.4924  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.5463  decode.d8.loss_dice: 0.4976
2025/03/31 08:52:33 - mmengine - INFO - Iter(train) [16700/20000]  base_lr: 1.9759e-05 lr: 1.9759e-05  eta: 0:47:28  time: 0.8629  data_time: 0.0171  memory: 10093  loss: 11.3078  decode.loss_cls: 0.0048  decode.loss_mask: 0.5850  decode.loss_dice: 0.5328  decode.d0.loss_cls: 0.0703  decode.d0.loss_mask: 0.5973  decode.d0.loss_dice: 0.5576  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.5848  decode.d1.loss_dice: 0.5323  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.5849  decode.d2.loss_dice: 0.5310  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.5862  decode.d3.loss_dice: 0.5346  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.5837  decode.d4.loss_dice: 0.5165  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.5808  decode.d5.loss_dice: 0.5332  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.5841  decode.d6.loss_dice: 0.5259  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.5843  decode.d7.loss_dice: 0.5383  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.5822  decode.d8.loss_dice: 0.5301
2025/03/31 08:53:17 - mmengine - INFO - Iter(train) [16750/20000]  base_lr: 1.9489e-05 lr: 1.9489e-05  eta: 0:46:45  time: 0.8640  data_time: 0.0168  memory: 10098  loss: 10.9077  decode.loss_cls: 0.0125  decode.loss_mask: 0.5532  decode.loss_dice: 0.5099  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.5591  decode.d0.loss_dice: 0.5133  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.5547  decode.d1.loss_dice: 0.5208  decode.d2.loss_cls: 0.0230  decode.d2.loss_mask: 0.5566  decode.d2.loss_dice: 0.5198  decode.d3.loss_cls: 0.0215  decode.d3.loss_mask: 0.5507  decode.d3.loss_dice: 0.5133  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.5525  decode.d4.loss_dice: 0.5099  decode.d5.loss_cls: 0.0394  decode.d5.loss_mask: 0.5528  decode.d5.loss_dice: 0.5098  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.5500  decode.d6.loss_dice: 0.5134  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.5519  decode.d7.loss_dice: 0.5239  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.5528  decode.d8.loss_dice: 0.5176
2025/03/31 08:54:00 - mmengine - INFO - Iter(train) [16800/20000]  base_lr: 1.9219e-05 lr: 1.9219e-05  eta: 0:46:02  time: 0.8680  data_time: 0.0176  memory: 10095  loss: 10.7728  decode.loss_cls: 0.0115  decode.loss_mask: 0.5428  decode.loss_dice: 0.4930  decode.d0.loss_cls: 0.0606  decode.d0.loss_mask: 0.5386  decode.d0.loss_dice: 0.5284  decode.d1.loss_cls: 0.0281  decode.d1.loss_mask: 0.5385  decode.d1.loss_dice: 0.5260  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.5393  decode.d2.loss_dice: 0.5117  decode.d3.loss_cls: 0.0327  decode.d3.loss_mask: 0.5403  decode.d3.loss_dice: 0.5128  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.5417  decode.d4.loss_dice: 0.5031  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.5407  decode.d5.loss_dice: 0.5090  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.5447  decode.d6.loss_dice: 0.5198  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.5421  decode.d7.loss_dice: 0.5227  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.5392  decode.d8.loss_dice: 0.5181
2025/03/31 08:54:43 - mmengine - INFO - Iter(train) [16850/20000]  base_lr: 1.8948e-05 lr: 1.8948e-05  eta: 0:45:19  time: 0.8662  data_time: 0.0174  memory: 10139  loss: 10.2850  decode.loss_cls: 0.0018  decode.loss_mask: 0.5078  decode.loss_dice: 0.5068  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.5172  decode.d0.loss_dice: 0.5088  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.5133  decode.d1.loss_dice: 0.5037  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.5100  decode.d2.loss_dice: 0.5057  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.5089  decode.d3.loss_dice: 0.5132  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.5088  decode.d4.loss_dice: 0.5155  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.5066  decode.d5.loss_dice: 0.5076  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.5085  decode.d6.loss_dice: 0.5073  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.5088  decode.d7.loss_dice: 0.5073  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.5070  decode.d8.loss_dice: 0.5065
2025/03/31 08:55:26 - mmengine - INFO - Iter(train) [16900/20000]  base_lr: 1.8677e-05 lr: 1.8677e-05  eta: 0:44:36  time: 0.8633  data_time: 0.0161  memory: 10139  loss: 10.2435  decode.loss_cls: 0.0178  decode.loss_mask: 0.4916  decode.loss_dice: 0.5023  decode.d0.loss_cls: 0.0690  decode.d0.loss_mask: 0.4996  decode.d0.loss_dice: 0.5037  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.4932  decode.d1.loss_dice: 0.5021  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.4900  decode.d2.loss_dice: 0.5061  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.4902  decode.d3.loss_dice: 0.5016  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.4914  decode.d4.loss_dice: 0.5187  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.4919  decode.d5.loss_dice: 0.5033  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.4926  decode.d6.loss_dice: 0.4990  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.4881  decode.d7.loss_dice: 0.5043  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 0.4913  decode.d8.loss_dice: 0.5016
2025/03/31 08:56:10 - mmengine - INFO - Iter(train) [16950/20000]  base_lr: 1.8406e-05 lr: 1.8406e-05  eta: 0:43:53  time: 0.8709  data_time: 0.0169  memory: 10097  loss: 10.3402  decode.loss_cls: 0.0220  decode.loss_mask: 0.5184  decode.loss_dice: 0.5008  decode.d0.loss_cls: 0.0531  decode.d0.loss_mask: 0.5211  decode.d0.loss_dice: 0.4987  decode.d1.loss_cls: 0.0377  decode.d1.loss_mask: 0.5190  decode.d1.loss_dice: 0.4844  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.5190  decode.d2.loss_dice: 0.4962  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.5189  decode.d3.loss_dice: 0.4968  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.5156  decode.d4.loss_dice: 0.4912  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.5186  decode.d5.loss_dice: 0.4982  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.5157  decode.d6.loss_dice: 0.4932  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.5193  decode.d7.loss_dice: 0.4906  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 0.5172  decode.d8.loss_dice: 0.4903
2025/03/31 08:56:53 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 08:56:53 - mmengine - INFO - Iter(train) [17000/20000]  base_lr: 1.8134e-05 lr: 1.8134e-05  eta: 0:43:10  time: 0.8679  data_time: 0.0163  memory: 10142  loss: 10.0626  decode.loss_cls: 0.0032  decode.loss_mask: 0.5245  decode.loss_dice: 0.4707  decode.d0.loss_cls: 0.0440  decode.d0.loss_mask: 0.5330  decode.d0.loss_dice: 0.4821  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.5260  decode.d1.loss_dice: 0.4748  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.5252  decode.d2.loss_dice: 0.4675  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.5244  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.5234  decode.d4.loss_dice: 0.4761  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.5255  decode.d5.loss_dice: 0.4767  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.5257  decode.d6.loss_dice: 0.4752  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.5257  decode.d7.loss_dice: 0.4698  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.5240  decode.d8.loss_dice: 0.4651
2025/03/31 08:57:37 - mmengine - INFO - Iter(train) [17050/20000]  base_lr: 1.7862e-05 lr: 1.7862e-05  eta: 0:42:26  time: 0.8728  data_time: 0.0167  memory: 10151  loss: 10.9222  decode.loss_cls: 0.0083  decode.loss_mask: 0.5679  decode.loss_dice: 0.5057  decode.d0.loss_cls: 0.0571  decode.d0.loss_mask: 0.5833  decode.d0.loss_dice: 0.5033  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.5775  decode.d1.loss_dice: 0.5128  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.5752  decode.d2.loss_dice: 0.5037  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.5697  decode.d3.loss_dice: 0.4996  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.5705  decode.d4.loss_dice: 0.5103  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.5705  decode.d5.loss_dice: 0.5085  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.5718  decode.d6.loss_dice: 0.5059  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.5701  decode.d7.loss_dice: 0.4926  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.5703  decode.d8.loss_dice: 0.5004
2025/03/31 08:58:20 - mmengine - INFO - Iter(train) [17100/20000]  base_lr: 1.7589e-05 lr: 1.7589e-05  eta: 0:41:43  time: 0.8630  data_time: 0.0160  memory: 10094  loss: 10.2313  decode.loss_cls: 0.0143  decode.loss_mask: 0.4958  decode.loss_dice: 0.5119  decode.d0.loss_cls: 0.0468  decode.d0.loss_mask: 0.4995  decode.d0.loss_dice: 0.5262  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.4921  decode.d1.loss_dice: 0.5070  decode.d2.loss_cls: 0.0180  decode.d2.loss_mask: 0.4957  decode.d2.loss_dice: 0.5155  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.4933  decode.d3.loss_dice: 0.5044  decode.d4.loss_cls: 0.0218  decode.d4.loss_mask: 0.4950  decode.d4.loss_dice: 0.5097  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.4935  decode.d5.loss_dice: 0.5049  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.4947  decode.d6.loss_dice: 0.5085  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.4938  decode.d7.loss_dice: 0.5039  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.4958  decode.d8.loss_dice: 0.5000
2025/03/31 08:59:03 - mmengine - INFO - Iter(train) [17150/20000]  base_lr: 1.7316e-05 lr: 1.7316e-05  eta: 0:41:00  time: 0.8677  data_time: 0.0164  memory: 10145  loss: 10.2857  decode.loss_cls: 0.0044  decode.loss_mask: 0.5369  decode.loss_dice: 0.4789  decode.d0.loss_cls: 0.0445  decode.d0.loss_mask: 0.5442  decode.d0.loss_dice: 0.4850  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.5412  decode.d1.loss_dice: 0.4825  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.5369  decode.d2.loss_dice: 0.4748  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.5384  decode.d3.loss_dice: 0.4794  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.5378  decode.d4.loss_dice: 0.4796  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.5400  decode.d5.loss_dice: 0.4826  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.5372  decode.d6.loss_dice: 0.4814  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.5385  decode.d7.loss_dice: 0.4834  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.5360  decode.d8.loss_dice: 0.4760
2025/03/31 08:59:47 - mmengine - INFO - Iter(train) [17200/20000]  base_lr: 1.7043e-05 lr: 1.7043e-05  eta: 0:40:17  time: 0.8645  data_time: 0.0163  memory: 10143  loss: 11.2075  decode.loss_cls: 0.0201  decode.loss_mask: 0.5424  decode.loss_dice: 0.5265  decode.d0.loss_cls: 0.1073  decode.d0.loss_mask: 0.5456  decode.d0.loss_dice: 0.5570  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.5409  decode.d1.loss_dice: 0.5483  decode.d2.loss_cls: 0.0169  decode.d2.loss_mask: 0.5427  decode.d2.loss_dice: 0.5523  decode.d3.loss_cls: 0.0455  decode.d3.loss_mask: 0.5426  decode.d3.loss_dice: 0.5456  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.5407  decode.d4.loss_dice: 0.5464  decode.d5.loss_cls: 0.0315  decode.d5.loss_mask: 0.5431  decode.d5.loss_dice: 0.5303  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.5393  decode.d6.loss_dice: 0.5273  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.5405  decode.d7.loss_dice: 0.5460  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.5410  decode.d8.loss_dice: 0.5355
2025/03/31 09:00:30 - mmengine - INFO - Iter(train) [17250/20000]  base_lr: 1.6768e-05 lr: 1.6768e-05  eta: 0:39:34  time: 0.8663  data_time: 0.0167  memory: 10139  loss: 10.2426  decode.loss_cls: 0.0025  decode.loss_mask: 0.5448  decode.loss_dice: 0.4744  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.5466  decode.d0.loss_dice: 0.4722  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.5416  decode.d1.loss_dice: 0.4676  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.5446  decode.d2.loss_dice: 0.4701  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.5436  decode.d3.loss_dice: 0.4704  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.5424  decode.d4.loss_dice: 0.4678  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.5424  decode.d5.loss_dice: 0.4677  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.5449  decode.d6.loss_dice: 0.4690  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.5460  decode.d7.loss_dice: 0.4684  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.5457  decode.d8.loss_dice: 0.4705
2025/03/31 09:01:13 - mmengine - INFO - Iter(train) [17300/20000]  base_lr: 1.6494e-05 lr: 1.6494e-05  eta: 0:38:51  time: 0.8661  data_time: 0.0162  memory: 10144  loss: 10.8269  decode.loss_cls: 0.0057  decode.loss_mask: 0.5447  decode.loss_dice: 0.5188  decode.d0.loss_cls: 0.0549  decode.d0.loss_mask: 0.5514  decode.d0.loss_dice: 0.5380  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.5455  decode.d1.loss_dice: 0.5251  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.5467  decode.d2.loss_dice: 0.5210  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.5485  decode.d3.loss_dice: 0.5191  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.5438  decode.d4.loss_dice: 0.5211  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.5445  decode.d5.loss_dice: 0.5248  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.5447  decode.d6.loss_dice: 0.5241  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.5451  decode.d7.loss_dice: 0.5257  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.5461  decode.d8.loss_dice: 0.5188
2025/03/31 09:01:57 - mmengine - INFO - Iter(train) [17350/20000]  base_lr: 1.6219e-05 lr: 1.6219e-05  eta: 0:38:08  time: 0.8695  data_time: 0.0168  memory: 10099  loss: 10.1646  decode.loss_cls: 0.0046  decode.loss_mask: 0.5127  decode.loss_dice: 0.4926  decode.d0.loss_cls: 0.0527  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 0.4963  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.5096  decode.d1.loss_dice: 0.4924  decode.d2.loss_cls: 0.0037  decode.d2.loss_mask: 0.5108  decode.d2.loss_dice: 0.4940  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.5107  decode.d3.loss_dice: 0.5019  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.5107  decode.d4.loss_dice: 0.4974  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.5110  decode.d5.loss_dice: 0.4980  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.5125  decode.d6.loss_dice: 0.4962  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.5127  decode.d7.loss_dice: 0.4939  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.5116  decode.d8.loss_dice: 0.4918
2025/03/31 09:02:40 - mmengine - INFO - Iter(train) [17400/20000]  base_lr: 1.5943e-05 lr: 1.5943e-05  eta: 0:37:24  time: 0.8652  data_time: 0.0169  memory: 10142  loss: 10.1642  decode.loss_cls: 0.0012  decode.loss_mask: 0.5180  decode.loss_dice: 0.4946  decode.d0.loss_cls: 0.0366  decode.d0.loss_mask: 0.5145  decode.d0.loss_dice: 0.4898  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.5173  decode.d1.loss_dice: 0.4830  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.5173  decode.d2.loss_dice: 0.4960  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.5160  decode.d3.loss_dice: 0.5004  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.5149  decode.d4.loss_dice: 0.4977  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.5166  decode.d5.loss_dice: 0.5006  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.5143  decode.d6.loss_dice: 0.4915  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.5154  decode.d7.loss_dice: 0.4940  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.5160  decode.d8.loss_dice: 0.5022
2025/03/31 09:03:24 - mmengine - INFO - Iter(train) [17450/20000]  base_lr: 1.5667e-05 lr: 1.5667e-05  eta: 0:36:41  time: 0.8659  data_time: 0.0165  memory: 10151  loss: 10.5244  decode.loss_cls: 0.0020  decode.loss_mask: 0.5366  decode.loss_dice: 0.5045  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.5359  decode.d0.loss_dice: 0.5067  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.5379  decode.d1.loss_dice: 0.5102  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.5413  decode.d2.loss_dice: 0.5058  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.5388  decode.d3.loss_dice: 0.5144  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.5385  decode.d4.loss_dice: 0.5080  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.5381  decode.d5.loss_dice: 0.4980  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.5388  decode.d6.loss_dice: 0.5067  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.5384  decode.d7.loss_dice: 0.5097  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.5408  decode.d8.loss_dice: 0.5070
2025/03/31 09:04:07 - mmengine - INFO - Iter(train) [17500/20000]  base_lr: 1.5390e-05 lr: 1.5390e-05  eta: 0:35:58  time: 0.8780  data_time: 0.0163  memory: 10094  loss: 11.6031  decode.loss_cls: 0.0389  decode.loss_mask: 0.5946  decode.loss_dice: 0.5216  decode.d0.loss_cls: 0.0477  decode.d0.loss_mask: 0.6008  decode.d0.loss_dice: 0.5483  decode.d1.loss_cls: 0.0334  decode.d1.loss_mask: 0.5924  decode.d1.loss_dice: 0.5208  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.5921  decode.d2.loss_dice: 0.5211  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.5978  decode.d3.loss_dice: 0.5267  decode.d4.loss_cls: 0.0294  decode.d4.loss_mask: 0.6000  decode.d4.loss_dice: 0.5413  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.5976  decode.d5.loss_dice: 0.5357  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.5976  decode.d6.loss_dice: 0.5264  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.5967  decode.d7.loss_dice: 0.5215  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.6006  decode.d8.loss_dice: 0.5346
2025/03/31 09:04:50 - mmengine - INFO - Iter(train) [17550/20000]  base_lr: 1.5113e-05 lr: 1.5113e-05  eta: 0:35:15  time: 0.8672  data_time: 0.0162  memory: 10144  loss: 10.1661  decode.loss_cls: 0.0079  decode.loss_mask: 0.5005  decode.loss_dice: 0.5005  decode.d0.loss_cls: 0.0505  decode.d0.loss_mask: 0.5057  decode.d0.loss_dice: 0.5159  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.5037  decode.d1.loss_dice: 0.5034  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.5018  decode.d2.loss_dice: 0.5014  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.5028  decode.d3.loss_dice: 0.4994  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.5029  decode.d4.loss_dice: 0.5004  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.5057  decode.d5.loss_dice: 0.4987  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.5027  decode.d6.loss_dice: 0.4942  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.5004  decode.d7.loss_dice: 0.4989  decode.d8.loss_cls: 0.0215  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 0.4976
2025/03/31 09:05:34 - mmengine - INFO - Iter(train) [17600/20000]  base_lr: 1.4835e-05 lr: 1.4835e-05  eta: 0:34:32  time: 0.8646  data_time: 0.0165  memory: 10139  loss: 10.6218  decode.loss_cls: 0.0042  decode.loss_mask: 0.5456  decode.loss_dice: 0.5019  decode.d0.loss_cls: 0.0491  decode.d0.loss_mask: 0.5552  decode.d0.loss_dice: 0.5117  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.5405  decode.d1.loss_dice: 0.5048  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.5442  decode.d2.loss_dice: 0.4985  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.5446  decode.d3.loss_dice: 0.5045  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.5443  decode.d4.loss_dice: 0.5005  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.5444  decode.d5.loss_dice: 0.5012  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.5440  decode.d6.loss_dice: 0.5008  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.5459  decode.d7.loss_dice: 0.5017  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.5438  decode.d8.loss_dice: 0.5014
2025/03/31 09:06:17 - mmengine - INFO - Iter(train) [17650/20000]  base_lr: 1.4556e-05 lr: 1.4556e-05  eta: 0:33:49  time: 0.8624  data_time: 0.0161  memory: 10142  loss: 10.5908  decode.loss_cls: 0.0017  decode.loss_mask: 0.5507  decode.loss_dice: 0.4936  decode.d0.loss_cls: 0.0573  decode.d0.loss_mask: 0.5616  decode.d0.loss_dice: 0.4875  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.5558  decode.d1.loss_dice: 0.4978  decode.d2.loss_cls: 0.0297  decode.d2.loss_mask: 0.5514  decode.d2.loss_dice: 0.4943  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.5498  decode.d3.loss_dice: 0.4961  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.5506  decode.d4.loss_dice: 0.4987  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.5497  decode.d5.loss_dice: 0.4982  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.5509  decode.d6.loss_dice: 0.4941  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.5491  decode.d7.loss_dice: 0.4880  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.5506  decode.d8.loss_dice: 0.4996
2025/03/31 09:07:00 - mmengine - INFO - Iter(train) [17700/20000]  base_lr: 1.4277e-05 lr: 1.4277e-05  eta: 0:33:06  time: 0.8639  data_time: 0.0162  memory: 10145  loss: 9.9417  decode.loss_cls: 0.0103  decode.loss_mask: 0.4938  decode.loss_dice: 0.4802  decode.d0.loss_cls: 0.0598  decode.d0.loss_mask: 0.5003  decode.d0.loss_dice: 0.4922  decode.d1.loss_cls: 0.0270  decode.d1.loss_mask: 0.4917  decode.d1.loss_dice: 0.4809  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.4931  decode.d2.loss_dice: 0.4808  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.4925  decode.d3.loss_dice: 0.4836  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.4931  decode.d4.loss_dice: 0.4764  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.4952  decode.d5.loss_dice: 0.4783  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.4942  decode.d6.loss_dice: 0.4819  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.4952  decode.d7.loss_dice: 0.4773  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.4963  decode.d8.loss_dice: 0.4817
2025/03/31 09:07:44 - mmengine - INFO - Iter(train) [17750/20000]  base_lr: 1.3998e-05 lr: 1.3998e-05  eta: 0:32:22  time: 0.8648  data_time: 0.0165  memory: 10098  loss: 10.9503  decode.loss_cls: 0.0268  decode.loss_mask: 0.5233  decode.loss_dice: 0.5427  decode.d0.loss_cls: 0.0456  decode.d0.loss_mask: 0.5320  decode.d0.loss_dice: 0.5458  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.5224  decode.d1.loss_dice: 0.5300  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.5261  decode.d2.loss_dice: 0.5422  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.5258  decode.d3.loss_dice: 0.5509  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.5228  decode.d4.loss_dice: 0.5520  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.5217  decode.d5.loss_dice: 0.5426  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.5223  decode.d6.loss_dice: 0.5483  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.5232  decode.d7.loss_dice: 0.5293  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.5238  decode.d8.loss_dice: 0.5394
2025/03/31 09:08:27 - mmengine - INFO - Iter(train) [17800/20000]  base_lr: 1.3717e-05 lr: 1.3717e-05  eta: 0:31:39  time: 0.8639  data_time: 0.0161  memory: 10145  loss: 9.6195  decode.loss_cls: 0.0031  decode.loss_mask: 0.4785  decode.loss_dice: 0.4626  decode.d0.loss_cls: 0.0598  decode.d0.loss_mask: 0.4944  decode.d0.loss_dice: 0.4627  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.4840  decode.d1.loss_dice: 0.4729  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.4805  decode.d2.loss_dice: 0.4638  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.4805  decode.d3.loss_dice: 0.4710  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.4769  decode.d4.loss_dice: 0.4670  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.4814  decode.d5.loss_dice: 0.4738  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.4803  decode.d6.loss_dice: 0.4691  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.4797  decode.d7.loss_dice: 0.4633  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.4804  decode.d8.loss_dice: 0.4620
2025/03/31 09:09:10 - mmengine - INFO - Iter(train) [17850/20000]  base_lr: 1.3437e-05 lr: 1.3437e-05  eta: 0:30:56  time: 0.8700  data_time: 0.0168  memory: 10142  loss: 10.5839  decode.loss_cls: 0.0039  decode.loss_mask: 0.5660  decode.loss_dice: 0.4791  decode.d0.loss_cls: 0.0430  decode.d0.loss_mask: 0.5729  decode.d0.loss_dice: 0.4810  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.5665  decode.d1.loss_dice: 0.4829  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5675  decode.d2.loss_dice: 0.4895  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.5668  decode.d3.loss_dice: 0.4878  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.5660  decode.d4.loss_dice: 0.4793  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.5672  decode.d5.loss_dice: 0.4810  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.5700  decode.d6.loss_dice: 0.4877  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.5675  decode.d7.loss_dice: 0.4835  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.5652  decode.d8.loss_dice: 0.4756
2025/03/31 09:09:54 - mmengine - INFO - Iter(train) [17900/20000]  base_lr: 1.3155e-05 lr: 1.3155e-05  eta: 0:30:13  time: 0.8797  data_time: 0.0166  memory: 10144  loss: 10.6368  decode.loss_cls: 0.0270  decode.loss_mask: 0.5251  decode.loss_dice: 0.5156  decode.d0.loss_cls: 0.0429  decode.d0.loss_mask: 0.5305  decode.d0.loss_dice: 0.5241  decode.d1.loss_cls: 0.0400  decode.d1.loss_mask: 0.5255  decode.d1.loss_dice: 0.5192  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.5261  decode.d2.loss_dice: 0.5219  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.5240  decode.d3.loss_dice: 0.5142  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.5226  decode.d4.loss_dice: 0.5197  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.5258  decode.d5.loss_dice: 0.5240  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.5233  decode.d6.loss_dice: 0.5156  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.5243  decode.d7.loss_dice: 0.5206  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.5267  decode.d8.loss_dice: 0.5234
2025/03/31 09:10:37 - mmengine - INFO - Iter(train) [17950/20000]  base_lr: 1.2873e-05 lr: 1.2873e-05  eta: 0:29:30  time: 0.8637  data_time: 0.0161  memory: 10143  loss: 10.3395  decode.loss_cls: 0.0353  decode.loss_mask: 0.5372  decode.loss_dice: 0.4692  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.5377  decode.d0.loss_dice: 0.4720  decode.d1.loss_cls: 0.0249  decode.d1.loss_mask: 0.5383  decode.d1.loss_dice: 0.4839  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.5397  decode.d2.loss_dice: 0.4847  decode.d3.loss_cls: 0.0286  decode.d3.loss_mask: 0.5371  decode.d3.loss_dice: 0.4807  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.5367  decode.d4.loss_dice: 0.4782  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.5348  decode.d5.loss_dice: 0.4832  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.5352  decode.d6.loss_dice: 0.4790  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.5369  decode.d7.loss_dice: 0.4772  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.5355  decode.d8.loss_dice: 0.4761
2025/03/31 09:11:20 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 09:11:20 - mmengine - INFO - Iter(train) [18000/20000]  base_lr: 1.2590e-05 lr: 1.2590e-05  eta: 0:28:47  time: 0.8651  data_time: 0.0160  memory: 10145  loss: 10.9889  decode.loss_cls: 0.0408  decode.loss_mask: 0.5657  decode.loss_dice: 0.5008  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.5808  decode.d0.loss_dice: 0.5151  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.5682  decode.d1.loss_dice: 0.4922  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.5689  decode.d2.loss_dice: 0.5132  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.5667  decode.d3.loss_dice: 0.4961  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.5662  decode.d4.loss_dice: 0.4981  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.5688  decode.d5.loss_dice: 0.4935  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.5662  decode.d6.loss_dice: 0.4992  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.5705  decode.d7.loss_dice: 0.4929  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.5685  decode.d8.loss_dice: 0.4975
2025/03/31 09:11:20 - mmengine - INFO - Saving checkpoint at 18000 iterations
2025/03/31 09:11:27 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:07  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 09:11:32 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:01  time: 0.0944  data_time: 0.0012  memory: 1853  
2025/03/31 09:11:36 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:02:57  time: 0.0951  data_time: 0.0014  memory: 1853  
2025/03/31 09:11:41 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:02:52  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 09:11:46 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:47  time: 0.0951  data_time: 0.0013  memory: 1853  
2025/03/31 09:11:51 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:43  time: 0.0946  data_time: 0.0012  memory: 1853  
2025/03/31 09:11:55 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:38  time: 0.0963  data_time: 0.0015  memory: 1853  
2025/03/31 09:12:00 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:34  time: 0.0965  data_time: 0.0014  memory: 1853  
2025/03/31 09:12:05 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:29  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 09:12:10 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:24  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 09:12:14 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:19  time: 0.0960  data_time: 0.0014  memory: 1853  
2025/03/31 09:12:19 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:14  time: 0.0952  data_time: 0.0015  memory: 1853  
2025/03/31 09:12:24 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:09  time: 0.0942  data_time: 0.0012  memory: 1853  
2025/03/31 09:12:29 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:05  time: 0.0954  data_time: 0.0013  memory: 1853  
2025/03/31 09:12:33 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:02:00  time: 0.0944  data_time: 0.0012  memory: 1853  
2025/03/31 09:12:38 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:55  time: 0.0954  data_time: 0.0016  memory: 1853  
2025/03/31 09:12:43 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:50  time: 0.0961  data_time: 0.0013  memory: 1853  
2025/03/31 09:12:48 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:46  time: 0.0947  data_time: 0.0013  memory: 1853  
2025/03/31 09:12:52 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:41  time: 0.0947  data_time: 0.0012  memory: 1853  
2025/03/31 09:12:57 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:36  time: 0.0941  data_time: 0.0012  memory: 1853  
2025/03/31 09:13:02 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:31  time: 0.0944  data_time: 0.0012  memory: 1853  
2025/03/31 09:13:07 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:27  time: 0.0952  data_time: 0.0013  memory: 1853  
2025/03/31 09:13:11 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:22  time: 0.0948  data_time: 0.0016  memory: 1853  
2025/03/31 09:13:16 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:17  time: 0.0942  data_time: 0.0014  memory: 1853  
2025/03/31 09:13:21 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:12  time: 0.0959  data_time: 0.0014  memory: 1853  
2025/03/31 09:13:26 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:08  time: 0.0955  data_time: 0.0013  memory: 1853  
2025/03/31 09:13:31 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:03  time: 0.0982  data_time: 0.0013  memory: 1853  
2025/03/31 09:13:35 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:58  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 09:13:40 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:53  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 09:13:45 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:49  time: 0.0946  data_time: 0.0012  memory: 1853  
2025/03/31 09:13:50 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:44  time: 0.0944  data_time: 0.0012  memory: 1853  
2025/03/31 09:13:54 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:39  time: 0.0950  data_time: 0.0013  memory: 1853  
2025/03/31 09:13:59 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:34  time: 0.0945  data_time: 0.0012  memory: 1853  
2025/03/31 09:14:04 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:30  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 09:14:09 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0946  data_time: 0.0012  memory: 1853  
2025/03/31 09:14:13 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 09:14:18 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0944  data_time: 0.0012  memory: 1853  
2025/03/31 09:14:23 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:11  time: 0.0955  data_time: 0.0014  memory: 1853  
2025/03/31 09:14:28 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 09:14:32 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.0945  data_time: 0.0013  memory: 1853  
2025/03/31 09:14:34 - mmengine - INFO - per class results:
2025/03/31 09:14:34 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface |  68.7 | 92.45 |
|      building      | 82.58 | 94.66 |
|   low_vegetation   | 59.48 | 83.26 |
|        tree        | 31.81 | 32.83 |
|        car         | 74.19 | 83.78 |
|      clutter       |  1.36 |  1.36 |
+--------------------+-------+-------+
2025/03/31 09:14:34 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 76.4400  mIoU: 53.0200  mAcc: 64.7200  data_time: 0.0013  time: 0.0950
2025/03/31 09:15:17 - mmengine - INFO - Iter(train) [18050/20000]  base_lr: 1.2306e-05 lr: 1.2306e-05  eta: 0:28:03  time: 0.8654  data_time: 0.0165  memory: 10139  loss: 9.9581  decode.loss_cls: 0.0127  decode.loss_mask: 0.5138  decode.loss_dice: 0.4582  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.5232  decode.d0.loss_dice: 0.4669  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.5189  decode.d1.loss_dice: 0.4533  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.5186  decode.d2.loss_dice: 0.4631  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.5160  decode.d3.loss_dice: 0.4585  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.5134  decode.d4.loss_dice: 0.4566  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.5157  decode.d5.loss_dice: 0.4539  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.5108  decode.d6.loss_dice: 0.4602  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.5141  decode.d7.loss_dice: 0.4615  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.5106  decode.d8.loss_dice: 0.4585
2025/03/31 09:16:01 - mmengine - INFO - Iter(train) [18100/20000]  base_lr: 1.2022e-05 lr: 1.2022e-05  eta: 0:27:20  time: 0.8625  data_time: 0.0161  memory: 10142  loss: 10.2861  decode.loss_cls: 0.0376  decode.loss_mask: 0.4809  decode.loss_dice: 0.5023  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.4838  decode.d0.loss_dice: 0.5330  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.4838  decode.d1.loss_dice: 0.5138  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.4826  decode.d2.loss_dice: 0.5003  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.4812  decode.d3.loss_dice: 0.5109  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.4834  decode.d4.loss_dice: 0.5054  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 0.4835  decode.d5.loss_dice: 0.5014  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.4844  decode.d6.loss_dice: 0.5172  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.4834  decode.d7.loss_dice: 0.5004  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.4834  decode.d8.loss_dice: 0.4860
2025/03/31 09:16:44 - mmengine - INFO - Iter(train) [18150/20000]  base_lr: 1.1737e-05 lr: 1.1737e-05  eta: 0:26:37  time: 0.8641  data_time: 0.0164  memory: 10099  loss: 10.0514  decode.loss_cls: 0.0031  decode.loss_mask: 0.5055  decode.loss_dice: 0.4871  decode.d0.loss_cls: 0.0426  decode.d0.loss_mask: 0.5104  decode.d0.loss_dice: 0.4966  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.5081  decode.d1.loss_dice: 0.4928  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.5062  decode.d2.loss_dice: 0.4869  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.5060  decode.d3.loss_dice: 0.4893  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.5080  decode.d4.loss_dice: 0.4880  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.5042  decode.d5.loss_dice: 0.4807  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.5040  decode.d6.loss_dice: 0.4842  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.5042  decode.d7.loss_dice: 0.4900  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.5036  decode.d8.loss_dice: 0.4842
2025/03/31 09:17:27 - mmengine - INFO - Iter(train) [18200/20000]  base_lr: 1.1451e-05 lr: 1.1451e-05  eta: 0:25:54  time: 0.8650  data_time: 0.0161  memory: 10143  loss: 10.5801  decode.loss_cls: 0.0626  decode.loss_mask: 0.5200  decode.loss_dice: 0.4867  decode.d0.loss_cls: 0.0715  decode.d0.loss_mask: 0.5240  decode.d0.loss_dice: 0.5059  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.5183  decode.d1.loss_dice: 0.4795  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.5214  decode.d2.loss_dice: 0.4853  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.5193  decode.d3.loss_dice: 0.4713  decode.d4.loss_cls: 0.0522  decode.d4.loss_mask: 0.5188  decode.d4.loss_dice: 0.4820  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.5186  decode.d5.loss_dice: 0.4812  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.5196  decode.d6.loss_dice: 0.4820  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.5185  decode.d7.loss_dice: 0.4813  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.5194  decode.d8.loss_dice: 0.4710
2025/03/31 09:18:11 - mmengine - INFO - Iter(train) [18250/20000]  base_lr: 1.1164e-05 lr: 1.1164e-05  eta: 0:25:11  time: 0.8655  data_time: 0.0163  memory: 10100  loss: 11.0042  decode.loss_cls: 0.0245  decode.loss_mask: 0.5553  decode.loss_dice: 0.5107  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.5603  decode.d0.loss_dice: 0.5037  decode.d1.loss_cls: 0.0298  decode.d1.loss_mask: 0.5553  decode.d1.loss_dice: 0.5175  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.5451  decode.d2.loss_dice: 0.5003  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.5545  decode.d3.loss_dice: 0.5197  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.5546  decode.d4.loss_dice: 0.5108  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.5544  decode.d5.loss_dice: 0.5129  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.5536  decode.d6.loss_dice: 0.5183  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.5547  decode.d7.loss_dice: 0.5235  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.5537  decode.d8.loss_dice: 0.5191
2025/03/31 09:18:54 - mmengine - INFO - Iter(train) [18300/20000]  base_lr: 1.0877e-05 lr: 1.0877e-05  eta: 0:24:28  time: 0.8639  data_time: 0.0159  memory: 10139  loss: 10.1691  decode.loss_cls: 0.0049  decode.loss_mask: 0.5328  decode.loss_dice: 0.4759  decode.d0.loss_cls: 0.0505  decode.d0.loss_mask: 0.5384  decode.d0.loss_dice: 0.4764  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.5327  decode.d1.loss_dice: 0.4729  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.5326  decode.d2.loss_dice: 0.4765  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.5314  decode.d3.loss_dice: 0.4719  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.5319  decode.d4.loss_dice: 0.4768  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.5309  decode.d5.loss_dice: 0.4655  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.5356  decode.d6.loss_dice: 0.4699  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.5338  decode.d7.loss_dice: 0.4791  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.5331  decode.d8.loss_dice: 0.4756
2025/03/31 09:19:38 - mmengine - INFO - Iter(train) [18350/20000]  base_lr: 1.0588e-05 lr: 1.0588e-05  eta: 0:23:45  time: 0.8641  data_time: 0.0162  memory: 10100  loss: 10.7540  decode.loss_cls: 0.0144  decode.loss_mask: 0.5285  decode.loss_dice: 0.5280  decode.d0.loss_cls: 0.0659  decode.d0.loss_mask: 0.5305  decode.d0.loss_dice: 0.5463  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.5281  decode.d1.loss_dice: 0.5161  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.5294  decode.d2.loss_dice: 0.5117  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.5309  decode.d3.loss_dice: 0.5146  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.5291  decode.d4.loss_dice: 0.5198  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.5263  decode.d5.loss_dice: 0.5238  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.5269  decode.d6.loss_dice: 0.5376  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.5267  decode.d7.loss_dice: 0.5190  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.5300  decode.d8.loss_dice: 0.5355
2025/03/31 09:20:21 - mmengine - INFO - Iter(train) [18400/20000]  base_lr: 1.0299e-05 lr: 1.0299e-05  eta: 0:23:01  time: 0.8633  data_time: 0.0160  memory: 10143  loss: 10.4443  decode.loss_cls: 0.0030  decode.loss_mask: 0.5281  decode.loss_dice: 0.5101  decode.d0.loss_cls: 0.0452  decode.d0.loss_mask: 0.5272  decode.d0.loss_dice: 0.5123  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.5291  decode.d1.loss_dice: 0.5176  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.5259  decode.d2.loss_dice: 0.5153  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.5296  decode.d3.loss_dice: 0.5078  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.5245  decode.d4.loss_dice: 0.5058  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.5301  decode.d5.loss_dice: 0.5167  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.5280  decode.d6.loss_dice: 0.4820  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.5296  decode.d7.loss_dice: 0.5216  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.5273  decode.d8.loss_dice: 0.4987
2025/03/31 09:21:05 - mmengine - INFO - Iter(train) [18450/20000]  base_lr: 1.0009e-05 lr: 1.0009e-05  eta: 0:22:18  time: 0.8685  data_time: 0.0164  memory: 10142  loss: 10.5223  decode.loss_cls: 0.0017  decode.loss_mask: 0.5498  decode.loss_dice: 0.4934  decode.d0.loss_cls: 0.0473  decode.d0.loss_mask: 0.5554  decode.d0.loss_dice: 0.4970  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.5545  decode.d1.loss_dice: 0.4923  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.5512  decode.d2.loss_dice: 0.4997  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.5514  decode.d3.loss_dice: 0.4946  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.5504  decode.d4.loss_dice: 0.4908  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.5524  decode.d5.loss_dice: 0.4936  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.5508  decode.d6.loss_dice: 0.4934  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.5493  decode.d7.loss_dice: 0.4975  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.5486  decode.d8.loss_dice: 0.4840
2025/03/31 09:21:48 - mmengine - INFO - Iter(train) [18500/20000]  base_lr: 9.7180e-06 lr: 9.7180e-06  eta: 0:21:35  time: 0.8662  data_time: 0.0161  memory: 10144  loss: 10.1961  decode.loss_cls: 0.0045  decode.loss_mask: 0.4578  decode.loss_dice: 0.5527  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.4568  decode.d0.loss_dice: 0.5547  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.4592  decode.d1.loss_dice: 0.5545  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.4568  decode.d2.loss_dice: 0.5535  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.4602  decode.d3.loss_dice: 0.5491  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.4558  decode.d4.loss_dice: 0.5584  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4577  decode.d5.loss_dice: 0.5559  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 0.5611  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.4576  decode.d7.loss_dice: 0.5544  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.4597  decode.d8.loss_dice: 0.5517
2025/03/31 09:22:31 - mmengine - INFO - Iter(train) [18550/20000]  base_lr: 9.4259e-06 lr: 9.4259e-06  eta: 0:20:52  time: 0.8649  data_time: 0.0165  memory: 10096  loss: 9.8214  decode.loss_cls: 0.0325  decode.loss_mask: 0.4744  decode.loss_dice: 0.4784  decode.d0.loss_cls: 0.0793  decode.d0.loss_mask: 0.4757  decode.d0.loss_dice: 0.4972  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.4750  decode.d1.loss_dice: 0.4776  decode.d2.loss_cls: 0.0264  decode.d2.loss_mask: 0.4724  decode.d2.loss_dice: 0.4609  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.4748  decode.d3.loss_dice: 0.4794  decode.d4.loss_cls: 0.0327  decode.d4.loss_mask: 0.4735  decode.d4.loss_dice: 0.4578  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.4746  decode.d5.loss_dice: 0.4855  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.4754  decode.d6.loss_dice: 0.4822  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.4726  decode.d7.loss_dice: 0.4733  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.4745  decode.d8.loss_dice: 0.4650
2025/03/31 09:23:15 - mmengine - INFO - Iter(train) [18600/20000]  base_lr: 9.1329e-06 lr: 9.1329e-06  eta: 0:20:09  time: 0.8668  data_time: 0.0161  memory: 10142  loss: 11.4155  decode.loss_cls: 0.0441  decode.loss_mask: 0.5960  decode.loss_dice: 0.4968  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.6021  decode.d0.loss_dice: 0.5203  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.5981  decode.d1.loss_dice: 0.5228  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.5967  decode.d2.loss_dice: 0.5027  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.5952  decode.d3.loss_dice: 0.4966  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.5959  decode.d4.loss_dice: 0.5014  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.5967  decode.d5.loss_dice: 0.5202  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 0.4987  decode.d7.loss_cls: 0.0312  decode.d7.loss_mask: 0.5933  decode.d7.loss_dice: 0.4960  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.5958  decode.d8.loss_dice: 0.5009
2025/03/31 09:23:58 - mmengine - INFO - Iter(train) [18650/20000]  base_lr: 8.8388e-06 lr: 8.8388e-06  eta: 0:19:26  time: 0.8689  data_time: 0.0167  memory: 10142  loss: 10.7857  decode.loss_cls: 0.0378  decode.loss_mask: 0.5547  decode.loss_dice: 0.4916  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.5580  decode.d0.loss_dice: 0.4953  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.5541  decode.d1.loss_dice: 0.4948  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5610  decode.d2.loss_dice: 0.5017  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.5586  decode.d3.loss_dice: 0.5040  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.5530  decode.d4.loss_dice: 0.4976  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.5582  decode.d5.loss_dice: 0.5036  decode.d6.loss_cls: 0.0339  decode.d6.loss_mask: 0.5519  decode.d6.loss_dice: 0.4910  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.5499  decode.d7.loss_dice: 0.4879  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.5501  decode.d8.loss_dice: 0.4901
2025/03/31 09:24:41 - mmengine - INFO - Iter(train) [18700/20000]  base_lr: 8.5436e-06 lr: 8.5436e-06  eta: 0:18:42  time: 0.8635  data_time: 0.0161  memory: 10144  loss: 10.8376  decode.loss_cls: 0.0302  decode.loss_mask: 0.5338  decode.loss_dice: 0.5146  decode.d0.loss_cls: 0.0472  decode.d0.loss_mask: 0.5426  decode.d0.loss_dice: 0.5314  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.5396  decode.d1.loss_dice: 0.5072  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.5381  decode.d2.loss_dice: 0.5061  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.5349  decode.d3.loss_dice: 0.5060  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.5353  decode.d4.loss_dice: 0.5141  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.5339  decode.d5.loss_dice: 0.5122  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.5331  decode.d6.loss_dice: 0.5015  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.5337  decode.d7.loss_dice: 0.5034  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.5335  decode.d8.loss_dice: 0.5227
2025/03/31 09:25:25 - mmengine - INFO - Iter(train) [18750/20000]  base_lr: 8.2473e-06 lr: 8.2473e-06  eta: 0:17:59  time: 0.8655  data_time: 0.0162  memory: 10093  loss: 10.6748  decode.loss_cls: 0.0104  decode.loss_mask: 0.5324  decode.loss_dice: 0.5091  decode.d0.loss_cls: 0.0516  decode.d0.loss_mask: 0.5398  decode.d0.loss_dice: 0.5330  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.5347  decode.d1.loss_dice: 0.5239  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.5317  decode.d2.loss_dice: 0.5103  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.5357  decode.d3.loss_dice: 0.5148  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.5312  decode.d4.loss_dice: 0.5118  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.5335  decode.d5.loss_dice: 0.5130  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.5340  decode.d6.loss_dice: 0.5071  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.5333  decode.d7.loss_dice: 0.5069  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.5320  decode.d8.loss_dice: 0.5143
2025/03/31 09:26:08 - mmengine - INFO - Iter(train) [18800/20000]  base_lr: 7.9498e-06 lr: 7.9498e-06  eta: 0:17:16  time: 0.8638  data_time: 0.0160  memory: 10144  loss: 10.2268  decode.loss_cls: 0.0271  decode.loss_mask: 0.5216  decode.loss_dice: 0.4725  decode.d0.loss_cls: 0.0631  decode.d0.loss_mask: 0.5274  decode.d0.loss_dice: 0.4847  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.5261  decode.d1.loss_dice: 0.4854  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.5216  decode.d2.loss_dice: 0.4870  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.5233  decode.d3.loss_dice: 0.4901  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5224  decode.d4.loss_dice: 0.4813  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.5236  decode.d5.loss_dice: 0.4799  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.5232  decode.d6.loss_dice: 0.4859  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.5245  decode.d7.loss_dice: 0.4906  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.5233  decode.d8.loss_dice: 0.4824
2025/03/31 09:26:51 - mmengine - INFO - Iter(train) [18850/20000]  base_lr: 7.6510e-06 lr: 7.6510e-06  eta: 0:16:33  time: 0.8617  data_time: 0.0159  memory: 10143  loss: 10.5835  decode.loss_cls: 0.0064  decode.loss_mask: 0.5257  decode.loss_dice: 0.5115  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.5343  decode.d0.loss_dice: 0.5284  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.5303  decode.d1.loss_dice: 0.5156  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.5300  decode.d2.loss_dice: 0.5141  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.5291  decode.d3.loss_dice: 0.5132  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.5280  decode.d4.loss_dice: 0.5060  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.5251  decode.d5.loss_dice: 0.5073  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.5242  decode.d6.loss_dice: 0.5136  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.5252  decode.d7.loss_dice: 0.5112  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.5301  decode.d8.loss_dice: 0.5149
2025/03/31 09:27:35 - mmengine - INFO - Iter(train) [18900/20000]  base_lr: 7.3510e-06 lr: 7.3510e-06  eta: 0:15:50  time: 0.8630  data_time: 0.0162  memory: 10139  loss: 10.3067  decode.loss_cls: 0.0193  decode.loss_mask: 0.5119  decode.loss_dice: 0.4948  decode.d0.loss_cls: 0.0438  decode.d0.loss_mask: 0.5182  decode.d0.loss_dice: 0.4923  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.5136  decode.d1.loss_dice: 0.4942  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.5118  decode.d2.loss_dice: 0.4943  decode.d3.loss_cls: 0.0209  decode.d3.loss_mask: 0.5118  decode.d3.loss_dice: 0.4992  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.5114  decode.d4.loss_dice: 0.5010  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.5122  decode.d5.loss_dice: 0.5059  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.5131  decode.d6.loss_dice: 0.4855  decode.d7.loss_cls: 0.0204  decode.d7.loss_mask: 0.5111  decode.d7.loss_dice: 0.4939  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.5107  decode.d8.loss_dice: 0.5048
2025/03/31 09:28:18 - mmengine - INFO - Iter(train) [18950/20000]  base_lr: 7.0496e-06 lr: 7.0496e-06  eta: 0:15:06  time: 0.8648  data_time: 0.0162  memory: 10139  loss: 10.8753  decode.loss_cls: 0.0146  decode.loss_mask: 0.5652  decode.loss_dice: 0.5163  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.5697  decode.d0.loss_dice: 0.5069  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.5694  decode.d1.loss_dice: 0.4901  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.5690  decode.d2.loss_dice: 0.4990  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.5691  decode.d3.loss_dice: 0.5036  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.5665  decode.d4.loss_dice: 0.4981  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.5654  decode.d5.loss_dice: 0.5019  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.5660  decode.d6.loss_dice: 0.4983  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.5667  decode.d7.loss_dice: 0.5035  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.5653  decode.d8.loss_dice: 0.4973
2025/03/31 09:29:01 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 09:29:01 - mmengine - INFO - Iter(train) [19000/20000]  base_lr: 6.7467e-06 lr: 6.7467e-06  eta: 0:14:23  time: 0.8628  data_time: 0.0160  memory: 10142  loss: 11.1027  decode.loss_cls: 0.0037  decode.loss_mask: 0.5950  decode.loss_dice: 0.5032  decode.d0.loss_cls: 0.0558  decode.d0.loss_mask: 0.6043  decode.d0.loss_dice: 0.5120  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.5946  decode.d1.loss_dice: 0.5007  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.5955  decode.d2.loss_dice: 0.5072  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.5965  decode.d3.loss_dice: 0.5017  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.5932  decode.d4.loss_dice: 0.5024  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.5960  decode.d5.loss_dice: 0.5095  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.5957  decode.d6.loss_dice: 0.5080  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.5940  decode.d7.loss_dice: 0.5037  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.5936  decode.d8.loss_dice: 0.5020
2025/03/31 09:29:45 - mmengine - INFO - Iter(train) [19050/20000]  base_lr: 6.4423e-06 lr: 6.4423e-06  eta: 0:13:40  time: 0.8665  data_time: 0.0163  memory: 10094  loss: 9.4510  decode.loss_cls: 0.0203  decode.loss_mask: 0.4564  decode.loss_dice: 0.4554  decode.d0.loss_cls: 0.0482  decode.d0.loss_mask: 0.4624  decode.d0.loss_dice: 0.4844  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.4608  decode.d1.loss_dice: 0.4718  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.4590  decode.d2.loss_dice: 0.4554  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.4612  decode.d3.loss_dice: 0.4624  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.4616  decode.d4.loss_dice: 0.4742  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.4584  decode.d5.loss_dice: 0.4663  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.4577  decode.d6.loss_dice: 0.4586  decode.d7.loss_cls: 0.0199  decode.d7.loss_mask: 0.4566  decode.d7.loss_dice: 0.4610  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.4564  decode.d8.loss_dice: 0.4608
2025/03/31 09:30:28 - mmengine - INFO - Iter(train) [19100/20000]  base_lr: 6.1364e-06 lr: 6.1364e-06  eta: 0:12:57  time: 0.8625  data_time: 0.0160  memory: 10144  loss: 8.8799  decode.loss_cls: 0.0075  decode.loss_mask: 0.4476  decode.loss_dice: 0.4255  decode.d0.loss_cls: 0.0547  decode.d0.loss_mask: 0.4510  decode.d0.loss_dice: 0.4408  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.4499  decode.d1.loss_dice: 0.4267  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.4500  decode.d2.loss_dice: 0.4300  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.4504  decode.d3.loss_dice: 0.4228  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.4456  decode.d4.loss_dice: 0.4275  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.4483  decode.d5.loss_dice: 0.4238  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.4508  decode.d6.loss_dice: 0.4249  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.4479  decode.d7.loss_dice: 0.4207  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.4457  decode.d8.loss_dice: 0.4273
2025/03/31 09:31:11 - mmengine - INFO - Iter(train) [19150/20000]  base_lr: 5.8287e-06 lr: 5.8287e-06  eta: 0:12:14  time: 0.8632  data_time: 0.0161  memory: 10142  loss: 11.2855  decode.loss_cls: 0.0208  decode.loss_mask: 0.5488  decode.loss_dice: 0.5323  decode.d0.loss_cls: 0.0602  decode.d0.loss_mask: 0.5550  decode.d0.loss_dice: 0.5366  decode.d1.loss_cls: 0.0475  decode.d1.loss_mask: 0.5504  decode.d1.loss_dice: 0.5401  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.5521  decode.d2.loss_dice: 0.5409  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.5527  decode.d3.loss_dice: 0.5527  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.5532  decode.d4.loss_dice: 0.5387  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.5490  decode.d5.loss_dice: 0.5343  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.5519  decode.d6.loss_dice: 0.5224  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.5508  decode.d7.loss_dice: 0.5416  decode.d8.loss_cls: 0.0398  decode.d8.loss_mask: 0.5514  decode.d8.loss_dice: 0.5349
2025/03/31 09:31:55 - mmengine - INFO - Iter(train) [19200/20000]  base_lr: 5.5192e-06 lr: 5.5192e-06  eta: 0:11:31  time: 0.8666  data_time: 0.0165  memory: 10095  loss: 10.1518  decode.loss_cls: 0.0315  decode.loss_mask: 0.5053  decode.loss_dice: 0.4809  decode.d0.loss_cls: 0.0605  decode.d0.loss_mask: 0.5053  decode.d0.loss_dice: 0.4909  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.5067  decode.d1.loss_dice: 0.4825  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.5054  decode.d2.loss_dice: 0.4821  decode.d3.loss_cls: 0.0224  decode.d3.loss_mask: 0.5047  decode.d3.loss_dice: 0.4834  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.5032  decode.d4.loss_dice: 0.4731  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.5069  decode.d5.loss_dice: 0.4890  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.5076  decode.d6.loss_dice: 0.4849  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.5064  decode.d7.loss_dice: 0.4828  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.5061  decode.d8.loss_dice: 0.4833
2025/03/31 09:32:38 - mmengine - INFO - Iter(train) [19250/20000]  base_lr: 5.2077e-06 lr: 5.2077e-06  eta: 0:10:47  time: 0.8669  data_time: 0.0168  memory: 10142  loss: 10.1609  decode.loss_cls: 0.0296  decode.loss_mask: 0.5165  decode.loss_dice: 0.4588  decode.d0.loss_cls: 0.0572  decode.d0.loss_mask: 0.5218  decode.d0.loss_dice: 0.4809  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.5141  decode.d1.loss_dice: 0.4560  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.5160  decode.d2.loss_dice: 0.4636  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.5163  decode.d3.loss_dice: 0.4557  decode.d4.loss_cls: 0.0329  decode.d4.loss_mask: 0.5166  decode.d4.loss_dice: 0.4679  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.5208  decode.d5.loss_dice: 0.4599  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.5174  decode.d6.loss_dice: 0.4658  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 0.5171  decode.d7.loss_dice: 0.4601  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.5188  decode.d8.loss_dice: 0.4589
2025/03/31 09:33:22 - mmengine - INFO - Iter(train) [19300/20000]  base_lr: 4.8942e-06 lr: 4.8942e-06  eta: 0:10:04  time: 0.8699  data_time: 0.0167  memory: 10145  loss: 9.9999  decode.loss_cls: 0.0035  decode.loss_mask: 0.5206  decode.loss_dice: 0.4625  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.5209  decode.d0.loss_dice: 0.4699  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.5206  decode.d1.loss_dice: 0.4763  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5189  decode.d2.loss_dice: 0.4660  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.5199  decode.d3.loss_dice: 0.4662  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.5188  decode.d4.loss_dice: 0.4669  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.5175  decode.d5.loss_dice: 0.4729  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.5189  decode.d6.loss_dice: 0.4807  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.5175  decode.d7.loss_dice: 0.4694  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.5182  decode.d8.loss_dice: 0.4652
2025/03/31 09:34:05 - mmengine - INFO - Iter(train) [19350/20000]  base_lr: 4.5784e-06 lr: 4.5784e-06  eta: 0:09:21  time: 0.8633  data_time: 0.0161  memory: 10151  loss: 10.9820  decode.loss_cls: 0.0273  decode.loss_mask: 0.5420  decode.loss_dice: 0.5219  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.5419  decode.d0.loss_dice: 0.5253  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.5413  decode.d1.loss_dice: 0.5479  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.5414  decode.d2.loss_dice: 0.5197  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.5384  decode.d3.loss_dice: 0.5333  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.5423  decode.d4.loss_dice: 0.5279  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.5400  decode.d5.loss_dice: 0.5295  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.5385  decode.d6.loss_dice: 0.5305  decode.d7.loss_cls: 0.0173  decode.d7.loss_mask: 0.5411  decode.d7.loss_dice: 0.5246  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.5405  decode.d8.loss_dice: 0.5075
2025/03/31 09:34:48 - mmengine - INFO - Iter(train) [19400/20000]  base_lr: 4.2602e-06 lr: 4.2602e-06  eta: 0:08:38  time: 0.8639  data_time: 0.0160  memory: 10151  loss: 10.0645  decode.loss_cls: 0.0029  decode.loss_mask: 0.5417  decode.loss_dice: 0.4545  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.5469  decode.d0.loss_dice: 0.4586  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.5437  decode.d1.loss_dice: 0.4576  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.5401  decode.d2.loss_dice: 0.4594  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.5386  decode.d3.loss_dice: 0.4557  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.5399  decode.d4.loss_dice: 0.4555  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.5402  decode.d5.loss_dice: 0.4537  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.5411  decode.d6.loss_dice: 0.4567  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.5420  decode.d7.loss_dice: 0.4564  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.5380  decode.d8.loss_dice: 0.4549
2025/03/31 09:35:32 - mmengine - INFO - Iter(train) [19450/20000]  base_lr: 3.9393e-06 lr: 3.9393e-06  eta: 0:07:55  time: 0.8673  data_time: 0.0162  memory: 10142  loss: 10.1240  decode.loss_cls: 0.0014  decode.loss_mask: 0.5162  decode.loss_dice: 0.4842  decode.d0.loss_cls: 0.0459  decode.d0.loss_mask: 0.5233  decode.d0.loss_dice: 0.4928  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.5195  decode.d1.loss_dice: 0.4938  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.5184  decode.d2.loss_dice: 0.4905  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.5178  decode.d3.loss_dice: 0.4913  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.5161  decode.d4.loss_dice: 0.4853  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.5166  decode.d5.loss_dice: 0.4852  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.5175  decode.d6.loss_dice: 0.4908  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.5144  decode.d7.loss_dice: 0.4841  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.5155  decode.d8.loss_dice: 0.4861
2025/03/31 09:36:15 - mmengine - INFO - Iter(train) [19500/20000]  base_lr: 3.6155e-06 lr: 3.6155e-06  eta: 0:07:11  time: 0.8674  data_time: 0.0165  memory: 10144  loss: 9.8886  decode.loss_cls: 0.0040  decode.loss_mask: 0.4932  decode.loss_dice: 0.4789  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.4919  decode.d0.loss_dice: 0.4905  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 0.4876  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.4919  decode.d2.loss_dice: 0.4822  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.4948  decode.d3.loss_dice: 0.4902  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.4939  decode.d4.loss_dice: 0.4817  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.4923  decode.d5.loss_dice: 0.4858  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.4928  decode.d6.loss_dice: 0.4806  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.4922  decode.d7.loss_dice: 0.4810  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.4911  decode.d8.loss_dice: 0.4890
2025/03/31 09:36:58 - mmengine - INFO - Iter(train) [19550/20000]  base_lr: 3.2884e-06 lr: 3.2884e-06  eta: 0:06:28  time: 0.8811  data_time: 0.0164  memory: 10145  loss: 10.1344  decode.loss_cls: 0.0164  decode.loss_mask: 0.4828  decode.loss_dice: 0.5036  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.4889  decode.d0.loss_dice: 0.5161  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.4837  decode.d1.loss_dice: 0.5213  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.4845  decode.d2.loss_dice: 0.4992  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.4827  decode.d3.loss_dice: 0.5003  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.4808  decode.d4.loss_dice: 0.5057  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.4827  decode.d5.loss_dice: 0.5001  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.4848  decode.d6.loss_dice: 0.5076  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.4817  decode.d7.loss_dice: 0.4839  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.4838  decode.d8.loss_dice: 0.5001
2025/03/31 09:37:42 - mmengine - INFO - Iter(train) [19600/20000]  base_lr: 2.9576e-06 lr: 2.9576e-06  eta: 0:05:45  time: 0.8637  data_time: 0.0162  memory: 10146  loss: 9.5036  decode.loss_cls: 0.0038  decode.loss_mask: 0.4889  decode.loss_dice: 0.4502  decode.d0.loss_cls: 0.0560  decode.d0.loss_mask: 0.4914  decode.d0.loss_dice: 0.4591  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.4859  decode.d1.loss_dice: 0.4549  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.4855  decode.d2.loss_dice: 0.4563  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.4880  decode.d3.loss_dice: 0.4490  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.4860  decode.d4.loss_dice: 0.4547  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.4876  decode.d5.loss_dice: 0.4594  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.4871  decode.d6.loss_dice: 0.4542  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.4859  decode.d7.loss_dice: 0.4516  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.4838  decode.d8.loss_dice: 0.4477
2025/03/31 09:38:25 - mmengine - INFO - Iter(train) [19650/20000]  base_lr: 2.6227e-06 lr: 2.6227e-06  eta: 0:05:02  time: 0.8652  data_time: 0.0165  memory: 10100  loss: 11.2350  decode.loss_cls: 0.0180  decode.loss_mask: 0.5613  decode.loss_dice: 0.5207  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.5641  decode.d0.loss_dice: 0.5291  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.5565  decode.d1.loss_dice: 0.5236  decode.d2.loss_cls: 0.0380  decode.d2.loss_mask: 0.5550  decode.d2.loss_dice: 0.5182  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.5587  decode.d3.loss_dice: 0.5165  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.5570  decode.d4.loss_dice: 0.5291  decode.d5.loss_cls: 0.0197  decode.d5.loss_mask: 0.5592  decode.d5.loss_dice: 0.5274  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 0.5574  decode.d6.loss_dice: 0.5241  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.5554  decode.d7.loss_dice: 0.5251  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.5592  decode.d8.loss_dice: 0.5256
2025/03/31 09:39:08 - mmengine - INFO - Iter(train) [19700/20000]  base_lr: 2.2830e-06 lr: 2.2830e-06  eta: 0:04:19  time: 0.8623  data_time: 0.0162  memory: 10096  loss: 11.4662  decode.loss_cls: 0.0088  decode.loss_mask: 0.5734  decode.loss_dice: 0.5329  decode.d0.loss_cls: 0.0607  decode.d0.loss_mask: 0.5841  decode.d0.loss_dice: 0.5495  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.5757  decode.d1.loss_dice: 0.5334  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.5749  decode.d2.loss_dice: 0.5338  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.5725  decode.d3.loss_dice: 0.5250  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.5720  decode.d4.loss_dice: 0.5152  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.5697  decode.d5.loss_dice: 0.5243  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.5722  decode.d6.loss_dice: 0.5303  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.5713  decode.d7.loss_dice: 0.5377  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.5723  decode.d8.loss_dice: 0.5317
2025/03/31 09:39:52 - mmengine - INFO - Iter(train) [19750/20000]  base_lr: 1.9375e-06 lr: 1.9375e-06  eta: 0:03:35  time: 0.8643  data_time: 0.0160  memory: 10145  loss: 9.5949  decode.loss_cls: 0.0022  decode.loss_mask: 0.5040  decode.loss_dice: 0.4510  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.5043  decode.d0.loss_dice: 0.4488  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.5048  decode.d1.loss_dice: 0.4466  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.5023  decode.d2.loss_dice: 0.4480  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.5043  decode.d3.loss_dice: 0.4479  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.5037  decode.d4.loss_dice: 0.4507  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.5006  decode.d5.loss_dice: 0.4475  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.5026  decode.d6.loss_dice: 0.4452  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.5041  decode.d7.loss_dice: 0.4524  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.5054  decode.d8.loss_dice: 0.4442
2025/03/31 09:40:35 - mmengine - INFO - Iter(train) [19800/20000]  base_lr: 1.5850e-06 lr: 1.5850e-06  eta: 0:02:52  time: 0.8640  data_time: 0.0161  memory: 10143  loss: 10.2805  decode.loss_cls: 0.0050  decode.loss_mask: 0.5417  decode.loss_dice: 0.4795  decode.d0.loss_cls: 0.0441  decode.d0.loss_mask: 0.5453  decode.d0.loss_dice: 0.4765  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.5419  decode.d1.loss_dice: 0.4795  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.5420  decode.d2.loss_dice: 0.4795  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.5418  decode.d3.loss_dice: 0.4782  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5403  decode.d4.loss_dice: 0.4815  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.5405  decode.d5.loss_dice: 0.4749  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.5393  decode.d6.loss_dice: 0.4794  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.5390  decode.d7.loss_dice: 0.4789  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.5391  decode.d8.loss_dice: 0.4788
2025/03/31 09:41:18 - mmengine - INFO - Iter(train) [19850/20000]  base_lr: 1.2234e-06 lr: 1.2234e-06  eta: 0:02:09  time: 0.8656  data_time: 0.0162  memory: 10142  loss: 10.4119  decode.loss_cls: 0.0396  decode.loss_mask: 0.5214  decode.loss_dice: 0.4811  decode.d0.loss_cls: 0.0618  decode.d0.loss_mask: 0.5255  decode.d0.loss_dice: 0.4818  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.5268  decode.d1.loss_dice: 0.4772  decode.d2.loss_cls: 0.0384  decode.d2.loss_mask: 0.5231  decode.d2.loss_dice: 0.4756  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.5234  decode.d3.loss_dice: 0.4687  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.5213  decode.d4.loss_dice: 0.4803  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.5221  decode.d5.loss_dice: 0.4681  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.5225  decode.d6.loss_dice: 0.4855  decode.d7.loss_cls: 0.0368  decode.d7.loss_mask: 0.5230  decode.d7.loss_dice: 0.4789  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.5202  decode.d8.loss_dice: 0.4853
2025/03/31 09:42:02 - mmengine - INFO - Iter(train) [19900/20000]  base_lr: 8.4936e-07 lr: 8.4936e-07  eta: 0:01:26  time: 0.8642  data_time: 0.0168  memory: 10142  loss: 9.6943  decode.loss_cls: 0.0314  decode.loss_mask: 0.4844  decode.loss_dice: 0.4791  decode.d0.loss_cls: 0.0465  decode.d0.loss_mask: 0.4866  decode.d0.loss_dice: 0.4702  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.4838  decode.d1.loss_dice: 0.4704  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.4836  decode.d2.loss_dice: 0.4686  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.4812  decode.d3.loss_dice: 0.4721  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.4839  decode.d4.loss_dice: 0.4708  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.4835  decode.d5.loss_dice: 0.4585  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.4838  decode.d6.loss_dice: 0.4623  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.4841  decode.d7.loss_dice: 0.4553  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.4834  decode.d8.loss_dice: 0.4563
2025/03/31 09:42:45 - mmengine - INFO - Iter(train) [19950/20000]  base_lr: 4.5516e-07 lr: 4.5516e-07  eta: 0:00:43  time: 0.8692  data_time: 0.0173  memory: 10093  loss: 10.2299  decode.loss_cls: 0.0283  decode.loss_mask: 0.5095  decode.loss_dice: 0.4811  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.5193  decode.d0.loss_dice: 0.4961  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.5138  decode.d1.loss_dice: 0.4936  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.5153  decode.d2.loss_dice: 0.4924  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.5109  decode.d3.loss_dice: 0.4912  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.5117  decode.d4.loss_dice: 0.4977  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.5091  decode.d5.loss_dice: 0.4746  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.5115  decode.d6.loss_dice: 0.4873  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.5114  decode.d7.loss_dice: 0.4944  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.5153  decode.d8.loss_dice: 0.4770
2025/03/31 09:43:29 - mmengine - INFO - Exp name: vi2pr_20250331_042624
2025/03/31 09:43:29 - mmengine - INFO - Iter(train) [20000/20000]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 0.8684  data_time: 0.0168  memory: 10093  loss: 9.3084  decode.loss_cls: 0.0046  decode.loss_mask: 0.4836  decode.loss_dice: 0.4312  decode.d0.loss_cls: 0.0682  decode.d0.loss_mask: 0.4904  decode.d0.loss_dice: 0.4424  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.4842  decode.d1.loss_dice: 0.4435  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.4849  decode.d2.loss_dice: 0.4336  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.4834  decode.d3.loss_dice: 0.4306  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.4840  decode.d4.loss_dice: 0.4311  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.4839  decode.d5.loss_dice: 0.4308  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.4861  decode.d6.loss_dice: 0.4285  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.4838  decode.d7.loss_dice: 0.4335  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.4838  decode.d8.loss_dice: 0.4286
2025/03/31 09:43:29 - mmengine - INFO - Saving checkpoint at 20000 iterations
2025/03/31 09:43:35 - mmengine - INFO - Iter(val) [  50/2016]    eta: 0:03:17  time: 0.0996  data_time: 0.0015  memory: 1853  
2025/03/31 09:43:40 - mmengine - INFO - Iter(val) [ 100/2016]    eta: 0:03:12  time: 0.1000  data_time: 0.0013  memory: 1853  
2025/03/31 09:43:45 - mmengine - INFO - Iter(val) [ 150/2016]    eta: 0:03:06  time: 0.0997  data_time: 0.0013  memory: 1853  
2025/03/31 09:43:50 - mmengine - INFO - Iter(val) [ 200/2016]    eta: 0:03:01  time: 0.1002  data_time: 0.0013  memory: 1853  
2025/03/31 09:43:55 - mmengine - INFO - Iter(val) [ 250/2016]    eta: 0:02:56  time: 0.0998  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:00 - mmengine - INFO - Iter(val) [ 300/2016]    eta: 0:02:51  time: 0.0999  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:05 - mmengine - INFO - Iter(val) [ 350/2016]    eta: 0:02:45  time: 0.0940  data_time: 0.0013  memory: 1853  
2025/03/31 09:44:10 - mmengine - INFO - Iter(val) [ 400/2016]    eta: 0:02:39  time: 0.0942  data_time: 0.0013  memory: 1853  
2025/03/31 09:44:15 - mmengine - INFO - Iter(val) [ 450/2016]    eta: 0:02:33  time: 0.0936  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:19 - mmengine - INFO - Iter(val) [ 500/2016]    eta: 0:02:28  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:24 - mmengine - INFO - Iter(val) [ 550/2016]    eta: 0:02:22  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 09:44:29 - mmengine - INFO - Iter(val) [ 600/2016]    eta: 0:02:17  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 09:44:34 - mmengine - INFO - Iter(val) [ 650/2016]    eta: 0:02:12  time: 0.0938  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:38 - mmengine - INFO - Iter(val) [ 700/2016]    eta: 0:02:07  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:43 - mmengine - INFO - Iter(val) [ 750/2016]    eta: 0:02:02  time: 0.0937  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:48 - mmengine - INFO - Iter(val) [ 800/2016]    eta: 0:01:57  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 09:44:52 - mmengine - INFO - Iter(val) [ 850/2016]    eta: 0:01:52  time: 0.0941  data_time: 0.0013  memory: 1853  
2025/03/31 09:44:57 - mmengine - INFO - Iter(val) [ 900/2016]    eta: 0:01:47  time: 0.0947  data_time: 0.0012  memory: 1853  
2025/03/31 09:45:02 - mmengine - INFO - Iter(val) [ 950/2016]    eta: 0:01:42  time: 0.0942  data_time: 0.0012  memory: 1853  
2025/03/31 09:45:07 - mmengine - INFO - Iter(val) [1000/2016]    eta: 0:01:37  time: 0.0993  data_time: 0.0015  memory: 1853  
2025/03/31 09:45:12 - mmengine - INFO - Iter(val) [1050/2016]    eta: 0:01:32  time: 0.0953  data_time: 0.0013  memory: 1853  
2025/03/31 09:45:16 - mmengine - INFO - Iter(val) [1100/2016]    eta: 0:01:28  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 09:45:21 - mmengine - INFO - Iter(val) [1150/2016]    eta: 0:01:23  time: 0.0943  data_time: 0.0012  memory: 1853  
2025/03/31 09:45:26 - mmengine - INFO - Iter(val) [1200/2016]    eta: 0:01:18  time: 0.0955  data_time: 0.0014  memory: 1853  
2025/03/31 09:45:30 - mmengine - INFO - Iter(val) [1250/2016]    eta: 0:01:13  time: 0.0953  data_time: 0.0014  memory: 1853  
2025/03/31 09:45:35 - mmengine - INFO - Iter(val) [1300/2016]    eta: 0:01:08  time: 0.0949  data_time: 0.0013  memory: 1853  
2025/03/31 09:45:40 - mmengine - INFO - Iter(val) [1350/2016]    eta: 0:01:03  time: 0.1013  data_time: 0.0014  memory: 1853  
2025/03/31 09:45:45 - mmengine - INFO - Iter(val) [1400/2016]    eta: 0:00:59  time: 0.1000  data_time: 0.0012  memory: 1853  
2025/03/31 09:45:50 - mmengine - INFO - Iter(val) [1450/2016]    eta: 0:00:54  time: 0.1001  data_time: 0.0012  memory: 1853  
2025/03/31 09:45:55 - mmengine - INFO - Iter(val) [1500/2016]    eta: 0:00:49  time: 0.0996  data_time: 0.0012  memory: 1853  
2025/03/31 09:46:00 - mmengine - INFO - Iter(val) [1550/2016]    eta: 0:00:44  time: 0.0997  data_time: 0.0012  memory: 1853  
2025/03/31 09:46:05 - mmengine - INFO - Iter(val) [1600/2016]    eta: 0:00:40  time: 0.0939  data_time: 0.0012  memory: 1853  
2025/03/31 09:46:10 - mmengine - INFO - Iter(val) [1650/2016]    eta: 0:00:35  time: 0.0940  data_time: 0.0012  memory: 1853  
2025/03/31 09:46:15 - mmengine - INFO - Iter(val) [1700/2016]    eta: 0:00:30  time: 0.0943  data_time: 0.0013  memory: 1853  
2025/03/31 09:46:19 - mmengine - INFO - Iter(val) [1750/2016]    eta: 0:00:25  time: 0.0946  data_time: 0.0013  memory: 1853  
2025/03/31 09:46:24 - mmengine - INFO - Iter(val) [1800/2016]    eta: 0:00:20  time: 0.0944  data_time: 0.0013  memory: 1853  
2025/03/31 09:46:29 - mmengine - INFO - Iter(val) [1850/2016]    eta: 0:00:15  time: 0.0968  data_time: 0.0015  memory: 1853  
2025/03/31 09:46:34 - mmengine - INFO - Iter(val) [1900/2016]    eta: 0:00:11  time: 0.1002  data_time: 0.0013  memory: 1853  
2025/03/31 09:46:39 - mmengine - INFO - Iter(val) [1950/2016]    eta: 0:00:06  time: 0.0997  data_time: 0.0012  memory: 1853  
2025/03/31 09:46:44 - mmengine - INFO - Iter(val) [2000/2016]    eta: 0:00:01  time: 0.1005  data_time: 0.0013  memory: 1853  
2025/03/31 09:46:45 - mmengine - INFO - per class results:
2025/03/31 09:46:45 - mmengine - INFO - 
+--------------------+-------+-------+
|       Class        |  IoU  |  Acc  |
+--------------------+-------+-------+
| impervious_surface | 68.08 | 92.88 |
|      building      | 81.94 | 94.35 |
|   low_vegetation   | 59.06 | 82.06 |
|        tree        | 30.13 | 31.09 |
|        car         |  74.3 | 83.92 |
|      clutter       |  1.35 |  1.36 |
+--------------------+-------+-------+
2025/03/31 09:46:45 - mmengine - INFO - Iter(val) [2016/2016]    aAcc: 75.9500  mIoU: 52.4800  mAcc: 64.2800  data_time: 0.0013  time: 0.0965
